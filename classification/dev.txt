318	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.graphviz<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexer for the DOT language (graphviz).<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups<<NEWL>>from pygments.token import Comment, Keyword, Operator, Name, String, Number, \<<NEWL>>    Punctuation, Whitespace<<NEWL>><<NEWL>><<NEWL>>__all__ = ['GraphvizLexer']<<NEWL>><<NEWL>><<NEWL>>class GraphvizLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For graphviz DOT graph description language.<<NEWL>><<NEWL>>    .. versionadded:: 2.8<<NEWL>>    """"""<<NEWL>>    name = 'Graphviz'<<NEWL>>    url = 'https://www.graphviz.org/doc/info/lang.html'<<NEWL>>    aliases = ['graphviz', 'dot']<<NEWL>>    filenames = ['*.gv', '*.dot']<<NEWL>>    mimetypes = ['text/x-graphviz', 'text/vnd.graphviz']<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'\s+', Whitespace),<<NEWL>>            (r'(#|//).*?$', Comment.Single),<<NEWL>>            (r'/(\\\n)?[*](.|\n)*?[*](\\\n)?/', Comment.Multiline),<<NEWL>>            (r'(?i)(node|edge|graph|digraph|subgraph|strict)\b', Keyword),<<NEWL>>            (r'--|->', Operator),<<NEWL>>            (r'[{}[\]:;,]', Punctuation),<<NEWL>>            (r'(\b\D\w*)(\s*)(=)(\s*)',<<NEWL>>                bygroups(Name.Attribute, Whitespace, Punctuation, Whitespace),<<NEWL>>                'attr_id'),<<NEWL>>            (r'\b(n|ne|e|se|s|sw|w|nw|c|_)\b', Name.Builtin),<<NEWL>>            (r'\b\D\w*', Name.Tag),  # node<<NEWL>>            (r'[-]?((\.[0-9]+)|([0-9]+(\.[0-9]*)?))', Number),<<NEWL>>            (r'""(\\""|[^""])*?""', Name.Tag),  # quoted node<<NEWL>>            (r'<', Punctuation, 'xml'),<<NEWL>>        ],<<NEWL>>        'attr_id': [<<NEWL>>            (r'\b\D\w*', String, '#pop'),<<NEWL>>            (r'[-]?((\.[0-9]+)|([0-9]+(\.[0-9]*)?))', Number, '#pop'),<<NEWL>>            (r'""(\\""|[^""])*?""', String.Double, '#pop'),<<NEWL>>            (r'<', Punctuation, ('#pop', 'xml')),<<NEWL>>        ],<<NEWL>>        'xml': [<<NEWL>>            (r'<', Punctuation, '#push'),<<NEWL>>            (r'>', Punctuation, '#pop'),<<NEWL>>            (r'\s+', Whitespace),<<NEWL>>            (r'[^<>\s]', Name.Tag),<<NEWL>>        ]<<NEWL>>    }"
89	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._yanchor import YanchorValidator<<NEWL>>    from ._y import YValidator<<NEWL>>    from ._xanchor import XanchorValidator<<NEWL>>    from ._x import XValidator<<NEWL>>    from ._visible import VisibleValidator<<NEWL>>    from ._type import TypeValidator<<NEWL>>    from ._templateitemname import TemplateitemnameValidator<<NEWL>>    from ._showactive import ShowactiveValidator<<NEWL>>    from ._pad import PadValidator<<NEWL>>    from ._name import NameValidator<<NEWL>>    from ._font import FontValidator<<NEWL>>    from ._direction import DirectionValidator<<NEWL>>    from ._buttondefaults import ButtondefaultsValidator<<NEWL>>    from ._buttons import ButtonsValidator<<NEWL>>    from ._borderwidth import BorderwidthValidator<<NEWL>>    from ._bordercolor import BordercolorValidator<<NEWL>>    from ._bgcolor import BgcolorValidator<<NEWL>>    from ._active import ActiveValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._yanchor.YanchorValidator"",<<NEWL>>            ""._y.YValidator"",<<NEWL>>            ""._xanchor.XanchorValidator"",<<NEWL>>            ""._x.XValidator"",<<NEWL>>            ""._visible.VisibleValidator"",<<NEWL>>            ""._type.TypeValidator"",<<NEWL>>            ""._templateitemname.TemplateitemnameValidator"",<<NEWL>>            ""._showactive.ShowactiveValidator"",<<NEWL>>            ""._pad.PadValidator"",<<NEWL>>            ""._name.NameValidator"",<<NEWL>>            ""._font.FontValidator"",<<NEWL>>            ""._direction.DirectionValidator"",<<NEWL>>            ""._buttondefaults.ButtondefaultsValidator"",<<NEWL>>            ""._buttons.ButtonsValidator"",<<NEWL>>            ""._borderwidth.BorderwidthValidator"",<<NEWL>>            ""._bordercolor.BordercolorValidator"",<<NEWL>>            ""._bgcolor.BgcolorValidator"",<<NEWL>>            ""._active.ActiveValidator"",<<NEWL>>        ],<<NEWL>>    )"
258	adjudicated	2	"import re<<NEWL>>import textwrap<<NEWL>>import email.message<<NEWL>><<NEWL>>from ._text import FoldedCase<<NEWL>><<NEWL>><<NEWL>>class Message(email.message.Message):<<NEWL>>    multiple_use_keys = set(<<NEWL>>        map(<<NEWL>>            FoldedCase,<<NEWL>>            [<<NEWL>>                'Classifier',<<NEWL>>                'Obsoletes-Dist',<<NEWL>>                'Platform',<<NEWL>>                'Project-URL',<<NEWL>>                'Provides-Dist',<<NEWL>>                'Provides-Extra',<<NEWL>>                'Requires-Dist',<<NEWL>>                'Requires-External',<<NEWL>>                'Supported-Platform',<<NEWL>>                'Dynamic',<<NEWL>>            ],<<NEWL>>        )<<NEWL>>    )<<NEWL>>    """"""<<NEWL>>    Keys that may be indicated multiple times per PEP 566.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __new__(cls, orig: email.message.Message):<<NEWL>>        res = super().__new__(cls)<<NEWL>>        vars(res).update(vars(orig))<<NEWL>>        return res<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        self._headers = self._repair_headers()<<NEWL>><<NEWL>>    # suppress spurious error from mypy<<NEWL>>    def __iter__(self):<<NEWL>>        return super().__iter__()<<NEWL>><<NEWL>>    def _repair_headers(self):<<NEWL>>        def redent(value):<<NEWL>>            ""Correct for RFC822 indentation""<<NEWL>>            if not value or '\n' not in value:<<NEWL>>                return value<<NEWL>>            return textwrap.dedent(' ' * 8 + value)<<NEWL>><<NEWL>>        headers = [(key, redent(value)) for key, value in vars(self)['_headers']]<<NEWL>>        if self._payload:<<NEWL>>            headers.append(('Description', self.get_payload()))<<NEWL>>        return headers<<NEWL>><<NEWL>>    @property<<NEWL>>    def json(self):<<NEWL>>        """"""<<NEWL>>        Convert PackageMetadata to a JSON-compatible format<<NEWL>>        per PEP 0566.<<NEWL>>        """"""<<NEWL>><<NEWL>>        def transform(key):<<NEWL>>            value = self.get_all(key) if key in self.multiple_use_keys else self[key]<<NEWL>>            if key == 'Keywords':<<NEWL>>                value = re.split(r'\s+', value)<<NEWL>>            tk = key.lower().replace('-', '_')<<NEWL>>            return tk, value<<NEWL>><<NEWL>>        return dict(map(transform, map(FoldedCase, self)))"
349	adjudicated	3	"import typing as t<<NEWL>>from threading import local<<NEWL>><<NEWL>>if t.TYPE_CHECKING:<<NEWL>>    import typing_extensions as te<<NEWL>>    from .core import Context<<NEWL>><<NEWL>>_local = local()<<NEWL>><<NEWL>><<NEWL>>@t.overload<<NEWL>>def get_current_context(silent: ""te.Literal[False]"" = False) -> ""Context"":<<NEWL>>    ...<<NEWL>><<NEWL>><<NEWL>>@t.overload<<NEWL>>def get_current_context(silent: bool = ...) -> t.Optional[""Context""]:<<NEWL>>    ...<<NEWL>><<NEWL>><<NEWL>>def get_current_context(silent: bool = False) -> t.Optional[""Context""]:<<NEWL>>    """"""Returns the current click context.  This can be used as a way to<<NEWL>>    access the current context object from anywhere.  This is a more implicit<<NEWL>>    alternative to the :func:`pass_context` decorator.  This function is<<NEWL>>    primarily useful for helpers such as :func:`echo` which might be<<NEWL>>    interested in changing its behavior based on the current context.<<NEWL>><<NEWL>>    To push the current context, :meth:`Context.scope` can be used.<<NEWL>><<NEWL>>    .. versionadded:: 5.0<<NEWL>><<NEWL>>    :param silent: if set to `True` the return value is `None` if no context<<NEWL>>                   is available.  The default behavior is to raise a<<NEWL>>                   :exc:`RuntimeError`.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        return t.cast(""Context"", _local.stack[-1])<<NEWL>>    except (AttributeError, IndexError) as e:<<NEWL>>        if not silent:<<NEWL>>            raise RuntimeError(""There is no active click context."") from e<<NEWL>><<NEWL>>    return None<<NEWL>><<NEWL>><<NEWL>>def push_context(ctx: ""Context"") -> None:<<NEWL>>    """"""Pushes a new context to the current stack.""""""<<NEWL>>    _local.__dict__.setdefault(""stack"", []).append(ctx)<<NEWL>><<NEWL>><<NEWL>>def pop_context() -> None:<<NEWL>>    """"""Removes the top level from the stack.""""""<<NEWL>>    _local.stack.pop()<<NEWL>><<NEWL>><<NEWL>>def resolve_color_default(color: t.Optional[bool] = None) -> t.Optional[bool]:<<NEWL>>    """"""Internal helper to get the default value of the color flag.  If a<<NEWL>>    value is passed it's returned unchanged, otherwise it's looked up from<<NEWL>>    the current context.<<NEWL>>    """"""<<NEWL>>    if color is not None:<<NEWL>>        return color<<NEWL>><<NEWL>>    ctx = get_current_context(silent=True)<<NEWL>><<NEWL>>    if ctx is not None:<<NEWL>>        return ctx.color<<NEWL>><<NEWL>>    return None"
209	adjudicated	0	"# (Â©)Codexbotz<<NEWL>># Recode by @mrismanaziz<<NEWL>># t.me/SharingUserbot & t.me/Lunatic0de<<NEWL>><<NEWL>>from bot import Bot<<NEWL>>from config import OWNER<<NEWL>>from Data import Data<<NEWL>>from pyrogram import filters<<NEWL>>from pyrogram.errors import MessageNotModified<<NEWL>>from pyrogram.types import CallbackQuery, InlineKeyboardMarkup, Message<<NEWL>><<NEWL>><<NEWL>>@Bot.on_message(filters.private & filters.incoming & filters.command(""about""))<<NEWL>>async def _about(client: Bot, msg: Message):<<NEWL>>    await client.send_message(<<NEWL>>        msg.chat.id,<<NEWL>>        Data.ABOUT.format(client.username, OWNER),<<NEWL>>        disable_web_page_preview=True,<<NEWL>>        reply_markup=InlineKeyboardMarkup(Data.mbuttons),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@Bot.on_message(filters.private & filters.incoming & filters.command(""help""))<<NEWL>>async def _help(client: Bot, msg: Message):<<NEWL>>    await client.send_message(<<NEWL>>        msg.chat.id,<<NEWL>>        ""<b>Cara Menggunakan Bot ini</b>\n"" + Data.HELP,<<NEWL>>        disable_web_page_preview=True,<<NEWL>>        reply_markup=InlineKeyboardMarkup(Data.buttons),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@Bot.on_callback_query()<<NEWL>>async def cb_handler(client: Bot, query: CallbackQuery):<<NEWL>>    data = query.data<<NEWL>>    if data == ""about"":<<NEWL>>        try:<<NEWL>>            await query.message.edit_text(<<NEWL>>                text=Data.ABOUT.format(client.username, OWNER),<<NEWL>>                disable_web_page_preview=True,<<NEWL>>                reply_markup=InlineKeyboardMarkup(Data.mbuttons),<<NEWL>>            )<<NEWL>>        except MessageNotModified:<<NEWL>>            pass<<NEWL>>    elif data == ""help"":<<NEWL>>        try:<<NEWL>>            await query.message.edit_text(<<NEWL>>                text=""<b>Cara Menggunakan Bot ini</b>\n"" + Data.HELP,<<NEWL>>                disable_web_page_preview=True,<<NEWL>>                reply_markup=InlineKeyboardMarkup(Data.buttons),<<NEWL>>            )<<NEWL>>        except MessageNotModified:<<NEWL>>            pass<<NEWL>>    elif data == ""close"":<<NEWL>>        await query.message.delete()<<NEWL>>        try:<<NEWL>>            await query.message.reply_to_message.delete()<<NEWL>>        except BaseException:<<NEWL>>            pass"
198	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.roboconf<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for Roboconf DSL.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, words, re<<NEWL>>from pygments.token import Text, Operator, Keyword, Name, Comment<<NEWL>><<NEWL>>__all__ = ['RoboconfGraphLexer', 'RoboconfInstancesLexer']<<NEWL>><<NEWL>><<NEWL>>class RoboconfGraphLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Roboconf graph files.<<NEWL>><<NEWL>>    .. versionadded:: 2.1<<NEWL>>    """"""<<NEWL>>    name = 'Roboconf Graph'<<NEWL>>    aliases = ['roboconf-graph']<<NEWL>>    filenames = ['*.graph']<<NEWL>><<NEWL>>    flags = re.IGNORECASE | re.MULTILINE<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            # Skip white spaces<<NEWL>>            (r'\s+', Text),<<NEWL>><<NEWL>>            # There is one operator<<NEWL>>            (r'=', Operator),<<NEWL>><<NEWL>>            # Keywords<<NEWL>>            (words(('facet', 'import'), suffix=r'\s*\b', prefix=r'\b'), Keyword),<<NEWL>>            (words((<<NEWL>>                'installer', 'extends', 'exports', 'imports', 'facets',<<NEWL>>                'children'), suffix=r'\s*:?', prefix=r'\b'), Name),<<NEWL>><<NEWL>>            # Comments<<NEWL>>            (r'#.*\n', Comment),<<NEWL>><<NEWL>>            # Default<<NEWL>>            (r'[^#]', Text),<<NEWL>>            (r'.*\n', Text)<<NEWL>>        ]<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>class RoboconfInstancesLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Roboconf instances files.<<NEWL>><<NEWL>>    .. versionadded:: 2.1<<NEWL>>    """"""<<NEWL>>    name = 'Roboconf Instances'<<NEWL>>    aliases = ['roboconf-instances']<<NEWL>>    filenames = ['*.instances']<<NEWL>><<NEWL>>    flags = re.IGNORECASE | re.MULTILINE<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>><<NEWL>>            # Skip white spaces<<NEWL>>            (r'\s+', Text),<<NEWL>><<NEWL>>            # Keywords<<NEWL>>            (words(('instance of', 'import'), suffix=r'\s*\b', prefix=r'\b'), Keyword),<<NEWL>>            (words(('name', 'count'), suffix=r's*:?', prefix=r'\b'), Name),<<NEWL>>            (r'\s*[\w.-]+\s*:', Name),<<NEWL>><<NEWL>>            # Comments<<NEWL>>            (r'#.*\n', Comment),<<NEWL>><<NEWL>>            # Default<<NEWL>>            (r'[^#]', Text),<<NEWL>>            (r'.*\n', Text)<<NEWL>>        ]<<NEWL>>    }"
456	adjudicated	0	import json<<NEWL>><<NEWL>>from .oauth import OAuth2Test<<NEWL>><<NEWL>><<NEWL>>class GiteaOAuth2Test(OAuth2Test):<<NEWL>>    backend_path = 'social_core.backends.gitea.GiteaOAuth2'<<NEWL>>    user_data_url = 'https://gitea.com/api/v1/user'<<NEWL>>    expected_username = 'foobar'<<NEWL>>    access_token_body = json.dumps({<<NEWL>>        'access_token': 'foobar',<<NEWL>>        'token_type': 'bearer',<<NEWL>>        'expires_in': 7200,<<NEWL>>        'refresh_token': 'barfoo'<<NEWL>>    })<<NEWL>>    user_data_body = json.dumps({<<NEWL>>        'id': 123456,<<NEWL>>        'login': 'foobar',<<NEWL>>        'full_name': 'Foo Bar',<<NEWL>>        'email': 'foobar@example.com',<<NEWL>>        'avatar_url': 'https://gitea.com/user/avatar/foobar/-1',<<NEWL>>        'language': 'en-US',<<NEWL>>        'is_admin': False,<<NEWL>>        'last_login': '2016-12-28T12:26:19+01:00',<<NEWL>>        'created': '2016-12-28T12:26:19+01:00',<<NEWL>>        'restricted': False,<<NEWL>>        'username': 'foobar'<<NEWL>>    })<<NEWL>><<NEWL>>    def test_login(self):<<NEWL>>        self.do_login()<<NEWL>><<NEWL>>    def test_partial_pipeline(self):<<NEWL>>        self.do_partial_pipeline()<<NEWL>><<NEWL>><<NEWL>>class GiteaCustomDomainOAuth2Test(OAuth2Test):<<NEWL>>    backend_path = 'social_core.backends.gitea.GiteaOAuth2'<<NEWL>>    user_data_url = 'https://example.com/api/v1/user'<<NEWL>>    expected_username = 'foobar'<<NEWL>>    access_token_body = json.dumps({<<NEWL>>        'access_token': 'foobar',<<NEWL>>        'token_type': 'bearer',<<NEWL>>        'expires_in': 7200,<<NEWL>>        'refresh_token': 'barfoo'<<NEWL>>    })<<NEWL>>    user_data_body = json.dumps({<<NEWL>>        'id': 123456,<<NEWL>>        'login': 'foobar',<<NEWL>>        'full_name': 'Foo Bar',<<NEWL>>        'email': 'foobar@example.com',<<NEWL>>        'avatar_url': 'https://example.com/user/avatar/foobar/-1',<<NEWL>>        'language': 'en-US',<<NEWL>>        'is_admin': False,<<NEWL>>        'last_login': '2016-12-28T12:26:19+01:00',<<NEWL>>        'created': '2016-12-28T12:26:19+01:00',<<NEWL>>        'restricted': False,<<NEWL>>        'username': 'foobar'<<NEWL>>    })<<NEWL>><<NEWL>>    def test_login(self):<<NEWL>>        self.strategy.set_settings({<<NEWL>>            'SOCIAL_AUTH_GITEA_API_URL': 'https://example.com'<<NEWL>>        })<<NEWL>>        self.do_login()<<NEWL>><<NEWL>>    def test_partial_pipeline(self):<<NEWL>>        self.strategy.set_settings({<<NEWL>>            'SOCIAL_AUTH_GITEA_API_URL': 'https://example.com'<<NEWL>>        })<<NEWL>>        self.do_partial_pipeline()
462	adjudicated	2	"""""""<<NEWL>>Dummy database backend for Django.<<NEWL>><<NEWL>>Django uses this if the database ENGINE setting is empty (None or empty string).<<NEWL>><<NEWL>>Each of these API functions, except connection.close(), raise<<NEWL>>ImproperlyConfigured.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.db.backends.base.base import BaseDatabaseWrapper<<NEWL>>from django.db.backends.base.client import BaseDatabaseClient<<NEWL>>from django.db.backends.base.creation import BaseDatabaseCreation<<NEWL>>from django.db.backends.base.introspection import BaseDatabaseIntrospection<<NEWL>>from django.db.backends.base.operations import BaseDatabaseOperations<<NEWL>>from django.db.backends.dummy.features import DummyDatabaseFeatures<<NEWL>><<NEWL>><<NEWL>>def complain(*args, **kwargs):<<NEWL>>    raise ImproperlyConfigured(<<NEWL>>        ""settings.DATABASES is improperly configured. ""<<NEWL>>        ""Please supply the ENGINE value. Check ""<<NEWL>>        ""settings documentation for more details.""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def ignore(*args, **kwargs):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class DatabaseOperations(BaseDatabaseOperations):<<NEWL>>    quote_name = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseClient(BaseDatabaseClient):<<NEWL>>    runshell = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseCreation(BaseDatabaseCreation):<<NEWL>>    create_test_db = ignore<<NEWL>>    destroy_test_db = ignore<<NEWL>><<NEWL>><<NEWL>>class DatabaseIntrospection(BaseDatabaseIntrospection):<<NEWL>>    get_table_list = complain<<NEWL>>    get_table_description = complain<<NEWL>>    get_relations = complain<<NEWL>>    get_indexes = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseWrapper(BaseDatabaseWrapper):<<NEWL>>    operators = {}<<NEWL>>    # Override the base class implementations with null<<NEWL>>    # implementations. Anything that tries to actually<<NEWL>>    # do something raises complain; anything that tries<<NEWL>>    # to rollback or undo something raises ignore.<<NEWL>>    _cursor = complain<<NEWL>>    ensure_connection = complain<<NEWL>>    _commit = complain<<NEWL>>    _rollback = ignore<<NEWL>>    _close = ignore<<NEWL>>    _savepoint = ignore<<NEWL>>    _savepoint_commit = complain<<NEWL>>    _savepoint_rollback = ignore<<NEWL>>    _set_autocommit = complain<<NEWL>>    # Classes instantiated in __init__().<<NEWL>>    client_class = DatabaseClient<<NEWL>>    creation_class = DatabaseCreation<<NEWL>>    features_class = DummyDatabaseFeatures<<NEWL>>    introspection_class = DatabaseIntrospection<<NEWL>>    ops_class = DatabaseOperations<<NEWL>><<NEWL>>    def is_usable(self):<<NEWL>>        return True"
433	adjudicated	2	"# Copyright 2016 Julien Danjou<<NEWL>># Copyright 2016 Joshua Harlow<<NEWL>># Copyright 2013-2014 Ray Holder<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import sys<<NEWL>>import typing<<NEWL>><<NEWL>><<NEWL>># sys.maxsize:<<NEWL>># An integer giving the maximum value a variable of type Py_ssize_t can take.<<NEWL>>MAX_WAIT = sys.maxsize / 2<<NEWL>><<NEWL>><<NEWL>>def find_ordinal(pos_num: int) -> str:<<NEWL>>    # See: https://en.wikipedia.org/wiki/English_numerals#Ordinal_numbers<<NEWL>>    if pos_num == 0:<<NEWL>>        return ""th""<<NEWL>>    elif pos_num == 1:<<NEWL>>        return ""st""<<NEWL>>    elif pos_num == 2:<<NEWL>>        return ""nd""<<NEWL>>    elif pos_num == 3:<<NEWL>>        return ""rd""<<NEWL>>    elif 4 <= pos_num <= 20:<<NEWL>>        return ""th""<<NEWL>>    else:<<NEWL>>        return find_ordinal(pos_num % 10)<<NEWL>><<NEWL>><<NEWL>>def to_ordinal(pos_num: int) -> str:<<NEWL>>    return f""{pos_num}{find_ordinal(pos_num)}""<<NEWL>><<NEWL>><<NEWL>>def get_callback_name(cb: typing.Callable[..., typing.Any]) -> str:<<NEWL>>    """"""Get a callback fully-qualified name.<<NEWL>><<NEWL>>    If no name can be produced ``repr(cb)`` is called and returned.<<NEWL>>    """"""<<NEWL>>    segments = []<<NEWL>>    try:<<NEWL>>        segments.append(cb.__qualname__)<<NEWL>>    except AttributeError:<<NEWL>>        try:<<NEWL>>            segments.append(cb.__name__)<<NEWL>>        except AttributeError:<<NEWL>>            pass<<NEWL>>    if not segments:<<NEWL>>        return repr(cb)<<NEWL>>    else:<<NEWL>>        try:<<NEWL>>            # When running under sphinx it appears this can be none?<<NEWL>>            if cb.__module__:<<NEWL>>                segments.insert(0, cb.__module__)<<NEWL>>        except AttributeError:<<NEWL>>            pass<<NEWL>>        return ""."".join(segments)"
491	adjudicated	3	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START automl_video_classification_list_datasets_beta]<<NEWL>># [START automl_video_object_tracking_list_datasets_beta]<<NEWL>>from google.cloud import automl_v1beta1 as automl<<NEWL>><<NEWL>><<NEWL>>def list_datasets(project_id=""YOUR_PROJECT_ID""):<<NEWL>>    """"""List datasets.""""""<<NEWL>>    client = automl.AutoMlClient()<<NEWL>>    # A resource that represents Google Cloud Platform location.<<NEWL>>    project_location = f""projects/{project_id}/locations/us-central1""<<NEWL>><<NEWL>>    # List all the datasets available in the region.<<NEWL>>    request = automl.ListDatasetsRequest(parent=project_location, filter="""")<<NEWL>>    response = client.list_datasets(request=request)<<NEWL>><<NEWL>>    print(""List of datasets:"")<<NEWL>>    for dataset in response:<<NEWL>>        print(""Dataset name: {}"".format(dataset.name))<<NEWL>>        print(""Dataset id: {}"".format(dataset.name.split(""/"")[-1]))<<NEWL>>        print(""Dataset display name: {}"".format(dataset.display_name))<<NEWL>>        print(""Dataset create time: {}"".format(dataset.create_time))<<NEWL>>        # [END automl_video_object_tracking_list_datasets_beta]<<NEWL>><<NEWL>>        print(<<NEWL>>            ""Video classification dataset metadata: {}"".format(<<NEWL>>                dataset.video_classification_dataset_metadata<<NEWL>>            )<<NEWL>>        )<<NEWL>>        # [END automl_video_classification_list_datasets_beta]<<NEWL>><<NEWL>>        # [START automl_video_object_tracking_list_datasets_beta]<<NEWL>>        print(<<NEWL>>            ""Video object tracking dataset metadata: {}"".format(<<NEWL>>                dataset.video_object_tracking_dataset_metadata<<NEWL>>            )<<NEWL>>        )<<NEWL>>        # [END automl_video_object_tracking_list_datasets_beta]"
413	adjudicated	2	"# -*- coding: utf-8 -*-<<NEWL>>""""""<<NEWL>>set_fake_passwords.py<<NEWL>><<NEWL>>    Reset all user passwords to a common value. Useful for testing in a<<NEWL>>    development environment. As such, this command is only available when<<NEWL>>    setting.DEBUG is True.<<NEWL>><<NEWL>>""""""<<NEWL>>from typing import List<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.contrib.auth import get_user_model<<NEWL>>from django.core.management.base import BaseCommand, CommandError<<NEWL>><<NEWL>>from django_extensions.management.utils import signalcommand<<NEWL>><<NEWL>>DEFAULT_FAKE_PASSWORD = 'password'<<NEWL>><<NEWL>><<NEWL>>class Command(BaseCommand):<<NEWL>>    help = 'DEBUG only: sets all user passwords to a common value (""%s"" by default)' % (DEFAULT_FAKE_PASSWORD, )<<NEWL>>    requires_system_checks: List[str] = []<<NEWL>><<NEWL>>    def add_arguments(self, parser):<<NEWL>>        super().add_arguments(parser)<<NEWL>>        parser.add_argument(<<NEWL>>            '--prompt', dest='prompt_passwd', default=False,<<NEWL>>            action='store_true',<<NEWL>>            help='Prompts for the new password to apply to all users'<<NEWL>>        )<<NEWL>>        parser.add_argument(<<NEWL>>            '--password', dest='default_passwd', default=DEFAULT_FAKE_PASSWORD,<<NEWL>>            help='Use this as default password.'<<NEWL>>        )<<NEWL>><<NEWL>>    @signalcommand<<NEWL>>    def handle(self, *args, **options):<<NEWL>>        if not settings.DEBUG:<<NEWL>>            raise CommandError('Only available in debug mode')<<NEWL>><<NEWL>>        if options['prompt_passwd']:<<NEWL>>            from getpass import getpass<<NEWL>>            passwd = getpass('Password: ')<<NEWL>>            if not passwd:<<NEWL>>                raise CommandError('You must enter a valid password')<<NEWL>>        else:<<NEWL>>            passwd = options['default_passwd']<<NEWL>><<NEWL>>        User = get_user_model()<<NEWL>>        user = User()<<NEWL>>        user.set_password(passwd)<<NEWL>>        count = User.objects.all().update(password=user.password)<<NEWL>><<NEWL>>        print('Reset %d passwords' % count)"
502	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""histogram2d"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
442	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from pandas.util._decorators import deprecate_kwarg<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"")<<NEWL>>def _f1(new=False):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>_f2_mappings = {""yes"": True, ""no"": False}<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"", _f2_mappings)<<NEWL>>def _f2(new=False):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>def _f3_mapping(x):<<NEWL>>    return x + 1<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"", _f3_mapping)<<NEWL>>def _f3(new=0):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key,klass"", [(""old"", FutureWarning), (""new"", None)])<<NEWL>>def test_deprecate_kwarg(key, klass):<<NEWL>>    x = 78<<NEWL>><<NEWL>>    with tm.assert_produces_warning(klass):<<NEWL>>        assert _f1(**{key: x}) == x<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", list(_f2_mappings.keys()))<<NEWL>>def test_dict_deprecate_kwarg(key):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f2(old=key) == _f2_mappings[key]<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", [""bogus"", 12345, -1.23])<<NEWL>>def test_missing_deprecate_kwarg(key):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f2(old=key) == key<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""x"", [1, -1.4, 0])<<NEWL>>def test_callable_deprecate_kwarg(x):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f3(old=x) == _f3_mapping(x)<<NEWL>><<NEWL>><<NEWL>>def test_callable_deprecate_kwarg_fail():<<NEWL>>    msg = ""((can only|cannot) concatenate)|(must be str)|(Can't convert)""<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        _f3(old=""hello"")<<NEWL>><<NEWL>><<NEWL>>def test_bad_deprecate_kwarg():<<NEWL>>    msg = ""mapping from old to new argument values must be dict or callable!""<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>><<NEWL>>        @deprecate_kwarg(""old"", ""new"", 0)<<NEWL>>        def f4(new=None):<<NEWL>>            return new<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", None)<<NEWL>>def _f4(old=True, unchanged=True):<<NEWL>>    return old, unchanged<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", [""old"", ""unchanged""])<<NEWL>>def test_deprecate_keyword(key):<<NEWL>>    x = 9<<NEWL>><<NEWL>>    if key == ""old"":<<NEWL>>        klass = FutureWarning<<NEWL>>        expected = (x, True)<<NEWL>>    else:<<NEWL>>        klass = None<<NEWL>>        expected = (True, x)<<NEWL>><<NEWL>>    with tm.assert_produces_warning(klass):<<NEWL>>        assert _f4(**{key: x}) == expected"
485	adjudicated	4	"""""""<<NEWL>>NGP VAN's `ActionID` Provider<<NEWL>><<NEWL>>http://developers.ngpvan.com/action-id<<NEWL>>""""""<<NEWL>>from openid.extensions import ax<<NEWL>><<NEWL>>from .open_id import OpenIdAuth<<NEWL>><<NEWL>><<NEWL>>class ActionIDOpenID(OpenIdAuth):<<NEWL>>    """"""<<NEWL>>    NGP VAN's ActionID OpenID 1.1 authentication backend<<NEWL>>    """"""<<NEWL>>    name = 'actionid-openid'<<NEWL>>    URL = 'https://accounts.ngpvan.com/Home/Xrds'<<NEWL>>    USERNAME_KEY = 'email'<<NEWL>><<NEWL>>    def get_ax_attributes(self):<<NEWL>>        """"""<<NEWL>>        Return the AX attributes that ActionID responds with, as well as the<<NEWL>>        user data result that it must map to.<<NEWL>>        """"""<<NEWL>>        return [<<NEWL>>            ('http://openid.net/schema/contact/internet/email', 'email'),<<NEWL>>            ('http://openid.net/schema/contact/phone/business', 'phone'),<<NEWL>>            ('http://openid.net/schema/namePerson/first', 'first_name'),<<NEWL>>            ('http://openid.net/schema/namePerson/last', 'last_name'),<<NEWL>>            ('http://openid.net/schema/namePerson', 'fullname'),<<NEWL>>        ]<<NEWL>><<NEWL>>    def setup_request(self, params=None):<<NEWL>>        """"""<<NEWL>>        Setup the OpenID request<<NEWL>><<NEWL>>        Because ActionID does not advertise the availiability of AX attributes<<NEWL>>        nor use standard attribute aliases, we need to setup the attributes<<NEWL>>        manually instead of rely on the parent OpenIdAuth.setup_request()<<NEWL>>        """"""<<NEWL>>        request = self.openid_request(params)<<NEWL>><<NEWL>>        fetch_request = ax.FetchRequest()<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/contact/internet/email',<<NEWL>>            alias='ngpvanemail',<<NEWL>>            required=True<<NEWL>>        ))<<NEWL>><<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/contact/phone/business',<<NEWL>>            alias='ngpvanphone',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/namePerson/first',<<NEWL>>            alias='ngpvanfirstname',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/namePerson/last',<<NEWL>>            alias='ngpvanlastname',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        request.addExtension(fetch_request)<<NEWL>><<NEWL>>        return request"
476	adjudicated	1	"import pytest<<NEWL>><<NEWL>>from pandas.util._validators import validate_args<<NEWL>><<NEWL>>_fname = ""func""<<NEWL>><<NEWL>><<NEWL>>def test_bad_min_fname_arg_count():<<NEWL>>    msg = ""'max_fname_arg_count' must be non-negative""<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        validate_args(_fname, (None,), -1, ""foo"")<<NEWL>><<NEWL>><<NEWL>>def test_bad_arg_length_max_value_single():<<NEWL>>    args = (None, None)<<NEWL>>    compat_args = (""foo"",)<<NEWL>><<NEWL>>    min_fname_arg_count = 0<<NEWL>>    max_length = len(compat_args) + min_fname_arg_count<<NEWL>>    actual_length = len(args) + min_fname_arg_count<<NEWL>>    msg = (<<NEWL>>        rf""{_fname}\(\) takes at most {max_length} ""<<NEWL>>        rf""argument \({actual_length} given\)""<<NEWL>>    )<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        validate_args(_fname, args, min_fname_arg_count, compat_args)<<NEWL>><<NEWL>><<NEWL>>def test_bad_arg_length_max_value_multiple():<<NEWL>>    args = (None, None)<<NEWL>>    compat_args = {""foo"": None}<<NEWL>><<NEWL>>    min_fname_arg_count = 2<<NEWL>>    max_length = len(compat_args) + min_fname_arg_count<<NEWL>>    actual_length = len(args) + min_fname_arg_count<<NEWL>>    msg = (<<NEWL>>        rf""{_fname}\(\) takes at most {max_length} ""<<NEWL>>        rf""arguments \({actual_length} given\)""<<NEWL>>    )<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        validate_args(_fname, args, min_fname_arg_count, compat_args)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""i"", range(1, 3))<<NEWL>>def test_not_all_defaults(i):<<NEWL>>    bad_arg = ""foo""<<NEWL>>    msg = (<<NEWL>>        f""the '{bad_arg}' parameter is not supported ""<<NEWL>>        rf""in the pandas implementation of {_fname}\(\)""<<NEWL>>    )<<NEWL>><<NEWL>>    compat_args = {""foo"": 2, ""bar"": -1, ""baz"": 3}<<NEWL>>    arg_vals = (1, -1, 3)<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        validate_args(_fname, arg_vals[:i], 2, compat_args)<<NEWL>><<NEWL>><<NEWL>>def test_validation():<<NEWL>>    # No exceptions should be raised.<<NEWL>>    validate_args(_fname, (None,), 2, {""out"": None})<<NEWL>><<NEWL>>    compat_args = {""axis"": 1, ""out"": None}<<NEWL>>    validate_args(_fname, (1, None), 2, compat_args)"
427	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the PostGIS backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class PostGISGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' view from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.3.2.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_catalog = models.CharField(max_length=256)<<NEWL>>    f_table_schema = models.CharField(max_length=256)<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    type = models.CharField(max_length=30)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class PostGISSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.2.1.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
369	adjudicated	3	"""""""<<NEWL>>    pygments.filter<<NEWL>>    ~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Module that implements the default filter.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def apply_filters(stream, filters, lexer=None):<<NEWL>>    """"""<<NEWL>>    Use this method to apply an iterable of filters to<<NEWL>>    a stream. If lexer is given it's forwarded to the<<NEWL>>    filter, otherwise the filter receives `None`.<<NEWL>>    """"""<<NEWL>>    def _apply(filter_, stream):<<NEWL>>        yield from filter_.filter(lexer, stream)<<NEWL>>    for filter_ in filters:<<NEWL>>        stream = _apply(filter_, stream)<<NEWL>>    return stream<<NEWL>><<NEWL>><<NEWL>>def simplefilter(f):<<NEWL>>    """"""<<NEWL>>    Decorator that converts a function into a filter::<<NEWL>><<NEWL>>        @simplefilter<<NEWL>>        def lowercase(self, lexer, stream, options):<<NEWL>>            for ttype, value in stream:<<NEWL>>                yield ttype, value.lower()<<NEWL>>    """"""<<NEWL>>    return type(f.__name__, (FunctionFilter,), {<<NEWL>>        '__module__': getattr(f, '__module__'),<<NEWL>>        '__doc__': f.__doc__,<<NEWL>>        'function': f,<<NEWL>>    })<<NEWL>><<NEWL>><<NEWL>>class Filter:<<NEWL>>    """"""<<NEWL>>    Default filter. Subclass this class or use the `simplefilter`<<NEWL>>    decorator to create own filters.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, **options):<<NEWL>>        self.options = options<<NEWL>><<NEWL>>    def filter(self, lexer, stream):<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>><<NEWL>>class FunctionFilter(Filter):<<NEWL>>    """"""<<NEWL>>    Abstract class used by `simplefilter` to create simple<<NEWL>>    function filters on the fly. The `simplefilter` decorator<<NEWL>>    automatically creates subclasses of this class for<<NEWL>>    functions passed to it.<<NEWL>>    """"""<<NEWL>>    function = None<<NEWL>><<NEWL>>    def __init__(self, **options):<<NEWL>>        if not hasattr(self, 'function'):<<NEWL>>            raise TypeError('%r used without bound function' %<<NEWL>>                            self.__class__.__name__)<<NEWL>>        Filter.__init__(self, **options)<<NEWL>><<NEWL>>    def filter(self, lexer, stream):<<NEWL>>        # pylint: disable=not-callable<<NEWL>>        yield from self.function(lexer, stream, self.options)"
229	adjudicated	0	"# Licensed to the Software Freedom Conservancy (SFC) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The SFC licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from .firefox.webdriver import WebDriver as Firefox  # noqa<<NEWL>>from .firefox.firefox_profile import FirefoxProfile  # noqa<<NEWL>>from .firefox.options import Options as FirefoxOptions  # noqa<<NEWL>>from .chrome.webdriver import WebDriver as Chrome  # noqa<<NEWL>>from .chrome.options import Options as ChromeOptions  # noqa<<NEWL>>from .ie.webdriver import WebDriver as Ie  # noqa<<NEWL>>from .ie.options import Options as IeOptions  # noqa<<NEWL>>from .edge.webdriver import WebDriver as Edge  # noqa<<NEWL>>from .opera.webdriver import WebDriver as Opera  # noqa<<NEWL>>from .safari.webdriver import WebDriver as Safari  # noqa<<NEWL>>from .blackberry.webdriver import WebDriver as BlackBerry  # noqa<<NEWL>>from .phantomjs.webdriver import WebDriver as PhantomJS  # noqa<<NEWL>>from .android.webdriver import WebDriver as Android  # noqa<<NEWL>>from .webkitgtk.webdriver import WebDriver as WebKitGTK # noqa<<NEWL>>from .webkitgtk.options import Options as WebKitGTKOptions # noqa<<NEWL>>from .remote.webdriver import WebDriver as Remote  # noqa<<NEWL>>from .common.desired_capabilities import DesiredCapabilities  # noqa<<NEWL>>from .common.action_chains import ActionChains  # noqa<<NEWL>>from .common.touch_actions import TouchActions  # noqa<<NEWL>>from .common.proxy import Proxy  # noqa<<NEWL>><<NEWL>>__version__ = '3.14.1'"
338	adjudicated	2	""""""" Test functions for linalg module using the matrix class.""""""<<NEWL>>import numpy as np<<NEWL>><<NEWL>>from numpy.linalg.tests.test_linalg import (<<NEWL>>    LinalgCase, apply_tag, TestQR as _TestQR, LinalgTestCase,<<NEWL>>    _TestNorm2D, _TestNormDoubleBase, _TestNormSingleBase, _TestNormInt64Base,<<NEWL>>    SolveCases, InvCases, EigvalsCases, EigCases, SVDCases, CondCases,<<NEWL>>    PinvCases, DetCases, LstsqCases)<<NEWL>><<NEWL>><<NEWL>>CASES = []<<NEWL>><<NEWL>># square test cases<<NEWL>>CASES += apply_tag('square', [<<NEWL>>    LinalgCase(""0x0_matrix"",<<NEWL>>               np.empty((0, 0), dtype=np.double).view(np.matrix),<<NEWL>>               np.empty((0, 1), dtype=np.double).view(np.matrix),<<NEWL>>               tags={'size-0'}),<<NEWL>>    LinalgCase(""matrix_b_only"",<<NEWL>>               np.array([[1., 2.], [3., 4.]]),<<NEWL>>               np.matrix([2., 1.]).T),<<NEWL>>    LinalgCase(""matrix_a_and_b"",<<NEWL>>               np.matrix([[1., 2.], [3., 4.]]),<<NEWL>>               np.matrix([2., 1.]).T),<<NEWL>>])<<NEWL>><<NEWL>># hermitian test-cases<<NEWL>>CASES += apply_tag('hermitian', [<<NEWL>>    LinalgCase(""hmatrix_a_and_b"",<<NEWL>>               np.matrix([[1., 2.], [2., 1.]]),<<NEWL>>               None),<<NEWL>>])<<NEWL>># No need to make generalized or strided cases for matrices.<<NEWL>><<NEWL>><<NEWL>>class MatrixTestCase(LinalgTestCase):<<NEWL>>    TEST_CASES = CASES<<NEWL>><<NEWL>><<NEWL>>class TestSolveMatrix(SolveCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestInvMatrix(InvCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestEigvalsMatrix(EigvalsCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestEigMatrix(EigCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestSVDMatrix(SVDCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestCondMatrix(CondCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestPinvMatrix(PinvCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestDetMatrix(DetCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestLstsqMatrix(LstsqCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class _TestNorm2DMatrix(_TestNorm2D):<<NEWL>>    array = np.matrix<<NEWL>><<NEWL>><<NEWL>>class TestNormDoubleMatrix(_TestNorm2DMatrix, _TestNormDoubleBase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestNormSingleMatrix(_TestNorm2DMatrix, _TestNormSingleBase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestNormInt64Matrix(_TestNorm2DMatrix, _TestNormInt64Base):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestQRMatrix(_TestQR):<<NEWL>>    array = np.matrix"
278	adjudicated	0	# Copyright (c) 2020, Oracle and/or its affiliates.<<NEWL>>#<<NEWL>># This program is free software; you can redistribute it and/or modify<<NEWL>># it under the terms of the GNU General Public License, version 2.0, as<<NEWL>># published by the Free Software Foundation.<<NEWL>>#<<NEWL>># This program is also distributed with certain software (including<<NEWL>># but not limited to OpenSSL) that is licensed under separate terms,<<NEWL>># as designated in a particular file or component or in included license<<NEWL>># documentation.  The authors of MySQL hereby grant you an<<NEWL>># additional permission to link the program and your derivative works<<NEWL>># with the separately licensed software that they have included with<<NEWL>># MySQL.<<NEWL>>#<<NEWL>># Without limiting anything contained in the foregoing, this file,<<NEWL>># which is part of MySQL Connector/Python, is also subject to the<<NEWL>># Universal FOSS Exception, version 1.0, a copy of which can be found at<<NEWL>># http://oss.oracle.com/licenses/universal-foss-exception.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but<<NEWL>># WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.<<NEWL>># See the GNU General Public License, version 2.0, for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License<<NEWL>># along with this program; if not, write to the Free Software Foundation, Inc.,<<NEWL>># 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA<<NEWL>><<NEWL>>from django.db.backends.mysql.features import DatabaseFeatures as MySQLDatabaseFeatures<<NEWL>>from django.utils.functional import cached_property<<NEWL>><<NEWL>><<NEWL>>class DatabaseFeatures(MySQLDatabaseFeatures):<<NEWL>>    empty_fetchmany_value = []<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def can_introspect_check_constraints(self):<<NEWL>>        return self.connection.mysql_version >= (8, 0, 16)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def supports_microsecond_precision(self):<<NEWL>>        if self.connection.mysql_version >= (5, 6, 3):<<NEWL>>            return True<<NEWL>>        return False
268	adjudicated	1	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools.extern import six<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        ('match=', 'm', ""patterns to match (required)""),<<NEWL>>        ('dist-dir=', 'd', ""directory where the distributions are""),<<NEWL>>        ('keep=', 'k', ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"")<<NEWL>>        if isinstance(self.match, six.string_types):<<NEWL>>            self.match = [<<NEWL>>                convert_path(p.strip()) for p in self.match.split(',')<<NEWL>>            ]<<NEWL>>        self.set_undefined_options('bdist', ('dist_dir', 'dist_dir'))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + '*' + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep:]<<NEWL>>            for (t, f) in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
328	adjudicated	0	"from esphome.components import fan<<NEWL>>import esphome.config_validation as cv<<NEWL>>import esphome.codegen as cg<<NEWL>>from esphome.const import CONF_OUTPUT_ID, CONF_SPEED_COUNT, CONF_SWITCH_DATAPOINT<<NEWL>>from .. import tuya_ns, CONF_TUYA_ID, Tuya<<NEWL>><<NEWL>>DEPENDENCIES = [""tuya""]<<NEWL>><<NEWL>>CONF_SPEED_DATAPOINT = ""speed_datapoint""<<NEWL>>CONF_OSCILLATION_DATAPOINT = ""oscillation_datapoint""<<NEWL>>CONF_DIRECTION_DATAPOINT = ""direction_datapoint""<<NEWL>><<NEWL>>TuyaFan = tuya_ns.class_(""TuyaFan"", cg.Component, fan.Fan)<<NEWL>><<NEWL>>CONFIG_SCHEMA = cv.All(<<NEWL>>    fan.FAN_SCHEMA.extend(<<NEWL>>        {<<NEWL>>            cv.GenerateID(CONF_OUTPUT_ID): cv.declare_id(TuyaFan),<<NEWL>>            cv.GenerateID(CONF_TUYA_ID): cv.use_id(Tuya),<<NEWL>>            cv.Optional(CONF_OSCILLATION_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SPEED_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SWITCH_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_DIRECTION_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SPEED_COUNT, default=3): cv.int_range(min=1, max=256),<<NEWL>>        }<<NEWL>>    ).extend(cv.COMPONENT_SCHEMA),<<NEWL>>    cv.has_at_least_one_key(CONF_SPEED_DATAPOINT, CONF_SWITCH_DATAPOINT),<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    parent = await cg.get_variable(config[CONF_TUYA_ID])<<NEWL>><<NEWL>>    var = cg.new_Pvariable(config[CONF_OUTPUT_ID], parent, config[CONF_SPEED_COUNT])<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await fan.register_fan(var, config)<<NEWL>><<NEWL>>    if CONF_SPEED_DATAPOINT in config:<<NEWL>>        cg.add(var.set_speed_id(config[CONF_SPEED_DATAPOINT]))<<NEWL>>    if CONF_SWITCH_DATAPOINT in config:<<NEWL>>        cg.add(var.set_switch_id(config[CONF_SWITCH_DATAPOINT]))<<NEWL>>    if CONF_OSCILLATION_DATAPOINT in config:<<NEWL>>        cg.add(var.set_oscillation_id(config[CONF_OSCILLATION_DATAPOINT]))<<NEWL>>    if CONF_DIRECTION_DATAPOINT in config:<<NEWL>>        cg.add(var.set_direction_id(config[CONF_DIRECTION_DATAPOINT]))"
239	adjudicated	3	"# Copyright 2015 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample App Engine application demonstrating how to use the Namespace Manager<<NEWL>>API with Datastore.<<NEWL>><<NEWL>>For more information, see README.md.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>>from google.appengine.api import namespace_manager<<NEWL>>from google.appengine.ext import ndb<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class Counter(ndb.Model):<<NEWL>>    count = ndb.IntegerProperty()<<NEWL>><<NEWL>><<NEWL>>@ndb.transactional<<NEWL>>def update_counter(name):<<NEWL>>    """"""Increment the named counter by 1.""""""<<NEWL>>    counter = Counter.get_by_id(name)<<NEWL>>    if counter is None:<<NEWL>>        counter = Counter(id=name, count=0)<<NEWL>><<NEWL>>    counter.count += 1<<NEWL>>    counter.put()<<NEWL>><<NEWL>>    return counter.count<<NEWL>><<NEWL>><<NEWL>>class DatastoreCounterHandler(webapp2.RequestHandler):<<NEWL>>    """"""Increments counters in the global namespace as well as in whichever<<NEWL>>    namespace is specified by the request, which is arbitrarily named 'default'<<NEWL>>    if not specified.""""""<<NEWL>><<NEWL>>    def get(self, namespace='default'):<<NEWL>>        global_count = update_counter('counter')<<NEWL>><<NEWL>>        # Save the current namespace.<<NEWL>>        previous_namespace = namespace_manager.get_namespace()<<NEWL>>        try:<<NEWL>>            namespace_manager.set_namespace(namespace)<<NEWL>>            namespace_count = update_counter('counter')<<NEWL>>        finally:<<NEWL>>            # Restore the saved namespace.<<NEWL>>            namespace_manager.set_namespace(previous_namespace)<<NEWL>><<NEWL>>        self.response.write('Global: {}, Namespace {}: {}'.format(<<NEWL>>            global_count, namespace, namespace_count))<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    (r'/datastore', DatastoreCounterHandler),<<NEWL>>    (r'/datastore/(.*)', DatastoreCounterHandler)<<NEWL>>], debug=True)<<NEWL>># [END all]"
379	adjudicated	0	"from typing import Optional<<NEWL>><<NEWL>>from fastapi import Depends, Request<<NEWL>>from fastapi_users import BaseUserManager, FastAPIUsers, IntegerIDMixin<<NEWL>>from fastapi_users.authentication import AuthenticationBackend, BearerTransport, CookieTransport, JWTStrategy<<NEWL>>from fastapi_users.db import SQLAlchemyUserDatabase<<NEWL>><<NEWL>>import crud<<NEWL>>from app import models<<NEWL>>from app.deps import get_db<<NEWL>>from .db import User, get_user_db<<NEWL>>from .secrets import secrets<<NEWL>><<NEWL>>class UserManager(IntegerIDMixin, BaseUserManager[User, int]):<<NEWL>>    reset_password_token_secret = secrets['SECRET_KEY']<<NEWL>>    verification_token_secret = secrets['SECRET_KEY']<<NEWL>><<NEWL>>    async def on_after_register(self, user: User, request: Optional[Request] = None):<<NEWL>>        print(f""User {user.id} has registered."")<<NEWL>><<NEWL>>    async def on_after_forgot_password(<<NEWL>>        self, user: User, token: str, request: Optional[Request] = None<<NEWL>>    ):<<NEWL>>        print(f""User {user.id} has forgot their password. Reset token: {token}"")<<NEWL>><<NEWL>>    async def on_after_request_verify(<<NEWL>>        self, user: User, token: str, request: Optional[Request] = None<<NEWL>>    ):<<NEWL>>        print(f""Verification requested for user {user.id}. Verification token: {token}"")<<NEWL>><<NEWL>><<NEWL>>async def get_user_manager(user_db: SQLAlchemyUserDatabase = Depends(get_user_db)):<<NEWL>>    yield UserManager(user_db)<<NEWL>><<NEWL>><<NEWL>>bearer_transport = BearerTransport(tokenUrl=""auth/jwt/login"")<<NEWL>><<NEWL>><<NEWL>>def get_jwt_strategy() -> JWTStrategy:<<NEWL>>    return JWTStrategy(secret=secrets['SECRET_KEY'], lifetime_seconds=3600)<<NEWL>><<NEWL>><<NEWL>>jwt_auth_backend = AuthenticationBackend(<<NEWL>>    name=""jwt"",<<NEWL>>    transport=bearer_transport,<<NEWL>>    get_strategy=get_jwt_strategy,<<NEWL>>)<<NEWL>><<NEWL>>cookie_transport = CookieTransport(cookie_max_age=3600)<<NEWL>><<NEWL>>cookie_auth_backend = AuthenticationBackend(<<NEWL>>    name=""cookie"",<<NEWL>>    transport=cookie_transport,<<NEWL>>    get_strategy=get_jwt_strategy,<<NEWL>>)<<NEWL>><<NEWL>>fastapi_users = FastAPIUsers[User, int](get_user_manager, [jwt_auth_backend, cookie_auth_backend])<<NEWL>><<NEWL>>current_active_user = fastapi_users.current_user(active=True)<<NEWL>><<NEWL>>async def get_current_profile(user: User = Depends(current_active_user), db = Depends(get_db)):<<NEWL>>    profile = await crud.read(_id=user.id, db=db, model=models.Profile)<<NEWL>>    return profile"
437	adjudicated	3	"import sys<<NEWL>>import platform<<NEWL>><<NEWL>><<NEWL>>__all__ = ['install', 'NullFinder', 'Protocol']<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    from typing import Protocol<<NEWL>>except ImportError:  # pragma: no cover<<NEWL>>    # Python 3.7 compatibility<<NEWL>>    from ..typing_extensions import Protocol  # type: ignore<<NEWL>><<NEWL>><<NEWL>>def install(cls):<<NEWL>>    """"""<<NEWL>>    Class decorator for installation on sys.meta_path.<<NEWL>><<NEWL>>    Adds the backport DistributionFinder to sys.meta_path and<<NEWL>>    attempts to disable the finder functionality of the stdlib<<NEWL>>    DistributionFinder.<<NEWL>>    """"""<<NEWL>>    sys.meta_path.append(cls())<<NEWL>>    disable_stdlib_finder()<<NEWL>>    return cls<<NEWL>><<NEWL>><<NEWL>>def disable_stdlib_finder():<<NEWL>>    """"""<<NEWL>>    Give the backport primacy for discovering path-based distributions<<NEWL>>    by monkey-patching the stdlib O_O.<<NEWL>><<NEWL>>    See #91 for more background for rationale on this sketchy<<NEWL>>    behavior.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def matches(finder):<<NEWL>>        return getattr(<<NEWL>>            finder, '__module__', None<<NEWL>>        ) == '_frozen_importlib_external' and hasattr(finder, 'find_distributions')<<NEWL>><<NEWL>>    for finder in filter(matches, sys.meta_path):  # pragma: nocover<<NEWL>>        del finder.find_distributions<<NEWL>><<NEWL>><<NEWL>>class NullFinder:<<NEWL>>    """"""<<NEWL>>    A ""Finder"" (aka ""MetaClassFinder"") that never finds any modules,<<NEWL>>    but may find distributions.<<NEWL>>    """"""<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def find_spec(*args, **kwargs):<<NEWL>>        return None<<NEWL>><<NEWL>>    # In Python 2, the import system requires finders<<NEWL>>    # to have a find_module() method, but this usage<<NEWL>>    # is deprecated in Python 3 in favor of find_spec().<<NEWL>>    # For the purposes of this finder (i.e. being present<<NEWL>>    # on sys.meta_path but having no other import<<NEWL>>    # system functionality), the two methods are identical.<<NEWL>>    find_module = find_spec<<NEWL>><<NEWL>><<NEWL>>def pypy_partial(val):<<NEWL>>    """"""<<NEWL>>    Adjust for variable stacklevel on partial under PyPy.<<NEWL>><<NEWL>>    Workaround for #327.<<NEWL>>    """"""<<NEWL>>    is_pypy = platform.python_implementation() == 'PyPy'<<NEWL>>    return val + is_pypy"
466	adjudicated	1	"import argparse<<NEWL>>import unittest<<NEWL>>from typing import Any, Dict, Sequence<<NEWL>><<NEWL>>import torch<<NEWL>>from fairseq.models import transformer<<NEWL>><<NEWL>>from tests.test_roberta import FakeTask<<NEWL>><<NEWL>><<NEWL>>def mk_sample(tok: Sequence[int] = None, batch_size: int = 2) -> Dict[str, Any]:<<NEWL>>    if not tok:<<NEWL>>        tok = [10, 11, 12, 13, 14, 15, 2]<<NEWL>><<NEWL>>    batch = torch.stack([torch.tensor(tok, dtype=torch.long)] * batch_size)<<NEWL>>    sample = {<<NEWL>>        ""net_input"": {<<NEWL>>            ""src_tokens"": batch,<<NEWL>>            ""prev_output_tokens"": batch,<<NEWL>>            ""src_lengths"": torch.tensor(<<NEWL>>                [len(tok)] * batch_size, dtype=torch.long, device=batch.device<<NEWL>>            ),<<NEWL>>        },<<NEWL>>        ""target"": batch[:, 1:],<<NEWL>>    }<<NEWL>>    return sample<<NEWL>><<NEWL>><<NEWL>>def mk_transformer(**extra_args: Any):<<NEWL>>    overrides = {<<NEWL>>        # Use characteristics dimensions<<NEWL>>        ""encoder_embed_dim"": 12,<<NEWL>>        ""encoder_ffn_embed_dim"": 14,<<NEWL>>        ""decoder_embed_dim"": 12,<<NEWL>>        ""decoder_ffn_embed_dim"": 14,<<NEWL>>        # Disable dropout so we have comparable tests.<<NEWL>>        ""dropout"": 0,<<NEWL>>        ""attention_dropout"": 0,<<NEWL>>        ""activation_dropout"": 0,<<NEWL>>        ""encoder_layerdrop"": 0,<<NEWL>>    }<<NEWL>>    overrides.update(extra_args)<<NEWL>>    # Overrides the defaults from the parser<<NEWL>>    args = argparse.Namespace(**overrides)<<NEWL>>    transformer.tiny_architecture(args)<<NEWL>><<NEWL>>    torch.manual_seed(0)<<NEWL>>    task = FakeTask(args)<<NEWL>>    return transformer.TransformerModel.build_model(args, task)<<NEWL>><<NEWL>><<NEWL>>class TransformerTestCase(unittest.TestCase):<<NEWL>>    def test_forward_backward(self):<<NEWL>>        model = mk_transformer(encoder_embed_dim=12, decoder_embed_dim=12)<<NEWL>>        sample = mk_sample()<<NEWL>>        o, _ = model.forward(**sample[""net_input""])<<NEWL>>        loss = o.sum()<<NEWL>>        loss.backward()<<NEWL>><<NEWL>>    def test_different_encoder_decoder_embed_dim(self):<<NEWL>>        model = mk_transformer(encoder_embed_dim=12, decoder_embed_dim=16)<<NEWL>>        sample = mk_sample()<<NEWL>>        o, _ = model.forward(**sample[""net_input""])<<NEWL>>        loss = o.sum()<<NEWL>>        loss.backward()"
452	adjudicated	3	"import os<<NEWL>>import string<<NEWL>>import urllib.parse<<NEWL>>import urllib.request<<NEWL>>from typing import Optional<<NEWL>><<NEWL>>from .compat import WINDOWS<<NEWL>><<NEWL>><<NEWL>>def get_url_scheme(url):<<NEWL>>    # type: (str) -> Optional[str]<<NEWL>>    if "":"" not in url:<<NEWL>>        return None<<NEWL>>    return url.split("":"", 1)[0].lower()<<NEWL>><<NEWL>><<NEWL>>def path_to_url(path):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""<<NEWL>>    Convert a path to a file: URL.  The path will be made absolute and have<<NEWL>>    quoted path parts.<<NEWL>>    """"""<<NEWL>>    path = os.path.normpath(os.path.abspath(path))<<NEWL>>    url = urllib.parse.urljoin(""file:"", urllib.request.pathname2url(path))<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def url_to_path(url):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""<<NEWL>>    Convert a file: URL to a path.<<NEWL>>    """"""<<NEWL>>    assert url.startswith(<<NEWL>>        ""file:""<<NEWL>>    ), f""You can only turn file: urls into filenames (not {url!r})""<<NEWL>><<NEWL>>    _, netloc, path, _, _ = urllib.parse.urlsplit(url)<<NEWL>><<NEWL>>    if not netloc or netloc == ""localhost"":<<NEWL>>        # According to RFC 8089, same as empty authority.<<NEWL>>        netloc = """"<<NEWL>>    elif WINDOWS:<<NEWL>>        # If we have a UNC path, prepend UNC share notation.<<NEWL>>        netloc = ""\\\\"" + netloc<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            f""non-local file URIs are not supported on this platform: {url!r}""<<NEWL>>        )<<NEWL>><<NEWL>>    path = urllib.request.url2pathname(netloc + path)<<NEWL>><<NEWL>>    # On Windows, urlsplit parses the path as something like ""/C:/Users/foo"".<<NEWL>>    # This creates issues for path-related functions like io.open(), so we try<<NEWL>>    # to detect and strip the leading slash.<<NEWL>>    if (<<NEWL>>        WINDOWS<<NEWL>>        and not netloc  # Not UNC.<<NEWL>>        and len(path) >= 3<<NEWL>>        and path[0] == ""/""  # Leading slash to strip.<<NEWL>>        and path[1] in string.ascii_letters  # Drive letter.<<NEWL>>        and path[2:4] in ("":"", "":/"")  # Colon + end of string, or colon + absolute path.<<NEWL>>    ):<<NEWL>>        path = path[1:]<<NEWL>><<NEWL>>    return path"
512	adjudicated	0	"# -*- coding: utf-8 -*-<<NEWL>><<NEWL>># Copyright 2010 Dirk Holtwick, holtwick.it<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import six<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>from xhtml2pdf.util import pisaTempFile, getFile, PyPDF2<<NEWL>><<NEWL>><<NEWL>>log = logging.getLogger(""xhtml2pdf"")<<NEWL>><<NEWL>><<NEWL>>class pisaPDF:<<NEWL>>    def __init__(self, capacity=-1):<<NEWL>>        self.capacity = capacity<<NEWL>>        self.files = []<<NEWL>><<NEWL>>    def addFromURI(self, url, basepath=None):<<NEWL>>        obj = getFile(url, basepath)<<NEWL>>        if obj and (not obj.notFound()):<<NEWL>>            self.files.append(obj.getFile())<<NEWL>><<NEWL>>    addFromFileName = addFromURI<<NEWL>><<NEWL>>    def addFromFile(self, f):<<NEWL>>        if hasattr(f, ""read""):<<NEWL>>            self.files.append(f)<<NEWL>>        else:<<NEWL>>            self.addFromURI(f)<<NEWL>><<NEWL>>    def addFromString(self, data):<<NEWL>>        self.files.append(pisaTempFile(data, capacity=self.capacity))<<NEWL>><<NEWL>>    def addDocument(self, doc):<<NEWL>>        if hasattr(doc.dest, ""read""):<<NEWL>>            self.files.append(doc.dest)<<NEWL>><<NEWL>>    def join(self, file=None):<<NEWL>>        output = PyPDF2.PdfFileWriter()<<NEWL>>        for pdffile in self.files:<<NEWL>>            input = PyPDF2.PdfFileReader(pdffile)<<NEWL>>            for pageNumber in six.moves.range(input.getNumPages()):<<NEWL>>                output.addPage(input.getPage(pageNumber))<<NEWL>><<NEWL>>        if file is not None:<<NEWL>>            output.write(file)<<NEWL>>            return file<<NEWL>>        out = pisaTempFile(capacity=self.capacity)<<NEWL>>        output.write(out)<<NEWL>>        return out.getvalue()<<NEWL>><<NEWL>>    getvalue = join<<NEWL>>    __str__ = join"
403	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""box"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
51	adjudicated	4	"""""""<<NEWL>>Unopinionated display configuration.<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import locale<<NEWL>>import sys<<NEWL>><<NEWL>>from pandas._config import config as cf<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Global formatting options<<NEWL>>_initial_defencoding: str | None = None<<NEWL>><<NEWL>><<NEWL>>def detect_console_encoding() -> str:<<NEWL>>    """"""<<NEWL>>    Try to find the most capable encoding supported by the console.<<NEWL>>    slightly modified from the way IPython handles the same issue.<<NEWL>>    """"""<<NEWL>>    global _initial_defencoding<<NEWL>><<NEWL>>    encoding = None<<NEWL>>    try:<<NEWL>>        encoding = sys.stdout.encoding or sys.stdin.encoding<<NEWL>>    except (AttributeError, OSError):<<NEWL>>        pass<<NEWL>><<NEWL>>    # try again for something better<<NEWL>>    if not encoding or ""ascii"" in encoding.lower():<<NEWL>>        try:<<NEWL>>            encoding = locale.getpreferredencoding()<<NEWL>>        except locale.Error:<<NEWL>>            # can be raised by locale.setlocale(), which is<<NEWL>>            #  called by getpreferredencoding<<NEWL>>            #  (on some systems, see stdlib locale docs)<<NEWL>>            pass<<NEWL>><<NEWL>>    # when all else fails. this will usually be ""ascii""<<NEWL>>    if not encoding or ""ascii"" in encoding.lower():<<NEWL>>        encoding = sys.getdefaultencoding()<<NEWL>><<NEWL>>    # GH#3360, save the reported defencoding at import time<<NEWL>>    # MPL backends may change it. Make available for debugging.<<NEWL>>    if not _initial_defencoding:<<NEWL>>        _initial_defencoding = sys.getdefaultencoding()<<NEWL>><<NEWL>>    return encoding<<NEWL>><<NEWL>><<NEWL>>pc_encoding_doc = """"""<<NEWL>>: str/unicode<<NEWL>>    Defaults to the detected encoding of the console.<<NEWL>>    Specifies the encoding to be used for strings returned by to_string,<<NEWL>>    these are generally strings meant to be displayed on the console.<<NEWL>>""""""<<NEWL>><<NEWL>>with cf.config_prefix(""display""):<<NEWL>>    cf.register_option(<<NEWL>>        ""encoding"", detect_console_encoding(), pc_encoding_doc, validator=cf.is_text<<NEWL>>    )"
280	adjudicated	3	"from django.urls import get_script_prefix, resolve<<NEWL>><<NEWL>><<NEWL>>def get_breadcrumbs(url, request=None):<<NEWL>>    """"""<<NEWL>>    Given a url returns a list of breadcrumbs, which are each a<<NEWL>>    tuple of (name, url).<<NEWL>>    """"""<<NEWL>>    from rest_framework.reverse import preserve_builtin_query_params<<NEWL>>    from rest_framework.views import APIView<<NEWL>><<NEWL>>    def breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen):<<NEWL>>        """"""<<NEWL>>        Add tuples of (name, url) to the breadcrumbs list,<<NEWL>>        progressively chomping off parts of the url.<<NEWL>>        """"""<<NEWL>>        try:<<NEWL>>            (view, unused_args, unused_kwargs) = resolve(url)<<NEWL>>        except Exception:<<NEWL>>            pass<<NEWL>>        else:<<NEWL>>            # Check if this is a REST framework view,<<NEWL>>            # and if so add it to the breadcrumbs<<NEWL>>            cls = getattr(view, ""cls"", None)<<NEWL>>            initkwargs = getattr(view, ""initkwargs"", {})<<NEWL>>            if cls is not None and issubclass(cls, APIView):<<NEWL>>                # Don't list the same view twice in a row.<<NEWL>>                # Probably an optional trailing slash.<<NEWL>>                if not seen or seen[-1] != view:<<NEWL>>                    c = cls(**initkwargs)<<NEWL>>                    name = c.get_view_name()<<NEWL>>                    insert_url = preserve_builtin_query_params(prefix + url, request)<<NEWL>>                    breadcrumbs_list.insert(0, (name, insert_url))<<NEWL>>                    seen.append(view)<<NEWL>><<NEWL>>        if url == """":<<NEWL>>            # All done<<NEWL>>            return breadcrumbs_list<<NEWL>><<NEWL>>        elif url.endswith(""/""):<<NEWL>>            # Drop trailing slash off the end and continue to try to<<NEWL>>            # resolve more breadcrumbs<<NEWL>>            url = url.rstrip(""/"")<<NEWL>>            return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)<<NEWL>><<NEWL>>        # Drop trailing non-slash off the end and continue to try to<<NEWL>>        # resolve more breadcrumbs<<NEWL>>        url = url[: url.rfind(""/"") + 1]<<NEWL>>        return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)<<NEWL>><<NEWL>>    prefix = get_script_prefix().rstrip(""/"")<<NEWL>>    url = url[len(prefix) :]<<NEWL>>    return breadcrumbs_recursive(url, [], prefix, [])"
111	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""funnelarea"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
391	adjudicated	1	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># XV Thumbnail file handler by Charles E. ""Gene"" Cash<<NEWL>># (gcash@magicnet.net)<<NEWL>>#<<NEWL>># see xvcolor.c and xvbrowse.c in the sources to John Bradley's XV,<<NEWL>># available from ftp://ftp.cis.upenn.edu/pub/xv/<<NEWL>>#<<NEWL>># history:<<NEWL>># 98-08-15 cec  created (b/w only)<<NEWL>># 98-12-09 cec  added color palette<<NEWL>># 98-12-28 fl   added to PIL (with only a few very minor modifications)<<NEWL>>#<<NEWL>># To do:<<NEWL>># FIXME: make save work (this requires quantization support)<<NEWL>>#<<NEWL>><<NEWL>>from . import Image, ImageFile, ImagePalette<<NEWL>>from ._binary import o8<<NEWL>><<NEWL>>_MAGIC = b""P7 332""<<NEWL>><<NEWL>># standard color palette for thumbnails (RGB332)<<NEWL>>PALETTE = b""""<<NEWL>>for r in range(8):<<NEWL>>    for g in range(8):<<NEWL>>        for b in range(4):<<NEWL>>            PALETTE = PALETTE + (<<NEWL>>                o8((r * 255) // 7) + o8((g * 255) // 7) + o8((b * 255) // 3)<<NEWL>>            )<<NEWL>><<NEWL>><<NEWL>>def _accept(prefix):<<NEWL>>    return prefix[:6] == _MAGIC<<NEWL>><<NEWL>><<NEWL>>##<<NEWL>># Image plugin for XV thumbnail images.<<NEWL>><<NEWL>><<NEWL>>class XVThumbImageFile(ImageFile.ImageFile):<<NEWL>><<NEWL>>    format = ""XVThumb""<<NEWL>>    format_description = ""XV thumbnail image""<<NEWL>><<NEWL>>    def _open(self):<<NEWL>><<NEWL>>        # check magic<<NEWL>>        if not _accept(self.fp.read(6)):<<NEWL>>            msg = ""not an XV thumbnail file""<<NEWL>>            raise SyntaxError(msg)<<NEWL>><<NEWL>>        # Skip to beginning of next line<<NEWL>>        self.fp.readline()<<NEWL>><<NEWL>>        # skip info comments<<NEWL>>        while True:<<NEWL>>            s = self.fp.readline()<<NEWL>>            if not s:<<NEWL>>                msg = ""Unexpected EOF reading XV thumbnail file""<<NEWL>>                raise SyntaxError(msg)<<NEWL>>            if s[0] != 35:  # ie. when not a comment: '#'<<NEWL>>                break<<NEWL>><<NEWL>>        # parse header line (already read)<<NEWL>>        s = s.strip().split()<<NEWL>><<NEWL>>        self.mode = ""P""<<NEWL>>        self._size = int(s[0]), int(s[1])<<NEWL>><<NEWL>>        self.palette = ImagePalette.raw(""RGB"", PALETTE)<<NEWL>><<NEWL>>        self.tile = [(""raw"", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))]<<NEWL>><<NEWL>><<NEWL>># --------------------------------------------------------------------<<NEWL>><<NEWL>>Image.register_open(XVThumbImageFile.format, XVThumbImageFile, _accept)"
140	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""bar.hoverlabel"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
362	adjudicated	3	"import pytest<<NEWL>>import pytest_asyncio<<NEWL>><<NEWL>>from rtsu_students_bot.rtsu import RTSUApi<<NEWL>><<NEWL>>pytest_plugins = ('pytest_asyncio',)<<NEWL>><<NEWL>>TEST_DATA = {<<NEWL>>    ""login"": ""your login"",<<NEWL>>    ""password"": ""your pass"",<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>@pytest_asyncio.fixture()<<NEWL>>async def rtsu_client():<<NEWL>>    """"""<<NEWL>>    Initializes client<<NEWL>>    :return: Prepared `RTSUApi` client<<NEWL>>    """"""<<NEWL>><<NEWL>>    async with RTSUApi() as api:<<NEWL>>        yield api<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_login(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu login<<NEWL>>    :param rtsu_client: A RTSU API client<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    resp = await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    assert resp.token is not None<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_profile_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu profile fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    profile = await rtsu_client.get_profile()<<NEWL>><<NEWL>>    assert profile is not None<<NEWL>>    assert profile.full_name is not None<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_academic_years_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu academic years fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    years = await rtsu_client.get_academic_years()<<NEWL>><<NEWL>>    assert type(years) == list<<NEWL>>    assert len(years) > 0<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_academic_year_subjects_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu academic year fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    ac_years = await rtsu_client.get_academic_years()<<NEWL>>    year = ac_years[0].id<<NEWL>>    years = await rtsu_client.get_academic_year_subjects(year)<<NEWL>><<NEWL>>    assert type(years) == list<<NEWL>>    assert len(years) > 0"
333	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import (<<NEWL>>    AlreadyFinalized,<<NEWL>>    InvalidKey,<<NEWL>>    UnsupportedAlgorithm,<<NEWL>>    _Reasons,<<NEWL>>)<<NEWL>>from cryptography.hazmat.primitives import constant_time, hashes<<NEWL>>from cryptography.hazmat.primitives.kdf import KeyDerivationFunction<<NEWL>><<NEWL>><<NEWL>>class PBKDF2HMAC(KeyDerivationFunction):<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        algorithm: hashes.HashAlgorithm,<<NEWL>>        length: int,<<NEWL>>        salt: bytes,<<NEWL>>        iterations: int,<<NEWL>>        backend: typing.Any = None,<<NEWL>>    ):<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import (<<NEWL>>            backend as ossl,<<NEWL>>        )<<NEWL>><<NEWL>>        if not ossl.pbkdf2_hmac_supported(algorithm):<<NEWL>>            raise UnsupportedAlgorithm(<<NEWL>>                ""{} is not supported for PBKDF2 by this backend."".format(<<NEWL>>                    algorithm.name<<NEWL>>                ),<<NEWL>>                _Reasons.UNSUPPORTED_HASH,<<NEWL>>            )<<NEWL>>        self._used = False<<NEWL>>        self._algorithm = algorithm<<NEWL>>        self._length = length<<NEWL>>        utils._check_bytes(""salt"", salt)<<NEWL>>        self._salt = salt<<NEWL>>        self._iterations = iterations<<NEWL>><<NEWL>>    def derive(self, key_material: bytes) -> bytes:<<NEWL>>        if self._used:<<NEWL>>            raise AlreadyFinalized(""PBKDF2 instances can only be used once."")<<NEWL>>        self._used = True<<NEWL>><<NEWL>>        utils._check_byteslike(""key_material"", key_material)<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import backend<<NEWL>><<NEWL>>        return backend.derive_pbkdf2_hmac(<<NEWL>>            self._algorithm,<<NEWL>>            self._length,<<NEWL>>            self._salt,<<NEWL>>            self._iterations,<<NEWL>>            key_material,<<NEWL>>        )<<NEWL>><<NEWL>>    def verify(self, key_material: bytes, expected_key: bytes) -> None:<<NEWL>>        derived_key = self.derive(key_material)<<NEWL>>        if not constant_time.bytes_eq(derived_key, expected_key):<<NEWL>>            raise InvalidKey(""Keys do not match."")"
273	adjudicated	0	"# Copyright (C) 2017-2023 The Sipwise Team - http://sipwise.com<<NEWL>>#<<NEWL>># This program is free software: you can redistribute it and/or modify it<<NEWL>># under the terms of the GNU General Public License as published by the Free<<NEWL>># Software Foundation, either version 3 of the License, or (at your option)<<NEWL>># any later version.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but WITHOUT<<NEWL>># ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or<<NEWL>># FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for<<NEWL>># more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License along<<NEWL>># with this program.  If not, see <http://www.gnu.org/licenses/>.<<NEWL>>from django.contrib import admin<<NEWL>>from import_export import resources<<NEWL>>from import_export.admin import ExportActionModelAdmin<<NEWL>>from import_export.admin import ImportExportModelAdmin<<NEWL>><<NEWL>>from . import models<<NEWL>><<NEWL>><<NEWL>>class BuildReleaseResource(resources.ModelResource):<<NEWL>>    class Meta:<<NEWL>>        model = models.BuildRelease<<NEWL>><<NEWL>><<NEWL>>@admin.register(models.BuildRelease)<<NEWL>>class BuildReleaseAdmin(ImportExportModelAdmin, ExportActionModelAdmin):<<NEWL>>    resource_class = BuildReleaseResource<<NEWL>>    list_filter = (""release"",)<<NEWL>>    readonly_fields = (<<NEWL>>        ""projects"",<<NEWL>>        ""triggered_projects"",<<NEWL>>        ""built_projects"",<<NEWL>>        ""failed_projects"",<<NEWL>>        ""pool_size"",<<NEWL>>        ""triggered_jobs"",<<NEWL>>        ""build_deps"",<<NEWL>>    )<<NEWL>>    modify_readonly_fields = (<<NEWL>>        ""uuid"",<<NEWL>>        ""release"",<<NEWL>>    ) + readonly_fields<<NEWL>><<NEWL>>    def get_readonly_fields(self, request, obj=None):<<NEWL>>        if obj is None:<<NEWL>>            return self.readonly_fields<<NEWL>>        return self.modify_readonly_fields<<NEWL>><<NEWL>>    def save_model(self, request, obj, form, change):<<NEWL>>        if change:<<NEWL>>            super(BuildReleaseAdmin, self).save_model(<<NEWL>>                request, obj, form, change<<NEWL>>            )<<NEWL>>        else:<<NEWL>>            new_obj = models.BuildRelease.objects.create_build_release(<<NEWL>>                uuid=obj.uuid, release=obj.release<<NEWL>>            )<<NEWL>>            obj.pk = new_obj.pk"
174	adjudicated	1	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>from bitstring import BitArray<<NEWL>>import structlog<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>>class IndexPool(object):<<NEWL>>    def __init__(self, max_entries, offset):<<NEWL>>        self.max_entries = max_entries<<NEWL>>        self.offset = offset<<NEWL>>        self.indices = BitArray(self.max_entries)<<NEWL>><<NEWL>>    def get_next(self):<<NEWL>>        try:<<NEWL>>            _pos = self.indices.find('0b0')<<NEWL>>            self.indices.set(1, _pos)<<NEWL>>            return self.offset + _pos[0]<<NEWL>>        except IndexError:<<NEWL>>            log.info(""exception-fail-to-allocate-id-all-bits-in-use"")<<NEWL>>            return None<<NEWL>><<NEWL>>    def allocate(self, index):<<NEWL>>        try:<<NEWL>>            _pos = index - self.offset<<NEWL>>            if not (0 <= _pos < self.max_entries):<<NEWL>>                log.info(""{}-out-of-range"".format(index))<<NEWL>>                return None<<NEWL>>            if self.indices[_pos]:<<NEWL>>                log.info(""{}-is-already-allocated"".format(index))<<NEWL>>                return None<<NEWL>>            self.indices.set(1, _pos)<<NEWL>>            return index<<NEWL>><<NEWL>>        except IndexError:<<NEWL>>            return None<<NEWL>><<NEWL>>    def release(self, index):<<NEWL>>        index -= self.offset<<NEWL>>        _pos = (index,)<<NEWL>>        try:<<NEWL>>            self.indices.set(0, _pos)<<NEWL>>        except IndexError:<<NEWL>>            log.info(""bit-position-{}-out-of-range"".format(index))<<NEWL>><<NEWL>>    #index or multiple indices to set all of them to 1 - need to be a tuple<<NEWL>>    def pre_allocate(self, index):<<NEWL>>        if(isinstance(index, tuple)):<<NEWL>>            _lst = list(index)<<NEWL>>            for i in range(len(_lst)):<<NEWL>>                _lst[i] -= self.offset<<NEWL>>            index = tuple(_lst)<<NEWL>>            self.indices.set(1, index)"
34	adjudicated	4	"# Filename: cider.py<<NEWL>>#<<NEWL>>#<<NEWL>># Description: Describes the class to compute the CIDEr<<NEWL>># (Consensus-Based Image Description Evaluation) Metric<<NEWL>>#          by Vedantam, Zitnick, and Parikh (http://arxiv.org/abs/1411.5726)<<NEWL>>#<<NEWL>># Creation Date: Sun Feb  8 14:16:54 2015<<NEWL>>#<<NEWL>># Authors: Ramakrishna Vedantam <vrama91@vt.edu> and<<NEWL>># Tsung-Yi Lin <tl483@cornell.edu><<NEWL>>from __future__ import absolute_import<<NEWL>>from __future__ import division<<NEWL>>from __future__ import print_function<<NEWL>><<NEWL>>from .cider_scorer import CiderScorer<<NEWL>><<NEWL>><<NEWL>>class Cider:<<NEWL>>    """"""<<NEWL>>    Main Class to compute the CIDEr metric<<NEWL>><<NEWL>>    """"""<<NEWL>>    def __init__(self, n=4, df=""corpus""):<<NEWL>>        """"""<<NEWL>>        Initialize the CIDEr scoring function<<NEWL>>        : param n (int): n-gram size<<NEWL>>        : param df (string): specifies where to get the IDF values from<<NEWL>>                    takes values 'corpus', 'coco-train'<<NEWL>>        : return: None<<NEWL>>        """"""<<NEWL>>        # set cider to sum over 1 to 4-grams<<NEWL>>        self._n = n<<NEWL>>        self._df = df<<NEWL>>        self.cider_scorer = CiderScorer(n=self._n, df_mode=self._df)<<NEWL>><<NEWL>>    def compute_score(self, gts, res):<<NEWL>>        """"""<<NEWL>>        Main function to compute CIDEr score<<NEWL>>        : param  gts (dict) : {image:tokenized reference sentence}<<NEWL>>        : param res (dict)  : {image:tokenized candidate sentence}<<NEWL>>        : return: cider (float) : computed CIDEr score for the corpus<<NEWL>>        """"""<<NEWL>><<NEWL>>        # clear all the previous hypos and refs<<NEWL>>        self.cider_scorer.clear()<<NEWL>><<NEWL>>        for res_id in res:<<NEWL>><<NEWL>>            hypo = res_id['caption']<<NEWL>>            ref = gts[res_id['image_id']]<<NEWL>><<NEWL>>            # Sanity check.<<NEWL>>            assert(type(hypo) is list)<<NEWL>>            assert(len(hypo) == 1)<<NEWL>>            assert(type(ref) is list)<<NEWL>>            assert(len(ref) > 0)<<NEWL>>            self.cider_scorer += (hypo[0], ref)<<NEWL>><<NEWL>>        (score, scores) = self.cider_scorer.compute_score()<<NEWL>><<NEWL>>        return score, scores<<NEWL>><<NEWL>>    def method(self):<<NEWL>>        return ""CIDEr"""
125	adjudicated	0	"# SPDX-License-Identifier: MIT<<NEWL>><<NEWL>>import sys<<NEWL>>import warnings<<NEWL>><<NEWL>>from functools import partial<<NEWL>><<NEWL>>from . import converters, exceptions, filters, setters, validators<<NEWL>>from ._cmp import cmp_using<<NEWL>>from ._config import get_run_validators, set_run_validators<<NEWL>>from ._funcs import asdict, assoc, astuple, evolve, has, resolve_types<<NEWL>>from ._make import (<<NEWL>>    NOTHING,<<NEWL>>    Attribute,<<NEWL>>    Factory,<<NEWL>>    attrib,<<NEWL>>    attrs,<<NEWL>>    fields,<<NEWL>>    fields_dict,<<NEWL>>    make_class,<<NEWL>>    validate,<<NEWL>>)<<NEWL>>from ._next_gen import define, field, frozen, mutable<<NEWL>>from ._version_info import VersionInfo<<NEWL>><<NEWL>><<NEWL>>if sys.version_info < (3, 7):  # pragma: no cover<<NEWL>>    warnings.warn(<<NEWL>>        ""Running attrs on Python 3.6 is deprecated & we intend to drop ""<<NEWL>>        ""support soon. If that's a problem for you, please let us know why & ""<<NEWL>>        ""we MAY re-evaluate: <https://github.com/python-attrs/attrs/pull/993>"",<<NEWL>>        DeprecationWarning,<<NEWL>>    )<<NEWL>><<NEWL>>__version__ = ""22.2.0""<<NEWL>>__version_info__ = VersionInfo._from_version_string(__version__)<<NEWL>><<NEWL>>__title__ = ""attrs""<<NEWL>>__description__ = ""Classes Without Boilerplate""<<NEWL>>__url__ = ""https://www.attrs.org/""<<NEWL>>__uri__ = __url__<<NEWL>>__doc__ = __description__ + "" <"" + __uri__ + "">""<<NEWL>><<NEWL>>__author__ = ""Hynek Schlawack""<<NEWL>>__email__ = ""hs@ox.cx""<<NEWL>><<NEWL>>__license__ = ""MIT""<<NEWL>>__copyright__ = ""Copyright (c) 2015 Hynek Schlawack""<<NEWL>><<NEWL>><<NEWL>>s = attributes = attrs<<NEWL>>ib = attr = attrib<<NEWL>>dataclass = partial(attrs, auto_attribs=True)  # happy Easter ;)<<NEWL>><<NEWL>><<NEWL>>class AttrsInstance:<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""Attribute"",<<NEWL>>    ""AttrsInstance"",<<NEWL>>    ""Factory"",<<NEWL>>    ""NOTHING"",<<NEWL>>    ""asdict"",<<NEWL>>    ""assoc"",<<NEWL>>    ""astuple"",<<NEWL>>    ""attr"",<<NEWL>>    ""attrib"",<<NEWL>>    ""attributes"",<<NEWL>>    ""attrs"",<<NEWL>>    ""cmp_using"",<<NEWL>>    ""converters"",<<NEWL>>    ""define"",<<NEWL>>    ""evolve"",<<NEWL>>    ""exceptions"",<<NEWL>>    ""field"",<<NEWL>>    ""fields"",<<NEWL>>    ""fields_dict"",<<NEWL>>    ""filters"",<<NEWL>>    ""frozen"",<<NEWL>>    ""get_run_validators"",<<NEWL>>    ""has"",<<NEWL>>    ""ib"",<<NEWL>>    ""make_class"",<<NEWL>>    ""mutable"",<<NEWL>>    ""resolve_types"",<<NEWL>>    ""s"",<<NEWL>>    ""set_run_validators"",<<NEWL>>    ""setters"",<<NEWL>>    ""validate"",<<NEWL>>    ""validators"",<<NEWL>>]"
65	adjudicated	0	"from _pydev_bundle._pydev_saved_modules import threading<<NEWL>><<NEWL>><<NEWL>>def wrapper(fun):<<NEWL>><<NEWL>>    def pydev_after_run_call():<<NEWL>>        pass<<NEWL>><<NEWL>>    def inner(*args, **kwargs):<<NEWL>>        fun(*args, **kwargs)<<NEWL>>        pydev_after_run_call()<<NEWL>><<NEWL>>    return inner<<NEWL>><<NEWL>><<NEWL>>def wrap_attr(obj, attr):<<NEWL>>    t_save_start = getattr(obj, attr)<<NEWL>>    setattr(obj, attr, wrapper(t_save_start))<<NEWL>>    obj._pydev_run_patched = True<<NEWL>><<NEWL>><<NEWL>>class ObjectWrapper(object):<<NEWL>><<NEWL>>    def __init__(self, obj):<<NEWL>>        self.wrapped_object = obj<<NEWL>>        try:<<NEWL>>            import functools<<NEWL>>            functools.update_wrapper(self, obj)<<NEWL>>        except:<<NEWL>>            pass<<NEWL>><<NEWL>>    def __getattr__(self, attr):<<NEWL>>        orig_attr = getattr(self.wrapped_object, attr)  # .__getattribute__(attr)<<NEWL>>        if callable(orig_attr):<<NEWL>><<NEWL>>            def patched_attr(*args, **kwargs):<<NEWL>>                self.call_begin(attr)<<NEWL>>                result = orig_attr(*args, **kwargs)<<NEWL>>                self.call_end(attr)<<NEWL>>                if result == self.wrapped_object:<<NEWL>>                    return self<<NEWL>>                return result<<NEWL>><<NEWL>>            return patched_attr<<NEWL>>        else:<<NEWL>>            return orig_attr<<NEWL>><<NEWL>>    def call_begin(self, attr):<<NEWL>>        pass<<NEWL>><<NEWL>>    def call_end(self, attr):<<NEWL>>        pass<<NEWL>><<NEWL>>    def __enter__(self):<<NEWL>>        self.call_begin(""__enter__"")<<NEWL>>        self.wrapped_object.__enter__()<<NEWL>>        self.call_end(""__enter__"")<<NEWL>><<NEWL>>    def __exit__(self, exc_type, exc_val, exc_tb):<<NEWL>>        self.call_begin(""__exit__"")<<NEWL>>        self.wrapped_object.__exit__(exc_type, exc_val, exc_tb)<<NEWL>><<NEWL>><<NEWL>>def factory_wrapper(fun):<<NEWL>><<NEWL>>    def inner(*args, **kwargs):<<NEWL>>        obj = fun(*args, **kwargs)<<NEWL>>        return ObjectWrapper(obj)<<NEWL>><<NEWL>>    return inner<<NEWL>><<NEWL>><<NEWL>>def wrap_threads():<<NEWL>>    # TODO: add wrappers for thread and _thread<<NEWL>>    # import _thread as mod<<NEWL>>    # print(""Thread imported"")<<NEWL>>    # mod.start_new_thread = wrapper(mod.start_new_thread)<<NEWL>>    threading.Lock = factory_wrapper(threading.Lock)<<NEWL>>    threading.RLock = factory_wrapper(threading.RLock)<<NEWL>><<NEWL>>    # queue patching<<NEWL>>    import queue  # @UnresolvedImport<<NEWL>>    queue.Queue = factory_wrapper(queue.Queue)"
247	adjudicated	1	#<<NEWL>># This file is part of pyasn1-modules software.<<NEWL>>#<<NEWL>># Created by Russ Housley with assistance from asn1ate v.0.6.0.<<NEWL>>#<<NEWL>># Copyright (c) 2019, Vigil Security, LLC<<NEWL>># License: http://snmplabs.com/pyasn1/license.html<<NEWL>>#<<NEWL>># Securing Header Fields with S/MIME<<NEWL>>#<<NEWL>># ASN.1 source from:<<NEWL>># https://www.rfc-editor.org/rfc/rfc7508.txt<<NEWL>># https://www.rfc-editor.org/errata/eid5875<<NEWL>>#<<NEWL>><<NEWL>>from pyasn1.type import char<<NEWL>>from pyasn1.type import constraint<<NEWL>>from pyasn1.type import namedtype<<NEWL>>from pyasn1.type import namedval<<NEWL>>from pyasn1.type import univ<<NEWL>><<NEWL>>from pyasn1_modules import rfc5652<<NEWL>><<NEWL>>import string<<NEWL>><<NEWL>>MAX = float('inf')<<NEWL>><<NEWL>><<NEWL>>class Algorithm(univ.Enumerated):<<NEWL>>    namedValues = namedval.NamedValues(<<NEWL>>        ('canonAlgorithmSimple', 0),<<NEWL>>        ('canonAlgorithmRelaxed', 1)<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldStatus(univ.Integer):<<NEWL>>    namedValues = namedval.NamedValues(<<NEWL>>        ('duplicated', 0),<<NEWL>>        ('deleted', 1),<<NEWL>>        ('modified', 2)<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldName(char.VisibleString):<<NEWL>>    subtypeSpec = (<<NEWL>>        constraint.PermittedAlphabetConstraint(*string.printable) -<<NEWL>>        constraint.PermittedAlphabetConstraint(':')<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldValue(char.UTF8String):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class HeaderField(univ.Sequence):<<NEWL>>    componentType = namedtype.NamedTypes(<<NEWL>>        namedtype.NamedType('field-Name', HeaderFieldName()),<<NEWL>>        namedtype.NamedType('field-Value', HeaderFieldValue()),<<NEWL>>        namedtype.DefaultedNamedType('field-Status',<<NEWL>>            HeaderFieldStatus().subtype(value='duplicated'))<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFields(univ.SequenceOf):<<NEWL>>    componentType = HeaderField()<<NEWL>>    subtypeSpec = constraint.ValueSizeConstraint(1, MAX)<<NEWL>><<NEWL>><<NEWL>>class SecureHeaderFields(univ.Set):<<NEWL>>    componentType = namedtype.NamedTypes(<<NEWL>>        namedtype.NamedType('canonAlgorithm', Algorithm()),<<NEWL>>        namedtype.NamedType('secHeaderFields', HeaderFields())<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>id_aa = univ.ObjectIdentifier((1, 2, 840, 113549, 1, 9, 16, 2, ))<<NEWL>><<NEWL>>id_aa_secureHeaderFieldsIdentifier = id_aa + (55, )<<NEWL>><<NEWL>><<NEWL>><<NEWL>># Map of Attribute Type OIDs to Attributes added to the<<NEWL>># ones that are in rfc5652.py<<NEWL>><<NEWL>>_cmsAttributesMapUpdate = {<<NEWL>>    id_aa_secureHeaderFieldsIdentifier: SecureHeaderFields(),<<NEWL>>}<<NEWL>><<NEWL>>rfc5652.cmsAttributesMap.update(_cmsAttributesMapUpdate)<<NEWL>>
307	adjudicated	0	"CONSOLE_HTML_FORMAT = """"""\<<NEWL>><!DOCTYPE html><<NEWL>><head><<NEWL>><meta charset=""UTF-8""><<NEWL>><style><<NEWL>>{stylesheet}<<NEWL>>body {{<<NEWL>>    color: {foreground};<<NEWL>>    background-color: {background};<<NEWL>>}}<<NEWL>></style><<NEWL>></head><<NEWL>><html><<NEWL>><body><<NEWL>>    <pre style=""font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace""><code>{code}</code></pre><<NEWL>></body><<NEWL>></html><<NEWL>>""""""<<NEWL>><<NEWL>>CONSOLE_SVG_FORMAT = """"""\<<NEWL>><svg class=""rich-terminal"" viewBox=""0 0 {width} {height}"" xmlns=""http://www.w3.org/2000/svg""><<NEWL>>    <!-- Generated with Rich https://www.textualize.io --><<NEWL>>    <style><<NEWL>><<NEWL>>    @font-face {{<<NEWL>>        font-family: ""Fira Code"";<<NEWL>>        src: local(""FiraCode-Regular""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2"") format(""woff2""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff"") format(""woff"");<<NEWL>>        font-style: normal;<<NEWL>>        font-weight: 400;<<NEWL>>    }}<<NEWL>>    @font-face {{<<NEWL>>        font-family: ""Fira Code"";<<NEWL>>        src: local(""FiraCode-Bold""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2"") format(""woff2""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff"") format(""woff"");<<NEWL>>        font-style: bold;<<NEWL>>        font-weight: 700;<<NEWL>>    }}<<NEWL>><<NEWL>>    .{unique_id}-matrix {{<<NEWL>>        font-family: Fira Code, monospace;<<NEWL>>        font-size: {char_height}px;<<NEWL>>        line-height: {line_height}px;<<NEWL>>        font-variant-east-asian: full-width;<<NEWL>>    }}<<NEWL>><<NEWL>>    .{unique_id}-title {{<<NEWL>>        font-size: 18px;<<NEWL>>        font-weight: bold;<<NEWL>>        font-family: arial;<<NEWL>>    }}<<NEWL>><<NEWL>>    {styles}<<NEWL>>    </style><<NEWL>><<NEWL>>    <defs><<NEWL>>    <clipPath id=""{unique_id}-clip-terminal""><<NEWL>>      <rect x=""0"" y=""0"" width=""{terminal_width}"" height=""{terminal_height}"" /><<NEWL>>    </clipPath><<NEWL>>    {lines}<<NEWL>>    </defs><<NEWL>><<NEWL>>    {chrome}<<NEWL>>    <g transform=""translate({terminal_x}, {terminal_y})"" clip-path=""url(#{unique_id}-clip-terminal)""><<NEWL>>    {backgrounds}<<NEWL>>    <g class=""{unique_id}-matrix""><<NEWL>>    {matrix}<<NEWL>>    </g><<NEWL>>    </g><<NEWL>></svg><<NEWL>>""""""<<NEWL>><<NEWL>>_SVG_FONT_FAMILY = ""Rich Fira Code""<<NEWL>>_SVG_CLASSES_PREFIX = ""rich-svg"""
96	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import datetime<<NEWL>>import warnings<<NEWL>><<NEWL>>from airflow.models import DAG<<NEWL>>from airflow.operators.bash import BashOperator<<NEWL>>from airflow.operators.subdag import SubDagOperator<<NEWL>><<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>def create_subdag_opt(main_dag):<<NEWL>>    subdag_name = ""daily_job""<<NEWL>>    subdag = DAG(<<NEWL>>        dag_id=""."".join([dag_name, subdag_name]),<<NEWL>>        start_date=start_date,<<NEWL>>        schedule=None,<<NEWL>>        max_active_tasks=2,<<NEWL>>    )<<NEWL>>    BashOperator(bash_command=""echo 1"", task_id=""daily_job_subdag_task"", dag=subdag)<<NEWL>>    with warnings.catch_warnings(record=True):<<NEWL>>        return SubDagOperator(<<NEWL>>            task_id=subdag_name,<<NEWL>>            subdag=subdag,<<NEWL>>            dag=main_dag,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>dag_name = ""clear_subdag_test_dag""<<NEWL>><<NEWL>>start_date = datetime.datetime(2016, 1, 1)<<NEWL>><<NEWL>>dag = DAG(dag_id=dag_name, max_active_tasks=3, start_date=start_date, schedule=""0 0 * * *"")<<NEWL>><<NEWL>>daily_job_irrelevant = BashOperator(<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    task_id=""daily_job_irrelevant"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>>daily_job_downstream = BashOperator(<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    task_id=""daily_job_downstream"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>>daily_job = create_subdag_opt(main_dag=dag)<<NEWL>><<NEWL>>daily_job >> daily_job_downstream"
216	adjudicated	2	"from ._common import pytz_imported<<NEWL>><<NEWL>><<NEWL>>class PytzUsageWarning(RuntimeWarning):<<NEWL>>    """"""Warning raised when accessing features specific to ``pytz``'s interface.<<NEWL>><<NEWL>>    This warning is used to direct users of ``pytz``-specific features like the<<NEWL>>    ``localize`` and ``normalize`` methods towards using the standard<<NEWL>>    ``tzinfo`` interface, so that these shims can be replaced with one of the<<NEWL>>    underlying libraries they are wrapping.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class UnknownTimeZoneError(KeyError):<<NEWL>>    """"""Raised when no time zone is found for a specified key.""""""<<NEWL>><<NEWL>><<NEWL>>class InvalidTimeError(Exception):<<NEWL>>    """"""The base class for exceptions related to folds and gaps.""""""<<NEWL>><<NEWL>><<NEWL>>class AmbiguousTimeError(InvalidTimeError):<<NEWL>>    """"""Exception raised when ``is_dst=None`` for an ambiguous time (fold).""""""<<NEWL>><<NEWL>><<NEWL>>class NonExistentTimeError(InvalidTimeError):<<NEWL>>    """"""Exception raised when ``is_dst=None`` for a non-existent time (gap).""""""<<NEWL>><<NEWL>><<NEWL>>PYTZ_BASE_ERROR_MAPPING = {}<<NEWL>><<NEWL>><<NEWL>>def _make_pytz_derived_errors(<<NEWL>>    InvalidTimeError_=InvalidTimeError,<<NEWL>>    AmbiguousTimeError_=AmbiguousTimeError,<<NEWL>>    NonExistentTimeError_=NonExistentTimeError,<<NEWL>>    UnknownTimeZoneError_=UnknownTimeZoneError,<<NEWL>>):<<NEWL>>    if PYTZ_BASE_ERROR_MAPPING or not pytz_imported():<<NEWL>>        return<<NEWL>><<NEWL>>    import pytz<<NEWL>><<NEWL>>    class InvalidTimeError(InvalidTimeError_, pytz.InvalidTimeError):<<NEWL>>        pass<<NEWL>><<NEWL>>    class AmbiguousTimeError(AmbiguousTimeError_, pytz.AmbiguousTimeError):<<NEWL>>        pass<<NEWL>><<NEWL>>    class NonExistentTimeError(<<NEWL>>        NonExistentTimeError_, pytz.NonExistentTimeError<<NEWL>>    ):<<NEWL>>        pass<<NEWL>><<NEWL>>    class UnknownTimeZoneError(<<NEWL>>        UnknownTimeZoneError_, pytz.UnknownTimeZoneError<<NEWL>>    ):<<NEWL>>        pass<<NEWL>><<NEWL>>    PYTZ_BASE_ERROR_MAPPING.update(<<NEWL>>        {<<NEWL>>            InvalidTimeError_: InvalidTimeError,<<NEWL>>            AmbiguousTimeError_: AmbiguousTimeError,<<NEWL>>            NonExistentTimeError_: NonExistentTimeError,<<NEWL>>            UnknownTimeZoneError_: UnknownTimeZoneError,<<NEWL>>        }<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def get_exception(exc_type, msg):<<NEWL>>    _make_pytz_derived_errors()<<NEWL>><<NEWL>>    out_exc_type = PYTZ_BASE_ERROR_MAPPING.get(exc_type, exc_type)<<NEWL>><<NEWL>>    return out_exc_type(msg)"
187	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># sequence support classes<<NEWL>>#<<NEWL>># history:<<NEWL>># 1997-02-20 fl     Created<<NEWL>>#<<NEWL>># Copyright (c) 1997 by Secret Labs AB.<<NEWL>># Copyright (c) 1997 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>##<<NEWL>><<NEWL>><<NEWL>>class Iterator:<<NEWL>>    """"""<<NEWL>>    This class implements an iterator object that can be used to loop<<NEWL>>    over an image sequence.<<NEWL>><<NEWL>>    You can use the ``[]`` operator to access elements by index. This operator<<NEWL>>    will raise an :py:exc:`IndexError` if you try to access a nonexistent<<NEWL>>    frame.<<NEWL>><<NEWL>>    :param im: An image object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, im):<<NEWL>>        if not hasattr(im, ""seek""):<<NEWL>>            msg = ""im must have seek method""<<NEWL>>            raise AttributeError(msg)<<NEWL>>        self.im = im<<NEWL>>        self.position = getattr(self.im, ""_min_frame"", 0)<<NEWL>><<NEWL>>    def __getitem__(self, ix):<<NEWL>>        try:<<NEWL>>            self.im.seek(ix)<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise IndexError from e  # end of sequence<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def __next__(self):<<NEWL>>        try:<<NEWL>>            self.im.seek(self.position)<<NEWL>>            self.position += 1<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise StopIteration from e<<NEWL>><<NEWL>><<NEWL>>def all_frames(im, func=None):<<NEWL>>    """"""<<NEWL>>    Applies a given function to all frames in an image or a list of images.<<NEWL>>    The frames are returned as a list of separate images.<<NEWL>><<NEWL>>    :param im: An image, or a list of images.<<NEWL>>    :param func: The function to apply to all of the image frames.<<NEWL>>    :returns: A list of images.<<NEWL>>    """"""<<NEWL>>    if not isinstance(im, list):<<NEWL>>        im = [im]<<NEWL>><<NEWL>>    ims = []<<NEWL>>    for imSequence in im:<<NEWL>>        current = imSequence.tell()<<NEWL>><<NEWL>>        ims += [im_frame.copy() for im_frame in Iterator(imSequence)]<<NEWL>><<NEWL>>        imSequence.seek(current)<<NEWL>>    return [func(im) for im in ims] if func else ims"
356	adjudicated	0	#<<NEWL>># This file is part of pyasn1-modules software.<<NEWL>>#<<NEWL>># Created by Russ Housley.<<NEWL>>#<<NEWL>># Copyright (c) 2019, Vigil Security, LLC<<NEWL>># License: http://snmplabs.com/pyasn1/license.html<<NEWL>>#<<NEWL>># RSAES-OAEP Key Transport Algorithm in CMS<<NEWL>>#<<NEWL>># Notice that all of the things needed in RFC 3560 are also defined<<NEWL>># in RFC 4055.  So, they are all pulled from the RFC 4055 module into<<NEWL>># this one so that people looking a RFC 3560 can easily find them.<<NEWL>>#<<NEWL>># ASN.1 source from:<<NEWL>># https://www.rfc-editor.org/rfc/rfc3560.txt<<NEWL>>#<<NEWL>><<NEWL>>from pyasn1_modules import rfc4055<<NEWL>><<NEWL>>id_sha1 = rfc4055.id_sha1<<NEWL>><<NEWL>>id_sha256 = rfc4055.id_sha256<<NEWL>><<NEWL>>id_sha384 = rfc4055.id_sha384<<NEWL>><<NEWL>>id_sha512 = rfc4055.id_sha512<<NEWL>><<NEWL>>id_mgf1 = rfc4055.id_mgf1<<NEWL>><<NEWL>>rsaEncryption = rfc4055.rsaEncryption<<NEWL>><<NEWL>>id_RSAES_OAEP = rfc4055.id_RSAES_OAEP<<NEWL>><<NEWL>>id_pSpecified = rfc4055.id_pSpecified<<NEWL>><<NEWL>>sha1Identifier = rfc4055.sha1Identifier<<NEWL>><<NEWL>>sha256Identifier = rfc4055.sha256Identifier<<NEWL>><<NEWL>>sha384Identifier = rfc4055.sha384Identifier<<NEWL>><<NEWL>>sha512Identifier = rfc4055.sha512Identifier<<NEWL>><<NEWL>>mgf1SHA1Identifier = rfc4055.mgf1SHA1Identifier<<NEWL>><<NEWL>>mgf1SHA256Identifier = rfc4055.mgf1SHA256Identifier<<NEWL>><<NEWL>>mgf1SHA384Identifier = rfc4055.mgf1SHA384Identifier<<NEWL>><<NEWL>>mgf1SHA512Identifier = rfc4055.mgf1SHA512Identifier<<NEWL>><<NEWL>>pSpecifiedEmptyIdentifier = rfc4055.pSpecifiedEmptyIdentifier<<NEWL>><<NEWL>><<NEWL>>class RSAES_OAEP_params(rfc4055.RSAES_OAEP_params):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>rSAES_OAEP_Default_Params = RSAES_OAEP_params()<<NEWL>><<NEWL>>rSAES_OAEP_Default_Identifier = rfc4055.rSAES_OAEP_Default_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA256_Params = rfc4055.rSAES_OAEP_SHA256_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA256_Identifier = rfc4055.rSAES_OAEP_SHA256_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA384_Params = rfc4055.rSAES_OAEP_SHA384_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA384_Identifier = rfc4055.rSAES_OAEP_SHA384_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA512_Params = rfc4055.rSAES_OAEP_SHA512_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA512_Identifier = rfc4055.rSAES_OAEP_SHA512_Identifier
418	adjudicated	4	"#<<NEWL>># Copyright 2011 Facebook<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License""); you may<<NEWL>># not use this file except in compliance with the License. You may obtain<<NEWL>># a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT<<NEWL>># WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the<<NEWL>># License for the specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>""""""Implementation of platform-specific functionality.<<NEWL>><<NEWL>>For each function or class described in `tornado.platform.interface`,<<NEWL>>the appropriate platform-specific implementation exists in this module.<<NEWL>>Most code that needs access to this functionality should do e.g.::<<NEWL>><<NEWL>>    from tornado.platform.auto import set_close_exec<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import absolute_import, division, print_function<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>if 'APPENGINE_RUNTIME' in os.environ:<<NEWL>>    from tornado.platform.common import Waker<<NEWL>><<NEWL>>    def set_close_exec(fd):<<NEWL>>        pass<<NEWL>>elif os.name == 'nt':<<NEWL>>    from tornado.platform.common import Waker<<NEWL>>    from tornado.platform.windows import set_close_exec<<NEWL>>else:<<NEWL>>    from tornado.platform.posix import set_close_exec, Waker<<NEWL>><<NEWL>>try:<<NEWL>>    # monotime monkey-patches the time module to have a monotonic function<<NEWL>>    # in versions of python before 3.3.<<NEWL>>    import monotime<<NEWL>>    # Silence pyflakes warning about this unused import<<NEWL>>    monotime<<NEWL>>except ImportError:<<NEWL>>    pass<<NEWL>>try:<<NEWL>>    # monotonic can provide a monotonic function in versions of python before<<NEWL>>    # 3.3, too.<<NEWL>>    from monotonic import monotonic as monotonic_time<<NEWL>>except ImportError:<<NEWL>>    try:<<NEWL>>        from time import monotonic as monotonic_time<<NEWL>>    except ImportError:<<NEWL>>        monotonic_time = None<<NEWL>><<NEWL>>__all__ = ['Waker', 'set_close_exec', 'monotonic_time']"
509	adjudicated	1	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>""""""Example DAG demonstrating the usage of the BranchPythonOperator.""""""<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import random<<NEWL>><<NEWL>>import pendulum<<NEWL>><<NEWL>>from airflow import DAG<<NEWL>>from airflow.operators.empty import EmptyOperator<<NEWL>>from airflow.operators.python import BranchPythonOperator<<NEWL>>from airflow.utils.edgemodifier import Label<<NEWL>>from airflow.utils.trigger_rule import TriggerRule<<NEWL>><<NEWL>>with DAG(<<NEWL>>    dag_id=""example_branch_operator"",<<NEWL>>    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),<<NEWL>>    catchup=False,<<NEWL>>    schedule=""@daily"",<<NEWL>>    tags=[""example"", ""example2""],<<NEWL>>) as dag:<<NEWL>>    run_this_first = EmptyOperator(<<NEWL>>        task_id=""run_this_first"",<<NEWL>>    )<<NEWL>><<NEWL>>    options = [""branch_a"", ""branch_b"", ""branch_c"", ""branch_d""]<<NEWL>><<NEWL>>    branching = BranchPythonOperator(<<NEWL>>        task_id=""branching"",<<NEWL>>        python_callable=lambda: random.choice(options),<<NEWL>>    )<<NEWL>>    run_this_first >> branching<<NEWL>><<NEWL>>    join = EmptyOperator(<<NEWL>>        task_id=""join"",<<NEWL>>        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,<<NEWL>>    )<<NEWL>><<NEWL>>    for option in options:<<NEWL>>        t = EmptyOperator(<<NEWL>>            task_id=option,<<NEWL>>        )<<NEWL>><<NEWL>>        empty_follow = EmptyOperator(<<NEWL>>            task_id=""follow_"" + option,<<NEWL>>        )<<NEWL>><<NEWL>>        # Label is optional here, but it can help identify more complex branches<<NEWL>>        branching >> Label(option) >> t >> empty_follow >> join"
449	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        (""install-dir="", ""d"", ""directory to install scripts to""),<<NEWL>>        (""build-dir="", ""b"", ""build directory (where to install from)""),<<NEWL>>        (""force"", ""f"", ""force installation (overwrite existing files)""),<<NEWL>>        (""skip-build"", None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = [""force"", ""skip-build""]<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options(""build"", (""build_scripts"", ""build_dir""))<<NEWL>>        self.set_undefined_options(<<NEWL>>            ""install"",<<NEWL>>            (""install_scripts"", ""install_dir""),<<NEWL>>            (""force"", ""force""),<<NEWL>>            (""skip_build"", ""skip_build""),<<NEWL>>        )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command(""build_scripts"")<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == ""posix"":<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
459	adjudicated	1	"# This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>import os<<NEWL>>import shutil<<NEWL>>import sys<<NEWL>>import tempfile<<NEWL>>import unittest<<NEWL>>from typing import Optional<<NEWL>>from unittest.mock import MagicMock<<NEWL>><<NEWL>><<NEWL>>class TestFileIO(unittest.TestCase):<<NEWL>><<NEWL>>    _tmpdir: Optional[str] = None<<NEWL>>    _tmpfile: Optional[str] = None<<NEWL>>    _tmpfile_contents = ""Hello, World""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def setUpClass(cls) -> None:<<NEWL>>        cls._tmpdir = tempfile.mkdtemp()<<NEWL>>        with open(os.path.join(cls._tmpdir, ""test.txt""), ""w"") as f:<<NEWL>>            cls._tmpfile = f.name<<NEWL>>            f.write(cls._tmpfile_contents)<<NEWL>>            f.flush()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def tearDownClass(cls) -> None:<<NEWL>>        # Cleanup temp working dir.<<NEWL>>        if cls._tmpdir is not None:<<NEWL>>            shutil.rmtree(cls._tmpdir)  # type: ignore<<NEWL>><<NEWL>>    def test_file_io(self):<<NEWL>>        from fairseq.file_io import PathManager<<NEWL>><<NEWL>>        with PathManager.open(os.path.join(self._tmpdir, ""test.txt""), ""r"") as f:<<NEWL>>            s = f.read()<<NEWL>>        self.assertEqual(s, self._tmpfile_contents)<<NEWL>><<NEWL>>    def test_file_io_oss(self):<<NEWL>>        # Mock iopath to simulate oss environment.<<NEWL>>        sys.modules[""iopath""] = MagicMock()<<NEWL>>        from fairseq.file_io import PathManager<<NEWL>><<NEWL>>        with PathManager.open(os.path.join(self._tmpdir, ""test.txt""), ""r"") as f:<<NEWL>>            s = f.read()<<NEWL>>        self.assertEqual(s, self._tmpfile_contents)<<NEWL>><<NEWL>>    def test_file_io_async(self):<<NEWL>>        # ioPath `PathManager` is initialized after the first `opena` call.<<NEWL>>        try:<<NEWL>>            from fairseq.file_io import IOPathManager, PathManager<<NEWL>>            _asyncfile = os.path.join(self._tmpdir, ""async.txt"")<<NEWL>>            f = PathManager.opena(_asyncfile, ""wb"")<<NEWL>>            f.close()<<NEWL>><<NEWL>>        finally:<<NEWL>>            self.assertTrue(PathManager.async_close())"
408	adjudicated	0	"# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<<NEWL>>import atexit<<NEWL>>import contextlib<<NEWL>>import sys<<NEWL>><<NEWL>>from .ansitowin32 import AnsiToWin32<<NEWL>><<NEWL>><<NEWL>>orig_stdout = None<<NEWL>>orig_stderr = None<<NEWL>><<NEWL>>wrapped_stdout = None<<NEWL>>wrapped_stderr = None<<NEWL>><<NEWL>>atexit_done = False<<NEWL>><<NEWL>><<NEWL>>def reset_all():<<NEWL>>    if AnsiToWin32 is not None:  # Issue #74: objects might become None at exit<<NEWL>>        AnsiToWin32(orig_stdout).reset_all()<<NEWL>><<NEWL>><<NEWL>>def init(autoreset=False, convert=None, strip=None, wrap=True):<<NEWL>>    if not wrap and any([autoreset, convert, strip]):<<NEWL>>        raise ValueError(""wrap=False conflicts with any other arg=True"")<<NEWL>><<NEWL>>    global wrapped_stdout, wrapped_stderr<<NEWL>>    global orig_stdout, orig_stderr<<NEWL>><<NEWL>>    orig_stdout = sys.stdout<<NEWL>>    orig_stderr = sys.stderr<<NEWL>><<NEWL>>    if sys.stdout is None:<<NEWL>>        wrapped_stdout = None<<NEWL>>    else:<<NEWL>>        sys.stdout = wrapped_stdout = wrap_stream(<<NEWL>>            orig_stdout, convert, strip, autoreset, wrap<<NEWL>>        )<<NEWL>>    if sys.stderr is None:<<NEWL>>        wrapped_stderr = None<<NEWL>>    else:<<NEWL>>        sys.stderr = wrapped_stderr = wrap_stream(<<NEWL>>            orig_stderr, convert, strip, autoreset, wrap<<NEWL>>        )<<NEWL>><<NEWL>>    global atexit_done<<NEWL>>    if not atexit_done:<<NEWL>>        atexit.register(reset_all)<<NEWL>>        atexit_done = True<<NEWL>><<NEWL>><<NEWL>>def deinit():<<NEWL>>    if orig_stdout is not None:<<NEWL>>        sys.stdout = orig_stdout<<NEWL>>    if orig_stderr is not None:<<NEWL>>        sys.stderr = orig_stderr<<NEWL>><<NEWL>><<NEWL>>@contextlib.contextmanager<<NEWL>>def colorama_text(*args, **kwargs):<<NEWL>>    init(*args, **kwargs)<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    finally:<<NEWL>>        deinit()<<NEWL>><<NEWL>><<NEWL>>def reinit():<<NEWL>>    if wrapped_stdout is not None:<<NEWL>>        sys.stdout = wrapped_stdout<<NEWL>>    if wrapped_stderr is not None:<<NEWL>>        sys.stderr = wrapped_stderr<<NEWL>><<NEWL>><<NEWL>>def wrap_stream(stream, convert, strip, autoreset, wrap):<<NEWL>>    if wrap:<<NEWL>>        wrapper = AnsiToWin32(stream, convert=convert, strip=strip, autoreset=autoreset)<<NEWL>>        if wrapper.should_wrap():<<NEWL>>            stream = wrapper.stream<<NEWL>>    return stream"
346	adjudicated	1	"from textwrap import dedent<<NEWL>><<NEWL>>from flaky import flaky<<NEWL>><<NEWL>>from .test_embed_kernel import setup_kernel<<NEWL>><<NEWL>>TIMEOUT = 15<<NEWL>><<NEWL>><<NEWL>>@flaky(max_runs=3)<<NEWL>>def test_ipython_start_kernel_userns():<<NEWL>>    cmd = dedent(<<NEWL>>        """"""<<NEWL>>        from ipykernel.kernelapp import launch_new_instance<<NEWL>>        ns = {""tre"": 123}<<NEWL>>        launch_new_instance(user_ns=ns)<<NEWL>>        """"""<<NEWL>>    )<<NEWL>><<NEWL>>    with setup_kernel(cmd) as client:<<NEWL>>        client.inspect(""tre"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""123"" in text<<NEWL>><<NEWL>>        # user_module should be an instance of DummyMod<<NEWL>>        client.execute(""usermod = get_ipython().user_module"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""status""] == ""ok""<<NEWL>>        client.inspect(""usermod"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""DummyMod"" in text<<NEWL>><<NEWL>><<NEWL>>@flaky(max_runs=3)<<NEWL>>def test_ipython_start_kernel_no_userns():<<NEWL>>    # Issue #4188 - user_ns should be passed to shell as None, not {}<<NEWL>>    cmd = dedent(<<NEWL>>        """"""<<NEWL>>        from ipykernel.kernelapp import launch_new_instance<<NEWL>>        launch_new_instance()<<NEWL>>        """"""<<NEWL>>    )<<NEWL>><<NEWL>>    with setup_kernel(cmd) as client:<<NEWL>>        # user_module should not be an instance of DummyMod<<NEWL>>        client.execute(""usermod = get_ipython().user_module"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""status""] == ""ok""<<NEWL>>        client.inspect(""usermod"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""DummyMod"" not in text"
197	adjudicated	1	"import requests<<NEWL>>from requests.exceptions import JSONDecodeError, ConnectionError<<NEWL>><<NEWL>>from pyrogram import filters<<NEWL>>from pyrogram.types import InlineKeyboardButton, InlineKeyboardMarkup<<NEWL>><<NEWL>>from HotspotRobot import pbot, SUPPORT_CHAT<<NEWL>><<NEWL>><<NEWL>>@pbot.on_message(filters.command(""imdb""))<<NEWL>>async def imdb(client, message):<<NEWL>>    text = message.text.split("" "", 1)<<NEWL>>    if len(text) == 1:<<NEWL>>        return await message.reply_text(""Â» É¢Éªá´ á´ á´á´ ê±á´á´á´ á´á´á´ Éªá´ É´á´á´á´.\n   á´x. /imdb Altron"")<<NEWL>><<NEWL>>    try:<<NEWL>>        response = requests.get(f""https://api.safone.me/tmdb?query={text[1]}"").json()[""results""][0]<<NEWL>>    except (JSONDecodeError, ConnectionError) as e:<<NEWL>>        return await message.reply_text(<<NEWL>>            f""**Some Error Occured:** á´Êá´á´ê±á´ Êá´á´á´Êá´ Éªá´ á´á´ á´á´Ê [ê±á´á´á´á´Êá´ á´Êá´á´](https://t.me/{SUPPORT_CHAT}).""<<NEWL>>            f""\n\n**Error:** {e}""<<NEWL>>            )<<NEWL>><<NEWL>>    poster = response[""poster""]<<NEWL>>    imdb_link = response[""imdbLink""]<<NEWL>>    title = response[""title""]<<NEWL>>    rating = response[""rating""]<<NEWL>>    releasedate = response[""releaseDate""]<<NEWL>>    description = response[""overview""]<<NEWL>>    popularity = response[""popularity""]<<NEWL>>    runtime = response[""runtime""]<<NEWL>>    status = response[""status""]<<NEWL>><<NEWL>>    await client.send_photo(<<NEWL>>        message.chat.id,<<NEWL>>        poster,<<NEWL>>        caption=f""""""**Â» IMDB Movie Details:**<<NEWL>><<NEWL>>â£ **Title** = `{title}`<<NEWL>>â£ **Description** = `{description}`<<NEWL>>â£ **Rating** = `{rating}`<<NEWL>>â£ **Release-Date** = `{releasedate}`<<NEWL>>â£ **Popularity** = `{popularity}`<<NEWL>>â£ **Runtime** = `{runtime}`<<NEWL>>â£ **Status** = `{status}`<<NEWL>>"""""",<<NEWL>>        reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton(text=""â¢ Éªá´á´Ê ÊÉªÉ´á´ â¢"", url=imdb_link)]])<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>__help__ = """"""<<NEWL>>  â² /imdb <á´á´á´ Éªá´ É´á´á´á´>: É¢á´á´ ê°á´ÊÊ ÉªÉ´ê°á´ á´Êá´á´á´ á´ á´á´á´ Éªá´ ê°Êá´á´ [imdb.com](https://m.imdb.com)<<NEWL>>""""""<<NEWL>>__mod_name__ = ""Iá´á´Ê"""
206	adjudicated	1	"#!/usr/bin/env python<<NEWL>># SPDX-License-Identifier: ISC<<NEWL>><<NEWL>>#<<NEWL>># Copyright (c) 2023 by<<NEWL>># Donatas Abraitis <donatas@opensourcerouting.org><<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Check if IPv6 Link-Local BGP peering works fine.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>import sys<<NEWL>>import json<<NEWL>>import pytest<<NEWL>>import functools<<NEWL>><<NEWL>>CWD = os.path.dirname(os.path.realpath(__file__))<<NEWL>>sys.path.append(os.path.join(CWD, ""../""))<<NEWL>><<NEWL>># pylint: disable=C0413<<NEWL>>from lib import topotest<<NEWL>>from lib.topogen import Topogen, TopoRouter, get_topogen<<NEWL>><<NEWL>>pytestmark = [pytest.mark.bgpd]<<NEWL>><<NEWL>><<NEWL>>def build_topo(tgen):<<NEWL>>    for routern in range(1, 3):<<NEWL>>        tgen.add_router(""r{}"".format(routern))<<NEWL>><<NEWL>>    switch = tgen.add_switch(""s1"")<<NEWL>>    switch.add_link(tgen.gears[""r1""])<<NEWL>>    switch.add_link(tgen.gears[""r2""])<<NEWL>><<NEWL>><<NEWL>>def setup_module(mod):<<NEWL>>    tgen = Topogen(build_topo, mod.__name__)<<NEWL>>    tgen.start_topology()<<NEWL>><<NEWL>>    router_list = tgen.routers()<<NEWL>><<NEWL>>    for i, (rname, router) in enumerate(router_list.items(), 1):<<NEWL>>        router.load_config(<<NEWL>>            TopoRouter.RD_ZEBRA, os.path.join(CWD, ""{}/zebra.conf"".format(rname))<<NEWL>>        )<<NEWL>>        router.load_config(<<NEWL>>            TopoRouter.RD_BGP, os.path.join(CWD, ""{}/bgpd.conf"".format(rname))<<NEWL>>        )<<NEWL>><<NEWL>>    tgen.start_router()<<NEWL>><<NEWL>><<NEWL>>def teardown_module(mod):<<NEWL>>    tgen = get_topogen()<<NEWL>>    tgen.stop_topology()<<NEWL>><<NEWL>><<NEWL>>def test_bgp_ipv6_link_local_peering():<<NEWL>>    tgen = get_topogen()<<NEWL>><<NEWL>>    if tgen.routers_have_failure():<<NEWL>>        pytest.skip(tgen.errors)<<NEWL>><<NEWL>>    r1 = tgen.gears[""r1""]<<NEWL>><<NEWL>>    def _bgp_converge():<<NEWL>>        output = json.loads(r1.vtysh_cmd(""show bgp summary json""))<<NEWL>>        expected = {<<NEWL>>            ""ipv4Unicast"": {<<NEWL>>                ""peers"": {<<NEWL>>                    ""fe80:1::2"": {<<NEWL>>                        ""state"": ""Established"",<<NEWL>>                    }<<NEWL>>                }<<NEWL>>            }<<NEWL>>        }<<NEWL>>        return topotest.json_cmp(output, expected)<<NEWL>><<NEWL>>    test_func = functools.partial(_bgp_converge)<<NEWL>>    _, result = topotest.run_and_expect(test_func, None, count=60, wait=0.5)<<NEWL>>    assert result is None, ""Failed to see BGP convergence on R2""<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    args = [""-s""] + sys.argv[1:]<<NEWL>>    sys.exit(pytest.main(args))"
86	adjudicated	1	"import cairo<<NEWL>>from color import Color, palette<<NEWL>>import numpy as np<<NEWL>><<NEWL>><<NEWL>>def set_color(cr, color, a=1):<<NEWL>>    if color.a == 1.0:<<NEWL>>        cr.set_source_rgba(color.r, color.g, color.b, a)<<NEWL>>    else:<<NEWL>>        cr.set_source_rgba(color.r, color.g, color.b, color.a)<<NEWL>><<NEWL>><<NEWL>>def draw_px_cross(cr, x, y, length_px, color=palette[""RED""]):<<NEWL>>    """"""Draws a cross with fixed dimensions in pixel space.""""""<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.move_to(x, y - length_px)<<NEWL>>    cr.line_to(x, y + length_px)<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>>    cr.move_to(x - length_px, y)<<NEWL>>    cr.line_to(x + length_px, y)<<NEWL>>    cr.stroke()<<NEWL>>    set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def draw_px_x(cr, x, y, length_px1, color=palette[""BLACK""]):<<NEWL>>    """"""Draws a x with fixed dimensions in pixel space.""""""<<NEWL>>    length_px = length_px1 / np.sqrt(2)<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.move_to(x - length_px, y - length_px)<<NEWL>>    cr.line_to(x + length_px, y + length_px)<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>>    cr.move_to(x - length_px, y + length_px)<<NEWL>>    cr.line_to(x + length_px, y - length_px)<<NEWL>>    cr.stroke()<<NEWL>>    set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def draw_circle(cr, x, y, radius, color=palette[""RED""]):<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.arc(x, y, radius, 0, 2 * np.pi)<<NEWL>>    cr.fill()<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>><<NEWL>>def draw_control_points_cross(cr,<<NEWL>>                              points,<<NEWL>>                              width=10,<<NEWL>>                              radius=4,<<NEWL>>                              color=palette[""BLUE""]):<<NEWL>>    for i in range(0, len(points)):<<NEWL>>        draw_px_x(cr, points[i][0], points[i][1], width, color)<<NEWL>>        set_color(cr, color)<<NEWL>>        cr.arc(points[i][0], points[i][1], radius, 0, 2.0 * np.pi)<<NEWL>>        cr.fill()<<NEWL>>        set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def display_text(cr, text, widtha, heighta, widthb, heightb):<<NEWL>>    cr.scale(widtha, -heighta)<<NEWL>>    cr.show_text(text)<<NEWL>>    cr.scale(widthb, -heightb)<<NEWL>><<NEWL>><<NEWL>>def draw_points(cr, p, size):<<NEWL>>    for i in range(0, len(p)):<<NEWL>>        draw_px_cross(cr, p[i][0], p[i][1], size,<<NEWL>>                      Color(0, np.sqrt(0.2 * i), 0))"
317	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = r'j\-\a \d\e F Y'         # '26-a de julio 1887'<<NEWL>>TIME_FORMAT = 'H:i'                     # '18:59'<<NEWL>>DATETIME_FORMAT = r'j\-\a \d\e F Y\, \j\e H:i'  # '26-a de julio 1887, je 18:59'<<NEWL>>YEAR_MONTH_FORMAT = r'F \d\e Y'         # 'julio de 1887'<<NEWL>>MONTH_DAY_FORMAT = r'j\-\a \d\e F'      # '26-a de julio'<<NEWL>>SHORT_DATE_FORMAT = 'Y-m-d'             # '1887-07-26'<<NEWL>>SHORT_DATETIME_FORMAT = 'Y-m-d H:i'     # '1887-07-26 18:59'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # Monday (lundo)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d',                         # '1887-07-26'<<NEWL>>    '%y-%m-%d',                         # '87-07-26'<<NEWL>>    '%Y %m %d',                         # '1887 07 26'<<NEWL>>    '%Y.%m.%d',                         # '1887.07.26'<<NEWL>>    '%d-a de %b %Y',                    # '26-a de jul 1887'<<NEWL>>    '%d %b %Y',                         # '26 jul 1887'<<NEWL>>    '%d-a de %B %Y',                    # '26-a de julio 1887'<<NEWL>>    '%d %B %Y',                         # '26 julio 1887'<<NEWL>>    '%d %m %Y',                         # '26 07 1887'<<NEWL>>    '%d/%m/%Y',                         # '26/07/1887'<<NEWL>>]<<NEWL>>TIME_INPUT_FORMATS = [<<NEWL>>    '%H:%M:%S',                         # '18:59:00'<<NEWL>>    '%H:%M',                            # '18:59'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',                # '1887-07-26 18:59:00'<<NEWL>>    '%Y-%m-%d %H:%M',                   # '1887-07-26 18:59'<<NEWL>><<NEWL>>    '%Y.%m.%d %H:%M:%S',                # '1887.07.26 18:59:00'<<NEWL>>    '%Y.%m.%d %H:%M',                   # '1887.07.26 18:59'<<NEWL>><<NEWL>>    '%d/%m/%Y %H:%M:%S',                # '26/07/1887 18:59:00'<<NEWL>>    '%d/%m/%Y %H:%M',                   # '26/07/1887 18:59'<<NEWL>><<NEWL>>    '%y-%m-%d %H:%M:%S',                # '87-07-26 18:59:00'<<NEWL>>    '%y-%m-%d %H:%M',                   # '87-07-26 18:59'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = ','<<NEWL>>THOUSAND_SEPARATOR = '\xa0'  # non-breaking space<<NEWL>>NUMBER_GROUPING = 3
257	adjudicated	0	"import json<<NEWL>>import openpyxl<<NEWL>>from configparser import ConfigParser<<NEWL>>from core.infrastructure.constants.data import PROJECT_PATH, CONFIG_PATH<<NEWL>><<NEWL>><<NEWL>>def read_config(key: str, value: str) -> str:<<NEWL>>    config = ConfigParser()<<NEWL>>    config.read(CONFIG_PATH)<<NEWL>>    return config.get(key, value)<<NEWL>><<NEWL>><<NEWL>>def read_json(path: str) -> dict:<<NEWL>>    with open(path, 'r', encoding='utf-8') as json_file:<<NEWL>>        file = json.load(json_file)<<NEWL>>        return file<<NEWL>><<NEWL>><<NEWL>>def write_json(path: str, key: str, value: str) -> None:<<NEWL>>    data = read_json(path)<<NEWL>>    data[key] = value<<NEWL>>    with open(path, 'w', encoding='utf-8') as json_file:<<NEWL>>        json.dump(data, json_file)<<NEWL>><<NEWL>><<NEWL>>def read_excel(sheet_name: str, value: str) -> dict[str]:<<NEWL>>    path = fr""{PROJECT_PATH}\{read_config('path', 'page_base')}""<<NEWL>>    workbook = openpyxl.load_workbook(path)<<NEWL>>    sheet = workbook[sheet_name]<<NEWL>>    cache = {}<<NEWL>>    for row in sheet.iter_rows(min_row=2, values_only=True):<<NEWL>>        result = {<<NEWL>>            'name': row[0],<<NEWL>>            'locator': row[1],<<NEWL>>            'type': row[2],<<NEWL>>            'image': row[3]<<NEWL>>        }<<NEWL>>        cache[result['name']] = result<<NEWL>>    try:<<NEWL>>        match cache[value]['name']:<<NEWL>>            case _:<<NEWL>>                return {<<NEWL>>                    'name': cache[value]['name'],<<NEWL>>                    'locator': cache[value]['locator'],<<NEWL>>                    'type': cache[value]['type'],<<NEWL>>                    'image': cache[value]['image']<<NEWL>>                }<<NEWL>>    except ValueError:<<NEWL>>        raise Exception('no such type')<<NEWL>><<NEWL>><<NEWL>>def get_name(*args: str) -> str:<<NEWL>>    return read_excel(*args)['name']<<NEWL>><<NEWL>><<NEWL>>def get_locator(*args: str) -> str:<<NEWL>>    return read_excel(*args)['locator']<<NEWL>><<NEWL>><<NEWL>>def get_type(*args: str) -> str:<<NEWL>>    return read_excel(*args)['type']<<NEWL>><<NEWL>><<NEWL>>def get_image(*args: str) -> str:<<NEWL>>    return read_excel(*args)['image']"
75	adjudicated	3	"import cx_Oracle<<NEWL>><<NEWL>>from django.db.backends.oracle.introspection import DatabaseIntrospection<<NEWL>>from django.utils.functional import cached_property<<NEWL>><<NEWL>><<NEWL>>class OracleIntrospection(DatabaseIntrospection):<<NEWL>>    # Associating any OBJECTVAR instances with GeometryField. This won't work<<NEWL>>    # right on Oracle objects that aren't MDSYS.SDO_GEOMETRY, but it is the<<NEWL>>    # only object type supported within Django anyways.<<NEWL>>    @cached_property<<NEWL>>    def data_types_reverse(self):<<NEWL>>        return {<<NEWL>>            **super().data_types_reverse,<<NEWL>>            cx_Oracle.OBJECT: ""GeometryField"",<<NEWL>>        }<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # Querying USER_SDO_GEOM_METADATA to get the SRID and dimension information.<<NEWL>>            try:<<NEWL>>                cursor.execute(<<NEWL>>                    'SELECT ""DIMINFO"", ""SRID"" FROM ""USER_SDO_GEOM_METADATA"" '<<NEWL>>                    'WHERE ""TABLE_NAME""=%s AND ""COLUMN_NAME""=%s',<<NEWL>>                    (table_name.upper(), description.name.upper()),<<NEWL>>                )<<NEWL>>                row = cursor.fetchone()<<NEWL>>            except Exception as exc:<<NEWL>>                raise Exception(<<NEWL>>                    ""Could not find entry in USER_SDO_GEOM_METADATA ""<<NEWL>>                    'corresponding to ""%s"".""%s""' % (table_name, description.name)<<NEWL>>                ) from exc<<NEWL>><<NEWL>>            # TODO: Research way to find a more specific geometry field type for<<NEWL>>            # the column's contents.<<NEWL>>            field_type = ""GeometryField""<<NEWL>><<NEWL>>            # Getting the field parameters.<<NEWL>>            field_params = {}<<NEWL>>            dim, srid = row<<NEWL>>            if srid != 4326:<<NEWL>>                field_params[""srid""] = srid<<NEWL>>            # Size of object array (SDO_DIM_ARRAY) is number of dimensions.<<NEWL>>            dim = dim.size()<<NEWL>>            if dim != 2:<<NEWL>>                field_params[""dim""] = dim<<NEWL>>        return field_type, field_params"
135	adjudicated	1	"# Copyright 2023 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from datetime import datetime<<NEWL>>import os<<NEWL>><<NEWL>>from flask import Flask, request<<NEWL>><<NEWL>>from weather.data import get_inputs_patch<<NEWL>>from weather.model import WeatherModel<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>><<NEWL>>MODEL = WeatherModel.from_pretrained(""model"")<<NEWL>><<NEWL>><<NEWL>>def to_bool(x: str) -> bool:<<NEWL>>    return x.lower() == ""true""<<NEWL>><<NEWL>><<NEWL>>@app.route(""/"")<<NEWL>>def ping() -> dict:<<NEWL>>    """"""Checks that we can communicate with the service and get arguments.""""""<<NEWL>>    return {<<NEWL>>        ""response"": ""â I got your request!"",<<NEWL>>        ""args"": request.args,<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>@app.route(""/predict/<iso_date>/<float(signed=True):lat>,<float(signed=True):lon>"")<<NEWL>>def predict(iso_date: str, lat: float, lon: float) -> dict:<<NEWL>>    # Optional HTTP request parameters.<<NEWL>>    #   https://en.wikipedia.org/wiki/Query_string<<NEWL>>    patch_size = request.args.get(""patch-size"", 128, type=int)<<NEWL>>    include_inputs = request.args.get(""include-inputs"", False, type=to_bool)<<NEWL>><<NEWL>>    date = datetime.fromisoformat(iso_date)<<NEWL>>    inputs = get_inputs_patch(date, (lon, lat), patch_size).tolist()<<NEWL>>    predictions = MODEL.predict(inputs).tolist()<<NEWL>><<NEWL>>    if include_inputs:<<NEWL>>        return {""inputs"": inputs, ""predictions"": predictions}<<NEWL>>    return {""predictions"": predictions}<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    app.run(debug=True, host=""0.0.0.0"", port=int(os.environ.get(""PORT"", 8080)))"
24	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""splom"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
164	adjudicated	1	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import configparser<<NEWL>>import os<<NEWL>><<NEWL>>from paste.deploy import loadapp<<NEWL>><<NEWL>>from gunicorn.app.wsgiapp import WSGIApplication<<NEWL>>from gunicorn.config import get_default_config_file<<NEWL>><<NEWL>><<NEWL>>def get_wsgi_app(config_uri, name=None, defaults=None):<<NEWL>>    if ':' not in config_uri:<<NEWL>>        config_uri = ""config:%s"" % config_uri<<NEWL>><<NEWL>>    return loadapp(<<NEWL>>        config_uri,<<NEWL>>        name=name,<<NEWL>>        relative_to=os.getcwd(),<<NEWL>>        global_conf=defaults,<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def has_logging_config(config_file):<<NEWL>>    parser = configparser.ConfigParser()<<NEWL>>    parser.read([config_file])<<NEWL>>    return parser.has_section('loggers')<<NEWL>><<NEWL>><<NEWL>>def serve(app, global_conf, **local_conf):<<NEWL>>    """"""\<<NEWL>>    A Paste Deployment server runner.<<NEWL>><<NEWL>>    Example configuration:<<NEWL>><<NEWL>>        [server:main]<<NEWL>>        use = egg:gunicorn#main<<NEWL>>        host = 127.0.0.1<<NEWL>>        port = 5000<<NEWL>>    """"""<<NEWL>>    config_file = global_conf['__file__']<<NEWL>>    gunicorn_config_file = local_conf.pop('config', None)<<NEWL>><<NEWL>>    host = local_conf.pop('host', '')<<NEWL>>    port = local_conf.pop('port', '')<<NEWL>>    if host and port:<<NEWL>>        local_conf['bind'] = '%s:%s' % (host, port)<<NEWL>>    elif host:<<NEWL>>        local_conf['bind'] = host.split(',')<<NEWL>><<NEWL>>    class PasterServerApplication(WSGIApplication):<<NEWL>>        def load_config(self):<<NEWL>>            self.cfg.set(""default_proc_name"", config_file)<<NEWL>><<NEWL>>            if has_logging_config(config_file):<<NEWL>>                self.cfg.set(""logconfig"", config_file)<<NEWL>><<NEWL>>            if gunicorn_config_file:<<NEWL>>                self.load_config_from_file(gunicorn_config_file)<<NEWL>>            else:<<NEWL>>                default_gunicorn_config_file = get_default_config_file()<<NEWL>>                if default_gunicorn_config_file is not None:<<NEWL>>                    self.load_config_from_file(default_gunicorn_config_file)<<NEWL>><<NEWL>>            for k, v in local_conf.items():<<NEWL>>                if v is not None:<<NEWL>>                    self.cfg.set(k.lower(), v)<<NEWL>><<NEWL>>        def load(self):<<NEWL>>            return app<<NEWL>><<NEWL>>    PasterServerApplication().run()"
263	adjudicated	0	"from graphql.language.location import SourceLocation<<NEWL>>from graphql.validation.rules import LoneAnonymousOperation<<NEWL>><<NEWL>>from .utils import expect_fails_rule, expect_passes_rule<<NEWL>><<NEWL>><<NEWL>>def anon_not_alone(line, column):<<NEWL>>    return {<<NEWL>>        ""message"": LoneAnonymousOperation.anonymous_operation_not_alone_message(),<<NEWL>>        ""locations"": [SourceLocation(line, column)],<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>def test_no_operations():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      fragment fragA on Type {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_one_anon_operation():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_multiple_named_operation():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      query Foo {<<NEWL>>        field<<NEWL>>      }<<NEWL>><<NEWL>>      query Bar {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_fragment():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        ...Foo<<NEWL>>      }<<NEWL>>      fragment Foo on Type {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_multiple_anon_operations():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7), anon_not_alone(5, 7)],<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_a_mutation():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      mutation Foo {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7)],<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_a_subscription():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      subscription Foo {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7)],<<NEWL>>    )"
323	adjudicated	4	"# -*- coding: utf-8 -*-<<NEWL>>""""""<<NEWL>>Charset-Normalizer<<NEWL>>~~~~~~~~~~~~~~<<NEWL>>The Real First Universal Charset Detector.<<NEWL>>A library that helps you read text from an unknown charset encoding.<<NEWL>>Motivated by chardet, This package is trying to resolve the issue by taking a new approach.<<NEWL>>All IANA character set names for which the Python core library provides codecs are supported.<<NEWL>><<NEWL>>Basic usage:<<NEWL>>   >>> from charset_normalizer import from_bytes<<NEWL>>   >>> results = from_bytes('BÑÐµÐºÐ¸ ÑÐ¾Ð²ÐµÐº Ð¸Ð¼Ð° Ð¿ÑÐ°Ð²Ð¾ Ð½Ð° Ð¾Ð±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ. OÐ±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸ÐµÑÐ¾!'.encode('utf_8'))<<NEWL>>   >>> best_guess = results.best()<<NEWL>>   >>> str(best_guess)<<NEWL>>   'BÑÐµÐºÐ¸ ÑÐ¾Ð²ÐµÐº Ð¸Ð¼Ð° Ð¿ÑÐ°Ð²Ð¾ Ð½Ð° Ð¾Ð±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ. OÐ±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸ÐµÑÐ¾!'<<NEWL>><<NEWL>>Others methods and usages are available - see the full documentation<<NEWL>>at <https://github.com/Ousret/charset_normalizer>.<<NEWL>>:copyright: (c) 2021 by Ahmed TAHRI<<NEWL>>:license: MIT, see LICENSE for more details.<<NEWL>>""""""<<NEWL>>import logging<<NEWL>><<NEWL>>from .api import from_bytes, from_fp, from_path, normalize<<NEWL>>from .legacy import (<<NEWL>>    CharsetDetector,<<NEWL>>    CharsetDoctor,<<NEWL>>    CharsetNormalizerMatch,<<NEWL>>    CharsetNormalizerMatches,<<NEWL>>    detect,<<NEWL>>)<<NEWL>>from .models import CharsetMatch, CharsetMatches<<NEWL>>from .utils import set_logging_handler<<NEWL>>from .version import VERSION, __version__<<NEWL>><<NEWL>>__all__ = (<<NEWL>>    ""from_fp"",<<NEWL>>    ""from_path"",<<NEWL>>    ""from_bytes"",<<NEWL>>    ""normalize"",<<NEWL>>    ""detect"",<<NEWL>>    ""CharsetMatch"",<<NEWL>>    ""CharsetMatches"",<<NEWL>>    ""CharsetNormalizerMatch"",<<NEWL>>    ""CharsetNormalizerMatches"",<<NEWL>>    ""CharsetDetector"",<<NEWL>>    ""CharsetDoctor"",<<NEWL>>    ""__version__"",<<NEWL>>    ""VERSION"",<<NEWL>>    ""set_logging_handler"",<<NEWL>>)<<NEWL>><<NEWL>># Attach a NullHandler to the top level logger by default<<NEWL>># https://docs.python.org/3.3/howto/logging.html#configuring-logging-for-a-library<<NEWL>><<NEWL>>logging.getLogger(""charset_normalizer"").addHandler(logging.NullHandler())"
232	adjudicated	2	"from _pydev_bundle._pydev_saved_modules import socket<<NEWL>>import sys<<NEWL>><<NEWL>>IS_JYTHON = sys.platform.find('java') != -1<<NEWL>><<NEWL>>_cache = None<<NEWL>><<NEWL>><<NEWL>>def get_localhost():<<NEWL>>    '''<<NEWL>>    Should return 127.0.0.1 in ipv4 and ::1 in ipv6<<NEWL>><<NEWL>>    localhost is not used because on windows vista/windows 7, there can be issues where the resolving doesn't work<<NEWL>>    properly and takes a lot of time (had this issue on the pyunit server).<<NEWL>><<NEWL>>    Using the IP directly solves the problem.<<NEWL>>    '''<<NEWL>>    # TODO: Needs better investigation!<<NEWL>><<NEWL>>    global _cache<<NEWL>>    if _cache is None:<<NEWL>>        try:<<NEWL>>            for addr_info in socket.getaddrinfo(""localhost"", 80, 0, 0, socket.SOL_TCP):<<NEWL>>                config = addr_info[4]<<NEWL>>                if config[0] == '127.0.0.1':<<NEWL>>                    _cache = '127.0.0.1'<<NEWL>>                    return _cache<<NEWL>>        except:<<NEWL>>            # Ok, some versions of Python don't have getaddrinfo or SOL_TCP... Just consider it 127.0.0.1 in this case.<<NEWL>>            _cache = '127.0.0.1'<<NEWL>>        else:<<NEWL>>            _cache = 'localhost'<<NEWL>><<NEWL>>    return _cache<<NEWL>><<NEWL>><<NEWL>>def get_socket_names(n_sockets, close=False):<<NEWL>>    socket_names = []<<NEWL>>    sockets = []<<NEWL>>    for _ in range(n_sockets):<<NEWL>>        if IS_JYTHON:<<NEWL>>            # Although the option which would be pure java *should* work for Jython, the socket being returned is still 0<<NEWL>>            # (i.e.: it doesn't give the local port bound, only the original port, which was 0).<<NEWL>>            from java.net import ServerSocket<<NEWL>>            sock = ServerSocket(0)<<NEWL>>            socket_name = get_localhost(), sock.getLocalPort()<<NEWL>>        else:<<NEWL>>            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<<NEWL>>            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<<NEWL>>            sock.bind((get_localhost(), 0))<<NEWL>>            socket_name = sock.getsockname()<<NEWL>><<NEWL>>        sockets.append(sock)<<NEWL>>        socket_names.append(socket_name)<<NEWL>><<NEWL>>    if close:<<NEWL>>        for s in sockets:<<NEWL>>            s.close()<<NEWL>>    return socket_names<<NEWL>><<NEWL>><<NEWL>>def get_socket_name(close=False):<<NEWL>>    return get_socket_names(1, close)[0]<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    print(get_socket_name())"
372	adjudicated	4	"""""""uestc URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/1.9/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^$', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^$', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.conf.urls import url, include<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.conf.urls import url<<NEWL>>from django.contrib import admin<<NEWL>>from subject import views<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    url(r'^admin/$', views.admin_login, name='admin_login'),<<NEWL>>    url(r'^$', views.login, name='login'),<<NEWL>>    url(r'^login/$', views.user_login, name='user_login'),<<NEWL>>    url(r'^index/$', views.index, name='index'),<<NEWL>>    url(r'^admin/index/$', views.admin_index, name='admin_index'),<<NEWL>>    url(r'^course/$', views.get_course, name='get_course'),<<NEWL>>    url(r'^log/$', views.get_log, name='get_log'),<<NEWL>>    url(r'^choose/$', views.get_already_choose, name='get_already_choose'),<<NEWL>>    url(r'^logout/$', views.logout, name='logout'),<<NEWL>>    url(r'^select/$', views.select_course, name='select_course'),<<NEWL>>    url(r'^cancel/$', views.cancel_course, name='cancel_course'),<<NEWL>>    url(r'^admin/get/course/$', views.list_course, name='list_course'),<<NEWL>>    url(r'^admin/get/student/$', views.list_student, name='list_student'),<<NEWL>>    url(r'^admin/get/teacher/$', views.list_teacher, name='list_teacher'),<<NEWL>>    url(r'^admin/delete/course/$', views.delete_course, name='delete_course'),<<NEWL>>    url(r'^admin/add/course/$', views.add_course, name='add_course'),<<NEWL>>    url(r'^admin/add/student/$', views.add_student, name='add_student'),<<NEWL>>    url(r'^admin/resetPassword/$', views.reset_passwd, name='reset_passwd'),<<NEWL>>    url(r'^admin/delete/teacher/$', views.delete_teacher, name='delete_teacher'),<<NEWL>>    url(r'^admin/add/teacher/$', views.add_teacher, name='add_teacher'),<<NEWL>>    url(r'^search/$', views.search, name='search'),<<NEWL>>    url(r'^password/$', views.change_passwd, name='change_passwd'),<<NEWL>>]"
150	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>><<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('install-dir=', 'd', ""directory to install scripts to""),<<NEWL>>        ('build-dir=','b', ""build directory (where to install from)""),<<NEWL>>        ('force', 'f', ""force installation (overwrite existing files)""),<<NEWL>>        ('skip-build', None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = ['force', 'skip-build']<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options('build', ('build_scripts', 'build_dir'))<<NEWL>>        self.set_undefined_options('install',<<NEWL>>                                   ('install_scripts', 'install_dir'),<<NEWL>>                                   ('force', 'force'),<<NEWL>>                                   ('skip_build', 'skip_build'),<<NEWL>>                                  )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command('build_scripts')<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == 'posix':<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
10	adjudicated	0	"from pandas.core.dtypes.common import (<<NEWL>>    is_array_like,<<NEWL>>    is_bool,<<NEWL>>    is_bool_dtype,<<NEWL>>    is_categorical,<<NEWL>>    is_categorical_dtype,<<NEWL>>    is_complex,<<NEWL>>    is_complex_dtype,<<NEWL>>    is_datetime64_any_dtype,<<NEWL>>    is_datetime64_dtype,<<NEWL>>    is_datetime64_ns_dtype,<<NEWL>>    is_datetime64tz_dtype,<<NEWL>>    is_dict_like,<<NEWL>>    is_dtype_equal,<<NEWL>>    is_extension_array_dtype,<<NEWL>>    is_extension_type,<<NEWL>>    is_file_like,<<NEWL>>    is_float,<<NEWL>>    is_float_dtype,<<NEWL>>    is_hashable,<<NEWL>>    is_int64_dtype,<<NEWL>>    is_integer,<<NEWL>>    is_integer_dtype,<<NEWL>>    is_interval,<<NEWL>>    is_interval_dtype,<<NEWL>>    is_iterator,<<NEWL>>    is_list_like,<<NEWL>>    is_named_tuple,<<NEWL>>    is_number,<<NEWL>>    is_numeric_dtype,<<NEWL>>    is_object_dtype,<<NEWL>>    is_period_dtype,<<NEWL>>    is_re,<<NEWL>>    is_re_compilable,<<NEWL>>    is_scalar,<<NEWL>>    is_signed_integer_dtype,<<NEWL>>    is_sparse,<<NEWL>>    is_string_dtype,<<NEWL>>    is_timedelta64_dtype,<<NEWL>>    is_timedelta64_ns_dtype,<<NEWL>>    is_unsigned_integer_dtype,<<NEWL>>    pandas_dtype,<<NEWL>>)<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""is_array_like"",<<NEWL>>    ""is_bool"",<<NEWL>>    ""is_bool_dtype"",<<NEWL>>    ""is_categorical"",<<NEWL>>    ""is_categorical_dtype"",<<NEWL>>    ""is_complex"",<<NEWL>>    ""is_complex_dtype"",<<NEWL>>    ""is_datetime64_any_dtype"",<<NEWL>>    ""is_datetime64_dtype"",<<NEWL>>    ""is_datetime64_ns_dtype"",<<NEWL>>    ""is_datetime64tz_dtype"",<<NEWL>>    ""is_dict_like"",<<NEWL>>    ""is_dtype_equal"",<<NEWL>>    ""is_extension_array_dtype"",<<NEWL>>    ""is_extension_type"",<<NEWL>>    ""is_file_like"",<<NEWL>>    ""is_float"",<<NEWL>>    ""is_float_dtype"",<<NEWL>>    ""is_hashable"",<<NEWL>>    ""is_int64_dtype"",<<NEWL>>    ""is_integer"",<<NEWL>>    ""is_integer_dtype"",<<NEWL>>    ""is_interval"",<<NEWL>>    ""is_interval_dtype"",<<NEWL>>    ""is_iterator"",<<NEWL>>    ""is_list_like"",<<NEWL>>    ""is_named_tuple"",<<NEWL>>    ""is_number"",<<NEWL>>    ""is_numeric_dtype"",<<NEWL>>    ""is_object_dtype"",<<NEWL>>    ""is_period_dtype"",<<NEWL>>    ""is_re"",<<NEWL>>    ""is_re_compilable"",<<NEWL>>    ""is_scalar"",<<NEWL>>    ""is_signed_integer_dtype"",<<NEWL>>    ""is_sparse"",<<NEWL>>    ""is_string_dtype"",<<NEWL>>    ""is_timedelta64_dtype"",<<NEWL>>    ""is_timedelta64_ns_dtype"",<<NEWL>>    ""is_unsigned_integer_dtype"",<<NEWL>>    ""pandas_dtype"",<<NEWL>>]"
381	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the Oracle spatial<<NEWL>> backend.<<NEWL>><<NEWL>> It should be noted that Oracle Spatial does not have database tables<<NEWL>> named according to the OGC standard, so the closest analogs are used.<<NEWL>> For example, the `USER_SDO_GEOM_METADATA` is used for the GeometryColumns<<NEWL>> model and the `SDO_COORD_REF_SYS` is used for the SpatialRefSys model.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db import models<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>><<NEWL>><<NEWL>>class OracleGeometryColumns(models.Model):<<NEWL>>    ""Maps to the Oracle USER_SDO_GEOM_METADATA table.""<<NEWL>>    table_name = models.CharField(max_length=32)<<NEWL>>    column_name = models.CharField(max_length=1024)<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    # TODO: Add support for `diminfo` column (type MDSYS.SDO_DIM_ARRAY).<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""USER_SDO_GEOM_METADATA""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s - %s (SRID: %s)"" % (self.table_name, self.column_name, self.srid)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""column_name""<<NEWL>><<NEWL>><<NEWL>>class OracleSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    ""Maps to the Oracle MDSYS.CS_SRS table.""<<NEWL>>    cs_name = models.CharField(max_length=68)<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    wktext = models.CharField(max_length=2046)<<NEWL>>    # Optional geometry representing the bounds of this coordinate<<NEWL>>    # system.  By default, all are NULL in the table.<<NEWL>>    cs_bounds = models.PolygonField(null=True)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""CS_SRS""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.wktext"
101	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.',<<NEWL>>    id='translation.E001',<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    'You have provided an invalid language code in the LANGUAGES setting: {!r}.',<<NEWL>>    id='translation.E002',<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    'You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}.',<<NEWL>>    id='translation.E003',<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    'You have provided a value for the LANGUAGE_CODE setting that is not in '<<NEWL>>    'the LANGUAGES setting.',<<NEWL>>    id='translation.E004',<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
290	adjudicated	0	# Copyright (c) 2020, Oracle and/or its affiliates.<<NEWL>>#<<NEWL>># This program is free software; you can redistribute it and/or modify<<NEWL>># it under the terms of the GNU General Public License, version 2.0, as<<NEWL>># published by the Free Software Foundation.<<NEWL>>#<<NEWL>># This program is also distributed with certain software (including<<NEWL>># but not limited to OpenSSL) that is licensed under separate terms,<<NEWL>># as designated in a particular file or component or in included license<<NEWL>># documentation.  The authors of MySQL hereby grant you an<<NEWL>># additional permission to link the program and your derivative works<<NEWL>># with the separately licensed software that they have included with<<NEWL>># MySQL.<<NEWL>>#<<NEWL>># Without limiting anything contained in the foregoing, this file,<<NEWL>># which is part of MySQL Connector/Python, is also subject to the<<NEWL>># Universal FOSS Exception, version 1.0, a copy of which can be found at<<NEWL>># http://oss.oracle.com/licenses/universal-foss-exception.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but<<NEWL>># WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.<<NEWL>># See the GNU General Public License, version 2.0, for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License<<NEWL>># along with this program; if not, write to the Free Software Foundation, Inc.,<<NEWL>># 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA<<NEWL>><<NEWL>>from django.db.backends.mysql.schema import DatabaseSchemaEditor as MySQLDatabaseSchemaEditor<<NEWL>><<NEWL>><<NEWL>>class DatabaseSchemaEditor(MySQLDatabaseSchemaEditor):<<NEWL>><<NEWL>>    def quote_value(self, value):<<NEWL>>        self.connection.ensure_connection()<<NEWL>>        if isinstance(value, str):<<NEWL>>            value = value.replace('%', '%%')<<NEWL>>        quoted = self.connection.connection.converter.escape(value)<<NEWL>>        if isinstance(value, str) and isinstance(quoted, bytes):<<NEWL>>            quoted = quoted.decode()<<NEWL>>        return quoted
41	adjudicated	1	"import glob<<NEWL>>import logging<<NEWL>>import socket<<NEWL>><<NEWL>>import debugpy<<NEWL>>import pandas as pd<<NEWL>>from rdkit import Chem<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>>logger.addHandler(logging.NullHandler())<<NEWL>><<NEWL>><<NEWL>>def getipaddress():<<NEWL>>    return socket.gethostbyname(socket.getfqdn())<<NEWL>><<NEWL>><<NEWL>>def debug():<<NEWL>>    logger.info(""Waiting for debugger to connect"")<<NEWL>>    if (<<NEWL>>        socket.getfqdn().startswith(""dcc"")<<NEWL>>        or socket.getfqdn().startswith(""mol"")<<NEWL>>        or socket.getfqdn().startswith(""ccc"")<<NEWL>>    ):<<NEWL>>        debugpy.listen(address=(getipaddress(), 3000))<<NEWL>>        debugpy.wait_for_client()<<NEWL>>    debugpy.breakpoint()<<NEWL>><<NEWL>><<NEWL>>class ListDataset:<<NEWL>>    def __init__(self, seqs):<<NEWL>>        self.seqs = seqs<<NEWL>><<NEWL>>    def __getitem__(self, index):<<NEWL>>        return self.seqs[index]<<NEWL>><<NEWL>>    def __len__(self):<<NEWL>>        return len(self.seqs)<<NEWL>><<NEWL>><<NEWL>>def transform_single_embedding_to_multiple(smiles_z_map):<<NEWL>>    """"""Transforms an embedding map of the format smi->embedding to<<NEWL>>    smi-> {""canonical_embeddings"":embedding}. This function exists<<NEWL>>    as a compatibility layer<<NEWL>><<NEWL>>    Args:<<NEWL>>        smiles_z_map ([type]): [description]<<NEWL>>    """"""<<NEWL>>    retval = dict()<<NEWL>>    for key in smiles_z_map:<<NEWL>>        retval[key] = {""canonical_embeddings"": smiles_z_map[key]}<<NEWL>>    return retval<<NEWL>><<NEWL>><<NEWL>>def normalize_smiles(smi, canonical, isomeric):<<NEWL>>    normalized = Chem.MolToSmiles(<<NEWL>>        Chem.MolFromSmiles(smi), canonical=canonical, isomericSmiles=isomeric<<NEWL>>    )<<NEWL>>    return normalized<<NEWL>><<NEWL>><<NEWL>>def get_all_proteins(affinity_dir: str):<<NEWL>>    files = glob.glob(affinity_dir + ""/*.csv"")<<NEWL>>    all_proteins = []<<NEWL>>    logger.info(files)<<NEWL>>    for file in files:<<NEWL>>        df = pd.read_csv(file)<<NEWL>>        all_proteins.extend(df[""protein""].tolist())<<NEWL>>    return set(all_proteins)<<NEWL>><<NEWL>><<NEWL>>def append_to_file(filename, line):<<NEWL>>    with open(filename, ""a"") as f:<<NEWL>>        f.write(line + ""\n"")<<NEWL>><<NEWL>><<NEWL>>def write_to_file(filename, line):<<NEWL>>    with open(filename, ""w"") as f:<<NEWL>>        f.write(line + ""\n"")"
121	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Korean"""
61	adjudicated	0	"# Copyright 2016 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import mock<<NEWL>>from protorpc import message_types<<NEWL>><<NEWL>>import main<<NEWL>><<NEWL>><<NEWL>>def test_list_greetings(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    response = api.list_greetings(message_types.VoidMessage())<<NEWL>>    assert len(response.items) == 2<<NEWL>><<NEWL>><<NEWL>>def test_get_greeting(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    request = main.GreetingApi.get_greeting.remote.request_type(id=1)<<NEWL>>    response = api.get_greeting(request)<<NEWL>>    assert response.message == 'goodbye world!'<<NEWL>><<NEWL>><<NEWL>>def test_multiply_greeting(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    request = main.GreetingApi.multiply_greeting.remote.request_type(<<NEWL>>        times=4,<<NEWL>>        message='help I\'m trapped in a test case.')<<NEWL>>    response = api.multiply_greeting(request)<<NEWL>>    assert response.message == 'help I\'m trapped in a test case.' * 4<<NEWL>><<NEWL>><<NEWL>>def test_authed_greet(testbed):<<NEWL>>    api = main.AuthedGreetingApi()<<NEWL>><<NEWL>>    with mock.patch('main.endpoints.get_current_user') as user_mock:<<NEWL>>        user_mock.return_value = None<<NEWL>>        response = api.greet(message_types.VoidMessage())<<NEWL>>        assert response.message == 'Hello, Anonymous'<<NEWL>><<NEWL>>        user_mock.return_value = mock.Mock()<<NEWL>>        user_mock.return_value.email.return_value = 'user@example.com'<<NEWL>>        response = api.greet(message_types.VoidMessage())<<NEWL>>        assert response.message == 'Hello, user@example.com'"
170	adjudicated	3	"from django.utils.cache import patch_vary_headers<<NEWL>>from django.utils.deprecation import MiddlewareMixin<<NEWL>>from django.utils.regex_helper import _lazy_re_compile<<NEWL>>from django.utils.text import compress_sequence, compress_string<<NEWL>><<NEWL>>re_accepts_gzip = _lazy_re_compile(r'\bgzip\b')<<NEWL>><<NEWL>><<NEWL>>class GZipMiddleware(MiddlewareMixin):<<NEWL>>    """"""<<NEWL>>    Compress content if the browser allows gzip compression.<<NEWL>>    Set the Vary header accordingly, so that caches will base their storage<<NEWL>>    on the Accept-Encoding header.<<NEWL>>    """"""<<NEWL>>    def process_response(self, request, response):<<NEWL>>        # It's not worth attempting to compress really short responses.<<NEWL>>        if not response.streaming and len(response.content) < 200:<<NEWL>>            return response<<NEWL>><<NEWL>>        # Avoid gzipping if we've already got a content-encoding.<<NEWL>>        if response.has_header('Content-Encoding'):<<NEWL>>            return response<<NEWL>><<NEWL>>        patch_vary_headers(response, ('Accept-Encoding',))<<NEWL>><<NEWL>>        ae = request.META.get('HTTP_ACCEPT_ENCODING', '')<<NEWL>>        if not re_accepts_gzip.search(ae):<<NEWL>>            return response<<NEWL>><<NEWL>>        if response.streaming:<<NEWL>>            # Delete the `Content-Length` header for streaming content, because<<NEWL>>            # we won't know the compressed size until we stream it.<<NEWL>>            response.streaming_content = compress_sequence(response.streaming_content)<<NEWL>>            del response['Content-Length']<<NEWL>>        else:<<NEWL>>            # Return the compressed content only if it's actually shorter.<<NEWL>>            compressed_content = compress_string(response.content)<<NEWL>>            if len(compressed_content) >= len(response.content):<<NEWL>>                return response<<NEWL>>            response.content = compressed_content<<NEWL>>            response['Content-Length'] = str(len(response.content))<<NEWL>><<NEWL>>        # If there is a strong ETag, make it weak to fulfill the requirements<<NEWL>>        # of RFC 7232 section-2.1 while also allowing conditional request<<NEWL>>        # matches on ETags.<<NEWL>>        etag = response.get('ETag')<<NEWL>>        if etag and etag.startswith('""'):<<NEWL>>            response['ETag'] = 'W/' + etag<<NEWL>>        response['Content-Encoding'] = 'gzip'<<NEWL>><<NEWL>>        return response"
30	adjudicated	2	"from collections import defaultdict, deque<<NEWL>><<NEWL>><<NEWL>>class Solution(object):<<NEWL>>    def shortestAlternatingPaths(self, n, redEdges, blueEdges):<<NEWL>>        """"""<<NEWL>>        :type n: int<<NEWL>>        :type redEdges: List[List[int]]<<NEWL>>        :type blueEdges: List[List[int]]<<NEWL>>        :rtype: List[int]<<NEWL>>        """"""<<NEWL>>        graph = defaultdict(list)<<NEWL>>        red = defaultdict(lambda: False)<<NEWL>>        blue = defaultdict(lambda: False)<<NEWL>>        visited = defaultdict(lambda: False)<<NEWL>>        res = [10**9]*n<<NEWL>>        res[0] = 0<<NEWL>>        for u, v in redEdges:<<NEWL>>            red[(u, v)] = True<<NEWL>>            graph[u].append(v)<<NEWL>>        for u, v in blueEdges:<<NEWL>>            blue[(u, v)] = True<<NEWL>>            graph[u].append(v)<<NEWL>>        queue = deque()<<NEWL>><<NEWL>>        # -1: red<<NEWL>>        # 0: whatever<<NEWL>>        # 1: blue<<NEWL>>        # current node, previous edge 's color, maxDistance<<NEWL>>        queue.append((0, 0, 0))<<NEWL>>        while queue:<<NEWL>>            u, c, d = queue.popleft()<<NEWL>>            for v in graph[u]:<<NEWL>>                if visited[(u, v, c)] == False:<<NEWL>>                    if c == 0:  # whatever<<NEWL>>                        if red[(u, v)] and blue[(u, v)]:<<NEWL>>                            color = 0<<NEWL>>                        elif red[(u, v)] and not blue[(u, v)]:<<NEWL>>                            color = -1<<NEWL>>                        elif not red[(u, v)] and blue[(u, v)]:<<NEWL>>                            color = 1<<NEWL>>                        queue.append((v, color, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>                    elif c == -1 and blue[(u, v)]:<<NEWL>>                        queue.append((v, 1, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>                    elif c == 1 and red[(u, v)]:<<NEWL>>                        queue.append((v, -1, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>        for i in range(n):<<NEWL>>            if res[i] == 10**9:<<NEWL>>                res[i] = -1<<NEWL>>        return res<<NEWL>><<NEWL>><<NEWL>>t = Solution()<<NEWL>># t.shortestAlternatingPaths(5, [[0, 1], [1, 2], [2, 3], [3, 4]], [<<NEWL>>#                            [1, 2], [2, 3], [3, 1]])<<NEWL>>t.shortestAlternatingPaths(3, [[0, 1], [0, 2]], [[1, 0]])"
183	adjudicated	3	"#<<NEWL>># Copyright 2018 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import structlog<<NEWL>>from voltha.extensions.omci.tasks.get_mds_task import GetMdsTask<<NEWL>><<NEWL>><<NEWL>>class BrcmGetMdsTask(GetMdsTask):<<NEWL>>    """"""<<NEWL>>    OpenOMCI Get MIB Data Sync value task - Broadcom ONU<<NEWL>><<NEWL>>    On successful completion, this task will call the 'callback' method of the<<NEWL>>    deferred returned by the start method and return the value of the MIB<<NEWL>>    Data Sync attribute of the ONT Data ME<<NEWL>>    """"""<<NEWL>>    name = ""BRCM: Get MDS Task""<<NEWL>><<NEWL>>    def __init__(self, omci_agent, device_id):<<NEWL>>        """"""<<NEWL>>        Class initialization<<NEWL>><<NEWL>>        :param omci_agent: (OmciAdapterAgent) OMCI Adapter agent<<NEWL>>        :param device_id: (str) ONU Device ID<<NEWL>>        """"""<<NEWL>>        self.log = structlog.get_logger(device_id=device_id)<<NEWL>>        self.log.debug('function-entry')<<NEWL>><<NEWL>>        super(BrcmGetMdsTask, self).__init__(omci_agent, device_id)<<NEWL>><<NEWL>>        self.name = BrcmGetMdsTask.name<<NEWL>>        self._device = omci_agent.get_device(device_id)<<NEWL>>        self._omci_managed = False      # TODO: Look up capabilities/model number/check handler<<NEWL>><<NEWL>>    def perform_get_mds(self):<<NEWL>>        """"""<<NEWL>>        Get the 'mib_data_sync' attribute of the ONU<<NEWL>>        """"""<<NEWL>>        self.log.debug('function-entry')<<NEWL>>        self.log.info('perform-get-mds')<<NEWL>><<NEWL>>        if self._omci_managed:<<NEWL>>            return super(BrcmGetMdsTask, self).perform_get_mds()<<NEWL>><<NEWL>>        # Non-OMCI managed BRCM ONUs always return 0 for MDS, use the MIB<<NEWL>>        # sync value and depend on an accelerated mib resync to do the<<NEWL>>        # proper comparison<<NEWL>><<NEWL>>        self.deferred.callback(self._device.mib_synchronizer.mib_data_sync)<<NEWL>>"
212	adjudicated	2	"""""""<<NEWL>>For backwards-compatibility. keep this file.<<NEWL>>(Many people are going to have key bindings that rely on this file.)<<NEWL>>""""""<<NEWL>>from .app import *<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    # Old names.<<NEWL>>    ""HasArg"",<<NEWL>>    ""HasCompletions"",<<NEWL>>    ""HasFocus"",<<NEWL>>    ""HasSelection"",<<NEWL>>    ""HasValidationError"",<<NEWL>>    ""IsDone"",<<NEWL>>    ""IsReadOnly"",<<NEWL>>    ""IsMultiline"",<<NEWL>>    ""RendererHeightIsKnown"",<<NEWL>>    ""InEditingMode"",<<NEWL>>    ""InPasteMode"",<<NEWL>>    ""ViMode"",<<NEWL>>    ""ViNavigationMode"",<<NEWL>>    ""ViInsertMode"",<<NEWL>>    ""ViInsertMultipleMode"",<<NEWL>>    ""ViReplaceMode"",<<NEWL>>    ""ViSelectionMode"",<<NEWL>>    ""ViWaitingForTextObjectMode"",<<NEWL>>    ""ViDigraphMode"",<<NEWL>>    ""EmacsMode"",<<NEWL>>    ""EmacsInsertMode"",<<NEWL>>    ""EmacsSelectionMode"",<<NEWL>>    ""IsSearching"",<<NEWL>>    ""HasSearch"",<<NEWL>>    ""ControlIsSearchable"",<<NEWL>>]<<NEWL>><<NEWL>># Keep the original classnames for backwards compatibility.<<NEWL>>HasValidationError = lambda: has_validation_error<<NEWL>>HasArg = lambda: has_arg<<NEWL>>IsDone = lambda: is_done<<NEWL>>RendererHeightIsKnown = lambda: renderer_height_is_known<<NEWL>>ViNavigationMode = lambda: vi_navigation_mode<<NEWL>>InPasteMode = lambda: in_paste_mode<<NEWL>>EmacsMode = lambda: emacs_mode<<NEWL>>EmacsInsertMode = lambda: emacs_insert_mode<<NEWL>>ViMode = lambda: vi_mode<<NEWL>>IsSearching = lambda: is_searching<<NEWL>>HasSearch = lambda: is_searching<<NEWL>>ControlIsSearchable = lambda: control_is_searchable<<NEWL>>EmacsSelectionMode = lambda: emacs_selection_mode<<NEWL>>ViDigraphMode = lambda: vi_digraph_mode<<NEWL>>ViWaitingForTextObjectMode = lambda: vi_waiting_for_text_object_mode<<NEWL>>ViSelectionMode = lambda: vi_selection_mode<<NEWL>>ViReplaceMode = lambda: vi_replace_mode<<NEWL>>ViInsertMultipleMode = lambda: vi_insert_multiple_mode<<NEWL>>ViInsertMode = lambda: vi_insert_mode<<NEWL>>HasSelection = lambda: has_selection<<NEWL>>HasCompletions = lambda: has_completions<<NEWL>>IsReadOnly = lambda: is_read_only<<NEWL>>IsMultiline = lambda: is_multiline<<NEWL>><<NEWL>>HasFocus = has_focus  # No lambda here! (Has_focus is callable that returns a callable.)<<NEWL>>InEditingMode = in_editing_mode"
352	adjudicated	0	"from time import time<<NEWL>><<NEWL>>from bot import DOWNLOAD_DIR, LOGGER<<NEWL>>from bot.helper.ext_utils.bot_utils import get_readable_file_size, MirrorStatus, EngineStatus, get_readable_time<<NEWL>>from bot.helper.ext_utils.fs_utils import get_path_size<<NEWL>><<NEWL>>class ZipStatus:<<NEWL>>    def __init__(self, name, size, gid, listener):<<NEWL>>        self.__name = name<<NEWL>>        self.__size = size<<NEWL>>        self.__gid = gid<<NEWL>>        self.__listener = listener<<NEWL>>        self.__uid = listener.uid<<NEWL>>        self.__start_time = time()<<NEWL>>        self.message = listener.message<<NEWL>><<NEWL>>    def gid(self):<<NEWL>>        return self.__gid<<NEWL>><<NEWL>>    def speed_raw(self):<<NEWL>>        return self.processed_bytes() / (time() - self.__start_time)<<NEWL>><<NEWL>>    def progress_raw(self):<<NEWL>>        try:<<NEWL>>            return self.processed_bytes() / self.__size * 100<<NEWL>>        except:<<NEWL>>            return 0<<NEWL>><<NEWL>>    def progress(self):<<NEWL>>        return f'{round(self.progress_raw(), 2)}%'<<NEWL>><<NEWL>>    def speed(self):<<NEWL>>        return f'{get_readable_file_size(self.speed_raw())}/s'<<NEWL>><<NEWL>>    def name(self):<<NEWL>>        return self.__name<<NEWL>><<NEWL>>    def size_raw(self):<<NEWL>>        return self.__size<<NEWL>><<NEWL>>    def size(self):<<NEWL>>        return get_readable_file_size(self.__size)<<NEWL>><<NEWL>>    def eta(self):<<NEWL>>        try:<<NEWL>>            seconds = (self.size_raw() - self.processed_bytes()) / self.speed_raw()<<NEWL>>            return f'{get_readable_time(seconds)}'<<NEWL>>        except:<<NEWL>>            return '-'<<NEWL>><<NEWL>>    def status(self):<<NEWL>>        return MirrorStatus.STATUS_ARCHIVING<<NEWL>><<NEWL>>    def processed_bytes(self):<<NEWL>>        if self.__listener.newDir:<<NEWL>>            return get_path_size(f""{DOWNLOAD_DIR}{self.__uid}10000"")<<NEWL>>        else:<<NEWL>>            return get_path_size(f""{DOWNLOAD_DIR}{self.__uid}"") - self.__size<<NEWL>><<NEWL>>    def download(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def cancel_download(self):<<NEWL>>        LOGGER.info(f'Cancelling Archive: {self.__name}')<<NEWL>>        if self.__listener.suproc is not None:<<NEWL>>            self.__listener.suproc.kill()<<NEWL>>        self.__listener.onUploadError('archiving stopped by user!')<<NEWL>><<NEWL>>    def eng(self):<<NEWL>>        return EngineStatus.STATUS_ZIP"
243	adjudicated	0	# Generated by Django 3.2.16 on 2023-02-10 16:24<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>>from django.template.backends import django<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    initial = True<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Category',<<NEWL>>            fields=[<<NEWL>>                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('name', models.CharField(db_index=True, max_length=100, verbose_name='ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ñ')),<<NEWL>>                ('slug', models.SlugField(max_length=255, unique=True, verbose_name='URL')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'verbose_name': 'ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ñ',<<NEWL>>                'verbose_name_plural': 'ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ð¸',<<NEWL>>                'ordering': ['id'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Food',<<NEWL>>            fields=[<<NEWL>>                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('title', models.CharField(max_length=255, verbose_name='ÐÐ°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº')),<<NEWL>>                ('slug', models.SlugField(max_length=255, unique=True, verbose_name='URL')),<<NEWL>>                ('content', models.TextField(blank=True, verbose_name='Ð¢ÐµÐºÑÑ ÑÑÐ°ÑÑÐ¸')),<<NEWL>>                ('photo', models.ImageField(upload_to='photos/%Y/%m/%d/', verbose_name='Ð¤Ð¾ÑÐ¾')),<<NEWL>>                ('time_create', models.DateTimeField(auto_now_add=True, verbose_name='ÐÑÐµÐ¼Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ')),<<NEWL>>                ('time_update', models.DateTimeField(auto_now=True, verbose_name='ÐÑÐµÐ¼Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ')),<<NEWL>>                ('is_published', models.BooleanField(default=True, verbose_name='ÐÑÐ±Ð»Ð¸ÐºÐ°ÑÐ¸Ñ')),<<NEWL>>                ('cat', models.ForeignKey(on_delete=django.db.models.deletion.PROTECT, to='food.category', verbose_name='ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ð¸')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'verbose_name': 'ÐÐ·Ð²ÐµÑÑÐ½ÑÐµ ,Ð±Ð»ÑÐ´Ð°',<<NEWL>>                'verbose_name_plural': 'ÐÐ·Ð²ÐµÑÑÐ½ÑÐµ Ð±Ð»ÑÐ´Ð°',<<NEWL>>                'ordering': ['-time_create', 'title'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    ]
92	adjudicated	2	"# Copyright 2018 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START gae_python38_cloudsql_psql_pooling]<<NEWL>># [START gae_python3_cloudsql_psql_pooling]<<NEWL>>import os<<NEWL>><<NEWL>>from flask import Flask<<NEWL>>import psycopg2.pool<<NEWL>><<NEWL>>db_user = os.environ.get('CLOUD_SQL_USERNAME')<<NEWL>>db_password = os.environ.get('CLOUD_SQL_PASSWORD')<<NEWL>>db_name = os.environ.get('CLOUD_SQL_DATABASE_NAME')<<NEWL>>db_connection_name = os.environ.get('CLOUD_SQL_CONNECTION_NAME')<<NEWL>><<NEWL>># When deployed to App Engine, the `GAE_ENV` environment variable will be<<NEWL>># set to `standard`<<NEWL>>if os.environ.get('GAE_ENV') == 'standard':<<NEWL>>    # If deployed, use the local socket interface for accessing Cloud SQL<<NEWL>>    host = '/cloudsql/{}'.format(db_connection_name)<<NEWL>>else:<<NEWL>>    # If running locally, use the TCP connections instead<<NEWL>>    # Set up Cloud SQL Proxy (cloud.google.com/sql/docs/mysql/sql-proxy)<<NEWL>>    # so that your application can use 127.0.0.1:3306 to connect to your<<NEWL>>    # Cloud SQL instance<<NEWL>>    host = '127.0.0.1'<<NEWL>><<NEWL>>db_config = {<<NEWL>>    'user': db_user,<<NEWL>>    'password': db_password,<<NEWL>>    'database': db_name,<<NEWL>>    'host': host<<NEWL>>}<<NEWL>><<NEWL>>cnxpool = psycopg2.pool.ThreadedConnectionPool(minconn=1, maxconn=3,<<NEWL>>                                               **db_config)<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>><<NEWL>><<NEWL>>@app.route('/')<<NEWL>>def main():<<NEWL>>    cnx = cnxpool.getconn()<<NEWL>>    with cnx.cursor() as cursor:<<NEWL>>        cursor.execute('SELECT NOW() as now;')<<NEWL>>        result = cursor.fetchall()<<NEWL>>    current_time = result[0][0]<<NEWL>>    cnx.commit()<<NEWL>>    cnxpool.putconn(cnx)<<NEWL>><<NEWL>>    return str(current_time)<<NEWL>># [END gae_python3_cloudsql_psql_pooling]<<NEWL>># [END gae_python38_cloudsql_psql_pooling]<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    app.run(host='127.0.0.1', port=8080, debug=True)"
303	adjudicated	4	"#  Copyright 2022 Google LLC<<NEWL>>#<<NEWL>>#  Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>#  you may not use this file except in compliance with the License.<<NEWL>>#  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>>#  Unless required by applicable law or agreed to in writing, software<<NEWL>>#  distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>#  See the License for the specific language governing permissions and<<NEWL>>#  limitations under the License.<<NEWL>><<NEWL>><<NEWL>># This is an ingredient file. It is not meant to be run directly. Check the samples/snippets<<NEWL>># folder for complete code samples that are ready to be used.<<NEWL>># Disabling flake8 for the ingredients file, as it would fail F821 - undefined name check.<<NEWL>># flake8: noqa<<NEWL>>from google.cloud import compute_v1<<NEWL>><<NEWL>><<NEWL>># <INGREDIENT set_deprecation_status><<NEWL>>def set_deprecation_status(project_id: str, image_name: str, status: compute_v1.DeprecationStatus.State) -> None:<<NEWL>>    """"""<<NEWL>>    Modify the deprecation status of an image.<<NEWL>><<NEWL>>    Note: Image objects by default don't have the `deprecated` attribute at all unless it's set.<<NEWL>><<NEWL>>    Args:<<NEWL>>        project_id: project ID or project number of the Cloud project that hosts the image.<<NEWL>>        image_name: name of the image you want to modify<<NEWL>>        status: the status you want to set for the image. Available values are available in<<NEWL>>            `compute_v1.DeprecationStatus.State` enum. Learn more about image deprecation statuses:<<NEWL>>            https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images#deprecation-states<<NEWL>>    """"""<<NEWL>>    image_client = compute_v1.ImagesClient()<<NEWL>>    deprecation_status = compute_v1.DeprecationStatus()<<NEWL>>    deprecation_status.state = status.name<<NEWL>>    operation = image_client.deprecate(project=project_id, image=image_name,<<NEWL>>                                       deprecation_status_resource=deprecation_status)<<NEWL>><<NEWL>>    wait_for_extended_operation(operation, ""changing deprecation state of an image"")<<NEWL>># </INGREDIENT>"
4	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import jmespath<<NEWL>>import pytest<<NEWL>><<NEWL>>from tests.charts.helm_template_generator import render_chart<<NEWL>><<NEWL>><<NEWL>>class TestPodLauncher:<<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        ""executor, rbac, allow, expected_accounts"",<<NEWL>>        [<<NEWL>>            (""CeleryKubernetesExecutor"", True, True, [""scheduler"", ""worker""]),<<NEWL>>            (""KubernetesExecutor"", True, True, [""scheduler"", ""worker""]),<<NEWL>>            (""CeleryExecutor"", True, True, [""worker""]),<<NEWL>>            (""LocalExecutor"", True, True, [""scheduler""]),<<NEWL>>            (""LocalExecutor"", False, False, []),<<NEWL>>        ],<<NEWL>>    )<<NEWL>>    def test_pod_launcher_role(self, executor, rbac, allow, expected_accounts):<<NEWL>>        docs = render_chart(<<NEWL>>            values={<<NEWL>>                ""rbac"": {""create"": rbac},<<NEWL>>                ""allowPodLaunching"": allow,<<NEWL>>                ""executor"": executor,<<NEWL>>            },<<NEWL>>            show_only=[""templates/rbac/pod-launcher-rolebinding.yaml""],<<NEWL>>        )<<NEWL>>        if expected_accounts:<<NEWL>>            for idx, suffix in enumerate(expected_accounts):<<NEWL>>                assert f""release-name-airflow-{suffix}"" == jmespath.search(f""subjects[{idx}].name"", docs[0])<<NEWL>>        else:<<NEWL>>            assert [] == docs"
395	adjudicated	0	# -*- coding: utf-8 -*-<<NEWL>># Copyright (C) 2006-2007 SÃ¸ren Roug, European Environment Agency<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#<<NEWL>><<NEWL>>from odf.namespaces import ANIMNS<<NEWL>>from odf.element import Element<<NEWL>><<NEWL>><<NEWL>># Autogenerated<<NEWL>>def Animate(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animate'), **args)<<NEWL>><<NEWL>>def Animatecolor(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateColor'), **args)<<NEWL>><<NEWL>>def Animatemotion(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateMotion'), **args)<<NEWL>><<NEWL>>def Animatetransform(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateTransform'), **args)<<NEWL>><<NEWL>>def Audio(**args):<<NEWL>>    return Element(qname = (ANIMNS,'audio'), **args)<<NEWL>><<NEWL>>def Command(**args):<<NEWL>>    return Element(qname = (ANIMNS,'command'), **args)<<NEWL>><<NEWL>>def Iterate(**args):<<NEWL>>    return Element(qname = (ANIMNS,'iterate'), **args)<<NEWL>><<NEWL>>def Par(**args):<<NEWL>>    return Element(qname = (ANIMNS,'par'), **args)<<NEWL>><<NEWL>>def Param(**args):<<NEWL>>    return Element(qname = (ANIMNS,'param'), **args)<<NEWL>><<NEWL>>def Seq(**args):<<NEWL>>    return Element(qname = (ANIMNS,'seq'), **args)<<NEWL>><<NEWL>>def Set(**args):<<NEWL>>    return Element(qname = (ANIMNS,'set'), **args)<<NEWL>><<NEWL>>def Transitionfilter(**args):<<NEWL>>    return Element(qname = (ANIMNS,'transitionFilter'), **args)<<NEWL>>
144	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter=None):<<NEWL>>        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber(),<<NEWL>>        ]<<NEWL>>        self.reset()
55	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
115	adjudicated	1	"from fastapi import APIRouter, Depends, HTTPException<<NEWL>>from fastapi.security import OAuth2PasswordRequestForm<<NEWL>>from starlette import status<<NEWL>><<NEWL>>from app.repository.users_repository import UsersRepository<<NEWL>>from app.repository.unit_of_work import UnitOfWork<<NEWL>>from app.users_service.users_service import UsersService<<NEWL>>from app.users_service.users import User<<NEWL>>from app.web.api.schemas import UserRegisterInSchema, UserOutSchema, Token<<NEWL>>from app.web.api.auth import authenticate_user, issue_new_token, get_current_user<<NEWL>><<NEWL>>router = APIRouter(tags=[""auth""])<<NEWL>><<NEWL>><<NEWL>>@router.post(<<NEWL>>    ""/register"", status_code=status.HTTP_201_CREATED, response_model=UserOutSchema<<NEWL>>)<<NEWL>>async def register(payload: UserRegisterInSchema):<<NEWL>>    with UnitOfWork() as unit_of_work:<<NEWL>>        repo = UsersRepository(unit_of_work.session)<<NEWL>>        users_service = UsersService(repo)<<NEWL>>        # user ID didn't exist before commit<<NEWL>>        # we have to get it now when the SQLAlchemy session is still active.<<NEWL>>        user_data = payload.dict()<<NEWL>>        del user_data[""password_confirm""]<<NEWL>>        user = users_service.add_user(**user_data)<<NEWL>>        unit_of_work.commit()<<NEWL>>        res = user.dict()<<NEWL>>    return res<<NEWL>><<NEWL>><<NEWL>>@router.post(""/token"", response_model=Token)<<NEWL>>async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()):<<NEWL>>    user = authenticate_user(form_data.username, form_data.password)<<NEWL>>    if not user:<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_401_UNAUTHORIZED,<<NEWL>>            detail=""Incorrect username or password"",<<NEWL>>            headers={""WWW-Authenticate"": ""Bearer""},<<NEWL>>        )<<NEWL>>    token = issue_new_token(user)<<NEWL>>    return token<<NEWL>><<NEWL>><<NEWL>>@router.get(""/current_user"", response_model=UserOutSchema)<<NEWL>>async def get_current_user(current_user: User = Depends(get_current_user)):<<NEWL>>    return current_user.dict()"
284	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the PostGIS backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class PostGISGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' view from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.3.2.<<NEWL>>    """"""<<NEWL>>    f_table_catalog = models.CharField(max_length=256)<<NEWL>>    f_table_schema = models.CharField(max_length=256)<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    type = models.CharField(max_length=30)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'geometry_columns'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return '%s.%s - %dD %s field (SRID: %d)' % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return 'f_table_name'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return 'f_geometry_column'<<NEWL>><<NEWL>><<NEWL>>class PostGISSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.2.1.<<NEWL>>    """"""<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'spatial_ref_sys'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
337	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter=None):<<NEWL>>        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber()<<NEWL>>        ]<<NEWL>>        self.reset()
277	adjudicated	4	"from __future__ import annotations<<NEWL>><<NEWL>>import numpy as np<<NEWL>><<NEWL>>from pandas._typing import NumpyIndexT<<NEWL>><<NEWL>>from pandas.core.dtypes.common import is_list_like<<NEWL>><<NEWL>><<NEWL>>def cartesian_product(X) -> list[np.ndarray]:<<NEWL>>    """"""<<NEWL>>    Numpy version of itertools.product.<<NEWL>>    Sometimes faster (for large inputs)...<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    X : list-like of list-likes<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    product : list of ndarrays<<NEWL>><<NEWL>>    Examples<<NEWL>>    --------<<NEWL>>    >>> cartesian_product([list('ABC'), [1, 2]])<<NEWL>>    [array(['A', 'A', 'B', 'B', 'C', 'C'], dtype='<U1'), array([1, 2, 1, 2, 1, 2])]<<NEWL>><<NEWL>>    See Also<<NEWL>>    --------<<NEWL>>    itertools.product : Cartesian product of input iterables.  Equivalent to<<NEWL>>        nested for-loops.<<NEWL>>    """"""<<NEWL>>    msg = ""Input must be a list-like of list-likes""<<NEWL>>    if not is_list_like(X):<<NEWL>>        raise TypeError(msg)<<NEWL>>    for x in X:<<NEWL>>        if not is_list_like(x):<<NEWL>>            raise TypeError(msg)<<NEWL>><<NEWL>>    if len(X) == 0:<<NEWL>>        return []<<NEWL>><<NEWL>>    lenX = np.fromiter((len(x) for x in X), dtype=np.intp)<<NEWL>>    cumprodX = np.cumproduct(lenX)<<NEWL>><<NEWL>>    if np.any(cumprodX < 0):<<NEWL>>        raise ValueError(""Product space too large to allocate arrays!"")<<NEWL>><<NEWL>>    a = np.roll(cumprodX, 1)<<NEWL>>    a[0] = 1<<NEWL>><<NEWL>>    if cumprodX[-1] != 0:<<NEWL>>        b = cumprodX[-1] / cumprodX<<NEWL>>    else:<<NEWL>>        # if any factor is empty, the cartesian product is empty<<NEWL>>        b = np.zeros_like(cumprodX)<<NEWL>><<NEWL>>    # error: Argument of type ""int_"" cannot be assigned to parameter ""num"" of<<NEWL>>    # type ""int"" in function ""tile_compat""<<NEWL>>    return [<<NEWL>>        tile_compat(<<NEWL>>            np.repeat(x, b[i]),<<NEWL>>            np.product(a[i]),  # pyright: ignore[reportGeneralTypeIssues]<<NEWL>>        )<<NEWL>>        for i, x in enumerate(X)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>def tile_compat(arr: NumpyIndexT, num: int) -> NumpyIndexT:<<NEWL>>    """"""<<NEWL>>    Index compat for np.tile.<<NEWL>><<NEWL>>    Notes<<NEWL>>    -----<<NEWL>>    Does not support multi-dimensional `num`.<<NEWL>>    """"""<<NEWL>>    if isinstance(arr, np.ndarray):<<NEWL>>        return np.tile(arr, num)<<NEWL>><<NEWL>>    # Otherwise we have an Index<<NEWL>>    taker = np.tile(np.arange(len(arr)), num)<<NEWL>>    return arr.take(taker)"
366	adjudicated	3	"from six import string_types<<NEWL>><<NEWL>>from .base import GraphQLDocument<<NEWL>><<NEWL>># Necessary for static type checking<<NEWL>>if False:  # flake8: noqa<<NEWL>>    from ..type.schema import GraphQLSchema<<NEWL>>    from typing import Any, Optional, Dict, Callable, Union<<NEWL>><<NEWL>><<NEWL>>class GraphQLCompiledDocument(GraphQLDocument):<<NEWL>>    @classmethod<<NEWL>>    def from_code(<<NEWL>>        cls,<<NEWL>>        schema,  # type: GraphQLSchema<<NEWL>>        code,  # type: Union[str, Any]<<NEWL>>        uptodate=None,  # type: Optional[bool]<<NEWL>>        extra_namespace=None,  # type: Optional[Dict[str, Any]]<<NEWL>>    ):<<NEWL>>        # type: (...) -> GraphQLCompiledDocument<<NEWL>>        """"""Creates a GraphQLDocument object from compiled code and the globals.  This<<NEWL>>        is used by the loaders and schema to create a document object.<<NEWL>>        """"""<<NEWL>>        if isinstance(code, string_types):<<NEWL>>            filename = ""<document>""<<NEWL>>            code = compile(code, filename, ""exec"")<<NEWL>>        namespace = {""__file__"": code.co_filename}<<NEWL>>        exec(code, namespace)<<NEWL>>        if extra_namespace:<<NEWL>>            namespace.update(extra_namespace)<<NEWL>>        rv = cls._from_namespace(schema, namespace)<<NEWL>>        # rv._uptodate = uptodate<<NEWL>>        return rv<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def from_module_dict(cls, schema, module_dict):<<NEWL>>        # type: (GraphQLSchema, Dict[str, Any]) -> GraphQLCompiledDocument<<NEWL>>        """"""Creates a template object from a module.  This is used by the<<NEWL>>        module loader to create a document object.<<NEWL>>        """"""<<NEWL>>        return cls._from_namespace(schema, module_dict)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def _from_namespace(cls, schema, namespace):<<NEWL>>        # type: (GraphQLSchema, Dict[str, Any]) -> GraphQLCompiledDocument<<NEWL>>        document_string = namespace.get(""document_string"", """")  # type: str<<NEWL>>        document_ast = namespace.get(""document_ast"")  # type: ignore<<NEWL>>        execute = namespace[""execute""]  # type: Callable<<NEWL>><<NEWL>>        namespace[""schema""] = schema<<NEWL>>        return cls(<<NEWL>>            schema=schema,<<NEWL>>            document_string=document_string,<<NEWL>>            document_ast=document_ast,  # type: ignore<<NEWL>>            execute=execute,<<NEWL>>        )"
226	adjudicated	2	"# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html<<NEWL>># For details: https://github.com/PyCQA/pylint/blob/main/LICENSE<<NEWL>><<NEWL>>import contextlib<<NEWL>>from typing import Dict, Optional, Type<<NEWL>><<NEWL>>from pylint.testutils.global_test_linter import linter<<NEWL>>from pylint.testutils.unittest_linter import UnittestLinter<<NEWL>>from pylint.utils import ASTWalker<<NEWL>><<NEWL>><<NEWL>>class CheckerTestCase:<<NEWL>>    """"""A base testcase class for unit testing individual checker classes.""""""<<NEWL>><<NEWL>>    CHECKER_CLASS: Optional[Type] = None<<NEWL>>    CONFIG: Dict = {}<<NEWL>><<NEWL>>    def setup_method(self):<<NEWL>>        self.linter = UnittestLinter()<<NEWL>>        self.checker = self.CHECKER_CLASS(self.linter)  # pylint: disable=not-callable<<NEWL>>        for key, value in self.CONFIG.items():<<NEWL>>            setattr(self.checker.config, key, value)<<NEWL>>        self.checker.open()<<NEWL>><<NEWL>>    @contextlib.contextmanager<<NEWL>>    def assertNoMessages(self):<<NEWL>>        """"""Assert that no messages are added by the given method.""""""<<NEWL>>        with self.assertAddsMessages():<<NEWL>>            yield<<NEWL>><<NEWL>>    @contextlib.contextmanager<<NEWL>>    def assertAddsMessages(self, *messages):<<NEWL>>        """"""Assert that exactly the given method adds the given messages.<<NEWL>><<NEWL>>        The list of messages must exactly match *all* the messages added by the<<NEWL>>        method. Additionally, we check to see whether the args in each message can<<NEWL>>        actually be substituted into the message string.<<NEWL>>        """"""<<NEWL>>        yield<<NEWL>>        got = self.linter.release_messages()<<NEWL>>        no_msg = ""No message.""<<NEWL>>        expected = ""\n"".join(repr(m) for m in messages) or no_msg<<NEWL>>        got_str = ""\n"".join(repr(m) for m in got) or no_msg<<NEWL>>        msg = (<<NEWL>>            ""Expected messages did not match actual.\n""<<NEWL>>            f""\nExpected:\n{expected}\n\nGot:\n{got_str}\n""<<NEWL>>        )<<NEWL>>        assert got == list(messages), msg<<NEWL>><<NEWL>>    def walk(self, node):<<NEWL>>        """"""recursive walk on the given node""""""<<NEWL>>        walker = ASTWalker(linter)<<NEWL>>        walker.add_checker(self.checker)<<NEWL>>        walker.walk(node)"
428	adjudicated	1	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>import structlog<<NEWL>>from enum import Enum<<NEWL>>from google.protobuf.json_format import MessageToDict<<NEWL>>from google.protobuf.message import Message<<NEWL>>from simplejson import dumps<<NEWL>><<NEWL>>from common.event_bus import EventBusClient<<NEWL>>from voltha.core.config.config_proxy import CallbackType<<NEWL>>from voltha.protos import third_party<<NEWL>>from voltha.protos.events_pb2 import ConfigEvent, ConfigEventType<<NEWL>><<NEWL>>IGNORED_CALLBACKS = [CallbackType.PRE_ADD, CallbackType.GET,<<NEWL>>                     CallbackType.POST_LISTCHANGE, CallbackType.PRE_REMOVE,<<NEWL>>                     CallbackType.PRE_UPDATE]<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>>class ConfigEventBus(object):<<NEWL>><<NEWL>>    __slots__ = (<<NEWL>>        '_event_bus_client',  # The event bus client used to publish events.<<NEWL>>        '_topic'  # the topic to publish to<<NEWL>>    )<<NEWL>><<NEWL>>    def __init__(self):<<NEWL>>        self._event_bus_client = EventBusClient()<<NEWL>>        self._topic = 'model-change-events'<<NEWL>><<NEWL>>    def advertise(self, type, data, hash=None):<<NEWL>>        if type in IGNORED_CALLBACKS:<<NEWL>>            log.info('Ignoring event {} with data {}'.format(type, data))<<NEWL>>            return<<NEWL>><<NEWL>>        if type is CallbackType.POST_ADD:<<NEWL>>            kind = ConfigEventType.add<<NEWL>>        elif type is CallbackType.POST_REMOVE:<<NEWL>>            kind = ConfigEventType.remove<<NEWL>>        else:<<NEWL>>            kind = ConfigEventType.update<<NEWL>><<NEWL>>        if isinstance(data, Message):<<NEWL>>            msg = dumps(MessageToDict(data, True, True))<<NEWL>>        else:<<NEWL>>            msg = data<<NEWL>><<NEWL>>        event = ConfigEvent(<<NEWL>>            type=kind,<<NEWL>>            hash=hash,<<NEWL>>            data=msg<<NEWL>>        )<<NEWL>><<NEWL>>        self._event_bus_client.publish(self._topic, event)<<NEWL>>"
479	adjudicated	3	"# A demo for the IDsObjectPicker interface.<<NEWL>>import win32clipboard<<NEWL>>import pythoncom<<NEWL>>from win32com.adsi import adsi<<NEWL>>from win32com.adsi.adsicon import *<<NEWL>><<NEWL>>cf_objectpicker = win32clipboard.RegisterClipboardFormat(CFSTR_DSOP_DS_SELECTION_LIST)<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    hwnd = 0<<NEWL>><<NEWL>>    # Create an instance of the object picker.<<NEWL>>    picker = pythoncom.CoCreateInstance(<<NEWL>>        adsi.CLSID_DsObjectPicker,<<NEWL>>        None,<<NEWL>>        pythoncom.CLSCTX_INPROC_SERVER,<<NEWL>>        adsi.IID_IDsObjectPicker,<<NEWL>>    )<<NEWL>><<NEWL>>    # Create our scope init info.<<NEWL>>    siis = adsi.DSOP_SCOPE_INIT_INFOs(1)<<NEWL>>    sii = siis[0]<<NEWL>><<NEWL>>    # Combine multiple scope types in a single array entry.<<NEWL>><<NEWL>>    sii.type = (<<NEWL>>        DSOP_SCOPE_TYPE_UPLEVEL_JOINED_DOMAIN | DSOP_SCOPE_TYPE_DOWNLEVEL_JOINED_DOMAIN<<NEWL>>    )<<NEWL>><<NEWL>>    # Set uplevel and downlevel filters to include only computer objects.<<NEWL>>    # Uplevel filters apply to both mixed and native modes.<<NEWL>>    # Notice that the uplevel and downlevel flags are different.<<NEWL>><<NEWL>>    sii.filterFlags.uplevel.bothModes = DSOP_FILTER_COMPUTERS<<NEWL>>    sii.filterFlags.downlevel = DSOP_DOWNLEVEL_FILTER_COMPUTERS<<NEWL>><<NEWL>>    # Initialize the interface.<<NEWL>>    picker.Initialize(<<NEWL>>        None,  # Target is the local computer.<<NEWL>>        siis,  # scope infos<<NEWL>>        DSOP_FLAG_MULTISELECT,  # options<<NEWL>>        (""objectGUID"", ""displayName""),<<NEWL>>    )  # attributes to fetch<<NEWL>><<NEWL>>    do = picker.InvokeDialog(hwnd)<<NEWL>>    # Extract the data from the IDataObject.<<NEWL>>    format_etc = (<<NEWL>>        cf_objectpicker,<<NEWL>>        None,<<NEWL>>        pythoncom.DVASPECT_CONTENT,<<NEWL>>        -1,<<NEWL>>        pythoncom.TYMED_HGLOBAL,<<NEWL>>    )<<NEWL>>    medium = do.GetData(format_etc)<<NEWL>>    data = adsi.StringAsDS_SELECTION_LIST(medium.data)<<NEWL>>    for item in data:<<NEWL>>        name, klass, adspath, upn, attrs, flags = item<<NEWL>>        print(""Item"", name)<<NEWL>>        print("" Class:"", klass)<<NEWL>>        print("" AdsPath:"", adspath)<<NEWL>>        print("" UPN:"", upn)<<NEWL>>        print("" Attrs:"", attrs)<<NEWL>>        print("" Flags:"", flags)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    main()"
469	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""choroplethmapbox"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
438	adjudicated	0	import time<<NEWL>><<NEWL>>from jet_bridge_base.settings import set_settings<<NEWL>><<NEWL>><<NEWL>>class Configuration(object):<<NEWL>><<NEWL>>    def __init__(self):<<NEWL>>        self.init_time = time.time()<<NEWL>><<NEWL>>    def get_type(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_version(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_model_description(self, db_table):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_hidden_model_description(self):<<NEWL>>        return []<<NEWL>><<NEWL>>    def get_settings(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_create(self, model, pk):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_create(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_update(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_update(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_delete(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_delete(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_get_available_name(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_exists(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_listdir(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_get_modified_time(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_open(self, path, mode='rb'):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_save(self, path, content):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_delete(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_url(self, path, request):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_set(self, request, name, value, secure=True):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_get(self, request, name, default=None, decode=True, secure=True):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_clear(self, request, name):<<NEWL>>        pass<<NEWL>><<NEWL>>    def clean_sso_application_name(self, name):<<NEWL>>        return name.lower().replace('-', '')<<NEWL>><<NEWL>>    def clean_sso_applications(self, applications):<<NEWL>>        return dict(map(lambda x: (self.clean_sso_application_name(x[0]), x[1]), applications.items()))<<NEWL>><<NEWL>><<NEWL>>configuration = Configuration()<<NEWL>><<NEWL>><<NEWL>>def set_configuration(new_configuration):<<NEWL>>    global configuration<<NEWL>>    configuration = new_configuration<<NEWL>>    set_settings(configuration.get_settings())
236	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scattersmith.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
376	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scattersmith.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
267	adjudicated	2	"""""""Basic implementation to support SOAP-Attachments<<NEWL>><<NEWL>>See https://www.w3.org/TR/SOAP-attachments<<NEWL>><<NEWL>>""""""<<NEWL>><<NEWL>>import base64<<NEWL>><<NEWL>>from cached_property import cached_property<<NEWL>>from requests.structures import CaseInsensitiveDict<<NEWL>><<NEWL>><<NEWL>>class MessagePack:<<NEWL>>    def __init__(self, parts):<<NEWL>>        self._parts = parts<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<MessagePack(attachments=[%s])>"" % (<<NEWL>>            "", "".join(repr(a) for a in self.attachments)<<NEWL>>        )<<NEWL>><<NEWL>>    @property<<NEWL>>    def root(self):<<NEWL>>        return self._root<<NEWL>><<NEWL>>    def _set_root(self, root):<<NEWL>>        self._root = root<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def attachments(self):<<NEWL>>        """"""Return a list of attachments.<<NEWL>><<NEWL>>        :rtype: list of Attachment<<NEWL>><<NEWL>>        """"""<<NEWL>>        return [Attachment(part) for part in self._parts]<<NEWL>><<NEWL>>    def get_by_content_id(self, content_id):<<NEWL>>        """"""get_by_content_id<<NEWL>><<NEWL>>        :param content_id: The content-id to return<<NEWL>>        :type content_id: str<<NEWL>>        :rtype: Attachment<<NEWL>><<NEWL>>        """"""<<NEWL>>        for attachment in self.attachments:<<NEWL>>            if attachment.content_id == content_id:<<NEWL>>                return attachment<<NEWL>><<NEWL>><<NEWL>>class Attachment:<<NEWL>>    def __init__(self, part):<<NEWL>>        encoding = part.encoding or ""utf-8""<<NEWL>>        self.headers = CaseInsensitiveDict(<<NEWL>>            {k.decode(encoding): v.decode(encoding) for k, v in part.headers.items()}<<NEWL>>        )<<NEWL>>        self.content_type = self.headers.get(""Content-Type"", None)<<NEWL>>        self.content_id = self.headers.get(""Content-ID"", None)<<NEWL>>        self.content_location = self.headers.get(""Content-Location"", None)<<NEWL>>        self._part = part<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<Attachment(%r, %r)>"" % (self.content_id, self.content_type)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def content(self):<<NEWL>>        """"""Return the content of the attachment<<NEWL>><<NEWL>>        :rtype: bytes or str<<NEWL>><<NEWL>>        """"""<<NEWL>>        encoding = self.headers.get(""Content-Transfer-Encoding"", None)<<NEWL>>        content = self._part.content<<NEWL>><<NEWL>>        if encoding == ""base64"":<<NEWL>>            return base64.b64decode(content)<<NEWL>>        elif encoding == ""binary"":<<NEWL>>            return content.strip(b""\r\n"")<<NEWL>>        else:<<NEWL>>            return content"
327	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self) -> None:<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self) -> str:<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self) -> str:<<NEWL>>        return ""Korean"""
